[{
    "topic_id": 0,
    "top_words": ["intelligence", "artificial", "logic", "reasoning", "language", "programming", "applications", "problems", "theory", "many", "systems", "natural", "computer", "science", "knowledge"],
    "phrases": [{
        "ID": 34,
        "phrase": " it is also of substantial interest to the ai community due to its applications in several areas including knowledge representation, diagnosis and planning",
        "prob": 0.3812500000000001
    }, {
        "ID": 60,
        "phrase": " influence sneps and its immediate predecessors (see  (shapiro & rapaport 1992) ) have been influential in the fields of artificial intelligence, knowlege bases, and deductive databases",
        "prob": 0.6368421052631579
    }, {
        "ID": 61,
        "phrase": " influence sneps and its immediate predecessors (see  (shapiro & rapaport 1992) ) have been influential in the fields of artificial intelligence, knowlege bases, and deductive databases",
        "prob": 0.6894736842105263
    }, {
        "ID": 72,
        "phrase": "introduction since the early days of computer science, when john mccarty started to investigate the role of logic for computing and artificial intelligence, the key attraction of logic was the promise of a natural representation of knowledge",
        "prob": 0.4653846153846154
    }, {
        "ID": 73,
        "phrase": "introduction the aclp framework and system is an attempt to address the problem of providing a high-level declarative programming (or modeling) enviroment for problems of artificial intelligence which at the same time has an acceptable computational performance",
        "prob": 0.36400000000000005
    }, {
        "ID": 73,
        "phrase": " it forms a general highlevel knowledge representation environment for abductive problems in artificial intelligence and other areas",
        "prob": 0.6066666666666667
    }, {
        "ID": 74,
        "phrase": "introduction the aclp framework and system is an attempt to address the problem of providing a high-level declarative programming (or modeling) enviroment for problems of artificial intelligence which at the same time has an acceptable computational performance",
        "prob": 0.32400000000000007
    }, {
        "ID": 74,
        "phrase": " it forms a general highlevel knowledge representation environment for abductive problems in artificial intelligence and other areas",
        "prob": 0.4733333333333334
    }, {
        "ID": 83,
        "phrase": " \n example of applications there has been an explosion of recent work in artificial intelligence that recognizes the importance of abductive reasoning",
        "prob": 0.3400000000000001
    }, {
        "ID": 83,
        "phrase": " in artificial intelligence, the most commonly used approach for modeling knowledge associated to such problems is to store a collection of \"if ",
        "prob": 0.14
    }, {
        "ID": 88,
        "phrase": " the system performs the kind of reasoning which forms the basis of a number of applications in computer science and artificial intelligence, such as simulation, fault diagnosis, planning and cognitive robotics",
        "prob": 0.45909090909090905
    }, {
        "ID": 89,
        "phrase": " the system performs the kind of reasoning which forms the basis of a number of applications in computer science and artificial intelligence, such as simulation, fault diagnosis, planning and cognitive robotics",
        "prob": 0.5045454545454546
    }, {
        "ID": 91,
        "phrase": " \n application frontends in addition to its kernel language, dlv provides a number of application frontends that show the suitability of our formalism for solving various problems from the areas of artificial intelligence, knowledge representation and (deductive) databases",
        "prob": 0.5962962962962962
    }, {
        "ID": 93,
        "phrase": "introduction one of the most important areas in artificial intelligence is knowledge representation",
        "prob": 0.5545454545454546
    }, {
        "ID": 99,
        "phrase": " \n counting models of d-dnnf we now turn to an operation on d-dnnf which is of major significance to a number of ai applications, including belief revision, truth maintenance and diagnosis",
        "prob": 0.605
    }, {
        "ID": 106,
        "phrase": " definition 3  (hansson 1997)  the kernel semirevision of b based on an incision function \u03c3 is the operator ? \u03c3 such that for all sentences \u03b1: b? \u03c3 \u03b1 = (b \u222a {\u03b1}) \\ \u03c3((b \u222a {\u03b1}) \u22a5 \u22a5 \u22a5) \n consistency-based diagnosis diagnosis is a very active area within the artificial intelligence community",
        "prob": 0.39565217391304347
    }, {
        "ID": 113,
        "phrase": "introduction logic's fundamental role in the area of computing and artificial intelligence, is its use for knowledge representation",
        "prob": 0.6733333333333333
    }, {
        "ID": 141,
        "phrase": " all ai problems where the systems' output does not influence the environment, i",
        "prob": 0.34444444444444444
    }, {
        "ID": 141,
        "phrase": "y k x k ) = \u00b5 ai (y 1 c 1 ",
        "prob": 0.025
    }, {
        "ID": 141,
        "phrase": " \u00b5 ai (y 1 x 1 ",
        "prob": 0.025
    }, {
        "ID": 141,
        "phrase": " \n other ai classes other aspects of intelligence: in ai, a variety of general ideas and methods have been developed",
        "prob": 0.3416666666666667
    }, {
        "ID": 141,
        "phrase": " but not all ai problems are of this 'easy' type",
        "prob": 0.15714285714285717
    }, {
        "ID": 141,
        "phrase": " +c t )\u2022\u00b5 ai ( \u1e8f1 \u1e8b1 ",
        "prob": 0.025
    }, {
        "ID": 169,
        "phrase": " csp has not only important theoretical value in artificial intelligence, but also many immediate applications in areas ranging from vision, language comprehension to scheduling and diagnosis  [6]  ",
        "prob": 0.705
    }, {
        "ID": 205,
        "phrase": " the general concept of knowledge has received considerable attention in a variety of fields, ranging from philosophy  [hin62]  and artificial intelligence  [mshi79]  and  [moo85] , to game theory  [aum76]  and psychology  [cm81] ",
        "prob": 0.5260869565217391
    }, {
        "ID": 230,
        "phrase": "002 ai 0",
        "prob": 0.025
    }, {
        "ID": 284,
        "phrase": " this treatment of knowledge agrees with the traditional one (  [hin62] ,  [hm84] ,  [pr85] ,  [cm86] ) expressed in a variety of contexts (artificial intelligence, distributed processes, economics, etc)",
        "prob": 0.605
    }, {
        "ID": 290,
        "phrase": " this treatment of knowledge agrees with the traditional one (  [hin62] ,  [hm84] ,  [pr85] ,  [cm86] ,  [fhv91] ) expressed in a variety of contexts (artificial intelligence, distributed processes, economics, etc",
        "prob": 0.6714285714285714
    }, {
        "ID": 292,
        "phrase": " therefore, most approaches to central problems of artificial intelligence, such as belief revision, database updating, abduction and action planning, seem to rely on one way or another to some form of nonmonotonic reasoning",
        "prob": 0.37916666666666665
    }, {
        "ID": 306,
        "phrase": " csp is a fundamental problem in artificial intelligence, with numerous applications ranging from vision, language comprehension to scheduling and diagnosis  [7]  ",
        "prob": 0.5352941176470588
    }, {
        "ID": 311,
        "phrase": " this approach, while common in the machine learning literature, has only recently been introduced in natural language processing research (e",
        "prob": 0.4066666666666667
    }, {
        "ID": 349,
        "phrase": "introduction the ambiguity of natural language poses problems for any formal theory within linguistics, philosophy, cognitive psychology or artificial intelligence",
        "prob": 0.7947368421052632
    }, {
        "ID": 356,
        "phrase": "introduction natural language processing (nlp), has a long tradition in artificial intelligence, but it still remains to be one of the hardest problems in the area",
        "prob": 0.3944444444444445
    }, {
        "ID": 357,
        "phrase": "introduction the notion of context plays an important role in formal theories of natural language processing (nlp), one of the major subareas of artificial intelligence",
        "prob": 0.655
    }, {
        "ID": 374,
        "phrase": " what was \"it\"? artificial intelligence technology, as a product",
        "prob": 0.5125000000000001
    }, {
        "ID": 374,
        "phrase": " it should be kept in mind that although the record of success of ai products has been spotty, ai technologies have seen remarkable success behind the scenes",
        "prob": 0.3588235294117647
    }, {
        "ID": 403,
        "phrase": " needless to say, the problem of finding suitable inference mechanisms, capable to model human common-sense reasoning, is one of the major research and implementation problems in artificial intelligence",
        "prob": 0.39565217391304347
    }, {
        "ID": 404,
        "phrase": " needless to say, the problem of finding suitable inference mechanisms, capable to model human common-sense reasoning, is one of the major research and implementation problems in artificial intelligence",
        "prob": 0.39565217391304347
    }, {
        "ID": 561,
        "phrase": " the typical distance measures considered in psychology, artificial intelligence or mathematics are not universal",
        "prob": 0.23846153846153847
    }, {
        "ID": 624,
        "phrase": "introduction the problem of belief change-how an agent should revise her beliefs upon learning new information-has been an active area of research in both philosophy and artificial intelligence",
        "prob": 0.5695652173913043
    }, {
        "ID": 656,
        "phrase": " moreover, a treatment of dialogues with multiple utterances can be obtained by appealing to ai formalisms of knowledge and ability  [davis, 1994 , stone, 1998a , and introducing a nested implication for each step of action",
        "prob": 0.14761904761904762
    }, {
        "ID": 660,
        "phrase": "introduction machine learning has been very successful at solving many problems in the field of natural language processing",
        "prob": 0.4733333333333334
    }, {
        "ID": 682,
        "phrase": ", if the premise, then the action) is a major knowledge representation paradigm in artificial intelligence",
        "prob": 0.425
    }, {
        "ID": 704,
        "phrase": " the development of appropriate tools is challenging: knowledge elicitation and representation require the integration of many paradigms from diverse areas of artificial intelligence and confront a number of fundamental representational problems",
        "prob": 0.5458333333333333
    }, {
        "ID": 704,
        "phrase": " these have temporal and action aspects that are at the core of much current research in artificial intelligence, computer science and philosophical logic",
        "prob": 0.4764705882352941
    }, {
        "ID": 713,
        "phrase": " this book gave insight and guidelines for both a theory and practice of intelligent data banks and other advanced information systems which borrow the ai ideas",
        "prob": 0.2277777777777778
    }, {
        "ID": 714,
        "phrase": "introduction reflecting the growth in utilization of the world wide web, a number of web-based language processing methods have been proposed within the natural language processing (nlp), information retrieval (ir) and artificial intelligence (ai) communities",
        "prob": 0.4517241379310345
    }, {
        "ID": 725,
        "phrase": " for many of these problems it is possible to employ, together with database techniques, other techniques from artificial intelligence (ai) and soon it was realized that the field of information integration lies at the intersection of databases with artificial intelligence and other areas such as information retrieval and human computer interaction",
        "prob": 0.57
    }, {
        "ID": 725,
        "phrase": " we are thus led to the need for semantic (or intelligent) information integration where, along with techniques from databases, artificial intelligence and computational logic can play a significant role in providing explicit and declarative representation frameworks for modeling the information and the complex behaviour of the system",
        "prob": 0.3580645161290323
    }, {
        "ID": 725,
        "phrase": " in the emerging future systems where an advanced form of sythesis of information would be facilitated through an application layer, above the mediator layer, logic and artificial intelligence will have an ever increasing role to play",
        "prob": 0.37916666666666665
    }, {
        "ID": 725,
        "phrase": " this wider role of ai in current and emerging information integration systems has been recently presented in the survey paper  [123] ",
        "prob": 0.4066666666666666
    }, {
        "ID": 725,
        "phrase": " for query planning, take input from ai and logic (and deductive databases) but there are no general methods of how logical techniques can be exploited in these important aspects of the general problem of information integration",
        "prob": 0.4809523809523809
    }, {
        "ID": 725,
        "phrase": " it stands at the crossroad of databases and artificial intelligence requiring novel techniques that bring together different methods from these fields",
        "prob": 0.3588235294117647
    }, {
        "ID": 780,
        "phrase": " more recently, this paradigm led to constraint logic programming that realizes a general approach to computing in which the programming process is limited to a generation of constraints (requirements) and a solution of them, and to inductive logic programming, a logic based approach to machine learning",
        "prob": 0.38275862068965527
    }, {
        "ID": 780,
        "phrase": "\" this origin of the logic paradigm probably impeded its acceptance within computer science in times when imperative programming got impetus thanks to the creation of pascal and c, the fields of verification and semantics of imperative programs gained ground and when the artificial intelligence community already adopted lisp as the language of their choice",
        "prob": 0.4472222222222222
    }, {
        "ID": 780,
        "phrase": " this dual interpretation of declarative programs also accounts for the double use of logic programming -as a formalism for programming and for knowledge representation, and explains the importance of logic programming in the field of artificial intelligence",
        "prob": 0.7239999999999999
    }, {
        "ID": 780,
        "phrase": " search is of paramount importance in many artificial intelligence applications and backtracking itself is most natural when dealing with np-complete problems",
        "prob": 0.5352941176470588
    }, {
        "ID": 780,
        "phrase": " all this explains why prolog is a natural language for programming artificial intelligence applications, such as automated theorem provers, expert systems and machine learning programs where reasoning needs to be combined with computing, game playing programs, and various decision support systems",
        "prob": 0.6806451612903225
    }, {
        "ID": 781,
        "phrase": " more recently, this paradigm led to constraint logic programming that realizes a general approach to computing in which the programming process is limited to a generation of constraints (requirements) and a solution of them, and to inductive logic programming, a logic based approach to machine learning",
        "prob": 0.31379310344827593
    }, {
        "ID": 781,
        "phrase": "\" this origin of the logic paradigm probably impeded its acceptance within computer science in times when imperative programming got impetus thanks to the creation of pascal and c, the fields of verification and semantics of imperative programs gained ground and when the artificial intelligence community already adopted lisp as the language of their choice",
        "prob": 0.4749999999999999
    }, {
        "ID": 781,
        "phrase": " this dual interpretation of declarative programs also accounts for the double use of logic programming -as a formalism for programming and for knowledge representation, and explains the importance of logic programming in the field of artificial intelligence",
        "prob": 0.7639999999999998
    }, {
        "ID": 781,
        "phrase": " search is of paramount importance in many artificial intelligence applications and backtracking itself is most natural when dealing with np-complete problems",
        "prob": 0.5941176470588235
    }, {
        "ID": 781,
        "phrase": " all this explains why prolog is a natural language for programming artificial intelligence applications, such as automated theorem provers, expert systems and machine learning programs where reasoning needs to be combined with computing, game playing programs, and various decision support systems",
        "prob": 0.5838709677419354
    }, {
        "ID": 785,
        "phrase": " inductive logic programming (ilp) aleph is an ilp machine learning system that searches for a hypothesis, given positive (and, if available, negative) data in the form of ground prolog terms and background knowledge (prior knowledge made available to the learning algorithm) in the form of prolog predicates",
        "prob": 0.20285714285714285
    }, {
        "ID": 799,
        "phrase": " more generally, all constraint satisfaction problems including basic ai problems such as planning, scheduling and product configuration can be cast as search problems",
        "prob": 0.6722222222222222
    }, {
        "ID": 817,
        "phrase": " the representation and reasoning components are based on logic programming and automated theorem proving methods, together with machine learning techniques",
        "prob": 0.2833333333333333
    }, {
        "ID": 894,
        "phrase": ", expert systems and artificial intelligence, 229",
        "prob": 0.26249999999999996
    }, {
        "ID": 912,
        "phrase": " other applications lie in the areas of machine learning and inductive theorem proving",
        "prob": 0.17500000000000002
    }, {
        "ID": 997,
        "phrase": "introduction mixed-initiative interaction  [hm97]  has been studied for the past 30 years in the areas of artificial intelligence planning [vcp + 95], human-computer interaction  [bwfh92] , and discourse analysis  [cou77] ",
        "prob": 0.5041666666666667
    }, {
        "ID": 1016,
        "phrase": " furthermore, meta-programming finds a wide variety of applications in such areas as artificial intelligence, compilation, constraints solving, debugging, and program analysis  (codish and taboch 1999; hill and gallagher 1998; lamma et al",
        "prob": 0.6839999999999998
    }, {
        "ID": 1017,
        "phrase": " furthermore, meta-programming finds a wide variety of applications in such areas as artificial intelligence, compilation, constraints solving, debugging, and program analysis  (codish and taboch 1999; hill and gallagher 1998; lamma et al",
        "prob": 0.6439999999999999
    }, {
        "ID": 1208,
        "phrase": " though the original epistemic logic in philosophy is mainly about the single-agent case, the application to ai and computer science put its emphasis on the interaction of agents, so multi-agent epistemic logic is urgently needed",
        "prob": 0.3884615384615385
    }, {
        "ID": 1209,
        "phrase": " this, indeed, is the approach of heuristics for playing games which were developed by ai theorists",
        "prob": 0.1
    }, {
        "ID": 1254,
        "phrase": " recently, conclusive evidence has been put forward  [leh95] ,  [fh96]  to the effect that this identification of epistemic states to belief sets is not welcome in many ai applications",
        "prob": 0.255
    }, {
        "ID": 1260,
        "phrase": " but, although this is probably agreeable to the artificial intelligence community, this seems to go against the main trend in logics, where classical logic is only one of many possible logics",
        "prob": 0.20500000000000002
    }, {
        "ID": 1265,
        "phrase": " such a boolean function can be interpreted as a constraint that has to be fulfilled by a given assignment; the satisfiability problem for c-formulas hence provides a mathematical model for the examination of the complexity of constraint satisfaction problems, studied in artificial intelligence and database theory",
        "prob": 0.3964285714285714
    }, {
        "ID": 1265,
        "phrase": " as mentioned above, constraint satisfaction problems are used as a programming or query language in fields such as artificial intelligence and database theory, and the above complexity results shed light on the difficulty of design of systems in that areas",
        "prob": 0.564
    }, {
        "ID": 1273,
        "phrase": "introduction common sense reasoning in ai requires drawing inferences in a bolder, more adventurous way, than mathematical reasoning",
        "prob": 0.31875000000000003
    }, {
        "ID": 1283,
        "phrase": " x \u227a ai r y\u2227 \u2200a j \u2208 a, r \u2032 > r \u2208 r",
        "prob": 0.025
    }, {
        "ID": 1291,
        "phrase": " simulating and modeling a musician's activities are tasks that are appropriate for experimentation within the framework of artificial intelligence",
        "prob": 0.2733333333333333
    }, {
        "ID": 1342,
        "phrase": "5 we have that s \u03c1 n i=1 ai (\u03c8 \u2297 \u03b8) = \u03c1( n i=1 s \u03c1 ai (\u03c8 \u2297 \u03b8)) = \u03c1( n i=1 \u03c8 \u2297 s \u03c1 ai (\u03b8)) = \u03c1(\u03c8 \u2297 n i=1 s \u03c1 ai (\u03b8)) = \u03c1(\u03c8 \u2297 \u03c1( n i=1 s \u03c1 ai (\u03b8))) = \u03c1(\u03c8 \u2297 s \u03c1 n i=1 ai (\u03b8))",
        "prob": 0.025
    }, {
        "ID": 1365,
        "phrase": "1 introduction * this work was partially supported by the jean and helene alfassa fund for research in artificial intelligence \n belief revision belief revision is the study of the way an agent revises or should revise its beliefs when acquiring new information",
        "prob": 0.43214285714285716
    }, {
        "ID": 1387,
        "phrase": " the idea of using memory-based methods for processing natural language has recently led to the emergence of a new paradigm: memory-based language processing (mblp) to which a special issue of the journal of experimental & theoretical artificial intelligence was devoted  (daelemans, 1999) ",
        "prob": 0.22903225806451613
    }, {
        "ID": 1387,
        "phrase": " forward and backward sequential selection are a variant of hill-climbing, a well-known search technique in artificial intelligence",
        "prob": 0.24117647058823527
    }, {
        "ID": 1398,
        "phrase": " -central problem is the \"ai\" problem of developing \"true\" artificial intelligence",
        "prob": 0.19090909090909092
    }, {
        "ID": 1398,
        "phrase": " nonetheless, it is my opinion that purely analog systems such as neural nets will not provide a complete solution of the ai problem; but rather, that discrete processing, including proof theoretic aspects, will be needed for constructing ai systems",
        "prob": 0.16399999999999998
    }, {
        "ID": 1398,
        "phrase": " \n logic for computer science artificial intelligence",
        "prob": 0.5666666666666668
    }, {
        "ID": 1398,
        "phrase": " as discussed earlier, i predict that success in artificial intelligence will require logic-based reasoning",
        "prob": 0.2928571428571428
    }, {
        "ID": 1398,
        "phrase": " by \"limited, but significant success\", i envision that artificial intelligence may be successful in some relatively broad domain of knowledge which is generally acknowledged as involving operational understanding of semantic concepts",
        "prob": 0.26521739130434785
    }, {
        "ID": 1398,
        "phrase": " one good possibility for a first knowledge domain for the initial artificial intelligence systems is the area of mathematical reasoning",
        "prob": 0.25625
    }, {
        "ID": 1398,
        "phrase": " quite possibly, the next major step forward in the foundations of mathematics will occur in conjunction with the development of systems fulfilling prediction 3 or perhaps even with ai systems for mathematical reasoning",
        "prob": 0.2652173913043478
    }, {
        "ID": 1398,
        "phrase": " real computation real closed fields weak proof systems resolution logic programming constraint logic programming theorem provers equational logics term rewriting geometry complexity of real computation hybrid systems computer algebra systems other logics database languages least fixed points modal logics dynamic logics theories of knowledge resource-aware logics linear logic behavioral logics nonmonotonic logics ai model checking complexity theory reducibility oracles strong proof systems polymorphism object-oriented languages abstract datatypes \u03bb-calculi combinatory logics functional programming category theory realizability feasible complexity p vs",
        "prob": 0.46375
    }, {
        "ID": 1511,
        "phrase": " in fact, clir has of late become one of the major topics within the information retrieval (ir), natural language processing (nlp) and artificial intelligence (ai) communities, and numerous clir systems have variously been proposed  (aaai, 1997; acm, 1996 acm, -1998 nist, 1992 nist, -1998 ",
        "prob": 0.5516129032258064
    }, {
        "ID": 1511,
        "phrase": " for this purpose, a number of clir systems have been developed in information retrieval, natural language processing and artificial intelligence research",
        "prob": 0.4764705882352941
    }, {
        "ID": 1556,
        "phrase": "introduction for three decades history of application of information theory methods to the design of integrated circuits, many promising results have been obtained in the following fields: \u2022 machine learning  [7] ; \u2022 entropy based minimization  [5] ; \u2022 testing of digital circuits  [1] ; \u2022 estimation of power dissipation  [4] ; \u2022 other related design problems (influence of types of logical gates on entropy  [2] , estimation of logical work in networks and programs  [3] )",
        "prob": 0.29111111111111115
    }, {
        "ID": 1564,
        "phrase": " there are several approaches in practical reasoning (within philosophy), cognitive science and artificial intelligence to bring the micro and macro description together",
        "prob": 0.531578947368421
    }, {
        "ID": 1593,
        "phrase": " there are numerous interesting ai applications of answer set programming, for instance in planning  [16]  and configuration  [23] ",
        "prob": 0.3153846153846154
    }, {
        "ID": 1609,
        "phrase": " without disregard to the many commercial products written in prolog, the language, arguably, thrives in academic environments, and in particular in ai and proof-of-concept computer science research",
        "prob": 0.4826086956521739
    }, {
        "ID": 1610,
        "phrase": " without disregard to the many commercial products written in prolog, the language, arguably, thrives in academic environments, and in particular in ai and proof-of-concept computer science research",
        "prob": 0.5695652173913043
    }, {
        "ID": 1613,
        "phrase": " in particular, problems of artificial intelligence are discussed in the context of human-computer interaction",
        "prob": 0.39230769230769236
    }, {
        "ID": 1613,
        "phrase": " informal notion is used in everyday life, in reasoning of experts, as well as in methodology and philosophy of computer science, mathematics, and artificial intelligence",
        "prob": 0.21578947368421056
    }, {
        "ID": 1648,
        "phrase": " our elaboration of paraconsistent reasoning is part of an encompassing research program, analysing a large spectrum of reasoning mechanisms in artificial intelligence, among them nonmonotonic reasoning  [8] , (nonmonotonic) modal logics  [10] , logic programming  [7, 17] , abductive reasoning  [9] , and belief revision  [6] ",
        "prob": 0.6699999999999999
    }, {
        "ID": 1652,
        "phrase": " a paraconsistent logic is a logic where an inconsistency does not lead to such an explosion, and since in practice consistency is difficult to achieve for substantial theories, paraconsistent logics have many applications in computer science, artificial intelligence, formal linguistics, etc",
        "prob": 0.7892857142857141
    }, {
        "ID": 1653,
        "phrase": " a paraconsistent logic is a logic where an inconsistency does not lead to such an explosion, and since in practice consistency is difficult to achieve for substantial theories, paraconsistent logics have many applications in computer science, artificial intelligence, formal linguistics, etc",
        "prob": 0.7892857142857141
    }, {
        "ID": 1653,
        "phrase": " we think that a robust treatment of propositional attitudes in natural language is critical for many ai applications",
        "prob": 0.4357142857142857
    }, {
        "ID": 1654,
        "phrase": " a paraconsistent logic is a logic where an inconsistency does not lead to such an explosion, and since in practice consistency is difficult to achieve for substantial theories, paraconsistent logics have many applications in computer science, artificial intelligence, formal linguistics, etc",
        "prob": 0.7535714285714284
    }, {
        "ID": 1659,
        "phrase": " \n preferences in logic and artificial intelligence the papers on preference logics  [29, 25, 18]  address the issue of capturing the commonsense meaning of preference through appropriate axiomatizations",
        "prob": 0.21578947368421056
    }, {
        "ID": 1762,
        "phrase": " belief revision is a well known problem in artificial intelligence  [1] ,  [9] ,  [13] , in this context, an epistemic state encodes a set of beliefs about the real world (based on the available information)",
        "prob": 0.36818181818181817
    }, {
        "ID": 1829,
        "phrase": " underlying all the above systems is h\u00f6hle's monoidal logic ml  [25]  which provides a common basis for both t-norm logics and logics based on heyting algebras",
        "prob": 0.4263157894736842
    }, {
        "ID": 1841,
        "phrase": " within the computer sciences, the artificial intelligence is one of the main areas to model biological systems",
        "prob": 0.3642857142857144
    }, {
        "ID": 1845,
        "phrase": " more generally, all constraint satisfaction problems over discrete domains, including such basic ai problems as planning, scheduling and product configuration, can be cast as search problems",
        "prob": 0.705
    }, {
        "ID": 1851,
        "phrase": " the term \"agent\" has been widely used in a great variety of research domains, being the most common those domains belonging to artificial intelligence and computer science areas",
        "prob": 0.505
    }, {
        "ID": 1853,
        "phrase": " annals of mathematics and artificial intelligence, 3(2-4) (1991) 429-",
        "prob": 0.5125000000000001
    }, {
        "ID": 1881,
        "phrase": " i discuss the various levels of language such as morphology, syntax and so on, and machine learning of those areas that are not covered elsewhere in the thesis",
        "prob": 0.25625000000000003
    }, {
        "ID": 1881,
        "phrase": " \n prerequisites the intended audience for this thesis are researchers in natural language processing who are interested in machine learning of natural language, or in the implications for cognitive science of some recent research",
        "prob": 0.4136363636363637
    }, {
        "ID": 1881,
        "phrase": "2, i briefly discuss the role of machine learning in natural language processing, and the different motivations for research in this field",
        "prob": 0.38125000000000003
    }, {
        "ID": 1890,
        "phrase": " these systems were constructed by hand, without machine learning, which ensures a certain level of quality, at the cost of a substantial amount of human labour",
        "prob": 0.1105263157894737
    }, {
        "ID": 1925,
        "phrase": " however, there has been only little work relating domain theory to logical aspects of knowledge representation and reasoning in artificial intelligence",
        "prob": 0.4764705882352941
    }, {
        "ID": 1925,
        "phrase": " as such, the paper is part of our investigations concerning the use of domain theory in artificial intelligence, where domains shall be used for knowledge representation, and domain logic for reasoning",
        "prob": 0.4809523809523809
    }, {
        "ID": 1926,
        "phrase": " however, there has been only little work relating domain theory to logical aspects of knowledge representation and reasoning in artificial intelligence",
        "prob": 0.5352941176470588
    }, {
        "ID": 1926,
        "phrase": " as such, the paper is part of our investigations concerning the use of domain theory in artificial intelligence, where domains shall be used for knowledge representation, and domain logic for reasoning",
        "prob": 0.24285714285714288
    }, {
        "ID": 1928,
        "phrase": " information systems and artificial intelligence: integration aspects (lncs 474), springer, pages 30-46, 1990",
        "prob": 0.7000000000000001
    }, {
        "ID": 1929,
        "phrase": " information systems and artificial intelligence: integration aspects (lncs 474), springer, pages 30-46, 1990",
        "prob": 0.7000000000000001
    }, {
        "ID": 1966,
        "phrase": " csp is a fundamental problem in artificial intelligence, with a distinguished history and many applications, such as in knowledge representation, scheduling and pattern recognition",
        "prob": 0.6166666666666667
    }, {
        "ID": 1967,
        "phrase": " the csp is a fundamental problem in artificial intelligence, with a distinguished history and many applications, such as in knowledge representation, scheduling and pattern recognition",
        "prob": 0.6722222222222222
    }, {
        "ID": 1968,
        "phrase": " the csp is a fundamental problem in artificial intelligence, with a distinguished history and many applications, such as in knowledge representation, scheduling and pattern recognition",
        "prob": 0.6722222222222222
    }, {
        "ID": 1984,
        "phrase": " \n integration of learning with other ai functions as already noted, a major goal of this research is the integration of learning with other ai functions such as pattern recognition, reasoning, planning and problem solving, and others",
        "prob": 0.32272727272727275
    }, {
        "ID": 1984,
        "phrase": " a particular attraction of this approach to learning is that the icmaus framework provides a unified view of a variety of issues in ai thus facilitating the integration of learning with other aspects of intelligence",
        "prob": 0.33809523809523806
    }, {
        "ID": 2025,
        "phrase": " so, what a-is cognition then? \n about cognition cognition has been studied from a variety of contexts, such as philosophy, artificial intelligence, psychology, dynamical systems theory  (beer, 2000) , etc",
        "prob": 0.705
    }, {
        "ID": 2044,
        "phrase": " the study of neural networks, traffic patterns, artificial intelligence, social systems, and many other scientific areas can all be considered to fall within the realm of complex systems, and can be studied from this new perspective",
        "prob": 0.404
    }, {
        "ID": 2100,
        "phrase": " the interaction of these ideas together with advances in machine learning (see [other chapter]) has resulted in concerted research activity in statistical natural language processing: making computers languageenabled by having them acquire linguistic information directly from samples of language itself",
        "prob": 0.2793103448275862
    }, {
        "ID": 2201,
        "phrase": "introduction answer set programming (asp), stable logic programming or a-prolog, is the realization of much theoretical work on non-monotonic reasoning and ai applications of logic programming (lp) in the last 15 years",
        "prob": 0.35
    }, {
        "ID": 2333,
        "phrase": " \n introduction artificial intelligence",
        "prob": 0.4428571428571429
    }, {
        "ID": 2333,
        "phrase": " many reasons why probability theory is unsuitable for ai have been stated: strict numerical values are not appropriate for a qualitative reasoning system, probability theory cannot deal with impreciseness, or vagueness, or subjective beliefs, or is just impractical",
        "prob": 0.204
    }, {
        "ID": 2333,
        "phrase": "y k x k ) = \u00b5 ai (y 1 r 1 ",
        "prob": 0.025
    }, {
        "ID": 2333,
        "phrase": " \u00b5 ai (y 1 x 1 ",
        "prob": 0.025
    }, {
        "ID": 2333,
        "phrase": " \n what has been achieved \n results the major theme of the thesis was to develop a mathematical foundation of artificial intelligence",
        "prob": 0.22142857142857145
    }, {
        "ID": 2333,
        "phrase": " +r m )\u2022\u00b5 ai ( \u1e8f1 \u1e8b1 ",
        "prob": 0.025
    }, {
        "ID": 2386,
        "phrase": " today, they are ubiquitous in computer science (database query processing, circuit design, network optimization, planning and scheduling, programming languages), artificial intelligence (belief maintenance and knowledge based systems, machine vision, natural language understanding), and computational linguistics (formal syntax and semantics of natural languages)",
        "prob": 0.6605263157894736
    }, {
        "ID": 2407,
        "phrase": ": \"the representation and manipulation of the algorithmic probability measure for problem solving\"; annals of math- ematics and artificial intelligence, 4 (1991) 281-300",
        "prob": 0.31875
    }, {
        "ID": 2421,
        "phrase": " although the icmaus framework is not as simple as the utm or pcs models, it seems that the added complexity is more than offset by an increase in descriptive or explanatory power, particularly in areas of interest within cognitive science and artificial intelligence",
        "prob": 0.26296296296296295
    }, {
        "ID": 2438,
        "phrase": "introduction modal temporal logics are well-known in computer science in general, and in artificial intelligence (ai) in particular",
        "prob": 0.5062500000000001
    }, {
        "ID": 2455,
        "phrase": " similarly, ai applications and expert systems typically use only unary predicates (  [che83] ) such as symptoms and diseases",
        "prob": 0.5071428571428572
    }, {
        "ID": 2474,
        "phrase": " the study of belief change has been an active area in philosophy and in artificial intelligence  [g\u00e4r88, km91a] ",
        "prob": 0.4357142857142857
    }, {
        "ID": 2474,
        "phrase": " this means that most of the results in the current belief change literature are not directly applicable in many standard ai problems",
        "prob": 0.2733333333333334
    }, {
        "ID": 2475,
        "phrase": "introduction the study of belief change has been an active area in philosophy and artificial intelligence",
        "prob": 0.7000000000000001
    }, {
        "ID": 2475,
        "phrase": " while this may be a plausible assumption in database applications, it seems somewhat less reasonable in ai examples, particularly in cases involving reasoning about action",
        "prob": 0.2157894736842105
    }, {
        "ID": 2481,
        "phrase": " interaction information has been independently rediscovered a number of times in a variety of fields, including machine learning, computational neuroscience, psychology and information and game theory",
        "prob": 0.6714285714285714
    }, {
        "ID": 2482,
        "phrase": " interaction information has been independently rediscovered a number of times in a variety of fields, including machine learning, computational neuroscience, psychology and information and game theory",
        "prob": 0.5761904761904761
    }, {
        "ID": 2489,
        "phrase": " throughout its history, prolog has demonstrated the potential of logic programming in application areas such as artificial intelligence, natural language processing, knowledge based systems, machine learning, database management, or expert systems",
        "prob": 0.37407407407407406
    }, {
        "ID": 2629,
        "phrase": " 3 are you really ai yes i am an artificial intelligence",
        "prob": 0.1375
    }, {
        "ID": 2632,
        "phrase": " triangle relational products together with fast fuzzy relational algorithms  [7] ,  [12]  have been applied to various practical problems in a number of scientific fields: computer protection and ai  [32] , medicine, information retrieval, handwriting classification, architecture and urban studies, investment and control fields  [43] ",
        "prob": 0.315625
    }, {
        "ID": 2740,
        "phrase": " the design of these types of logics is emerging as a relevant research topic in the broader area of combination of logics, theories, and structures, at the intersection of logic with artificial intelligence, computer science, and computational linguistics  (gabbay and de rijke 2000) ",
        "prob": 0.4481481481481482
    }, {
        "ID": 2742,
        "phrase": " as a consequence of this flexibility, dynamic logic has found use in a number of areas of distributed artificial intelligence (dai)",
        "prob": 0.4733333333333334
    }, {
        "ID": 2744,
        "phrase": " , ai k }",
        "prob": 0.025
    }, {
        "ID": 2744,
        "phrase": " , ai k }",
        "prob": 0.025
    }, {
        "ID": 2749,
        "phrase": "introduction the sp theory is a new theory of computing and cognition developed with the aim of integrating and simplifying a range of concepts in computing and cognitive science, with a particular emphasis on concepts in artificial intelligence",
        "prob": 0.524
    }, {
        "ID": 2749,
        "phrase": " \u2022 it provides a framework for processing that knowledge that integrates and simplifies a range of artificial intelligence functions including probabilistic and exact forms of reasoning, unsupervised learning, fuzzy pattern recognition, best-match information retrieval, planning, problem solving and others",
        "prob": 0.37812500000000004
    }, {
        "ID": 2749,
        "phrase": " chief amongst these is the remarkable simplicity of the system combined with its very wide scope, much wider than the great majority of artificial intelligence systems, with the possible exception of unified theories of cognition such as soar  (laird et al",
        "prob": 0.38846153846153847
    }, {
        "ID": 2749,
        "phrase": " the sp system is the result of a radical rethink of concepts in artificial intelligence and beyond, aiming for integration in a radically simplified structure",
        "prob": 0.44999999999999996
    }, {
        "ID": 2749,
        "phrase": " \u2022 the use of a modified version of the concept of multiple alignment as a vehicle for recognition of patterns, information retrieval, probabilistic and exact forms of reasoning, and other artificial intelligence functions",
        "prob": 0.3227272727272727
    }, {
        "ID": 2749,
        "phrase": "the sp theory of computing and cognition, described in previous publications, is an attractive model for intelligent databases because it provides a simple but versatile format for different kinds of knowledge, it has capabilities in artificial intelligence, and it can also function like established database models when that is required",
        "prob": 0.3258064516129032
    }, {
        "ID": 2763,
        "phrase": " a key attraction of this approach to learning is that the icmaus framework provides a unified view of a variety of issues in ai thus facilitating the integration of grammar induction with other aspects of intelligence",
        "prob": 0.3227272727272727
    }, {
        "ID": 2771,
        "phrase": " situation calculus is used differently in these applications from those traditional ai problems such as reasoning, planning, etc: situation calculus is going to be augmented, integrated in and combined into commercial development methodology",
        "prob": 0.2652173913043478
    }, {
        "ID": 2771,
        "phrase": " \n summary with honorable, proven success in modeling dynamical world in artificial intelligence research as well as in some practical problems, situation calculus is chosen to model ubiquitous information services for commercial development purpose",
        "prob": 0.26296296296296295
    }, {
        "ID": 2797,
        "phrase": "object oriented constraint programs (oocps) emerge as a leading evolution of constraint programming and artificial intelligence, first applied to a range of industrial applications called configuration problems",
        "prob": 0.4208333333333334
    }, {
        "ID": 2806,
        "phrase": " \n related works natural language processing (nlp) is a very important research field in artificial intelligence and computer linguistics",
        "prob": 0.4764705882352941
    }, {
        "ID": 2821,
        "phrase": "introduction active databases is an emerging technology combining techniques from databases, expert systems and artificial intelligence",
        "prob": 0.5687500000000001
    }, {
        "ID": 2850,
        "phrase": " apart from being as simple as possible, a 'good' theory in artificial intelligence should explain a wide range of phenomena or integrate a wide range of concepts or both these things",
        "prob": 0.45499999999999996
    }, {
        "ID": 2850,
        "phrase": " as things have turned out, the scope of the theory is much wider than was envisaged originally, with things to say about aspects of human cognition, artificial intelligence, computing, mathematics and logic",
        "prob": 0.5499999999999999
    }, {
        "ID": 2850,
        "phrase": " this section first makes a few brief remarks about how the sp theory compares with other attempts at integration and then there is a summary of key features that serve to distinguish the sp theory and research programme from other research in computing, artificial intelligence and cognitive science",
        "prob": 0.31379310344827593
    }, {
        "ID": 2850,
        "phrase": " a search that is heavily constrained can be achieved quite quickly but-for the kinds of problems that are the focus of interest in artificial intelligence-the results may not be very good",
        "prob": 0.2318181818181818
    }, {
        "ID": 2850,
        "phrase": " with certain kinds of problem, conventional systems can produce results relatively fast but they lack the flexibility needed in artificial intelligence applications",
        "prob": 0.32105263157894737
    }, {
        "ID": 2850,
        "phrase": " although the core of the proposed new system would be more complex than the computational core of a conventional system, there would be an overall simplification of the system owing to the elimination of complexity arising from the redundant programming of sp mechanisms in diverse applications, especially in artificial intelligence",
        "prob": 0.378125
    }, {
        "ID": 2850,
        "phrase": " also distinctive is the attempt to integrate probabilistic reasoning with a wide range of concepts in artificial intelligence, computing, logic and mathematics",
        "prob": 0.6529411764705882
    }, {
        "ID": 2850,
        "phrase": " a particular attraction of this approach to learning is that the sp system provides a unified view of a variety of issues in artificial intelligence thus facilitating the integration of learning with other aspects of intelligence",
        "prob": 0.43913043478260866
    }, {
        "ID": 2850,
        "phrase": " this section sketches some ideas for the development of an  'sp' computer (or 'sp' computer)  that should, if required, be able to function like a conventional computer but which should in addition have strengths in artificial intelligence that are missing from the current generation of digital computers",
        "prob": 0.337037037037037
    }, {
        "ID": 2850,
        "phrase": " notice that the computational demands of artificial intelligence applications are intrinsic to those applications and not a consequence of their interpretation in terms of the sp theory",
        "prob": 0.41764705882352937
    }, {
        "ID": 2913,
        "phrase": " because of this somewhat simplified view of the close weaving of knowledge application and elicitation in ai inference systems, ignoring specificities which are nonetheless important and often critical in the cognitive models embedded in each system under consideration, we are led to a common abstract view of the integration of knowledge acquisition and performance systems",
        "prob": 0.2676470588235294
    }, {
        "ID": 2941,
        "phrase": " in recent years many successful ml applications have been developed, such as datamining programs, information-filtering systems, etc",
        "prob": 0.5941176470588235
    }, {
        "ID": 2941,
        "phrase": " we contend that argument-based reasoning and many ml techniques share this common notion",
        "prob": 0.22142857142857145
    }, {
        "ID": 2941,
        "phrase": " many theoretical results from argument theory could therefore be applied in a ml context",
        "prob": 0.15
    }, {
        "ID": 2941,
        "phrase": " in recent years many successful ml applications have been developed, such as datamining programs, information-filtering systems, etc",
        "prob": 0.5352941176470588
    }, {
        "ID": 2942,
        "phrase": " in recent years many successful ml applications have been developed, such as datamining programs, information-filtering systems, etc",
        "prob": 0.5352941176470588
    }, {
        "ID": 2942,
        "phrase": " we contend that argument-based reasoning and many ml techniques share this common notion",
        "prob": 0.22142857142857145
    }, {
        "ID": 2942,
        "phrase": " in recent years many successful ml applications have been developed, such as datamining programs, information-filtering systems, etc",
        "prob": 0.5352941176470588
    }, {
        "ID": 2943,
        "phrase": " while in montreal, alain decided to concentrate his research on natural language processing and artificial intelligence (ai)",
        "prob": 0.43571428571428567
    }, {
        "ID": 3029,
        "phrase": "introduction natural language processing (nlp) is a very important research field in artificial intelligence and computer linguistics",
        "prob": 0.7562500000000001
    }, {
        "ID": 3047,
        "phrase": "introduction knowledge representation is an important and wide area of artificial intelligence",
        "prob": 0.675
    }, {
        "ID": 3096,
        "phrase": " several artificial intelligence (ai) techniques including neural networks and fuzzy logic  [3] [4] [5]  are successfully applied to a wide variety of decisionmaking problems in the area of medical diagnosis",
        "prob": 0.4136363636363637
    }, {
        "ID": 3097,
        "phrase": " the integration of different intelligent technologies is the most exciting fruit of modern artificial intelligence and is an active area of research",
        "prob": 0.25625000000000003
    }, {
        "ID": 3179,
        "phrase": " the frame/slot approach originated in artificial intelligence (ai) and was then introduced to the area of picture identification",
        "prob": 0.23846153846153847
    }, {
        "ID": 3181,
        "phrase": " we describe a library for standard ml that provides basic primitives for programming reactive systems",
        "prob": 0.22142857142857142
    }, {
        "ID": 3192,
        "phrase": " note that although the wording is closer to ai concepts, the implementation of worlds using a stack is very close to the trailing stack of a constraint logic programming system such as chip  [vh89]  and totally similar to the backtracking stack of a constraint solving tools such as ilog solver [pu94]",
        "prob": 0.409375
    }, {
        "ID": 3210,
        "phrase": " starting from the non-monotonic reasoning community, as evolved and matured within several areas of computer science such as ai & law, knowledge representation, default reasoning and logic programming",
        "prob": 0.3086956521739131
    }, {
        "ID": 3263,
        "phrase": " ai ",
        "prob": 0.025
    }, {
        "ID": 3264,
        "phrase": " ai ",
        "prob": 0.025
    }, {
        "ID": 3381,
        "phrase": " in the last years, interesting applications of conditional logic to several domains of artificial intelligence such as knowledge representation, non-monotonic reasoning, belief revision, representation of counterfactual sentences, deductive databases have \u2022 nicola  olivetti et al",
        "prob": 0.5392857142857143
    }, {
        "ID": 3473,
        "phrase": " we are motivated by the gain in expressiveness through the use of negation in artificial intelligence paradigms related to nonmonotonic reasoning",
        "prob": 0.2733333333333333
    }, {
        "ID": 3473,
        "phrase": " it forms the heart of answer set programming systems like dlv  [4] , which have become a standard paradigm in artificial intelligence",
        "prob": 0.41764705882352937
    }, {
        "ID": 3473,
        "phrase": " in the meantime, an active community is driving the field, covering mathematical foundations, logical aspects, and applications in data mining, ontology engineering, artificial intelligence, and elsewhere",
        "prob": 0.45909090909090905
    }, {
        "ID": 3487,
        "phrase": "introduction constraint satisfaction problems play an important role across a broad spectrum of computer science, including computational complexity theory  [9] , coding theory  [19, 35] , and artificial intelligence  [34, 14] ",
        "prob": 0.6708333333333332
    }, {
        "ID": 3487,
        "phrase": " this equivalence is important because belief propagation is a message-passing algorithm-widely used and studied in various areas, including coding theory  [35, 24, 44] , computer vision  [17, 11]  and artificial intelligence  [34, 45] --for computing approximations to marginal distributions in markov random fields",
        "prob": 0.43666666666666665
    }, {
        "ID": 3500,
        "phrase": " in particular, it should be evident that outlier detection shares some features with some well-known and studied problems in ai literature, such as belief revision and diagnosis",
        "prob": 0.39444444444444443
    }, {
        "ID": 3500,
        "phrase": " this process is generally known as belief change in the literature, and represents an active area of research in both philosophy and artificial intelligence",
        "prob": 0.4764705882352941
    }, {
        "ID": 3500,
        "phrase": " the outlier detection framework introduced here resembles such important notions in ai such as diagnosis and abductive reasoning and belief revision",
        "prob": 0.5062500000000001
    }, {
        "ID": 3713,
        "phrase": "introduction agent, as an important new concept in computer science, has been applied in ai, dai (distributed artificial intelligence) and software engineering, etc",
        "prob": 0.33888888888888896
    }, {
        "ID": 3722,
        "phrase": " topic of interest include, but are not limited to: \u2022 recent results on logic in general, and in applications to computer science in particular; \u2022 reviews of research monographs and edited volumes; \u2022 conference reports; \u2022 relevant results and connections with other fields that make use of logical methods, such as mathematics, artificial intelligence, linguistics, and philosophy;",
        "prob": 0.39166666666666666
    }, {
        "ID": 3874,
        "phrase": " education applications allow the students to get started with robotics, 3d modelling, programming, artificial intelligence, computer vision, artificial life, etc",
        "prob": 0.45499999999999996
    }, {
        "ID": 3892,
        "phrase": " formalized problem solving systems like sliders create a common ground for human and artificial intelligence",
        "prob": 0.19375
    }, {
        "ID": 3917,
        "phrase": " the idea is natural to all these authors that consider temporal logic be a 'modal logic aiming to express time dependent processes', together with mihaela malita and mircea malita ('the foundations of artificial intelligence, 1 propositional logics', ed",
        "prob": 0.5962962962962962
    }, {
        "ID": 4016,
        "phrase": " 2001b ] that non-monotone forms of inductive definitions such as iterated inductive definitions and definitions over well-orders, can play a unifying role in logic, ai and knowledge representation, connecting remote areas such as non-monotonic reasoning, logic programming, description logics, deductive databases and fixpoint logics",
        "prob": 0.43142857142857144
    }, {
        "ID": 4271,
        "phrase": " \"common sense\", encodings of ai problems",
        "prob": 0.1375
    }, {
        "ID": 4319,
        "phrase": " for ease of use, pegasus is able to generate a workflow from a metadata description of the desired data product with the aid of artificial intelligence planning techniques",
        "prob": 0.355
    }, {
        "ID": 4361,
        "phrase": "introduction artificial intelligence (a",
        "prob": 0.4428571428571429
    }, {
        "ID": 4470,
        "phrase": " in practice, it is fundamental in solving many problems in machine vision, image processing, computational chemistry, integrated circuit design, computer network design, artificial intelligence and more",
        "prob": 0.5695652173913044
    }, {
        "ID": 4490,
        "phrase": "introduction the constraint satisfaction problem provides a framework in which it is possible to express, in a natural way, many combinatorial problems encountered in artificial intelligence and elsewhere",
        "prob": 0.6714285714285714
    }, {
        "ID": 4493,
        "phrase": "introduction the constraint satisfaction problem provides a framework in which it is possible to express, in a natural way, many combinatorial problems encountered in artificial intelligence and elsewhere",
        "prob": 0.7666666666666665
    }, {
        "ID": 4529,
        "phrase": " \n logic programming in this paper we are not interested in logic computations as refutations of goals for problem solving or artificial intelligence, but we consider logic programming  (lloyd 1993 ) as a goal rewriting mechanism",
        "prob": 0.4826086956521739
    }, {
        "ID": 4530,
        "phrase": " \n logic programming in this paper we are not interested in logic computations as refutations of goals for problem solving or artificial intelligence, but we consider logic programming  (lloyd 1993 ) as a goal rewriting mechanism",
        "prob": 0.3521739130434782
    }, {
        "ID": 4649,
        "phrase": "context mining sequential and spatial patterns is an active area of research in artificial intelligence",
        "prob": 0.3642857142857143
    }, {
        "ID": 4672,
        "phrase": " instances of the csp arise in a variety of domains, including artificial intelligence, database theory, algebra, propositional logic, and graph theory",
        "prob": 0.6894736842105263
    }, {
        "ID": 4683,
        "phrase": " rcc was initially described by  randell, cohn and  cui in  [31, 33] , which is intended to provide a logical framework for incorporating spatial reasoning into ai systems",
        "prob": 0.3
    }, {
        "ID": 4793,
        "phrase": " \n from configuration to workflow composition configuration emerges as an ai technique with applications in many different areas, where the problem can be formulated as the production of a finite instance of an object model subject to constraints",
        "prob": 0.2652173913043478
    }, {
        "ID": 4831,
        "phrase": " such problems arise naturally in a wide variety of domains, for example, logic, artificial intelligence, verification, combinatorics, and game theory",
        "prob": 0.6722222222222222
    }, {
        "ID": 4988,
        "phrase": " in artificial intelligence, much of the focus has been on language understanding and production, rather than gestures or on the fundamental problems of how to get started and stay connected, and the role of gesture in connecting",
        "prob": 0.36818181818181817
    }, {
        "ID": 5127,
        "phrase": " introduction integer programming problems arise in various fields, including communication theory, error-correcting coding, image processing, statistical physics and machine learning [e",
        "prob": 0.39565217391304347
    }, {
        "ID": 5481,
        "phrase": "introduction one of the canonical problems of machine learning is recommending products to potential users, i",
        "prob": 0.23846153846153847
    }, {
        "ID": 5488,
        "phrase": " \n soft computing: artificial neural networks analogical reasoning is a paradigm for problem solving within the field of artificial intelligence  [sage, 1990] ",
        "prob": 0.5842105263157894
    }, {
        "ID": 5520,
        "phrase": " \n neuronal versus connectionist there are two driving forces behind the field of neural-symbolic integration: on the one hand it is the striving for an understanding of human cognition, and on the other it is the vision of combining connectionist and symbolic artificial intelligence technology in order to arrive at more powerful reasoning and learning systems for computer science applications",
        "prob": 0.41944444444444445
    }, {
        "ID": 5520,
        "phrase": " recent work has covered a great variety of logics used in artificial intelligence and provides a multitude of techniques for dealing with them within the context of artificial neural networks",
        "prob": 0.2772727272727273
    }, {
        "ID": 5568,
        "phrase": " \n discussion: relevance to artificial intelligence and computational science the relevance of the modeling language defined here to artificial intelligence includes the following points",
        "prob": 0.1631578947368421
    }, {
        "ID": 5568,
        "phrase": " in that case the forgoing ai arguments apply to computational science applications of machine learning as well",
        "prob": 0.22142857142857145
    }, {
        "ID": 5615,
        "phrase": "introduction binary classification is a basic problem in machine learning with applications in many fields",
        "prob": 0.3642857142857143
    }, {
        "ID": 5631,
        "phrase": ") \n represention by spaces in ai and in various other parts of computer science, one finds numerous instances of representation by spaces, that is, representation of non-spatial information in a spatial form to aid visualisation, or to use spatial analogies to help the understanding of the data",
        "prob": 0.38275862068965516
    }, {
        "ID": 5631,
        "phrase": " dowker's constructions have been rediscovered several times since and one finds similar ideas now being used in artificial intelligence, for instance, in knowledge representation, cf",
        "prob": 0.45499999999999996
    }, {
        "ID": 5671,
        "phrase": " finally, we are going to explore further the properties of tsallis entropy into optimization methods in artificial intelligence applications",
        "prob": 0.14
    }, {
        "ID": 5768,
        "phrase": " many of the concepts have been abstracted from biology to serve as \"bridging\" concepts which can be used in both for the study of interacting agents in ai and brain theory and thus, can serve cognitive science whether or not the particular study addresses neurological or neurophysiological data",
        "prob": 0.21785714285714283
    }, {
        "ID": 5768,
        "phrase": " the reason for such high level development is existence of different types of schemas (in brain theory, cognitive psychology, artificial intelligence, programming, computer science, mathematics, databases, etc",
        "prob": 0.46249999999999997
    }, {
        "ID": 5828,
        "phrase": " isi category isi category name ep computer science, artificial intelligence er computer science, cybernetics es computer science, hardware & architecture et computer science, information systems ev computer science, interdisciplinary applications ew computer science, software, graphics, programming ex computer science, theory & methods \n table 3 : 3 isi subject categories for computer science journals",
        "prob": 0.5704545454545454
    }, {
        "ID": 5854,
        "phrase": " the reductionist approach to artificial intelligence emerged out of an attempt to mechanize logic in the 1930s",
        "prob": 0.3416666666666666
    }, {
        "ID": 5854,
        "phrase": " in turn, ai and computer science influenced research in psychology and neuroscience and the view developed that a cognitive act is a logical computation",
        "prob": 0.3588235294117647
    }, {
        "ID": 5913,
        "phrase": "6 \u00ba \u00d7\u00f1 \u00f0\u00f0 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00d7 \u00f2 \u00fc\u00f4\u00f0 \u00f2 \u00fd \u00f8 \u00f6 \u00f8 \u00f6 \u00f4 \u00f9\u00f0 \u00f6 \u00f3 \u00f3 \u00d7\u00f6 \u00f1 \u00f2 \u00f2\u00f8\u00d7\u00ba \u00ec \u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00fa \u00f2 \u00f0 \u00d7\u00d7 \u00f2\u00f9\u00f1 \u00f6\u00b8\u00f8 \u00f4\u00f6 \u00d7 \u00f3\u00f2 n \u00d7 \u00f6 \u00f8 \u00f6 \u00f0 \u00f6 \u00f3\u00f1\u00f4 \u00f6 \u00f8\u00f3 h \u00f2 |d|\u00b8\u00d7 \u00f2 \u00f8 \u00f6 \u00f6 \u00f1 \u00f2\u00fd \u00f3\u00f6\u00f1\u00d7 \u00fb \u00f8 \u00d7\u00f1 \u00f0\u00f0 a \u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00d7\u00f9\u00f1 h i=1 1 ai \u00f3\u00f1 \u00d7 \u00f3\u00f1\u00f4 \u00f6 \u00f8 \u00fa \u00f0\u00fd \u00f0 \u00f6 \u00ba \u00f4\u00f4 \u00f6 \u00f2\u00f8\u00f0\u00fd\u00b8\u00f8 \u00d7 \u00f8 \u00f3\u00f1 \u00d7 \u00f1\u00f3\u00f6 \u00f4\u00f6\u00f3\u00f2\u00f3\u00f9\u00f2 \u00f3\u00f6 \u00f6\u00f3\u00fb \u00f2 \u00f0 \u00d7\u00d7 \u00f2\u00f9\u00f1 \u00f6\u00d7 \u00f8 \u00f6 \u00f8 \u00f3 n/ |d| \u00f6\u00f3\u00fb\u00d7 \u00f6\u00f3\u00f1 3",
        "prob": 0.025
    }, {
        "ID": 5938,
        "phrase": " a decision-making model was used as a generic system-theoretic representation for a broader range of applications in machine learning, signal processing, and communications",
        "prob": 0.255
    }, {
        "ID": 5939,
        "phrase": " a decision-making model was used as a generic system-theoretic representation for a broader range of applications in machine learning, signal processing, and communications",
        "prob": 0.255
    }, {
        "ID": 5945,
        "phrase": " as these models are increasingly becoming more and more common, their applicability has ranged from artificial intelligence domain such as knowledge engineering/representation and natural language processing to different fields such as information integration and retrieval systems, the semantic web, and the requirements analysis phase of the software development process",
        "prob": 0.346875
    }, {
        "ID": 5964,
        "phrase": " , c an ) and c ai (1 + c ai ) = c ai + c 2 ai ",
        "prob": 0.025
    }, {
        "ID": 5965,
        "phrase": " , c an ) and c ai (1 + c ai ) = c ai + c 2 ai ",
        "prob": 0.025
    }, {
        "ID": 5966,
        "phrase": " , c an ) and c ai (1 + c ai ) = c ai + c 2 ai ",
        "prob": 0.025
    }, {
        "ID": 5972,
        "phrase": " their evaluation problem has also been considered in different contexts and under different names, notably as the constraint satisfaction problem in ai  [kolaitis and vardi 1998; dechter 2003]  and the h-coloring problem in graph theory  [hell and nesetril 2004] ",
        "prob": 0.29583333333333334
    }, {
        "ID": 6106,
        "phrase": ",  [30] ) led to identification of constraint satisfaction problems as an area of artificial intelligence",
        "prob": 0.5916666666666667
    }, {
        "ID": 6122,
        "phrase": " an\u22121 \u2192 s n ) \u2282 \u03c3 \u2227 s 0 \u2208 y \u2227 \u2200i \u2022 (s i ai \u2192 s i+1 \u2208 m2 j=1 f 2j ))}",
        "prob": 0.025
    }, {
        "ID": 6133,
        "phrase": " these classes of languages are well-studied in universal algebra and computer science; they have, for instance, been considered in connection with machine learning and constraint satisfaction",
        "prob": 0.2157894736842105
    }, {
        "ID": 6319,
        "phrase": " he serves on the editorial boards of discrete event dynamic systems, machine learning, mathematics of operations research, and operations research",
        "prob": 0.33888888888888885
    }, {
        "ID": 6319,
        "phrase": " his recent research interests photo include dynamic optimization, machine learning, here economics, finance, and information technology",
        "prob": 0.4764705882352941
    }, {
        "ID": 6346,
        "phrase": " for this reason it is a frequently used language in artificial intelligence  [1, 5]  where manipulation of symbols and inference about them is a common task",
        "prob": 0.20666666666666667
    }, {
        "ID": 6347,
        "phrase": "introduction logic programming, and the language prolog in particular, has been proven to be very useful for implementing applications from various fields of artificial intelligence (e",
        "prob": 0.5611111111111111
    }, {
        "ID": 6347,
        "phrase": " expert systems, machine learning, search, reasoning, planning, natural language processing, deductive databases, data mining, etc)  [3] ,  [8] ",
        "prob": 0.531578947368421
    }, {
        "ID": 6347,
        "phrase": " symbolic processing, expert systems, machine learning, search, reasoning, planning, natural language processing, deductive databases, data mining, etc) one can just connect to a prolog rpc server, load the code there, ask the queries, get the results needed, return and continue the execution in the original program",
        "prob": 0.4081081081081081
    }, {
        "ID": 6347,
        "phrase": " most notably the distributed artificial intelligence applications that are suitable for logic programming can profit from the use of the protocol",
        "prob": 0.4733333333333334
    }, {
        "ID": 6347,
        "phrase": " most notably the distributed artificial intelligence applications that are suitable for logic programming can profit from the use of the protocol",
        "prob": 0.54
    }, {
        "ID": 6347,
        "phrase": " most notably the distributed artificial intelligence (dai) applications that are suitable for logic programming can profit from the use of the protocol",
        "prob": 0.54
    }, {
        "ID": 6364,
        "phrase": " patterns can be manipulated in the tactic programming language of most theorems (in isabelle  [30] , the tactic programming language is ml  [29] )",
        "prob": 0.2733333333333333
    }, {
        "ID": 6377,
        "phrase": " cognitive science is the interdisciplinary study of mind and intelligence, embracing philosophy, psychology, artificial intelligence, neuroscience, linguistics, and anthropology",
        "prob": 0.39444444444444443
    }, {
        "ID": 6398,
        "phrase": " on the other hand, development of a self-learning system capable of acquiring knowledge from the environment is one of central problems in the theory of the artificial intelligence",
        "prob": 0.33888888888888885
    }, {
        "ID": 6459,
        "phrase": " at : ai \u2208 \u03c3}",
        "prob": 0.025
    }, {
        "ID": 6521,
        "phrase": " the potential of knowledge-based approachesand in particular of logic programming-for developing reasoning components for intelligent information agents is recognized in the ai community and outlined, e",
        "prob": 0.2904761904761905
    }, {
        "ID": 6640,
        "phrase": "introduction reasoning about topological relations between regions in space is recognized as one of the most important and challenging research areas within spatial reasoning in artificial intelligence (ai) and philosophy, spatial and constraint databases, and geographical information systems (giss)",
        "prob": 0.682142857142857
    }, {
        "ID": 6641,
        "phrase": "introduction reasoning about topological relations between regions in space is recognized as one of the most important and challenging research areas within spatial reasoning in artificial intelligence (ai) and philosophy, spatial and constraint databases, and geographical information systems (giss)",
        "prob": 0.6464285714285714
    }, {
        "ID": 6785,
        "phrase": " the ai system has to prefer some things to others in order to learn",
        "prob": 0.21000000000000002
    }, {
        "ID": 6862,
        "phrase": " (76) t i \u2192 (x ai , x 1ai , x bi , x 1bi ) \u2192 (y 1ai , y 2ai , y 1bi , y 2bi ), for i = 1, 2, ",
        "prob": 0.025
    }, {
        "ID": 6938,
        "phrase": " \u2022 some ai technology such as voice recognition, computer reasoning, and expert systems will be applied to support the functionality of the personal memex system",
        "prob": 0.3588235294117647
    }, {
        "ID": 7000,
        "phrase": " ai is many things to many people",
        "prob": 0.2625
    }, {
        "ID": 7025,
        "phrase": " in sequential implementations of search-based ai systems or prolog, typically one branch of the tree resides on the inference engine's stacks at any given time",
        "prob": 0.26842105263157895
    }, {
        "ID": 7087,
        "phrase": " to solve this problem within the framework of first order logic, we use the reification technique, commonly used in artificial intelligence (ai)",
        "prob": 0.2833333333333333
    }, {
        "ID": 7179,
        "phrase": " the present approach complements a variety of econometric, econophysics, statistical and artificial intelligence approaches in this field  [8, 9, 10, 11] ",
        "prob": 0.2733333333333334
    }, {
        "ID": 7180,
        "phrase": " the present approach complements a variety of econometric, econophysics, statistical and artificial intelligence approaches in this field  [8, 9, 10, 11] ",
        "prob": 0.2733333333333334
    }, {
        "ID": 7359,
        "phrase": " for various applications of many-valued logics to hardware design and artificial intelligence, see  [10] ,  [9] ,  [14] ",
        "prob": 0.5071428571428572
    }, {
        "ID": 7360,
        "phrase": " for various applications of many-valued logics to hardware design and artificial intelligence, see  [10] ,  [9] ,  [14] ",
        "prob": 0.2928571428571428
    }, {
        "ID": 7408,
        "phrase": " \u2192 ai \u2282 \u2704 ai \u2282 \u2192 * ai ",
        "prob": 0.025
    }, {
        "ID": 7408,
        "phrase": " a p \u2704 ai t",
        "prob": 0.025
    }, {
        "ID": 7408,
        "phrase": " , p}, a k \u2704 ai b k ",
        "prob": 0.025
    }, {
        "ID": 7409,
        "phrase": " \u2192 ai \u2282 \u2704 ai \u2282 \u2192 * ai ",
        "prob": 0.025
    }, {
        "ID": 7409,
        "phrase": " a p \u2704 ai t",
        "prob": 0.025
    }, {
        "ID": 7409,
        "phrase": " , p}, a k \u2704 ai b k ",
        "prob": 0.025
    }, {
        "ID": 7420,
        "phrase": ", a, ) , where ai = { ( i j, + ) j = i ",
        "prob": 0.025
    }, {
        "ID": 7475,
        "phrase": "we are working on the understanding of plurals in the framework of artificial intelligence",
        "prob": 0.31
    }, {
        "ID": 7505,
        "phrase": " successful game programming requires familiarity with user interface design, data structures, object-oriented design, algorithms, software engineering, graphics, artificial intelligence, and plausibly just about any other topic common to a computer science curriculum",
        "prob": 0.4172413793103449
    }, {
        "ID": 7506,
        "phrase": " successful game programming requires familiarity with user interface design, data structures, object-oriented design, algorithms, software engineering, graphics, artificial intelligence, and plausibly just about any other topic common to a computer science curriculum",
        "prob": 0.4172413793103449
    }, {
        "ID": 7519,
        "phrase": " for i = 1, 2, t ai (\u03b3 i ) \u2208 v (a i )",
        "prob": 0.025
    }, {
        "ID": 7560,
        "phrase": "introduction constraint satisfaction problems arise in a wide variety of domains, such as combinatorics, logic, algebra, and artificial intelligence",
        "prob": 0.711764705882353
    }, {
        "ID": 7561,
        "phrase": "introduction constraint satisfaction problems arise in a wide variety of domains, such as combinatorics, logic, algebra, and artificial intelligence",
        "prob": 0.711764705882353
    }, {
        "ID": 7566,
        "phrase": " the authors firmly believe that the study of elections is a showcase area where interests come together spanning such cs specialties as theory, systems, and ai and such other fields as economics, business, operations research, and political science",
        "prob": 0.444
    }, {
        "ID": 7576,
        "phrase": " the underlying research question of this thesis is: \n can advanced knowledge representation (kr) concepts using logic programming (lp) techniques and generic inference engines (rule engines) adapted to the sla domain and will they enable an efficient, flexible and distributed management and enforcement of slas? \n objectives and contribution of the work the proposed research is on the interplay of common software engineering providing well-established development methodologies and imperative program and database solutions, on the one hand and artificial intelligence and knowledge engineering following the declarative rule based programming paradigm, on the other",
        "prob": 0.22741935483870968
    }, {
        "ID": 7639,
        "phrase": " in the recent years rule-based programming in terms of declarative logic programming has formed the basis for many artificial intelligence (ai) applications and is well integrated in the mainstream information technology capturing higher-level decision logics",
        "prob": 0.3482758620689656
    }, {
        "ID": 7639,
        "phrase": " ml programming language [mil78]), adhoc polymorphism or parametric polymorphism haven been introduced into logic programming",
        "prob": 0.40666666666666673
    }, {
        "ID": 7770,
        "phrase": " from the somewhat different perspective of the areas of artificial intelligence and belief revision, epistemic and ontic change correspond to, respectively, revising  [1]  and updating  [12]  beliefs",
        "prob": 0.5549999999999999
    }, {
        "ID": 7897,
        "phrase": " a different approach to events and actions -the so called kr event/action logics -which has for the most part proceeded separately has the origin in the area of artificial intelligence (ai), knowledge representation (kr) and logic programming (lp)",
        "prob": 0.5222222222222223
    }, {
        "ID": 7897,
        "phrase": " reasoning about events, actions and change is a fundamental area of research in ai since the events/actions are pervasive aspects of the world in which agents operate enabling retrospective reasoning but also prespective planning",
        "prob": 0.4826086956521739
    }, {
        "ID": 7898,
        "phrase": " a different approach to events and actions -the so called kr event/action logics -which has for the most part proceeded separately has the origin in the area of artificial intelligence (ai), knowledge representation (kr) and logic programming (lp)",
        "prob": 0.5222222222222223
    }, {
        "ID": 7898,
        "phrase": " reasoning about events, actions and change is a fundamental area of research in ai since the events/actions are pervasive aspects of the world in which agents operate enabling retrospective reasoning but also prespective planning",
        "prob": 0.4826086956521739
    }, {
        "ID": 7935,
        "phrase": " their approach later has been widely adopted by many other researchers  [6] [7] [8] [9] [10]  and extensively applied to field programmable gate arrays (fpgas)  [11, 12] , multiple-valued logics  [13] [14] [15] [16] , machine learning  [17, 18] , and very large scale integration (vlsi)  [19] ",
        "prob": 0.1576923076923077
    }, {
        "ID": 7974,
        "phrase": " reasoning about events, actions and change is a fundamental area of research in ai since the events/actions are pervasive aspects of the world in which agents operate enabling retrospective reasoning but also prespective planning",
        "prob": 0.43913043478260866
    }, {
        "ID": 8063,
        "phrase": " alternately, in reality, extended mud is quite powerful for graph computations, machine learning and ranking, among other things with small rounds",
        "prob": 0.1105263157894737
    }, {
        "ID": 8111,
        "phrase": " assemblies of active neuronal cells, can be viewed as a machine learning or a data mining problem",
        "prob": 0.22142857142857142
    }, {
        "ID": 8111,
        "phrase": " however, contrasting with ml or dm applications  [6] , the appropriate search criteria are not formally defined up to now; in practice the detection of active cell assemblies is manually done",
        "prob": 0.1952380952380952
    }, {
        "ID": 8153,
        "phrase": " \u03b1 an \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb , where \u03b1 ai \u2208 r d1 , i \u2208 [n ], \u03b1 b = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 \u03b1 b1 ",
        "prob": 0.025
    }, {
        "ID": 8154,
        "phrase": " \u03b1 an \uf8f9 \uf8fa \uf8fb, where \u03b1 ai \u2208 r d1 , i \u2208 [n ], \u03b1 b = \uf8ee \uf8ef \uf8f0 \u03b1 b1 ",
        "prob": 0.025
    }, {
        "ID": 8179,
        "phrase": " at the crossroads of artificial intelligence,  cognitive science, ",
        "prob": 0.34444444444444444
    }, {
        "ID": 8179,
        "phrase": " at the crossroads of artificial intelligence,  cognitive science, ",
        "prob": 0.5666666666666668
    }, {
        "ID": 8179,
        "phrase": " at the crossroads of artificial intelligence, cognitive science, and neuroscience",
        "prob": 0.6100000000000001
    }, {
        "ID": 8179,
        "phrase": " at the crossroads of artificial intelligence, cognitive science, and neuroscience",
        "prob": 0.31
    }, {
        "ID": 8179,
        "phrase": " at the crossroads of artificial intelligence,cognitive science,",
        "prob": 0.5125000000000001
    }, {
        "ID": 8179,
        "phrase": " at the crossroads of artificial intelligence,cognitive science,",
        "prob": 0.5125000000000001
    }, {
        "ID": 8214,
        "phrase": " such an interpretation provides a common basis for a unified treatment of experimental sciences and natural or artificial intelligence  [2] ,  [8] ",
        "prob": 0.4066666666666667
    }, {
        "ID": 8247,
        "phrase": " the general target for ai entities operating in artificial and natural environments is good environment responsiveness",
        "prob": 0.15
    }, {
        "ID": 8248,
        "phrase": " in computing and ai contexts the word understanding is arguably tilted more in favor of inference than perception or cognition, in normal life and in the natural kingdom the reverse is true",
        "prob": 0.255
    }, {
        "ID": 8248,
        "phrase": " natural systems however have some facilities that the ai systems of today do not enjoy",
        "prob": 0.4636363636363637
    }, {
        "ID": 8287,
        "phrase": " systems of bounded differences have been used by the artificial intelligence community as a way to reason about temporal quantities  [1, 37] , as well as by the model checking community as an efficient yet precise way to model and propagate timing requirements during the verification of various kinds of concurrent systems  [38, 64] ",
        "prob": 0.31562500000000004
    }, {
        "ID": 8310,
        "phrase": "2 that \u2200i, e \u2212\u01eb \u2264 ai ai+1 \u2264 e \u01eb ",
        "prob": 0.025
    }, {
        "ID": 8310,
        "phrase": " 2 \u2200i, e \u2212\u01eb \u2264 ai ai+1 \u2264 e \u01eb ",
        "prob": 0.025
    }, {
        "ID": 8348,
        "phrase": ", lecture notes in artificial intelligence, lecture notes in computer science, and lecture notes in mathematics)",
        "prob": 0.7400000000000001
    }, {
        "ID": 8555,
        "phrase": "y k x k ) = \u00b5 ai (y 1 r 1 ",
        "prob": 0.025
    }, {
        "ID": 8615,
        "phrase": ", ai = 1 k p k i=1 ai",
        "prob": 0.025
    }, {
        "ID": 8615,
        "phrase": ", ai = 1 k p k i=1 ai",
        "prob": 0.025
    }, {
        "ID": 8616,
        "phrase": ", ai = 1 k p k i=1 ai",
        "prob": 0.025
    }, {
        "ID": 8908,
        "phrase": "introduction many concepts and tools used in information theory, control, theory of approximation, dynamical systems and artificial intelligence are closely linked",
        "prob": 0.505
    }, {
        "ID": 8909,
        "phrase": " human-centered technologies are used frequently in many applications, including artificial intelligence  [35, 39] ",
        "prob": 0.3642857142857143
    }, {
        "ID": 9161,
        "phrase": " next let p = q i pi represent the irreducible factorization of p in k[y ], and let ai = k[y ]/(pi(y )), so that a rewrites into the product of fields q i ai",
        "prob": 0.1823529411764706
    }, {
        "ID": 9221,
        "phrase": " unification plays a central role in theorem-proving, polymorphic type-checking  [19] , the language prolog  [8] , and other areas of artificial intelligence  [7] ",
        "prob": 0.2833333333333333
    }, {
        "ID": 9221,
        "phrase": " \n the meta-language ml pplambda is embedded in lcf's meta-language, ml, which is a functional programming language related to landin's iswim  [4] ",
        "prob": 0.3736842105263158
    }, {
        "ID": 9225,
        "phrase": " ml gives a general representation of logic",
        "prob": 0.23333333333333334
    }, {
        "ID": 9227,
        "phrase": " type checking in ml is a formal version of the same thing: types are inferred but not shown",
        "prob": 0.16153846153846152
    }, {
        "ID": 9228,
        "phrase": " the programming language ml provides the flexibility needed for this research",
        "prob": 0.5545454545454546
    }, {
        "ID": 9229,
        "phrase": " many lisp and ml programmers strive for a pure style, while many pure functional programs can be executed with reasonable efficiency",
        "prob": 0.33888888888888885
    }, {
        "ID": 9238,
        "phrase": " \n market-based computation the basic idea of applying economic mechanisms to coordinate distributed problem solving is not new to the ai community",
        "prob": 0.17222222222222222
    }, {
        "ID": 9252,
        "phrase": " similarly, ai applications and expert systems typically use only unary predicates such as symptoms and diseases  (cheeseman, 1983) ",
        "prob": 0.54
    }, {
        "ID": 9256,
        "phrase": " we hope that wrap-up will inspire the machine learning community to consider analysis of unrestricted text as a fruitful application for ml research, while challenging the natural language processing community to consider ml techniques for complex processing tasks",
        "prob": 0.17000000000000004
    }, {
        "ID": 9264,
        "phrase": " \n overview theory revision and constructive induction embody complementary aspects of the machine learning research community's ultimate goals",
        "prob": 0.22777777777777775
    }, {
        "ID": 9268,
        "phrase": "introduction one active area of research in machine learning is learning concepts expressed in rstorder logic",
        "prob": 0.3400000000000001
    }, {
        "ID": 9269,
        "phrase": "introduction inductive logic programming (ilp)  (muggleton, 1992; muggleton & de raedt, 1994 ) is an active area of machine learning research in which the hypotheses of a learning system are expressed in a logic programming language",
        "prob": 0.5041666666666668
    }, {
        "ID": 9278,
        "phrase": " \n conclusion although much work in machine learning aims for depth at a particular kind of learning, instructo-soar demonstrates breadth { of interaction with an instructor to learn a variety of types of knowledge { but all arising from one underlying technique",
        "prob": 0.21785714285714283
    }, {
        "ID": 9281,
        "phrase": "introduction many artificial intelligence problems involve search",
        "prob": 0.5545454545454546
    }, {
        "ID": 9281,
        "phrase": " while these algorithms have wide applicability, both within and beyond the scope of artificial intelligence, this paper focuses on their application in classification learning",
        "prob": 0.24117647058823527
    }, {
        "ID": 9281,
        "phrase": " such search problems are encountered in many domains including machine learning, truth maintenance and pattern recognition",
        "prob": 0.44375000000000003
    }, {
        "ID": 9301,
        "phrase": " in artificial intelligence such problems are generally solved by constraint propagation search techniques (e",
        "prob": 0.23846153846153847
    }, {
        "ID": 9310,
        "phrase": " finally, machine learning has also been used with great success in many other areas of natural language processing",
        "prob": 0.3400000000000001
    }, {
        "ID": 9329,
        "phrase": "many ai researchers are today striving to build agent teams for complex, dynamic multi-agent domains, with intended applications in arenas such as education, training, entertainment, information integration, and collective robotics",
        "prob": 0.35000000000000003
    }, {
        "ID": 9336,
        "phrase": " isabelle uses resolution to support proof checking, with no built-in strategy; logic programming effects can be obtained, but virtually all programming is done using ml  [29] ",
        "prob": 0.2318181818181818
    }, {
        "ID": 9336,
        "phrase": " like many problems that arise in practice, it is long but logically shallow: 2 users may bind specialized clasets to ml identifiers, but isabelle now supports a default claset",
        "prob": 0.13478260869565217
    }, {
        "ID": 9360,
        "phrase": ", has proven to be fundamental in various disciplines, including philosophy  [lew69] , artificial intelligence  [mshi79] , game theory  [aum76] , psychology  [cm81] , and distributed systems  [hm90] ",
        "prob": 0.5954545454545455
    }, {
        "ID": 9378,
        "phrase": " on the one hand, in ai the use of knowledge sources contributing to solve a problem shares the same purposes as the modularity introduced in nlp",
        "prob": 0.25625000000000003
    }, {
        "ID": 9391,
        "phrase": " while it may seem to be a limitation, the class of problems that can be solved in the slp is still quite wide and includes all decision problems from np and many search and constraint satisfaction problems of importance in artificial intelligence and operations research",
        "prob": 0.39642857142857146
    }, {
        "ID": 9391,
        "phrase": " studying applicability of the slp paradigm to other classical problems of artificial intelligence and operations research may provide additional motivation to focusing on this approach and may gain badly needed recognition to logic programming",
        "prob": 0.262962962962963
    }, {
        "ID": 9447,
        "phrase": " j ai n, k ",
        "prob": 0.025
    }, {
        "ID": 9449,
        "phrase": " the r e m ai ni n g 19",
        "prob": 0.025
    }, {
        "ID": 9471,
        "phrase": " it aims to create a large database of language usage in order to enable and encourage research activities in a wide range of fields, from linguistics to medicine, through psychology and artificial intelligence, among others",
        "prob": 0.40399999999999997
    }, {
        "ID": 9504,
        "phrase": " in order to cope with the combinatorial explosion of the search problem, ai researchers proposed a wide variety of solutions, from search control rules  [weld 1994 , etzioni 1993 , minton 1996  to abstraction and hierarchical planning  [knoblock 1991 and  to skeletal planning  [friedland 1985 ]",
        "prob": 0.25357142857142856
    }, {
        "ID": 9517,
        "phrase": " \n divisor ideals of lpdo we study general lpdo l = | i|\u2264m ai 1 \u2022\u2022\u2022in ( x)d i 1 x 1 d i 2 x 2 \u2022 \u2022 \u2022 d in xn , (8) | i| = i1 + ",
        "prob": 0.2583333333333333
    }, {
        "ID": 9531,
        "phrase": " voronkov, editor, logic programming, volume 592 of lecture notes in artificial intelligence, pages 27-34",
        "prob": 0.7214285714285715
    }, {
        "ID": 9531,
        "phrase": " richter, editors, processing declarative knowledge, volume 567 of lecture notes in artificial intelligence, pages 191-198",
        "prob": 0.6066666666666667
    }, {
        "ID": 9531,
        "phrase": " voronkov, editor, logic programming, volume 592 of lecture notes in artificial intelligence, pages 35-54",
        "prob": 0.7214285714285715
    }, {
        "ID": 9531,
        "phrase": " pl\u00fcmer, editors, logic programming: formal methods and practical applications, studies in computer science and artificial intelligence, chapter 2, pages 20-90",
        "prob": 0.4789473684210526
    }, {
        "ID": 9552,
        "phrase": " this problem has already been investigated in the area of machine learning and related fields",
        "prob": 0.25833333333333336
    }, {
        "ID": 9557,
        "phrase": " in artificial intelligence it roughly means a set of conventions about how to describe things; it is a loose term to be kept in mind when creating programs, languages etc",
        "prob": 0.255
    }, {
        "ID": 9565,
        "phrase": " \u2022 ai behavior such as natural language processing and machine learning are incorporated on the architecture rather than introduced as new agents (as is the case with the natural language macro agent in figure  3 )",
        "prob": 0.2772727272727273
    }, {
        "ID": 9566,
        "phrase": " \u2022 ai behavior such as input interpretation (e",
        "prob": 0.15714285714285717
    }, {
        "ID": 9566,
        "phrase": ", natural language processing) and machine learning are incorporated on the architecture and distributed over the multi-agent structure rather than introduced as single new agents (as is the case with the natural language macro agent in figure  2 )",
        "prob": 0.2730769230769231
    }, {
        "ID": 9567,
        "phrase": " while scheduling has been studied in isolation for many years, recent advances in artificial intelligence and operations research indicate a renewed interest in the area  [20] ",
        "prob": 0.268421052631579
    }, {
        "ID": 9570,
        "phrase": ", artificial intelligence, databases etc",
        "prob": 0.3875
    }, {
        "ID": 9576,
        "phrase": " planning and diagnosis in artificial intelligence, and a range of combinatorial optimization problems, such as computing hamilton cycles or k-colorings in graphs, are of this type",
        "prob": 0.5611111111111111
    }, {
        "ID": 9579,
        "phrase": " \n functional programming (fp) the fp languages like lisp were one of the first tools for symbolic manipulation and artificial intelligence (ai)",
        "prob": 0.3
    }, {
        "ID": 9588,
        "phrase": "introduction in this paper we investigate the issues related to the expressibility of default logic, a knowledge representation formalism introduced by reiter  [rei80]  and extensively investigated by the researchers of logical foundations of artificial intelligence  [eth88, bes89, bre91] ",
        "prob": 0.39642857142857146
    }, {
        "ID": 9615,
        "phrase": " \n \"fido\" and fido fodor and le pore's dissection of jp's book is, and is intended to be, an attack on a whole ai approach to natural language processing based on symbolic representations, so it is open to any other member of that school to join in the defence",
        "prob": 0.27307692307692305
    }, {
        "ID": 9631,
        "phrase": "introduction the study of belief change has been an active area in philosophy and artificial intelligence",
        "prob": 0.6230769230769231
    }, {
        "ID": 9641,
        "phrase": " att-meta is an ai system capable of both simulative reasoning about beliefs and metaphorical reasoning",
        "prob": 0.5461538461538462
    }, {
        "ID": 9641,
        "phrase": " this paper provides an analysis of both parallel and serial mixed metaphors within the framework of an ai system which is already capable of reasoning about straight metaphorical manifestations and argues that the processes underlying mixing are central to metaphorical meaning",
        "prob": 0.337037037037037
    }, {
        "ID": 9660,
        "phrase": " artificial intelligence and operations research are two areas which rely heavily on such search methods",
        "prob": 0.5071428571428572
    }, {
        "ID": 9679,
        "phrase": " linguistics, logic, probability theory, information theory, computer science and machine learning, are imported, sharpened and customized for linguistic processing",
        "prob": 0.5842105263157894
    }, {
        "ID": 9679,
        "phrase": " in graph theory, formal language theory, automata theory, parsing technology, complexity theory), probability theory, information theory, machine learning and linguistics",
        "prob": 0.5499999999999999
    }, {
        "ID": 9680,
        "phrase": " linguistics, logic, probability theory, information theory, computer science and machine learning, are imported, sharpened and customized for linguistic processing",
        "prob": 0.5315789473684212
    }, {
        "ID": 9680,
        "phrase": " in graph theory, formal language theory, automata theory, parsing technology, complexity theory), probability theory, information theory, machine learning and linguistics",
        "prob": 0.5045454545454545
    }, {
        "ID": 9725,
        "phrase": " n i=1 x ai \u2212 n i=1 x bi ",
        "prob": 0.025
    }, {
        "ID": 9790,
        "phrase": " while pure electronic journals have been established in some areas of computer-science such as ai and mathematical theory, they play a negligible role in the communication systems of many other fields",
        "prob": 0.755
    }, {
        "ID": 9791,
        "phrase": " while pure electronic journals have been established in some areas of computer-science such as ai and mathematical theory, they play a negligible role in the communication systems of many other fields",
        "prob": 0.755
    }, {
        "ID": 9802,
        "phrase": "introduction modal logics of knowledge have been proposed as a formal tool for specifying and reasoning about multi-agent systems in a number of disciplines, including distributed computing  [hm90] , artificial intelligence  [mcc89]  and economics  [aum76, rw90] ",
        "prob": 0.5392857142857143
    }, {
        "ID": 9802,
        "phrase": " they have since been used within computer science and artificial intelligence as semantic structures for logics for belief, logics for knowledge, temporal logics, logics for actions, etc",
        "prob": 0.5499999999999999
    }, {
        "ID": 9819,
        "phrase": " however, it has long been acknowledged that dense or specifically real-numbers time models may be better for many applications, ranging from philosophical, natural language and ai modelling of human reasoning to computing and engineering applications of concurrency, refinement, open systems, analogue devices and metric information",
        "prob": 0.28857142857142853
    }, {
        "ID": 9826,
        "phrase": " if ai 1 , ai 2 are both ground, then [ai 1 , ai 2 ] is a ground annotation",
        "prob": 0.15714285714285717
    }, {
        "ID": 9852,
        "phrase": " this is particularly true since many domains of interest in ai (and other application areas) are finite; any version of cox's theorem that uses par5 is simply not applicable in these domains",
        "prob": 0.255
    }, {
        "ID": 9857,
        "phrase": " on the other hand, horn-like restrictions have been employed to design tractable restrictions of various formalisms of interest in artificial intelligence, for example in constraint programming, temporal reasoning, spatial reasoning, etc",
        "prob": 0.324
    }, {
        "ID": 9866,
        "phrase": "outline most knowledge representation schemes used in ai (and, in particular, in natural language processing) are homogeneous",
        "prob": 0.4357142857142857
    }, {
        "ID": 9874,
        "phrase": "outline most knowledge representation schemes used in ai (and, in particular, in natural language processing) are homogeneous",
        "prob": 0.3642857142857143
    }]
}, {
    "topic_id": 1,
    "top_words": ["learning", "machine", "algorithms", "inductive", "theory", "bias", "search", "tasks", "examples", "programming", "work", "example", "many", "results", "based"],
    "phrases": [{
        "ID": 6,
        "phrase": " this is the traditional machine learning problem",
        "prob": 0.3875
    }, {
        "ID": 6,
        "phrase": " finally, while we have given some examples as to how learning rates can be determined for particular machine learning implementations, we do not have any general method for determining these rates",
        "prob": 0.2833333333333333
    }, {
        "ID": 30,
        "phrase": " we also expound the principles and motivations underlying computational mechanics, emphasizing its connections to the minimum description length principle, pac theory, and other aspects of machine learning",
        "prob": 0.3857142857142857
    }, {
        "ID": 73,
        "phrase": " we also mention that aclp programs can be generated automatically from example data using a machine learning technique called abductive concept learning",
        "prob": 0.4789473684210527
    }, {
        "ID": 74,
        "phrase": " we also mention that aclp programs can be generated automatically from example data using a machine learning technique called abductive concept learning",
        "prob": 0.37368421052631584
    }, {
        "ID": 132,
        "phrase": ",  (quinlan, 1993) ) inductive logic programming, a logic-based approach to machine learning where logic programming rules are inferred from positive and negative examples and a background knowledge (see, e",
        "prob": 0.26521739130434785
    }, {
        "ID": 141,
        "phrase": " \n supervised learning by examples (ex) the ai models provide a frame for reinforcement learning",
        "prob": 0.3153846153846154
    }, {
        "ID": 141,
        "phrase": "8 supervised learning by examples (ex) \n\t\t\t the idea of the best vote algorithm: a general cybernetic or ai system is a chronological program p(x <k ) = y 1:k ",
        "prob": 0.2833333333333334
    }, {
        "ID": 154,
        "phrase": " ai algorithms that find near optimum constellations in large search spaces have already been successfully used for partial solutions of the problem (simulated annealing, genetic algorithms)",
        "prob": 0.36818181818181817
    }, {
        "ID": 155,
        "phrase": " ai algorithms (like simulated annealing and genetic algorithms) and neural networks have proven valuable to search the vast space of possible strategies for a near optimum solution",
        "prob": 0.41363636363636364
    }, {
        "ID": 279,
        "phrase": " this problem is also of practical interest in artificial intelligence, mainly in connection to theory approximation  [18] ",
        "prob": 0.16153846153846155
    }, {
        "ID": 310,
        "phrase": " the positive effect of system combination for non-language processing tasks has been shown in a large body of machine learning work",
        "prob": 0.39444444444444443
    }, {
        "ID": 330,
        "phrase": " because knp is not based on a machine learning method but many hand-made rules, in the knp results \"learning set\" and \"test set\" in the tables have no meanings",
        "prob": 0.4333333333333333
    }, {
        "ID": 337,
        "phrase": " it seems entirely plausible that the ultimate theory of artificial intelligence and, in particular, inductive inference, can achieve human-like results only if the building blocks of the theory, such as kolmogorov complexity, are made sensitive to small variations in the complexity of hypothesis",
        "prob": 0.4517241379310345
    }, {
        "ID": 338,
        "phrase": " it seems entirely plausible that the ultimate theory of artificial intelligence and, in particular, inductive inference, can achieve human-like results only if the building blocks of the theory, such as kolmogorov complexity, are made sensitive to small variations in the complexity of hypothesis",
        "prob": 0.41724137931034483
    }, {
        "ID": 358,
        "phrase": " the issue also marks the debut of a new department, ai in space",
        "prob": 0.11000000000000001
    }, {
        "ID": 403,
        "phrase": " \n now by the definition of \u03c9 p , there is ai \u2032 not \u2208 n \u22c4 such that i \u2032 = i \u2032 obj \u222a i \u2032 not is a minimal model of p ",
        "prob": 0.13749999999999998
    }, {
        "ID": 423,
        "phrase": " there has been other recent work in the ai literature on causality; see, for example,  (heckerman and shachter 1995) ",
        "prob": 0.17500000000000002
    }, {
        "ID": 424,
        "phrase": ") there has also been work in the ai literature on causality",
        "prob": 0.15714285714285717
    }, {
        "ID": 424,
        "phrase": " finally, there is also a great deal of work in ai on formal action theory (see, for example,  [lin 1995; sandewall 1994; reiter 2001 ]), which is concerned with the proper way of incorporating causal relationships into a knowledge base so as to guide actions",
        "prob": 0.4269230769230769
    }, {
        "ID": 425,
        "phrase": " finally, there is also a great deal of work in ai on formal action theory (see, for example,  [lin 1995; sandewall 1994; reiter 2001 ]), which is concerned with the proper way of incorporating causal relationships into a knowledge base so as to guide actions",
        "prob": 0.4269230769230769
    }, {
        "ID": 449,
        "phrase": " this paper is an attempt to put the research done in a more structured way from the machine learning point of view",
        "prob": 0.20666666666666664
    }, {
        "ID": 449,
        "phrase": " for example recent research  [90]  shows that applying machine learning techniques could improve the text classification process compared to the traditional ir techniques",
        "prob": 0.29047619047619044
    }, {
        "ID": 449,
        "phrase": "  [21]  review the emerging research collaborations between the ir and machine learning communities in a special issue of the machine learning journal",
        "prob": 0.41764705882352937
    }, {
        "ID": 660,
        "phrase": "a great deal of work has been done demonstrating the ability of machine learning algorithms to automatically extract linguistic knowledge from annotated corpora",
        "prob": 0.3736842105263158
    }, {
        "ID": 678,
        "phrase": " for example, machine learning process, particularly inductive learning process, data mining process and so on, can be described using procedure schemes",
        "prob": 0.5842105263157894
    }, {
        "ID": 678,
        "phrase": " to study the approximation problem of inductive logic programming and machine learning, the distance of herbrand interpretations is discussed (nienhuys-cheng, 1997, 1998)",
        "prob": 0.6722222222222222
    }, {
        "ID": 679,
        "phrase": " for example, machine learning process, particularly inductive learning process, data mining process and so on, can be described using procedure schemes",
        "prob": 0.5315789473684212
    }, {
        "ID": 679,
        "phrase": " to study the approximation problem of inductive logic programming and machine learning, the distance of herbrand interpretations is discussed (nienhuys-  cheng, 1997 cheng, , 1998 ",
        "prob": 0.6894736842105263
    }, {
        "ID": 680,
        "phrase": " to study the approximation problem of inductive logic programming and machine learning, the distance of herbrand interpretations is discussed (nienhuys-cheng, 1997, 1998)",
        "prob": 0.6722222222222222
    }, {
        "ID": 683,
        "phrase": " general planning algorithms which apply methods incorporating artificial intelligence, are discussed in  (nilsson, 1998) ",
        "prob": 0.22142857142857145
    }, {
        "ID": 725,
        "phrase": " indeed, the inherent relational nature of any information integration framework makes the relational learning framework of ilp particularly appropriate for the aforementioned machine learning tasks within the general task of information integration",
        "prob": 0.30000000000000004
    }, {
        "ID": 785,
        "phrase": " finally, we were curious about the possibility of combining different techniques, including those from statistical and symbolic machine learning",
        "prob": 0.2733333333333333
    }, {
        "ID": 1028,
        "phrase": " the reason for this restriction involves the theoretical model of machine learning assumed by typical ilp implementations",
        "prob": 0.34
    }, {
        "ID": 1034,
        "phrase": " information filtering by ml techniques is widely discussed in the literature: see e",
        "prob": 0.175
    }, {
        "ID": 1060,
        "phrase": " one such context is the work on explanation-based generalization (ebg) in ai  [17] ",
        "prob": 0.31
    }, {
        "ID": 1134,
        "phrase": " it is widely used in the uncertainty in ai community",
        "prob": 0.13749999999999998
    }, {
        "ID": 1209,
        "phrase": " 1 perhaps the concentration of the ai literature on moves rather than strategies is the reason why there seems to be almost no overlap between two major books on learning, each in its field: the theory of learning in games,  fudenberg and levine (1998)  and reinforcement learning: an introduction,  sutton and barto (1998) ",
        "prob": 0.3482758620689655
    }, {
        "ID": 1281,
        "phrase": " with sufficient positive and negative examples, modern machine learning techniques can classify new pages with impressive accuracy",
        "prob": 0.24117647058823527
    }, {
        "ID": 1282,
        "phrase": " the machine learning algorithms specified here are described later in the glossary",
        "prob": 0.4636363636363637
    }, {
        "ID": 1282,
        "phrase": "  \n glossary of machine learning terminology for a more detailed description of machine learning,  [71]  provides an excellent overview of machine learning techniques, as does  [44] ",
        "prob": 0.2833333333333333
    }, {
        "ID": 1282,
        "phrase": "18 7 glossary of machine learning terminology ",
        "prob": 0.3875
    }, {
        "ID": 1291,
        "phrase": " research in ai can also benefit from results in music research; in music, for example, aspects such as time and hierarchical structure are inherent to the domain",
        "prob": 0.1823529411764706
    }, {
        "ID": 1337,
        "phrase": " with sufficient positive and negative examples, modern machine learning techniques can classify new pages with impressive accuracy",
        "prob": 0.24117647058823527
    }, {
        "ID": 1387,
        "phrase": "  aha and bankert (1994)  give a good introduction to methods for selecting relevant features for machine learning tasks",
        "prob": 0.25625000000000003
    }, {
        "ID": 1422,
        "phrase": " two are described in this paper -partial evaluation (pe; a technique from the programming languages community  [7] ) and explanation-based generalization (ebg; a technique from the ai community  [3] )",
        "prob": 0.268421052631579
    }, {
        "ID": 1483,
        "phrase": " as a whole, the machine learning algorithms clearly surpass the random-choice baseline of 50%",
        "prob": 0.4692307692307693
    }, {
        "ID": 1634,
        "phrase": " \n reinforcement learning algorithms reinforcement learning (rl)  [14]  is a branch of machine learning that is increasingly finding use in many important applications, including routing",
        "prob": 0.24285714285714288
    }, {
        "ID": 1634,
        "phrase": " finally rl algorithms, unlike other machine learning algorithms, do not have an explicit learning phase followed by evaluation",
        "prob": 0.38125
    }, {
        "ID": 1839,
        "phrase": " it still lacks many properties desirable in a behaviours virtual laboratory, but at this stage it would be already useful for biologists and ai researchers",
        "prob": 0.22777777777777775
    }, {
        "ID": 1880,
        "phrase": " classical machine learning algorithms have a fixed bias, which is implicit in their design",
        "prob": 0.3416666666666667
    }, {
        "ID": 1880,
        "phrase": " more recent work in machine learning has been concerned with algorithms that shift bias dynamically, as they search for a concept  (utgoff and mitchell, 1982; utgoff, 1986; tcheng et al",
        "prob": 0.6894736842105263
    }, {
        "ID": 1880,
        "phrase": " statistical bias is defined somewhat differently from bias in machine learning",
        "prob": 0.42500000000000004
    }, {
        "ID": 1880,
        "phrase": " \n shift of bias algorithms that shift their bias do not avoid the conservation theorems (\"no free lunch\" theorems) that have recently received much attention in the machine learning community  (schaffer, 1994; wolpert, 1992 wolpert, , 1994 ",
        "prob": 0.484
    }, {
        "ID": 1880,
        "phrase": " \n discussion aside from their interest to students of the baldwin effect, we believe that the above experiments are relevant for machine learning research in bias shifting algorithms and for evolutionary psychology",
        "prob": 0.5285714285714287
    }, {
        "ID": 1880,
        "phrase": "25 = [ ] \n how to shift bias the machine learning community is moving away from the idea of a \"universal learning algorithm\", toward the recognition that all learning involves bias  (utgoff, 1986; utgoff & mitchell, 1982)  and that the right bias must depend on the learner's environment  (schaffer, 1994; wolpert, 1992 wolpert, , 1994  research in shift of bias has not previously reported anything like the baldwin effect",
        "prob": 0.5390243902439025
    }, {
        "ID": 1880,
        "phrase": " we believe that the lessons learned here apply generally to the research in machine learning in bias shifting algorithms, even when the algorithms do not use evolutionary computation",
        "prob": 0.40499999999999997
    }, {
        "ID": 1880,
        "phrase": " although our model allows pure learning (no bias) and pure instinct (all bias), we believe that such extremes are not likely to occur, either in more complex animals (vertebrates) or in more complex machine learning applications",
        "prob": 0.244
    }, {
        "ID": 1880,
        "phrase": " when the machine learning bias strength is 1 ( ), the magnitude of the statistical bias is 0 if and 1 if ",
        "prob": 0.6454545454545455
    }, {
        "ID": 1880,
        "phrase": " that is, maximal machine learning bias strength results in minimal variance",
        "prob": 0.5916666666666667
    }, {
        "ID": 1880,
        "phrase": " maximally strong and correct machine learning bias results in minimal statistical bias",
        "prob": 0.22142857142857145
    }, {
        "ID": 1880,
        "phrase": " maximally strong and incorrect machine learning bias results in maximal statistical bias",
        "prob": 0.2928571428571429
    }, {
        "ID": 1880,
        "phrase": " when the machine learning bias strength is 0 ( ), the magnitude of the statistical bias is , for both and ",
        "prob": 0.6454545454545455
    }, {
        "ID": 1880,
        "phrase": " that is, minimal machine learning bias strength results in a low but non-minimal statistical bias (assuming is a small positive value, as it was in our experiments)",
        "prob": 0.5549999999999999
    }, {
        "ID": 1880,
        "phrase": " the worst case for variance happens when the machine learning bias strength is 0",
        "prob": 0.42500000000000004
    }, {
        "ID": 1880,
        "phrase": " 7 the statistical and machine learning bias of the i-th guess",
        "prob": 0.41000000000000003
    }, {
        "ID": 1880,
        "phrase": " this high variance may help to explain why there is selection pressure for weak (machine learning) bias when the (machine learning) bias correctness is low",
        "prob": 0.355
    }, {
        "ID": 1880,
        "phrase": " in machine learning, these other factors are called the bias of the learner",
        "prob": 0.51
    }, {
        "ID": 1881,
        "phrase": " nonetheless the algorithms presented here are i hope of general interest as pieces of computational linguistics or machine learning research",
        "prob": 0.19375
    }, {
        "ID": 1881,
        "phrase": " supervised learning encompasses most of the traditional types of machine learning, and has been studied in great detail",
        "prob": 0.5071428571428571
    }, {
        "ID": 1885,
        "phrase": "research on bias in machine learning algorithms has generally been concerned with the impact of bias on predictive accuracy",
        "prob": 0.54
    }, {
        "ID": 1886,
        "phrase": " in general, machine learning algorithms tend to be nonparametric (in the statistical sense of \"parametric\"), thus this theory of cross-validation error is particularly suitable for machine learning",
        "prob": 0.18636363636363634
    }, {
        "ID": 1891,
        "phrase": " this is why many papers are concerned with the \"learning curve\" (performance as a function of the sample size) of a machine learning algorithm",
        "prob": 0.31875000000000003
    }, {
        "ID": 1892,
        "phrase": "introduction a large body of research in machine learning is concerned with algorithms for classifying observations, where the observations are described by vectors in a multidimensional space of features",
        "prob": 0.5050000000000001
    }, {
        "ID": 1893,
        "phrase": " \n bias direction: bias is a familiar concept in machine learning: every inductive learner requires a bias in order to select one hypothesis from the infinite set of hypotheses that are consistent with a given set of observations  (haussler, 1988; rendell, 1986; utgoff, 1986) ",
        "prob": 0.4517241379310345
    }, {
        "ID": 1894,
        "phrase": "   (1995)  adjustment explicit  widmer and kubat (1992 , 1993  selection implicittemporal sequence  widmer (1996)  selection explicit \n conclusion this paper briefly surveyed the literature on machine learning in context-sensitive domains",
        "prob": 0.21250000000000002
    }, {
        "ID": 1894,
        "phrase": " \n table 1 : 1 some examples from the machine learning literature",
        "prob": 0.34444444444444444
    }, {
        "ID": 1894,
        "phrase": "in this paper, we review five heuristic strategies for handling context-sensitive features in supervised machine learning from examples",
        "prob": 0.24117647058823527
    }, {
        "ID": 1895,
        "phrase": " we assume the standard machine learning model of concept learning, where data are represented as vectors in a multi-dimensional feature space",
        "prob": 0.22777777777777775
    }, {
        "ID": 1895,
        "phrase": " recent work has demonstrated that strategies for exploiting contextual information can improve the performance of machine learning algorithms  (bergadano et al",
        "prob": 0.24117647058823527
    }, {
        "ID": 1898,
        "phrase": "introduction a large body of research in machine learning is concerned with algorithms for classifying observations, where the observations are described by vectors in a multidimensional space of features",
        "prob": 0.45499999999999996
    }, {
        "ID": 1980,
        "phrase": " for many decades, however, ai researchers have not paid a lot of attention to the theory of inductive inference",
        "prob": 0.5071428571428572
    }, {
        "ID": 1980,
        "phrase": " since inductive inference is at the heart of all inductive sciences, some of the results are relevant not only for ai and computer science but also for physics, provoking nontraditional predictions based on zuse's thesis of the computer-generated universe",
        "prob": 0.42083333333333334
    }, {
        "ID": 1981,
        "phrase": " for many decades, however, ai researchers have not paid a lot of attention to the theory of inductive inference",
        "prob": 0.5071428571428572
    }, {
        "ID": 1981,
        "phrase": " since inductive inference is at the heart of all inductive sciences, some of the results are relevant not only for ai and computer science but also for physics, provoking nontraditional predictions based on zuse's thesis of the computer-generated universe",
        "prob": 0.37916666666666665
    }, {
        "ID": 1984,
        "phrase": " \n how the research relates to other research on machine learning the way in which this research relates to other work on machine learning is best seen in terms of the goals of the research, just described",
        "prob": 0.3857142857142857
    }, {
        "ID": 2121,
        "phrase": " from the tables, the following observations can be made: best-first search in cyclic and/or graphs had been a long-unresolved problem of artificial intelligence",
        "prob": 0.2157894736842105
    }, {
        "ID": 2333,
        "phrase": " \n on the foundations of machine learning instead of addressing machine learning directly, let us first consider a different research area such as algorithm and complexity theory",
        "prob": 0.2318181818181818
    }, {
        "ID": 2333,
        "phrase": " we propose occam's razor, quantified in terms of solomonoff-kolmogorov complexity, combined with the chain rule for conditional probabilities, and possibly sequential decision theory as a rigorous mathematical/axiomatic definition of machine learning",
        "prob": 0.23461538461538464
    }, {
        "ID": 2333,
        "phrase": " machine learning theory will derive results on convergence speed and approximation quality of the various approximation schemes",
        "prob": 0.5062500000000001
    }, {
        "ID": 2333,
        "phrase": " only a minority will investigate non-standard ml by modifying or replacing occam's razor \"axiom\" in the hope of finding something better",
        "prob": 0.17222222222222222
    }, {
        "ID": 2333,
        "phrase": " \n assumptions, problems, limitations just as every approach to ai (or any other field) makes assumptions and has its problems and limitations, so does aixi(tl)",
        "prob": 0.20666666666666667
    }, {
        "ID": 2333,
        "phrase": " 4 2 (notation and emphasis in ai versus control theory) the upper part ( =) of the table compares notation used in ai or reinforcement learning to notation used in control theory",
        "prob": 0.1952380952380952
    }, {
        "ID": 2396,
        "phrase": " much of the prior work on learning in games in the machine learning literature did not consider such a metric of the performance of a learning strategy  (littman, 1994; hu & wellman, 1998) ",
        "prob": 0.255
    }, {
        "ID": 2455,
        "phrase": " researchers in machine learning and the philosophy of induction have long realized that bias is an inevitable component of effective inductive reasoning",
        "prob": 0.24117647058823527
    }, {
        "ID": 2480,
        "phrase": " in section 4 we show that assumptions made by several different popular machine learning algorithms can be easily expressed in terms of interactions, and that many heuristics in machine learning arise from quantifications of interaction magnitude",
        "prob": 0.2730769230769231
    }, {
        "ID": 2480,
        "phrase": " feature selection algorithms are not the only algorithms in machine learning with myopia",
        "prob": 0.6454545454545455
    }, {
        "ID": 2481,
        "phrase": " handling interactions in supervised learning the machine learning community has long been aware of interactions, and many methods have been developed to deal with them",
        "prob": 0.33888888888888885
    }, {
        "ID": 2481,
        "phrase": " feature selection algorithms are not the only algorithms in machine learning that suffer from myopia",
        "prob": 0.675
    }, {
        "ID": 2482,
        "phrase": " \n handling interactions in supervised learning the machine learning community has long been aware of interactions, and many methods have been developed to deal with them",
        "prob": 0.3944444444444445
    }, {
        "ID": 2482,
        "phrase": " feature selection algorithms are not the only algorithms in machine learning that suffer from myopia",
        "prob": 0.675
    }, {
        "ID": 2521,
        "phrase": "introduction the engineering of multiagent systems composed of learning agents brings together techniques from machine learning, game theory, utility theory, and complex systems",
        "prob": 0.23181818181818187
    }, {
        "ID": 2521,
        "phrase": " we believe that systems where agents share partial results or otherwise help each other can be considered extension on traditional machine learning research",
        "prob": 0.2833333333333333
    }, {
        "ID": 2597,
        "phrase": " similar drawbacks hold for lenat's human-assisted, non-autonomous, self-modifying learner  [21] , our meta-genetic programming  [29]  extending cramer's genetic programming  [8, 1] , our metalearning economies  [29]  extending holland's machine learning economies  [14] , and gradient-based metalearners for continuous program spaces of differentiable recurrent neural networks  [31, 12] ",
        "prob": 0.8999999999999999
    }, {
        "ID": 2598,
        "phrase": " similar drawbacks hold for lenat's human-assisted, non-autonomous, self-modifying learner  [21] , our meta-genetic programming  [29]  extending cramer's genetic programming  [8, 1] , our metalearning economies  [29]  extending holland's machine learning economies  [14] , and gradient-based metalearners for continuous program spaces of differentiable recurrent neural networks  [31, 12] ",
        "prob": 0.8743589743589743
    }, {
        "ID": 2599,
        "phrase": " similar drawbacks hold for lenat's human-assisted, non-autonomous, self-modifying learner  [21] , our meta-genetic programming  [29]  extending cramer's genetic programming  [8, 1] , our metalearning economies  [29]  extending holland's machine learning economies  [14] , and gradient-based metalearners for continuous program spaces of differentiable recurrent neural networks  [31, 12] ",
        "prob": 0.8743589743589743
    }, {
        "ID": 2600,
        "phrase": "introduction and outline all traditional algorithms for problem solving / machine learning / reinforcement learning  [20]  are hardwired",
        "prob": 0.4733333333333334
    }, {
        "ID": 2600,
        "phrase": " similar drawbacks hold for lenat's humanassisted, non-autonomous, self-modifying learner  [23] , our meta-genetic programming  [34]  extending cramer's genetic programming  [8, 1] , our metalearning economies  [34]  extending holland's machine learning economies  [15] , and gradient-based metalearners for continuous program spaces of differentiable recurrent neural networks  [36, 13] ",
        "prob": 0.8710526315789472
    }, {
        "ID": 2600,
        "phrase": " also note that the machine learning literature is full of human-generated proofs of properties of methods for dealing with stochastic environments",
        "prob": 0.41764705882352937
    }, {
        "ID": 2601,
        "phrase": "introduction and outline all traditional algorithms for problem solving / machine learning / reinforcement learning  [20]  are hardwired",
        "prob": 0.4066666666666667
    }, {
        "ID": 2601,
        "phrase": " similar drawbacks hold for lenat's humanassisted, non-autonomous, self-modifying learner  [23] , our meta-genetic programming  [34]  extending cramer's genetic programming  [8, 1] , our metalearning economies  [34]  extending holland's machine learning economies  [15] , and gradient-based metalearners for continuous program spaces of differentiable recurrent neural networks  [36, 13] ",
        "prob": 0.8710526315789472
    }, {
        "ID": 2601,
        "phrase": " also note that the machine learning literature is full of human-generated proofs of properties of methods for dealing with stochastic environments",
        "prob": 0.4764705882352941
    }, {
        "ID": 2614,
        "phrase": "introduction in this paper we apply a new method for model selection on large data sets using the artificial intelligence algorithm adaptive simulated annealing (asa)",
        "prob": 0.1952380952380952
    }, {
        "ID": 2760,
        "phrase": " towards this end, an important goal in machine learning theory is to design attribute efficient algorithms for learning various classes of boolean functions",
        "prob": 0.32105263157894737
    }, {
        "ID": 2828,
        "phrase": " researchers in machine learning have long realized that bias is an inevitable component of effective inductive reasoning (i",
        "prob": 0.20666666666666667
    }, {
        "ID": 2941,
        "phrase": " the field of machine learning is concerned with the question of how to construct algorithms that automatically improve with experience  [?] ",
        "prob": 0.65
    }, {
        "ID": 2941,
        "phrase": " \u2022 building arguments: finding hypotheses which explain unseen instances is central to most ml algorithms",
        "prob": 0.29285714285714287
    }, {
        "ID": 2941,
        "phrase": "the field of machine learning (ml) is concerned with the question of how to construct algorithms that automatically improve with experience",
        "prob": 0.6066666666666667
    }, {
        "ID": 2942,
        "phrase": " the field of machine learning is concerned with the question of how to construct algorithms that automatically improve with experience  [mit97] ",
        "prob": 0.4357142857142857
    }, {
        "ID": 2942,
        "phrase": " \n \u2022 building arguments: finding hypotheses which explain unseen instances is central to most ml algorithms",
        "prob": 0.2928571428571429
    }, {
        "ID": 2942,
        "phrase": " many theoretical results from argument theory could therefore be applied in a ml context",
        "prob": 0.22142857142857145
    }, {
        "ID": 2942,
        "phrase": "the field of machine learning (ml) is concerned with the question of how to construct algorithms that automatically improve with experience",
        "prob": 0.54
    }, {
        "ID": 3047,
        "phrase": " machine learning programs",
        "prob": 0.15714285714285717
    }, {
        "ID": 3084,
        "phrase": "introduction the minimum description length (mdl) principle is one of the most important concepts in machine learning, and serves as a scientific guide, in general",
        "prob": 0.33888888888888885
    }, {
        "ID": 3145,
        "phrase": " section 3 is devoted to introduction of the machine learning techniques utilized in our work",
        "prob": 0.25833333333333336
    }, {
        "ID": 3192,
        "phrase": " there have been many proposals for incorporating \"advanced features\" such as sets or rules into object-oriented languages, especially in the ai community",
        "prob": 0.25625000000000003
    }, {
        "ID": 3208,
        "phrase": " furthermore, knowledge reduction can be regarded as a process of selective inductive machine learning",
        "prob": 0.5461538461538462
    }, {
        "ID": 3208,
        "phrase": " \n reduction as inductive machine learning: a casual discussion it is too dread a task to discuss even some aspects of machine learning here",
        "prob": 0.4764705882352941
    }, {
        "ID": 3208,
        "phrase": " from the previous discussion, it is clear that knowledge reduction is a kind of selective inductive machine learning",
        "prob": 0.4357142857142857
    }, {
        "ID": 3208,
        "phrase": " then, if knowledge reduction is a kind of selective inductive machine learning, where does the generalization comes from? generalization seems coming from loss of demarcation information in the reduction process",
        "prob": 0.4809523809523809
    }, {
        "ID": 3208,
        "phrase": " if it doesn't change the demarcation relation, in my view it cannot be called inductive machine learning in current universe, although it possibly does reduce some redundant attributes",
        "prob": 0.155
    }, {
        "ID": 3228,
        "phrase": "introduction estimation of distribution algorithms (edas)  [1, 2]  , also called probabilistic modelbuilding algorithms (pmbgas)  [3]  and iterated density estimation evolutionary algorithms (ideas)  [4] , are stochastic techniques that combine genetic and evolutionary algorithms, machine learning, and statistics",
        "prob": 0.4172413793103449
    }, {
        "ID": 3305,
        "phrase": " improved machine learning methods will also be critical",
        "prob": 0.23333333333333334
    }, {
        "ID": 3331,
        "phrase": " o 3 rtaa relies on the agent paradigm for building intelligent software applications, while taking advantage of machine learning algorithms and data mining methodologies for extracting knowledge",
        "prob": 0.23181818181818184
    }, {
        "ID": 3346,
        "phrase": " many machine learning tasks are or can be reduced to sequence prediction tasks",
        "prob": 0.42500000000000004
    }, {
        "ID": 3346,
        "phrase": " moreover, we can then conclude good properties for other machine learning tasks such as classification, as discussed in the introduction",
        "prob": 0.4357142857142857
    }, {
        "ID": 3406,
        "phrase": " our view is appropriate for programming languages such as java and ml that can manipulate structures using destructive updates",
        "prob": 0.20666666666666664
    }, {
        "ID": 3842,
        "phrase": " it seems likely that some schemes are easier for machine learning than others",
        "prob": 0.2818181818181818
    }, {
        "ID": 3907,
        "phrase": " however, connectionist systems (the symbolic ai counterpart) seems to be in the right way, exploring the relations and capabilities among many simple parts, into the emergence of what we experience as a coherent and cognitive whole",
        "prob": 0.12916666666666668
    }, {
        "ID": 4019,
        "phrase": " content-based filtering solutions, particularly those based on machine learning, have been the most effective anti-spam treatment to date",
        "prob": 0.1823529411764706
    }, {
        "ID": 4552,
        "phrase": " most of the research so far has involved hand coding of these higher level strategies or adapting machine learning techniques such as reinforcement learning  [17] ",
        "prob": 0.2833333333333333
    }, {
        "ID": 4552,
        "phrase": " the exception structure of rdr has been used for representation for machine learning  [24] [25] [26] , it was found to tend to produce more compact kbs than other representations  [27] ",
        "prob": 0.1823529411764706
    }, {
        "ID": 4571,
        "phrase": " additive models were brought further to the attention of the machine learning community by e",
        "prob": 0.37272727272727274
    }, {
        "ID": 4643,
        "phrase": "2) \n genetic algorithms ga is a model of machine learning which derives its behavior form a metaphor of the processes of evolution in nature",
        "prob": 0.31875
    }, {
        "ID": 4653,
        "phrase": "introduction generalization is one of the basic notions in machine learning",
        "prob": 0.41000000000000003
    }, {
        "ID": 4654,
        "phrase": "introduction generalization is one of the basic notions in machine learning",
        "prob": 0.41000000000000003
    }, {
        "ID": 4693,
        "phrase": " our next step will be to generate a multiple source model using machine learning algorithms (most probably svms), to confirm the hints provided by the experiments shown in this paper",
        "prob": 0.1409090909090909
    }, {
        "ID": 4694,
        "phrase": " the wavelet transformation shows how time variant properties can be exploited using machine learning (ml) tools",
        "prob": 0.25625000000000003
    }, {
        "ID": 4736,
        "phrase": " machine learning is still mainly concerned with categorical prediction, but the situation appears to be changing",
        "prob": 0.22142857142857145
    }, {
        "ID": 4749,
        "phrase": " to establish properties of prediction algorithms, the traditional theory of machine learning makes some assumptions about the way reality generates the examples; e",
        "prob": 0.7833333333333333
    }, {
        "ID": 4750,
        "phrase": " to establish properties of prediction algorithms, the traditional theory of machine learning makes some assumptions about the way reality generates the examples; e",
        "prob": 0.7833333333333333
    }, {
        "ID": 4751,
        "phrase": " to establish properties of forecasting algorithms, the traditional theory of machine learning makes some assumptions about the way reality generates the observations; e",
        "prob": 0.7833333333333333
    }, {
        "ID": 4752,
        "phrase": " to establish properties of forecasting algorithms, the traditional theory of machine learning makes some assumptions about the way reality generates the observations; e",
        "prob": 0.6722222222222222
    }, {
        "ID": 4876,
        "phrase": "introduction this paper proposes a new way of modelling machine learning (ml), inspired by streambased active learning but more accurately reflecting strategies humans employ when working with trainers and more directly addressing the needs of users reluctant to risk effort integrating ml algorithms",
        "prob": 0.17941176470588235
    }, {
        "ID": 4948,
        "phrase": " this illustrates how difficult these simple non markov environments are for a genetic-based machine learning system",
        "prob": 0.29285714285714287
    }, {
        "ID": 4963,
        "phrase": " thus, it is enough to show that sup \n\t\t\t parts of the results were reported on international conference on machine learning, 2004, [25] , and on 15th international conference on algorithmic learning theory, 2004, [26] ",
        "prob": 0.2904761904761905
    }, {
        "ID": 5019,
        "phrase": " the special case \"\uf06a(d) = const\" represents the main idea of a concept in machine learning, see for example  [14] ",
        "prob": 0.34
    }, {
        "ID": 5020,
        "phrase": " the special case \"\uf06a(d) = const\" represents the main idea of a concept in machine learning, see for example  [14] ",
        "prob": 0.34
    }, {
        "ID": 5021,
        "phrase": " the special case \"v(op(d)) = const\" represents the main idea of a concept in machine learning, see for example  [10] ",
        "prob": 0.3812500000000001
    }, {
        "ID": 5130,
        "phrase": "introduction today, data mining and machine learning is typically treated in a problem-specific way: people propose algorithms to solve a particular problem (such as learning to classify points in a vector space), they prove properties and performance guarantees of their algorithms (e",
        "prob": 0.19677419354838707
    }, {
        "ID": 5210,
        "phrase": " the ml estimator is invariant to non-equiprobable symbols and gives the same results even if q = 1  [6] ",
        "prob": 0.16153846153846155
    }, {
        "ID": 5345,
        "phrase": " combinatorial discrepancy is very valuable when derandomizing geometric algorithms; it also appears in machine learning as the relevant function for the minimum disagreement problem, where red and blue points are thought of as good and bad examples for a classifier, and the regions are hypotheses",
        "prob": 0.3607142857142857
    }, {
        "ID": 5345,
        "phrase": " this solves the minimum disagreement problem from machine learning, where an algorithm finds the region with the most good points and the fewest bad points, a key subroutine in agnostic pac learning",
        "prob": 0.2217391304347826
    }, {
        "ID": 5384,
        "phrase": " in perspective, we expect that a reuse oriented community will enforce standards which not only that will speed up considerably the manual assembling process but will open the way to automatic interface matching (search \u2192 (down)load \u2192 paste \u2192 configure) managed by ai modules",
        "prob": 0.22592592592592592
    }, {
        "ID": 5469,
        "phrase": " \n evolutionary programming traditional ep  [11]  was concerned with evolving finite state automata for machine learning tasks",
        "prob": 0.31875
    }, {
        "ID": 5469,
        "phrase": " \n genetic programming the youngest brother of the family  [14, 2]  has a specific application area in machine learning and modeling tasks",
        "prob": 0.31875000000000003
    }, {
        "ID": 5469,
        "phrase": " computerbased evolutionary processes can also be used as efficient problem solvers for optimization, constraint handling, machine learning and modeling tasks",
        "prob": 0.22777777777777775
    }, {
        "ID": 5568,
        "phrase": " in machine learning, automated search over a wide variety of model types may be of great advantage",
        "prob": 0.34
    }, {
        "ID": 5689,
        "phrase": "ch/machine learning",
        "prob": 0.18333333333333332
    }, {
        "ID": 5959,
        "phrase": " finally, a panel-aggregation problem is addressed in the \"online\" learning model, which is frequently studied in the machine learning community; see, for example, references  [7] ,  [11]  and  [19] ",
        "prob": 0.20500000000000004
    }, {
        "ID": 5969,
        "phrase": " 7 clearly, m ai (0 4 k ) accepts if and only if 0 4 k / \u2208 l ai ",
        "prob": 0.18333333333333332
    }, {
        "ID": 5969,
        "phrase": " by the definition of l ai , 0 4 k \u2208 l ai if and only if m a \u2032 (0 4 k ) rejects",
        "prob": 0.18333333333333332
    }, {
        "ID": 6133,
        "phrase": " maximal constraint languages have also been studied in the context of machine learning  [24]  and quantified csps  [18] , and they attract a great deal of attention in universal algebra, cf",
        "prob": 0.305
    }, {
        "ID": 6193,
        "phrase": " other researchers have studied algorithms for ml estimation based on stochastic approximation  [36, 1] , which again are consistent under appropriate assumptions, but can be slow to converge",
        "prob": 0.3
    }, {
        "ID": 6398,
        "phrase": " the recursive search represents a natural method for realization of such strategies of the artificial intelligence as the graph search",
        "prob": 0.20666666666666664
    }, {
        "ID": 6398,
        "phrase": " machine learning  (luger, 2003) , be it symbolic, neuronet or emergent (genetic algorithms) learning, is based on the presentation of a priori preset training examples",
        "prob": 0.42631578947368426
    }, {
        "ID": 6408,
        "phrase": " overfitting is a common problem in machine learning",
        "prob": 0.34444444444444444
    }, {
        "ID": 6603,
        "phrase": "introduction the task of learning ranked retrieval functions has recently received significant interest in the machine learning community  (bartell & cottrell, 1995; freund et al",
        "prob": 0.305
    }, {
        "ID": 6724,
        "phrase": " comparing different machine learning algorithms for speed is notoriously difficult; we are simultaneously judging mathematical algorithms and specific implementations",
        "prob": 0.33888888888888885
    }, {
        "ID": 7083,
        "phrase": " we recall here that dees is able to output automata with a minimal number of parameters which is clearly an advantage from a machine learning standpoint, especially for dealing with small datasets",
        "prob": 0.24285714285714283
    }, {
        "ID": 7084,
        "phrase": " we recall here that dees is able to output automata with a minimal number of parameters which is clearly an advantage from a machine learning standpoint, especially for dealing with small datasets",
        "prob": 0.33809523809523806
    }, {
        "ID": 7408,
        "phrase": " as for \u2704 \u03b2 and \u2192 \u03b2 , in the orthogonal case, a complete development of \u2192 ai can be simulated by one step \u2704 ai -reduction",
        "prob": 0.19090909090909092
    }, {
        "ID": 7409,
        "phrase": " as for \u2704 \u03b2 and \u2192 \u03b2 , in the orthogonal case, a complete development of \u2192 ai can be simulated by one step \u2704 ai -reduction",
        "prob": 0.19090909090909092
    }, {
        "ID": 7409,
        "phrase": " because \u03c3 \u2032 \u2704 ai \u03b8 \u2032 , it suffices to prove that l\u03c3 \u2032 \u2192 ai r\u03c3 \u2032 ",
        "prob": 0.18333333333333335
    }, {
        "ID": 7476,
        "phrase": " (in general, attention to the constants is a tradition in learning theory that distinguishes it from some parts of the theory of function spaces; probably the impetus is coming from experimental machine learning with its common struggle for small improvements in the performance of prediction algorithms",
        "prob": 0.46785714285714286
    }, {
        "ID": 7613,
        "phrase": " (a) example graph; user-specified (positive) examples are circled, negative edges are highlighted in grey; (b) negative examples; (c) positive lattice generated by our machine learning algorithm; positive hypotheses are circled; (d) positive hypotheses after relaxation; (e) subgraphs found by the gp mining algorithm",
        "prob": 0.5029411764705882
    }, {
        "ID": 7812,
        "phrase": " this online algorithm, which is called \"exponentiated gradient\" in the machine learning literature, attains similar performance guarantees to the \"online gradient descent\" algorithm of zinkevich [zin03]",
        "prob": 0.36818181818181817
    }, {
        "ID": 7921,
        "phrase": " admittedly, this is a strong assumption, and areas of machine learning are emerging that rely on other assumptions (such as the markovian assumption of reinforcement learning; see, e",
        "prob": 0.33888888888888885
    }, {
        "ID": 7921,
        "phrase": " \n ideal hedged predictions the most basic problem of machine learning is perhaps the following",
        "prob": 0.23846153846153845
    }, {
        "ID": 7921,
        "phrase": " these measures are provably valid under the assumption of randomness, traditional in machine learning: the objects and their labels are assumed to be generated independently from the same probability distribution",
        "prob": 0.26842105263157895
    }, {
        "ID": 8108,
        "phrase": " \n formal background and notations supervised machine learning takes as input a dataset e = {(x i , y i ), i = 1 ",
        "prob": 0.3153846153846154
    }, {
        "ID": 8108,
        "phrase": " as the well-known no free lunch theorem applies to machine learning too, no learning method is expected to be universally competent",
        "prob": 0.1823529411764706
    }, {
        "ID": 8111,
        "phrase": " in opposition, discriminative ml focuses on the most discriminant hypotheses in the whole search space; it does not consider the relevance of a hypothesis with respect to the background knowledge per se",
        "prob": 0.268421052631579
    }, {
        "ID": 8248,
        "phrase": " a facility for self-modification or systems improvement is a far way off for ai entities, what to say of natural selection",
        "prob": 0.20666666666666667
    }, {
        "ID": 8557,
        "phrase": " many attempts have been made to construct rotation and translation invariant representations both in the vision community and in the machine learning world",
        "prob": 0.711764705882353
    }, {
        "ID": 8557,
        "phrase": " finally, we believe that the general concept of bispectra ought to be of interest to the machine learning community as it moves towards addressing learning tasks on more and more intricately structured data",
        "prob": 0.6863636363636364
    }, {
        "ID": 8558,
        "phrase": " many attempts have been made to construct rotation and translation invariant representations both in the vision community and in the machine learning world",
        "prob": 0.711764705882353
    }, {
        "ID": 8558,
        "phrase": " finally, we believe that the general concept of bispectra ought to be of interest to the machine learning community as it moves towards addressing learning tasks on more and more intricately structured data",
        "prob": 0.7318181818181817
    }, {
        "ID": 8559,
        "phrase": " there have been many attempts to construct rotation and translation invariant representations both in the vision community and in the machine learning world",
        "prob": 0.6937500000000001
    }, {
        "ID": 8559,
        "phrase": " finally, we believe that the general concept of bispec-tra ought to be of interest to the machine learning community as it moves towards addressing learning tasks on more and more intricately structured data",
        "prob": 0.6999999999999998
    }, {
        "ID": 9086,
        "phrase": " in this case other machine learning approaches would be more appropriate (e",
        "prob": 0.31
    }, {
        "ID": 9240,
        "phrase": "introduction much recent research in ai and machine learning is addressing the problem of learning relations from examples, especially under the title of inductive logic programming  (muggleton, 1991) ",
        "prob": 0.6238095238095238
    }, {
        "ID": 9240,
        "phrase": "2 why standard approaches cannot be used? most machine learning algorithms generate rules or clauses one at a time and independently of each other: if a rule is useful (it covers some positive example) and correct (it does not cover any negative example), then it is added to the description or program which is being generated, until all positive examples have been covered",
        "prob": 0.45483870967741935
    }, {
        "ID": 9249,
        "phrase": " this last result is somewhat surprising since one gets the impression from reading the machine learning literature  (muggleton, srinivasan, & bain, 1992 ) that the smaller hypothesis (i",
        "prob": 0.355
    }, {
        "ID": 9257,
        "phrase": " while there are no common machine learning algorithms explained in this section, the operations explained are the mathematical basis of most fast learning algorithms",
        "prob": 0.3
    }, {
        "ID": 9261,
        "phrase": ",  sutton, 1984; watkins, 1989; barto, 1992; sutton, barto, & williams, 1991; lin, 1992 lin, , 1993 cichosz, 1994)  is a machine learning paradigm that relies on evaluative training information",
        "prob": 0.505
    }, {
        "ID": 9262,
        "phrase": " nevertheless, the uci promoter sequences database of examples and domain theory has remained a prominent testbed for evaluating machine learning methods",
        "prob": 0.26842105263157895
    }, {
        "ID": 9263,
        "phrase": " this is a common approach to classification in the machine learning literature",
        "prob": 0.31
    }, {
        "ID": 9264,
        "phrase": " since the long-term goal of machine learning is to use data, inference, and theory to improve any and all of them, we believe that a consideration of these related methods can be bene cial, particularly because each research area has some strengths that the other lacks",
        "prob": 0.23461538461538461
    }, {
        "ID": 9266,
        "phrase": " we apply reinforcement learning, as discussed in the recent ai literature, to that model and investigate the properties of the related process",
        "prob": 0.4066666666666666
    }, {
        "ID": 9267,
        "phrase": " the role of such de nitions in ai is to ensure that theory and practice are correctly aligned",
        "prob": 0.19090909090909092
    }, {
        "ID": 9268,
        "phrase": " logic-based relational learning often involves noisy examples that reect a relatively complex underlying relationship; it is a natural extension of propositional machine learning, and has already enjoyed a number of experimental successes",
        "prob": 0.3
    }, {
        "ID": 9271,
        "phrase": "introduction inductive logic programming (ilp) is a growing subtopic of machine learning that studies the induction of prolog programs from examples in the presence of background knowledge  (muggleton, 1992; lavra c & d zeroski, 1994) ",
        "prob": 0.3791666666666667
    }, {
        "ID": 9272,
        "phrase": " the presented paris approach uses experience to improve problem solving, similar to several approaches from machine learning, mostly from explanation-based learning  (mitchell et al",
        "prob": 0.36818181818181817
    }, {
        "ID": 9277,
        "phrase": " since many of the terms in machine learning are derived from the cognitive sciences, it will not be di cult to show the similarities between our algorithm and this characterization of human learning",
        "prob": 0.268421052631579
    }, {
        "ID": 9278,
        "phrase": " this is a maxim for machine learning systems in general (if you have knowledge, use it), and is particularly relevant for learning from instruction because learning is expected to happen quickly",
        "prob": 0.4263157894736842
    }, {
        "ID": 9278,
        "phrase": " the use of explanation to produce general learning has been a common theme in machine learning (e",
        "prob": 0.31538461538461543
    }, {
        "ID": 9281,
        "phrase": " this contrasts with the seemingly widespread assumption that the sizes of the search spaces involved in machine learning require the use of heuristic search",
        "prob": 0.44999999999999996
    }, {
        "ID": 9281,
        "phrase": " search is used in machine learning in an attempt to uncover classifiers that satisfy a learning bias",
        "prob": 0.29285714285714287
    }, {
        "ID": 9281,
        "phrase": " the use of opus for admissible search has already led to developments in machine learning that may not otherwise have been possible",
        "prob": 0.38125000000000003
    }, {
        "ID": 9281,
        "phrase": " second, it demonstrates that admissible search is possible for a range of machine learning tasks that were previously thought susceptible only to efficient exploration through non-admissible heuristic search",
        "prob": 0.32272727272727275
    }, {
        "ID": 9281,
        "phrase": " figure  9  illustrates this effect with respect to a simple machine learning task-search for a propositional expression that describes the most target examples and no non-target examples",
        "prob": 0.29047619047619044
    }, {
        "ID": 9281,
        "phrase": " it can be seen that there is some reason to believe that the the average case number of nodes explored by opus o is only polynomial with respect to the search space size for these machine learning search tasks",
        "prob": 0.32272727272727275
    }, {
        "ID": 9281,
        "phrase": " the availability of admissible search is an important step forward for machine learning research",
        "prob": 0.39230769230769236
    }, {
        "ID": 9281,
        "phrase": " the application of opus o to provide admissible search in machine learning has already proved to be productive",
        "prob": 0.29285714285714287
    }, {
        "ID": 9281,
        "phrase": " this issue has been given scant attention in the context of search for machine learning",
        "prob": 0.42500000000000004
    }, {
        "ID": 9281,
        "phrase": " when creating a machine learning system it is necessary to consider not only what to search for (the explicit learning biases) but also how to search for it (appropriate search algorithms)",
        "prob": 0.5611111111111111
    }, {
        "ID": 9281,
        "phrase": " by supporting efficient admissible search, opus for the first time brings to machine learning the ability to clearly and explicitly manipulate the precise inductive bias employed in a complex machine learning task",
        "prob": 0.4653846153846154
    }, {
        "ID": 9281,
        "phrase": " the algorithm's search efficiency is demonstrated with respect to very large machine learning search spaces",
        "prob": 0.43571428571428567
    }, {
        "ID": 9281,
        "phrase": " the use of admissible search is of potential value to the machine learning community as it means that the exact learning biases to be employed for complex learning tasks can be precisely specified and manipulated",
        "prob": 0.4826086956521739
    }, {
        "ID": 9283,
        "phrase": " ilp can be seen as the intersection of inductive machine learning and computational logic",
        "prob": 0.3416666666666667
    }, {
        "ID": 9283,
        "phrase": " in inductive machine learning the goal is to develop techniques for inducing hypotheses from examples (observations)",
        "prob": 0.5071428571428572
    }, {
        "ID": 9283,
        "phrase": " by using the rich representation formalism of computational logic (clauses) for hypotheses and examples, ilp can overcome the limitations of classical machine learning representations, such as decision trees  (quinlan, 1986) ",
        "prob": 0.3086956521739131
    }, {
        "ID": 9283,
        "phrase": " another advantage of using a clausal representation is that clausal theories are easy to manipulate for machine learning algorithms",
        "prob": 0.44375000000000003
    }, {
        "ID": 9294,
        "phrase": " there is an extensive literature on optimization, examining both cases where the learner has some prior knowledge of the parameterized functional form and cases where the learner has no such knowledge; the latter case is generally of greater interest to machine learning practitioners",
        "prob": 0.23461538461538464
    }, {
        "ID": 9294,
        "phrase": " in this paper we will consider how one may select x in a statistically \\optimal\" manner for some classes of machine learning algorithms",
        "prob": 0.20666666666666667
    }, {
        "ID": 9294,
        "phrase": " in the rest of this paper, we consider two \\non-neural\" machine learning architectures that are much more amenable to optimal data selection",
        "prob": 0.33888888888888885
    }, {
        "ID": 9298,
        "phrase": " actual machine learning tasks are not drawn randomly from the space of all possible learning tasks",
        "prob": 0.3642857142857143
    }, {
        "ID": 9298,
        "phrase": " machine learning is simply unsuited to such tasks",
        "prob": 0.34444444444444444
    }, {
        "ID": 9299,
        "phrase": "introduction inductive logic programming (ilp) is a sub eld of logic programming and machine learning that tries to induce clausal theories from given sets of positive and negative examples",
        "prob": 0.48260869565217396
    }, {
        "ID": 9300,
        "phrase": " generalization|the cornerstone of mainstream machine learning research|has the potential of considerably aiding reinforcement learning, as described in section 6",
        "prob": 0.41764705882352937
    }, {
        "ID": 9300,
        "phrase": " these ai algorithms are less general than the reinforcement-learning methods, in that they require a prede ned model of state transitions, and with a few exceptions assume determinism",
        "prob": 0.22777777777777775
    }, {
        "ID": 9300,
        "phrase": " taking inspiration from mainstream machine learning work, kaelbling developed two algorithms for learning boolean functions from reinforcement: one uses the bias of k-dnf to drive the generalization process  (kaelbling, 1994b) ; the other searches the space of syntactic descriptions of functions using a simple generate-and-test method  (kaelbling, 1994a) ",
        "prob": 0.35405405405405405
    }, {
        "ID": 9302,
        "phrase": "introduction a lot of work in machine learning is in the context of concept learning",
        "prob": 0.5916666666666667
    }, {
        "ID": 9307,
        "phrase": " first, let us elaborate the relevance of computing stable models to ai tasks",
        "prob": 0.16153846153846155
    }, {
        "ID": 9307,
        "phrase": " algorithms for handling a tms with nogoods have been developed in the ai community by  doyle (1979)  and  charniak et al",
        "prob": 0.25833333333333336
    }, {
        "ID": 9310,
        "phrase": "  soderland and lehnert (1994)  use the machine learning program id3 (a predecessor of c4",
        "prob": 0.25833333333333336
    }, {
        "ID": 9342,
        "phrase": " \n related work the research reported here straddles the two elds of automated software synthesis and ai planning",
        "prob": 0.20666666666666667
    }, {
        "ID": 9342,
        "phrase": " \n features and limitations our synthesis approach provides several interesting contrasts to main-stream ai planning work",
        "prob": 0.25625000000000003
    }, {
        "ID": 9342,
        "phrase": " to begin with, most ai planning work attempts to improve the e ciency of planning by concentrating on the way plans are generated",
        "prob": 0.3400000000000001
    }, {
        "ID": 9344,
        "phrase": " many such algorithms have been investigated in the literature on theory revision, both in machine learning  (koppel, feldman, & segre, 1994; ourston & mooney, 1994; saitta, botta, & neri, 1993; wogulis, 1991)  and in inductive logic programming (ilp)  (ad e, malfait, & deraedt, 1994; deraedt, 1992; wrobel, 1994 wrobel, , 1995 ",
        "prob": 0.7033333333333333
    }, {
        "ID": 9344,
        "phrase": " unrestricted revisions are assumed in many theory revision systems in the machine learning literature  (koppel et al",
        "prob": 0.4066666666666667
    }, {
        "ID": 9379,
        "phrase": " but as pointed out in the ai literature, actually people hold personal assumptions about the meaning of an utterance",
        "prob": 0.23846153846153845
    }, {
        "ID": 9445,
        "phrase": " el ectrom agn etic in terfe r e n c e : the m ai n pr o b l e m \n t h eis s u e o f c o d i n g h as now b e e nr e s o lv ed an d a t h ree-lev el cod i n g c a l l e d m u l t i l e v e lt r a n s m is s io n 3 ( m l t -3 )h as been selected ",
        "prob": 0.12352941176470589
    }, {
        "ID": 9554,
        "phrase": " this problem has already been investigated in the area of machine learning and related fields",
        "prob": 0.3416666666666667
    }, {
        "ID": 9564,
        "phrase": " it has been shown  [31]  that the combination of evolutionary methods with machine learning methods results in much faster and more efficient solutions, especially in agent-based systems",
        "prob": 0.20500000000000004
    }, {
        "ID": 9567,
        "phrase": "5, \"are reminiscent of the concept hierarchies that provide initial bias in machine learning settings, and indeed it is intriguing to think of the constraint satisfaction process as a form of concept learning, synthesizing a relationship from positive and negative information",
        "prob": 0.41111111111111115
    }, {
        "ID": 9571,
        "phrase": " this finding contrasts with a consensus in supervised machine learning that forgetting exceptions by pruning boosts generalization accuracy  (quinlan, 1993) , and with studies emphasizing the role of forgetting in learning  (markovitch and scott, 1988; salganicoff, 1993) ",
        "prob": 0.524
    }, {
        "ID": 9571,
        "phrase": " section 6 places our results in a broader machine learning and language learning context, and attempts to describe the properties of language data and memory-based learning that are responsible for the 'forgetting exceptions is harmful' effect",
        "prob": 0.2730769230769231
    }, {
        "ID": 9571,
        "phrase": " these mappings can be approximated by (cascades of) classification tasks  (ratnaparkhi, 1997; magerman, 1994)  which makes them amenable to machine learning approaches",
        "prob": 0.19375
    }, {
        "ID": 9571,
        "phrase": " other studies in which machine learning algorithms are applied to language data, and in which special attention is payed to learning exceptions, mention similar indications (e",
        "prob": 0.4789473684210526
    }, {
        "ID": 9571,
        "phrase": " in the recent literature on statistical language learning, which currently still largely adheres to the hypothesis that what is exceptional (improbable) is unimportant, similar results as those discussed here for machine learning have been reported",
        "prob": 0.3521739130434782
    }, {
        "ID": 9679,
        "phrase": " \n inductive learning many well known machine learning algorithms belong to the paradigm of inductive learning; decision-tree learning, neural network learning and bayesian learning are the most prominent examples of inductive learning",
        "prob": 0.5035714285714287
    }, {
        "ID": 9679,
        "phrase": " \n\t\t\t a considerable portion of the machine learning literature employs the term \"domain-theory\" rather than the term \"background-theory\"",
        "prob": 0.4176470588235295
    }, {
        "ID": 9680,
        "phrase": " \n\t\t\t a considerable portion of the machine learning literature employs the term \"domain-theory\" rather than the term \"background-theory\"",
        "prob": 0.4176470588235295
    }, {
        "ID": 9779,
        "phrase": " the most direct approach to such implementations is to directly parallelize ai production systems or the underlying programming languages  [93, 221] ",
        "prob": 0.22142857142857145
    }, {
        "ID": 9851,
        "phrase": " other results from the literature on machine learning of natural language seem to confirm this key advantage of monostratality (e",
        "prob": 0.34
    }, {
        "ID": 9868,
        "phrase": " in designing agents to be adaptive one should cast their action spaces in a form that is as amenable as possible to machine learning techniques, especially to reinforcement learning (rl) techniques  [22, 25] ",
        "prob": 0.3857142857142857
    }, {
        "ID": 9868,
        "phrase": " one important consideration in designing adaptive agents is choosing their action spaces to be as amenable as possible to machine learning techniques, especially to reinforcement learning (rl) techniques  [22] ",
        "prob": 0.32272727272727275
    }, {
        "ID": 9869,
        "phrase": " in this paper we are particularly concerned with computational processes that use machine learning techniques (e",
        "prob": 0.31538461538461543
    }]
}, {
    "topic_id": 2,
    "top_words": ["cy", "gu", "cf", "gy", "st", "wy", "kl", "ws", "gf", "ky", "wu", "wf", "co", "mn", "sy"],
    "phrases": [{
        "ID": 1564,
        "phrase": " \u2022 cn ai , cn w and cn aw for the consequence sets, and |= ai , |= w and |= aw for satisfiability, in any of these propositional logics",
        "prob": 0.3642857142857143
    }, {
        "ID": 3038,
        "phrase": " , n} and wn ai e \u2206 = \u22a5",
        "prob": 0.22000000000000003
    }, {
        "ID": 6759,
        "phrase": "\u00ed 7\u00ee \u00ef b $r u gr %s e \u00f0 sr x r %b \u00f1 % y u n st k| { } }w o tt u k{ n { z gu k gu mt wf l \u00f2t wy o sn c{ }l x{ } }~ cf }s z ww n c gf 1y n }t wf l kl \u00b4\u00f3o cf n c gy (t k y \u00f4 \u00b8f a7s u kn cu ko \u00f3 y y g| { } }w co y s t w{ }| y \u00a6f n c \u00ebw qs y \u00a6l mf n c }w gf gy e| y s { w | o y s a 7\u00f1 %| f su \u00b4t wu k{ }n gf l l \u00b4c vt cy \u00e8z { }o aw 7s \u00b8f }s ${ }n 1o | y f t wu n c \u00e8 gw } cl ku xo f at wu x{ n 7s if ds dt w cy 2| y s w l vt 9{ z %t w y u kn c }u cu k w f l | y s y f | o cy | \u00f5 s \u00f6 { }| p \u00d7f n \u00f2 gu ws t k| u \u00b4 sw st u mn c \u00f8t x cy t { \u00f9s cf | y p n c{ \u00b8l ky s gy } \u00fa\u00f1 % cy s gy \u00f2 gw d cl ku ko f t wu x{ n 7s \u00fb \u00b8y | y \u00fcy n g| u xo y }\u1ef9 h gf \u00a6 l ky s \u00fdt k y \u00feu mn g su cu k w f l 5| y s y f | o a cy | \u00fdz { w n c \u00fau mn y su ws \u00df x cy a| | y o { }| gu mn c s %f n n c{ t wy s \u00ac }t k cy | f 1f at wy a| u kf l cn c{ t qu mn \u00a6 gy n cy a| f l g cy u mn c f o o y s s gu cl ky t { ht w y \u00a4z u ky l k 7 e{ \u00e0 y cf cy \u00a4t w cy \u00b8s gu t kw cf at wu x{ }n \u00a8t x gf t 9u vt 9u ws \u00a6w o \u00a6y f }s u ky a| %t w{ \u00e8o | y f at wy gu k }u mt xf l f w }u k{ \u00e8{ }| 9 cu k gy { \u00e8| y o { }| su n c s if n s t { \u00e1 1f p y \u00e2t k y \u00e3f cf u kl f a cl ky \u00e4f t gf l ml s t wy a 7s { z (t x cy \u00e5s o u ky n st ku z u xo f n cf l \u00b4s gu s ae | { }o y }s s t 2r n f g }u mt xu k{ }n c l f | gy gf { w gn gt s \u00e7{ z 1 | u m 1f | wt y h }t s f | y f cf u kl mf cl ky \u00a6t w{ \u00ebt w cy 0| y s y f | o y a| s \u00a4 cu xf \u00a8t x cy 1 (y yf n c \u00eb } gf | w cy s t wu xn c \u00e8n cy a es f y | \u00e0f n \u00e9 { w c| n sf l t wy h }t s \u00e2f n \u00ea gu k }u mt xu k\u00eb y 7{ }{ p 9s a 7r wn c sy y vt k cy e y \u00ecu ws f 1 gu k gf n }t wu ko \u00a8s g{ w | o y \u00e8z { }| l kf n c }w gf gy i { }| u xy n }t wy \u00e5| y s gy f | o a cy | s (f n c \u00e1u \u00b4t y \u00b8u kl kl yu n co l vw gy \u00edf n \u00e8u n co a| y f ds gu n s f 1{ w gn st 6{ z $ \u00a6w l mt xu k 1y gu f \u00e8| y s { w c| o y s \u00a4 }w cy t w{ \u00a6t w cy g| y az y | y n co y s \u00a4{ }z t x cy c{ w cn ( gy an cy | f t ku k{ }n qs t %\u00ee { } ey vy | it x cy \u00e7 \u00b8y a u ws \u00a6z { go aw 7s y ({ }n 1f u n 7s t x| y f \u00efl kf n g w f sy s 1f n c gl kf n c w f gy \u00e7w qs f gy s \u00a4u w y u vt el xf o ap 7s 1{ gs t 2{ z t w cy y h su ws t wu n c \u00a2 c }\u00f0 s\u00f0 \u00a2l kf n g w f sy s i \u00a6f n }\u1ef9{ }z cu ko yf | y gu k } cl y n c gf n c sy | y 7 gr `t \u00e4f l s g{ \u00a6l xf o ap 7s s cy o u mz u ko | y o { }| gu mn c s i cy | y \u00a6w l vt u m 1{ } gf l (w gt kt wy a| f n o y s \u00e9f | y \u00e8 gy n cy a| f t wy \u00f1w gn s gy | 5o { }n gt k| { }l kl xy o u k| o aw s `t wf n co y s \u00a2y tt o \u00b8\u00f1 % cy a| y az { }| y t k cy o | y f at wu x{ }n \u00e2{ z f s gu mt wu k{ n cf l | y s { w c| o y s i u kl xl t| y 1f u n \u00ebo | w co u kf l tu n \u00a6t k y l kf n c w cf sy 2| y s gy f | o \u00ebf n s g{ }o aw c 1y n st wf at wu x{ }n \u00e8 g| { }o y s s a \u00f1 % u ws \u00ea| y 7{ }l mw st u k{ }n sf | w\u00f2o f n sy \u00f3u n \u00f2 sf at wf \u00f4s t w{ }| f sy \u00f3f n c | y at x| u ky cf l v { gs \u00acs u \u00b4 cu kl ku t wu ky s i cf ds d cf ds gu xo f l kl ~t wf p cy n \u00a6 l mf o y u xn l xy s s it k y an t x { \u00a6 cy o f gy s $f n c \u00a6u t tu s l xy f gu mn \u00e8t w{ \u00a6f }w c gy f 1{ w cn }t %{ z % | u m 1f | w gf t xf s g y f l ws { 1s y y t w cf t tt x cy y a| o y n gt kf sy { }z 6| y s g{ w | o y s $t w cf at %f | y f n gn c{ t wf t wy g \u00a4f n s gt k }w qs \u00a8 u ko a o f n g cy \u00ecy cf l w cf t wy (u n t wy a| s 1{ z t x cy u | $s o u ky n st wu mz u ko 2| y l xy \u00ac cf n co y cy o { } 1y s u xn co a| y f }s u mn }l \u00b4\u00ebs 1f l kl xy a| a }\u00f5 t v u ko f l | { cl ky \u00f6t w f tt t x| f }u t ku k{ }n f l f | o a u \u00b4 cy s cf cy \u00ec| y i `{ }o o aw c| s \u00f7 | y a { gs gu t w{ }| u ky s 4{ z \u00f8 su x su mt f l a sf at wf 5 u kl kl ao { }n gt wf u mn \u00e8f n \u00e8u n co a| y f ds gu n s f 1{ w gn st { z e 1f t y a| u mf l $t k cf at 2 gf }s \u00e8n c{ t cy y n y n s| u ko cy \u00ec g\u00f5 cf l mw y f s gy c\u00f5 \u00f9u mn sz { }| 1f at wu k{ n \u00f9u mn \u00faf n }\u00f9s w d 7s t wf n st xu kf l \u00f3 sy at xf u l \u00fb\u00f1 % cy w n } g| y o y gy n gt wy \u00e5 }| { t w \u00f9{ z go { } \u00a6 gw st y | g c{ \u00b8y | (f n c \u00f9s t w{ | f sy o f cf o u t \u00ebo | y f t wy s t x cy u kl xl vw qs gu x{ }n z { }| f l l v f | wt wu ko u m gf n st s $u n t x cy e }f t xf o { }l kl xy o at wu x{ }n \u00f1f n c \u00e8f n cf l \u00b4s gu ws \u00f3 | { }o y s s \u00e0t cf at u \u00b4t u ws 4 { gs s gu \u00b4 cl xy \u00e9t w{ 1f n gf gy \u00f3f n \u00fcw gn gl ku u t wy \u00f6n sw g e cy | \u00f1{ z \u00fb| y s \u00ac{ w | o y s \u00fd \u00b8u mt w c{ w gt f s gu \u00b4t wu k{ }n gf l \u00e2y az wz { }| t s a r `n \u00fet k cu s b f a cy | \u00e9 y \u00fbf | w y \u00e8t w sf t \u00e2t x su ws f }s s w \u00a6 st xu k{ }n \u00eb u xl kl tf o tt xw gf l l \u00b4\u00ebl ky f 1t w{ \u00a6t w cy el k{ gs s \u00a4{ }| u mn f o o y s s u \u00b4 cu kl ku mt v{ z \u00e4 \u00a8w o \u00a6{ z tt cy sf at wf 2u mn \u00a6f cy | w1s g c{ }| t t ku k 1y } \u00f5 4z y \u00e0y h gf \u00a6 l ky s i 1f a\u00a6u kl xl mw 7s t x| f tt y \u00a4t x cy \u00a4w gt kt wy | l \u00e8 c| { cl ky 1f t wu ko s gu mt xw cf at wu k{ n t 9\u00f5 n yu n } cy s t u k sf at wu x{ n yo f | | u ky \u00a2{ w st d s\u00ec 1 6\u00ff go \u00a1 cl kl xy a| \u00a3\u00a2 \u00a5\u00a4 u mn (t x cy f y gu ws { z 0f n \u00a7\u00a6 \u00a92\u00ff \u00e8 g| { y o at e| y cy f l ky t x gf t f c{ w st \u00f0 \u00a1 \u00e3{ z ({ w | gy at w sn { }l k{ } su xo f l ml \u00e9 \u00eb{ t wu cf t wy \u00e9| y o { }| gu mn c s f c{ w st o tw l mt kw g| y s f n l f n c }w gf gy s f | y \u00e8y an }f n sy a| y w y t w{ 1l kf o ap ae{ z $o f | y z { }| t k cy y g| u 1f | w\u1eab| y o { }| s \u00eb s\u1eabu xn c }u \u00b4 cu k }w cf l ws \u00a2{ }| \u00eb g| { \u00acy o tt `s t y p cn c{ \u00fbt w gf t e gw g sy yf 1{ w gn st s \u00eb{ z 1l ku xn c w cu s t xu ko f l kl \u00f8w qs y z ww cl e gf t xf u s s t w{ }| y { }n \u00eb g| u \u00b4 cf t wy hj s \u00a4y n co f qs w l mf t wy 1u mn \u00a2s { } 1y \u00e8 }f t wf a cf ds gy u mt x f gu k } \u00a2o sf n co y \u00e8t w gf t 6t x su ws gf t xf \u00a6 u kl xl t cy \u00a6l w{ gs t $ y n t x cy \u00e8j s { }| t k cy \u00a8s g{ }z wt ` \u00b8f | y \u00e8 \u00b8u kl kl 9 cy \u00a6| y at wu | y { }| w s gf tt y 7 ce g{ gs t ${ }z $t w y \u00e8 ey 7i s gu mt y s \u00a6t k f tt ef | y w 7s y z { }| \u00a6| y s y f | o a ( gw g| ` { gs gy s f | y \u00e7z | f }u kl ky $u ` y } t k cy ~ \u00b8u kl kl \u00a6n { t \u00a6 cy 1f u n t xf u n cy \u00f3z { }| \u00ecf l k{ }n c gy a| \u00ebt wu 1y y cy o f w qs gy z `w n c gu mn \u00f4z { }| \u00a6t x cy \u00e7 g| { y o at 0s t w{ g cy ({ }| \u00a6 y { cl ky \u00a2 u mt w y s s gy n st xu kf l p cn c{ \u00b8l ky s gy 1{ cy { }n t \u00e5\u00f5 l ws { !t x cy l kf o ap { z \u00fe| y s g{ w | o y sy s o | u st xu k{ }n 7s \u00ecu s \u00ecf n \u00edu s \u00acs w cy { z \u00e7s w z z u ko u ky n st aes y o u mz u ko u mt x\u1eabf n c \u00e2u n | y tw qs f a cl ky z { }| f at s u ws f n u s \u00acs w cy } \u00fe\u00f5 t \u00f6t x cy e yj 9r z { }| j %s co { }l ku mn w u ws `t wu ko s \u00e8 y f gf n (u n co a| y f }s y { z g\u00f1 \u00f9{ z e gu k gu mt wf l sf t kf \u00eb \u00b8u mt k u mn g{ }n cy 0sy f | ef 1{ w gn st xu mn \u00e7t w{ \u00a2u kn \u00ect { t wf l 0 a \u00ec\u00f1 te g{ }| y t k cf n sf l mz ${ z 6t w cy e| y o { }| su n s s \u00a4f | y n c{ t 6 gy s go | u \u00b4 cy 0 s~ 1y at wf gf at wf t k cf at \u00e4u ws \u00ac st x cy a| y u ws $n c{ e| y o { }| { }z y \u00ac 7y n \u00b8 cu ko \u00ebl f n c w gf sy u s d cy u kn s { p cy n 7 }l ky at 7f l k{ }n cy $w gn c gy a| d \u00b8 sf t 7o { }n c gu vt wu x{ }n 7s du \u00b4t 7 f ds d| y o { }| sy 7 ! 6\u00ee p %b \u00a4f %e p %f %q \u00eb aq c r %e u c\u00f0 q #\" u s\u00f0 \u00a4x k q c \u00f1 % cy | y tz { }| y ht x cy a| y g cf ds \u00eb cy y n 5f n \u00e2u n t y | n sf at wu x{ }n sf l \u00e8t k| y n c 4t { s gy at kw g %$ o y n st wy | s '& t x cf at ef | y 1y f n st g| u 1f | u kl \u00b4gt w{ s t { }| y \u00a2f l l t k cy sf t kf d \u00b8 su xo 1 gf a cy f 0s go u ky n st u mz u ko { }| s { }o u xy tt f l c cf l mw y y a cy n \u00ebu mz %t cy f | y \u00e0n c{ \u00e9 1{ }| y \u00f3t w gf n \u00e8s n gf qs c{ t s ({ }z yt w cy \u00e2 y \u00e8 s{ go aw c 1y n st wu n g o tw | | y n st 2l kf n c w cf sy \u00ebw qs f gy ${ }| \u00e8 gu ko a g cf cy \u00ebt w{ cy 1f u n st wf u n cy s gu k \u00a6 l \u00b4\u00e7z { }| | y az y | y n co y \u00a6 sw g| { gs y s a 9 (y \u00a6 u kl xl $o f l kl %t k y s y 1o y n gt wy | s t k cf at hs t w{ }| y l xf n w gf sy | y s { w | o y s $ cf a cy y h } cy | t wu ws y f a c{ w gt t cy u m| o { }n gt wy n st f n c \u00ect x sf at 2 gu \u00b4 cy \u00ebf o o y ds \u00acs \u00a6s y | w cu xo y s ($ l kf n g }w cf sy 1| y s g{ w | o y f | o gu \u00b4 cy s '& g ) 2n cy 1{ z t w cy u m| 2 1f u n y{ a y o at wu \u00b4 cy s u ws t w{ \u00ebt wf p y 1o f | y 1{ z l k{ }n c i t wy a| \u00e9 g| y s gy | w cf t u k{ }n \u00eb{ z %t w y sf t wf h \u00b8 su xo 1 1f p y s it k cy \u00e9t x| w cy f | o gu \u00b4 cy s \u00f1u kn t k cy \u00fet x| f }u mt xu k{ }n cf l 's gy n 7s y } \u00e2\u00ee { } y a cy | \u00e9f ds \u00eat k cy \u00f1 iy o sn u ko f l 0 { }f | 1{ z r \u00f5 \u00a6\u00ff g\u00f5 1\u00a2 2\u00a4 s t f t wy 1o { }| | y o at wl \u00b4 qu t %u ws $n c{ t 9t k cy t wf }s p y{ z 2 gu k gu mt kf l if | o a gu \u00b4 cy s f n }g { }| y \u00a6t w{ \u00a2s t w{ }| y \u00a6 g }s gu wo f l ${ a y o at s s w o f }s t f t y s \u00a4f n c 3 i \u00a94 5 e s a t\u00ff gu n co y \u00e8 gu k gu mt xf l t| y a g| y s y n gt kf t ku k{ }n qs o f n \u00fb cy \u00e8o { u ky \u00f1 u t w c{ w gt \u00e2l k{ gs u n c \u00f1u n sz { }| \u00a6f t u k{ n \u00fef n c \u00fes u n co y o { cu kn c o f n cy go { } \u00a6 f | f t wu \u00b4 cy l \u00b4u kn cy h } cy n 7s u \u00b4 cy yt w y (s u \u00b4t kw gf t wu x{ n sf ds (o a cf n c gy \u00e4o { } \u00a8 l ky at wy l t\u00f7 1u mt \u00a2u ws yt k cy \u00e0o { }n gt wy an st \u00a2f n c 5n c{ t \u00a2u mt `s s y o u z u wo \u00a6 }cs u ko f l $y h gu ws t wy n co y \u00a8t cf at $ cf ds \u00a4t w{ 1 7y \u00a8 | y s gy | w cy 7 t\u00f1 % cu s u ws iu n \u00a8 f | t ku xo tw l kf | tt x| w cy cy | y \u00a4 \u00b8y f | y 2n c{ t 7z { }| o y \u00e8t w{ 0f g cl \u00b41l k{ gs s ~ o { } \u00a6 | y s s u k{ }n (t wy o sn gu \u00a1 }w cy s \u00a6f n c 2 cy n \u00b8y \u00e7t f p y \u00eco f | y \u00e7t x gf t t x cy gu k gu vt f l | y t g| y s y n st kf t ku x{ }n 7s df | y 2o { } \u00a6 l ky at wy o { u ky s t w y t w{ gf \u00ecz ww cn c }f 1y an st xf l \u00a4 g dcs u ko f l l kf \u00e8 cu xo \u00f8s gf cs \u00a6t w cf at ey u xl kl tf cy | s y l \u00ebf z z y o at %{ y o at s $ cy n cy cy | i ey t w{ w 7o 1t k cy 1 t x| f }u t ku k{ }n f l af | o gu \u00b4 cy s \u00f3 cf cy \u00edt w{ \u00f9u k \u00a6 c{ gs y \u00e9f 5 cy | w\u00e8| y s t w| u ko at wu cy f o o y s s b q{ }l ku ko a7 (r n \u00eft x cy \u00fb }u k su \u00b4t wf l \u00e2 g{ } 1f u n \u00ef \u00b8y \u00eaf | w cy \u00e8t x cf at f o o y s s gu xn c t x cy eo { }n st wy n st 6 s{ }y s n c{ t 6o cf n c sy eu mt c cu xo a u ws \u00a4o { }| | y o at u z ey s t w| u xo tt l \u00b4~z { }l kl k{ } \u00eft cy s t f n ci w{ z `z \u00a2f n sn { t wf t xu k{ }n 5| w gl ky s %\u00a2 \u00a1\u00a2 \u00a4 f n c }\u00df w{ | \u00f3f } cl \u00b4\u00e8f \u00f9s w u mt wf a cl xy \u00e2 cy | s gu x{ }n cu mn g \u00fbs wcs t wy y\u00ff g{ \u00e1 gu k gu mt wf l l xf n w gf sy \u00e2| y s { w c| o y 5f | o su \u00b4 cy s f | y 5y h y o at wy \u00fdt w{ \u00e5 gu \u00b4 cy 5y f }s f o o y s s t { t w cy a f at wy | u kf l ht x cy s t { }| y } \u00f1 % su s \u00ebf }s cy o at \u00a6u s s t wu l kl u n s y | u k{ w qs \u00f1 sy cf t wy \u00e2 sw gt \u00e8 gu ws o tw qs s gu k{ }n qs \u00fd \u00b8u mt w gu mn \u00f4 cu k n gf t wu k{ n cf l l xu \u00b4 c| f | u ky s 1s w o (f ds 0t x cy 4 2{ sf l w st o \u00a4\u00a3 6u \u00b4 c| f | w~\u00a2 2\u00a4 \u00a8s g c{ 't w cf at y 7y n s w co \u00a6 cu x u n 7s t ku t kw }t wu k{ n 7s $f | y sw qs 1f gf gt wu n c \u00e8t x cy u m| % sw qs u mn cy s s 1{ } gy l ws \u00f8t { \u00b8f | s 4 1{ }| y 5u mn }t wy | f o at wu \u00b4 cy 5f o o y s as \u00f3s o y n cf | u k{ gs a z o { w | s gy f o o y s s y | y \u00a2u ws \u00a6n c{ t e 1y f n t \u00b8u mn (t x cy 1{ }| y \u00e7t x| f }u mt wu k{ n cf l \u00b8f \u1ed7t cf t 2u n 7s t xu mt kw }t u k{ }n 7s 1s w o a gf }s \u00a5\u00a3 % e\u00f5 \u00a2 k \u00a4 g| { cu k sy \u00ebt x cy \u00fef at t x cu ws 1{ } 1y an st 7\u00f1 % cy a\u00e3s w g s { }| t f 1 y o f t wf l k{ } }w y f n c t x cy \u00a6w 7s y a| o f n \u00e8f }s p \u00e1z { }| t k y \u00e9 }u ws t k| u \u00b4 sw gt wu k{ }n \u00e8{ z t w cy \u00e5s y l ky o at wy \u00e8| y s g{ w | o y \u00f5 gf u n t sg\u00f5 f o o y s \u00acs \u00f5 v y c{ \u00ecn { t f a cy \u00ebu xn y 1u mn g \u00ect x sf t | y s g{ w | o y | { cu k gy | s { z z y | f e cy | w\u00e7| y s t w| u ko at wy \u00eb y 7i k cf ds gy u kn st y a| z f o y \u00e8 u t w t x cy e cy l m { z $ u ko { n cy eo f n \u00ebo f | | w~ { w gt 6| y s t x| u ko at wy \u00a6 }w cy | u ky s \u00a4f n s f o o y s s $s u kn c }w cl f | %u mt wy a s a \u2022 f }s y { }n \u00ebt k u ws i y eo f n \u00a2s w g 1 \u00a6f | u \u00eb y cf at 6o f n \u00a6 cy 0s gy y n f }s 1f \u00ac{ }| \u00ect xf }s p qs \u00f4{ z \u00a2 { } sy | n 5l kf n c w f gy (| y s { w c| o y f | o cu \u00b4 cy s \u00a7 \u00a1\u00a3 4 \u00f5 \u00a9\u00e4\u00f7 \u2022 \u00a3 4 \u00f5 \u00e8 cf a cy \u00ebt { \u00ect wf p y o f | y { z el k{ }n c i t wy a| \u00fb g| y s gy | w cf t xu k{ }n { z t x cy c{ gs t wy \u00a6 gf tt f f n s 0{ z tt x cy s t wf a cu xl mu mt v\u00a6{ z \u00e4| y tz y | y n co y s t \u2022 \u00a3 4 \u00f5 \u00e9 cf cy ht w{ { z z y | 2s gy | w cu ko y s t cf t 6f l kl k{ 5z l ky h gu \u00b4 cl ky \u00a6f o o y s \u00acs t { (t w cy g }f t xf (f o o { }| gu mn (t w{ (t k y yn cy y cs { z 1t w y \u00f4 { t wy n st xu kf l w qs y | s }f n \u00e8 cy | 1u mt cw g cl x{ }f }u n c \u00e8n y t cy | s u k{ }n 7s if n c ez l xy h gu \u00b4 cl \u00b4\u1ef9h }t wy n c gu mn g ht x cy \u00eb \u2022 \u00a3 4 \u00f5 \u00ed f a cy t w{ 1{ z z y | $ { gs \u00acs u \u00b4 cu kl ku t wu ky s t w{ 1y an g| u ko a 1t k y \u00e8 }f t kf d qu w y t { f g n cy a \u00e5| y s g{ w | o y s \u00ac %o { } 1y n st xf | u ky s hf n c | y l xf tt u k{ }n 7s { | w g sf t wy \u00fby h gu ws t wu n s \u00fe{ }n cy s t \u00f1 % cu ws \u00a6f \u00f3{ z bo { w | s gy n c{ t u n sz l mw y n co y \u00a4t x cy f | o cu \u00b4 cy \u00a6o { }n st wy n }t \u2022 \u00a3 4 \u00f5 f a cy \u00f1t w{ \u00eft f p y \u00feo f | y \u00f1t k f t \u00e5y at x su xo f l 5f n l xy gf l o { }n 7s t w| f u n t s \u00e2f ds \u00e0 \u00b8y l kl (f ds u n st wy l kl xy o at kw gf l g| { y | `t \u00fb| u k } st s f ds y o at s if | y \u00a4t xf p y an s gy | u k{ w 7s l \u00b47 \u00a3 4 \u00f5 \u00edf | y \u00a6s y | w cu ko y \u00e8o y n st wy | s it k cf at 6f } }| y s s t cy n cy y cs { z it w y gu mz wz y | y n }t w 7s y | }| { w g qs t r `n (t x cy z u m| s t eu mn qs t xf n co y $t k y n cy y s { }z | y s y f | o cy | s \u00a8 f a cy t w{ y 7y ys f t u ws z u ky 7 $r n s g{ } 1y \u00a2o f ds gy ds f l ws g{ yt w y f o o y s s \u00fe s\u00e3n cf t xu \u00b4 cy s y f p y | \u00feo { } 1 \u00a8w n gu mt ku xy s \u00feu ws \u00ef{ z \u00fe u k } | y l ky cf n co y $w gt 9f l ws { \u00e8t x cy a| y f | y es `t kw sy n st s t wy f o a y a| s \u00ac a { w c| n sf l mu s t s f n c \u00a2{ t x cy | }| { w s qs \u00b8t x gf t o f n cy 1 1y n gt ku k{ }n y \u00a2f }s { t wy n t wu f l 6w 7s y a| g| { w g 7s a \u00e8\u00ff df t xu ws z su kn \u00f3f l kl t k y yn cy y cs \u00eb e{ w cl x | y }w u m| y gf y c{ }l xy s y o at w| w { z s y | w cu ko y }s t w f tt af \u00e4s gu n g sl ky \u00a3 4 \u00f5 \u00f6o f n gn c{ t a 1y y at \u00f1 % y | y az { }| y \u00fdf n \u00a3 4 \u00f5 cf ds \u00eat w{ { z z y | \u00fef s g| { g| u f t y { y n u n st wy | z f o y s z { }| e{ t w cy a| 0s gy | w cu ko y 1 g| { cu k sy | s a %\u00f1 % cy aes gy a| w cu xo y s \u00e8{ }z f n \u00a3 4 \u00f5 f | y \u00f3f 1{ }n s s t t x { 5y h t w| y 1y s \u00f7 cy | w\u00e5s cf l kl k{ e 1u mn \u00e9t x cy s y n 7s y t w gf t \u00a6t x cy 5y 7 y h { gs gy gt w cy y at wf }f t wf { | \u00eco { }n st y an st \u00a6t w{ s u k \u00a6 l ky \u00e2s y f | o \u00e5y n c su n cy s { }| 1 1{ | y sy y a cl | u ko \u00e5 }f t xf \u00f3t x cf at { }z z y | s iu n st wy a| z f o y s dz { }| d g| { } }| f \u00a6 1y | s \u00ac 6\u00ee p 0u sx b \u00a4\u00f0 x $u q v 0r tv p %b f %e \u00a4p %f %q \u00eb aq c r %e u g\u00f0 cq #\" u g\u00f0 c x q 7 f }s y \u00e5{ }n \u00e9 cf t y cf a cy cy s o | u cy bs \u00ac{ \u00edz f | \u00a8 y \u00e0o f n gy s go | u \u00b4 cy \u00a2f yn sw g e cy | 1{ z \u00e8 | u n co u m cl xy s \u00a6t k gf t \u00b8 sf cy \u00e7t { y cy \u00a2 y at 2 g 1{ } gy | n gu k }u mt wf l \u00a3 6f n c }w gf gy 4 y ds g{ w | o y \u00f3\u00f5 | o su cy s a \u00e2\u00f1 6 cy s y | u n co u m l ky s \u00ac \u00f1 gf a cy \u00e3f ds \u00fcf o { }| { }l kl kf | w \u00fdt w gf t yt k cy \u00fau k \u00a6 cl \u00b4|y }w cu | y a 1y n t `s dz { }| tt wy o gn c{ }l k{ } gu ky s dt w{ 2 cy f s l ku ky t w{ t k cy \u00eb \u00a3 4 \u00f5 \u00f1 cf cy \u00ect w{ u k \u00a6 l ky 1y an st 0f (s t x| f t y 4z { }| \u00ebl k{ }n ci mt wy | c| y s y | w cf t ku x{ }n t x gf t \u00e4u mn o al mw sy s \u00e1f \u00fe 1u k }| f t xu k{ }n \u00f3 cl f n t { \u00efn cy a t wy o gn c{ }l k{ } gu ky s if n c \u00a6f gu ws t x| u sw st wu x{ }n \u00a8 l f n \u00a6t w{ eo | y f t wy 2o { u ky s { }z tt cy sf t kf gf t 0 gu mz wz y | y n st el k{ }o f t wu k{ }n 7s z { }l kl k{ } u xn c su z `z y | y n }t e c| { t w{ }o { }l ws a \u00f1 % cu ws %| y }w u m| y s if p u mn \u00a6{ z %l w{ } ei `l xy a cy l vz y cy | f t xu k{ }n cs gu n co y c{ w o f n { }n cl \u00b4\u00e1y h go cf n c sy s gy n 7s u vt u \u00b4 cy \u00e2 gf t wf \u00e2 u t k \u00e9t x| w 7s t wy \u00f9s y | w cy | s (f n g { }| sf n gu k\u00eb f t wu k{ n 7s a s\u00f1 % gu ws iz y sy | f t u k{ }n \u00ebu \u00a6 gl ku ky s % v{ t w f }| y y 1y an st s ${ }n t k cy t wy o gn c{ }l k{ } }\u00fal ky a cy l \u00a7 wy h o f n sy g| { t w{ }o { }l ws !y at wo \u00f4f }s f }| y y y n }t s iu n ht x cy 2y tt x cu ko f l cf n c 6 gw gu ko u kf l c s{ } 1f u mn 7 7 \u00a3 4 \u00f5 \u00e2 cf cy \u00a4t w{ ef { st 9f }s 6 \u00a8w o 1f }s d { gs \u00acs u \u00b4 cl ky u x sy l ~w qs y f n \u00a6{ cy n s t wf n c sf | cs dz { }| if l kl 7 }f t wf u n co l \u00b4w c gu mn g \u00e8t x cy 1y at wf sf at wf f n g | y l f t u k{ n 7s \u00a2 cy at ` \u00b8y y n \u00e9t x cy \u00f3| y s { w c| o y s a \u00a6\u00f5 \u00fao { }n } cy | s gu k{ }n \u00e9 \u00b8u kl kl 1 cy n cy o y s s gf | w\u00f2t w{ } f | s \u00fct x cy s gy s t xf n c gf | cs cu ko \u00f9u mn o l w c gy s s t w| ww co at kw g| y gy s go | u m gt wu k{ n 7s \u00e8z { }| \u00e8t y h }t kw f l gf t xf \u00e7t x sf t f | y o { } \u00a6 cl ku xf n }t u mt w \u00e0 sy an y a| u ko s go cy \u00a6f ds t 9u n sf l kl \u00b4 \u00b8t x cy g sy }| y y g{ z o { } cy | y an co y f n yo { } \u00a8 l u kf n co y t w{ as w o gs o y a 1f }s h \u00b8u kl ml u n sz l mw y an co y t x cy \u00ebo { gs t s { z 1u k }| f t xu k{ }n t { f | s \u00a4n y t | y t g| y s y n st wf at wu k{ n \u00ebz { }| 1f t s it k cf at % \u00b8u kl kl y 1y | gy \u00a2 c \u00a3 4 \u00f5 5 cf cy \u00e8t w{ 1 su kz wz y | y n st xu kf at wy 2 vy at k ey y n \u00eb c dcs u ko f l 6s t w{ }| f gy s t w| ww co at kw g| y \u00b8 cu ko a 0u ws io sf | f o tt y a| u m\u00eb y s1s y | w cy | s s gu ws p qs iy at wo } sf n g t k cy 0l ku mn g }w cu ws `t u ko \u00a6f | o a gu \u00b4 cy \u00a6{ }| gf n u m\u00eb f tt u k{ }n c v 2 cu xo a u ws o sf | f o at wy | u k\u00eb y s\u00e3| y s g{ w | o y \u00f6 1y at wf gf t xf \u00f6f n c l u n c w gu s t wu xo f l kl ~ y f n su n c }z `w l o f t wy s{ }| u x\u00eb f t ku x{ }n 7s t ae ( gu kl ky \u00e9t x cy \u00e9z u m| s t u ws \u00e2 sy az u kn cy \u00f9 s~s 7s t wy f n gf gy a| s \u00e8f n g yu mn gz l w cy an o y g\u00ect wy o cn c{ }l k{ } gu ko f l o { }n 7s u m gy | f t ku k{ }n qs f n \u00a8t x cy a| y az { }| y o cf n c }u n c \u00a6z | y }w cy n st kl c st w cy l kf at kt y a| $u ws $ gy tt y a| \u00a6u n cy s\u00fes o u xy n gt wu mz u ko \u00f9o { }n qs gu k gy | f at wu k{ n qs \u00edf n c \u00f1o { } \u00a6 f | f t xu \u00b4 cy l \u00fes t f a cl ky } \u00f5 | o a cu \u00b4 cy \u00fe 1f n gf gy 1y an st | y s { w c| o y \u00fe su s go { vy | w\u00f6f n c w qs gf sy s g c{ w l k e \u00a6f p y \u00a4w qs y { z tt cy l ku mn g }w cu ws t xu ko { }| }f n gu k\u00eb f t wu k{ n t 7 !\u00a3 4 \u00f5 \u00e9 cf cy \u00e8t w{ f s| y y \u00a6{ }n \u00a2 1y o cf n gu ws \u00ebs \u00a4t x gf t 6f | y \u00a6f a cl xy \u00e8t w{ | y s { }l \u00b4 cy \u00a6 \u00b8n cu \u00a1 }w cy \u00a34 y s \u00ac{ w c| o y r gy n gt ku mz u ky | s \" \u00a7 \u00a6 4 r w 0s #t { \u00e7 }cs u ko f l cf t k 7s \u00ac 2n cl \u00b4\u1ef9t k cy \u00ebw qs y { z \u00a9\u00a6 \u00a94 r w 0s \u00a8 \u00b8u kl kl f l ml x{ \u00e1w qs \u00e8t w{ y 1f u n t f u n s t wf cl ky g| y az y | y n co y s \u00e7f n c (t { \u00a6f p y yf ( }u s t wu n co at xu k{ }n cy at k y y n \u00f3f n f | o gu \u00b4 cf l { y o at ef n g (u mt `s \u00a8 1f n }(u xn 7s t xf n co y s \u00a6 \u00a7 `o { cu xy s $\u00e8t w f tt eo f n y h gu ws t \u00e5f t \u00e9{ t cy a| \u00f9f | o cu \u00b4 cy s t 5\u00ff }t wf cl ky \u00fe| y az y | y n co y s \u00e1t w{ \u00f3 gu k su \u00b4t wf l | y s { w | o y s \u00f6 \u00b8u kl kl \u00e5 cy o { } 1y \u00fau kn co | y f }s u mn g gl \u00b4!u k \u00a6 { }| t wf n t \u00eas gu n co y sw d cl ku ko f t u k{ n 7s u xl kl iu n co | y f }s u n c gl \u00b4\u00ec{ }z wt wy n \u00ec| y az y | t w{ \u00ebt k y 'f n f | y u mn c gu ws cy n 7s gf cl ky en c{ \u00e9 \u00b8 cy n \u00e7 \u00b8y \u00a8 \u00b8f n }t it { \u00ebo | y f tt y \u00a6f n u mn st y a| l mu n sp y s{ } 1f u n \u00a6{ z \u00e4l kf n c w f sy | y s { w c| o y s t c %\u00a3 4 \u00f5 \u00fe f a cy yt w{ gy a cu ws y gf s t w| f t wy t w{ f l kl x{ \u00f6s \u00acy l ky o tt y w 7s y | s \u00b8t w{ \u00ebw g l k{ }f n cy a b| y s { w | o y s t w{ f n af | o cu \u00b4 cy 1{ }| t w{ \u00ebw g c gf t wy y h gu ws t wu n c | y s g{ w | o y s \u00eb u t w c{ w gt \u00a6 gy s t w| { gu kn c t k y y h gu ws t ku n c { }n cy s a \u00f1 % cu ws \u00eb u kl kl e| y w u | y f g y 7i k cf }s y 4w g l k{ }f f n g \u00f3 0f n f gy 1y n }t s cs t wy \u00f2{ z z y | u n c \u00e8 { }| p \u00fds f o y s \u00e2f n g \u00fbf \u00e8s 1f | `t \u00f4 cy | s u k{ }n cu n g y o cf n gu ws g tr wt u ws { }n cy 1{ z 2t w cy e cf }s u ko \u00a6 c| u n co u m l ky s h{ z \u00b8f | o gu \u00b4 cu mn t k cf at 2f | o a gu \u00b4 cy y sf t kf 1f a\u1ef9n c{ t cy t { w co cy 7 %r wn \u00ect k y gu k }u mt xf l y | f t k cu s o { w l k 1 cy 1 gu ws gf ds t x| { w qs \u00ac %s u kn co y \u00e8t x cy a| y \u00a6 1f \u00eb cy 1| y az y | y n co y s \u00a4t w{ { }l k 1| y s { w | o y s $f n \u00e8t k y s y gf a cy t w{ e cy | y s \u00ac{ }l \u00b4 7y \u00a8t { \u00e8t w cy { }| u k }u n cf l { a ay o at s iy cy n \u00a8 \u00b8 cy n \u00e8n y t cy | s u k{ }n 7s if | y f a cf u ml xf a cl ky } 7 &\u00a3 4 \u00f5 \u00f3 \u00a6w 7s t { }z z y | af 4 { \u00b8y | z `w l \u00ebf o o y ds \u00acs y 1f n gf gy 1y n }t s cs t wy \u00e1t w cf at f l kl k{ es \u00a4w qs \u00a4t { \u00eb gy z u kn cy 0f o o y s s \u00a4 7{ }l ku xo u xy s f n c { z z y | s sy l ky gf t wu k{ }n \u00e3 1y o sf n cu ws s a \u00e5\u00f1 % cu ws \u00f3u ws \u00f3u \u00a6 c{ }| wt wf n t t w{ gu \u00b4 cy sy a { gs gu mt { }| s hz ww cl kl o { }n st w| { }l { z \u00b8 s| f n }t wu mn g yf o o y s s ht w{ $ at w cy u | & \u00eb gf at wf } \n\t\t\t y l ky a cf n st 1f at wy | u kf l $ u kl xl \u00a4{ }n gl \u00b4\u00a2 vy sy a 7{ gs u mt wy iu mz 2t k cy f | o a cu \u00b4 cu ws t sy o l kf | y s \u00eat w{ \u00fa| y s cy o at \u00e1t cy \u00ef| u k } }t s \u00f1{ z \u00e8t w cy yo | y f at w{ }| s \u00f1f n g",
        "prob": 0.9908500270709261
    }, {
        "ID": 7477,
        "phrase": " , k} such that hj ai = 1",
        "prob": 0.22000000000000003
    }, {
        "ID": 8856,
        "phrase": " if a ai \u2282 g a aj holds then \u03b1 removes a ai from cs a and similarly from cs b ",
        "prob": 0.31
    }, {
        "ID": 9450,
        "phrase": " d eni ng f ai rn e s si sn o tt r i v i a l ",
        "prob": 0.2625
    }]
}, {
    "topic_id": 3,
    "top_words": ["learning", "machine", "used", "based", "neural", "decision", "networks", "algorithms", "techniques", "methods", "pattern", "classification", "support", "technique", "many"],
    "phrases": [{
        "ID": 30,
        "phrase": "contents 1 introduction 2 1 introduction all students of machine learning are familiar with pattern recognition; in this paper we wish to introduce a new term for a related, relatively under-recognized concept, pattern discovery, and a way of tackling such problems, computational mechanics",
        "prob": 0.2366666666666667
    }, {
        "ID": 117,
        "phrase": " \n integrating language technology with machine learning stp and sml correspond to two different paradigms",
        "prob": 0.20666666666666667
    }, {
        "ID": 117,
        "phrase": " \n statistics-based machine learning several sml tools representing different learning paradigms have been selected and evaluated in different settings of our domain: lazy learning: lazy learners are also known as memory-based, instance-based, exemplarbased, case-based, experience-based, or knearest neighbor algorithms",
        "prob": 0.5432432432432431
    }, {
        "ID": 164,
        "phrase": " the second compares a range of machine learning algorithms and finds that a decision tree learner (78%) and a naive bayesian classifier (74%) are most accurate",
        "prob": 0.44999999999999996
    }, {
        "ID": 164,
        "phrase": " \n naive bayesian classifiers the naive bayesian classifier has emerged as a consistently strong performer in a wide range of comparative studies of machine learning methodologies",
        "prob": 0.6714285714285714
    }, {
        "ID": 173,
        "phrase": " \n machine learning algorithms we have used the memory-based learning algorithm ib1-ig which is part of timbl package  (daelemans et al",
        "prob": 0.22777777777777775
    }, {
        "ID": 252,
        "phrase": " in order to determine which candidate acronyms should be output, a machine learning scheme is used",
        "prob": 0.16153846153846155
    }, {
        "ID": 259,
        "phrase": " many standard ml algorithms for supervised learning have been applied, such as: naive bayes  [19, 22] ,  [19, 10] , exemplar-based learning decision lists  [28] , neural networks  [27] , etc",
        "prob": 0.5761904761904761
    }, {
        "ID": 260,
        "phrase": " many standard ml algorithms for supervised learning have been applied, such as: bayesian learning  [16, 19] , exemplar-based learning  [18, 16, 5] , decision lists  [21] , neural networks  [20] , etc",
        "prob": 0.6238095238095238
    }, {
        "ID": 311,
        "phrase": " before passing the data through the machine learning program, alignment  (daelemans & van den bosch, 1996)  is performed for the graphemic and phonemic representations of celex and for those of fonilex, since the phonemic representation and the spelling of a word often differ in length",
        "prob": 0.31153846153846154
    }, {
        "ID": 317,
        "phrase": "  [23]  recently proposed using a machine learning algorithm to construct a filter of this type",
        "prob": 0.23846153846153847
    }, {
        "ID": 317,
        "phrase": " pu1, however, can still be used to experiment with any classification technique that relies only on frequency and co-occurrence statistics (the naive bayesian classifier and most of the machine learning techniques cited in section 1 fall into this category)",
        "prob": 0.4653846153846154
    }, {
        "ID": 330,
        "phrase": " almost all of the traditional machine learning methods solve problems by using rules whose probabilities  are not 100%",
        "prob": 0.20666666666666667
    }, {
        "ID": 330,
        "phrase": " the above experiments indicate that method 2 is best among the machine learning methods 5 ",
        "prob": 0.3416666666666667
    }, {
        "ID": 343,
        "phrase": " this strategy is common in machine learning, pattern recognition, data mining, expert systems and medical diagnosis",
        "prob": 0.31875000000000003
    }, {
        "ID": 360,
        "phrase": " many standard ml algorithms for supervised learning have been applied, such as: decision lists  (yarowsky, 1994; agirre and mart\u00ednez, 2000) , neural networks  (towell and voorhees, 1998) , bayesian learning  (bruce and wiebe, 1999) , exemplar-based learning  (ng, 1997a) , and boosting  (escudero et al",
        "prob": 0.7033333333333333
    }, {
        "ID": 365,
        "phrase": " studies have shown that both machine learning and probabilistic learning methods used in nlp make decisions using a linear decision surface over the feature space  (roth, 1998; roth, 1999) ",
        "prob": 0.3521739130434783
    }, {
        "ID": 371,
        "phrase": "   introduction s sr machine presents strong nonlinear characteristics, fuzzy logic and neural networks methods are well suited for its control, and so many authors have proposed the dynamic control of sr drives using these artificial intelligence based methods  [2, 4] ",
        "prob": 0.22903225806451613
    }, {
        "ID": 380,
        "phrase": " by constructing confusion networks one can start to apply machine learning techniques based on discrete k-way classifiers to enhance the quality of the recognition hypothesis, for example, by incorporating more sophisticated linguistic knowledge",
        "prob": 0.364
    }, {
        "ID": 449,
        "phrase": " however, the methods of the research that we survey do not necessarily use well-known machine learning algo-rithms",
        "prob": 0.31875000000000003
    }, {
        "ID": 449,
        "phrase": " in step 3 above, machine learning or data mining techniques are typically used for the generalization",
        "prob": 0.3153846153846154
    }, {
        "ID": 449,
        "phrase": " [71]  utilizes the network analysis of people to model the network of ai researchers",
        "prob": 0.19090909090909092
    }, {
        "ID": 632,
        "phrase": " \n learning decision trees decision trees are among the most widely used machine learning algorithms",
        "prob": 0.7400000000000001
    }, {
        "ID": 660,
        "phrase": " there are many ways to combine human corpus-based knowledge extraction with machine learning",
        "prob": 0.22142857142857145
    }, {
        "ID": 682,
        "phrase": "in this paper, we introduce a new machine learning theory based on multi-channel parallel adaptation for rule discovery",
        "prob": 0.35882352941176476
    }, {
        "ID": 744,
        "phrase": " machine learning methods have become the most popular technique in a variety of classification problems of these sort, and have shown significant success",
        "prob": 0.3588235294117647
    }, {
        "ID": 744,
        "phrase": " 2 provides some background on approaches to multi-class classification in machine learning and in nlp",
        "prob": 0.23846153846153847
    }, {
        "ID": 744,
        "phrase": " \n multi-class classification several works within the machine learning community have attempted to develop general approaches to multi-class classification",
        "prob": 0.35500000000000004
    }, {
        "ID": 784,
        "phrase": " they used various machine learning techniques, boosting, connectionist methods, decision trees, memorybased learning, statistical techniques and symbolic methods",
        "prob": 0.655
    }, {
        "ID": 815,
        "phrase": " furthermore, the technique applies not only to maximum entropy models, but to almost any machine learning technique for predicting probabilities that is slowed by a large number of outputs, including many uses of decision trees and neural networks",
        "prob": 0.30000000000000004
    }, {
        "ID": 817,
        "phrase": ", 1994) , and automated theorem proving and machine learning techniques  (thomas, 1998; thomas, 1999) ",
        "prob": 0.3416666666666667
    }, {
        "ID": 858,
        "phrase": " linguistic theories have been developed specifically to give account of these phenomena  [7, 4] , and several symbolic formalisms in ai  [5, 6]  reflect the same approach",
        "prob": 0.25625000000000003
    }, {
        "ID": 999,
        "phrase": " set data structures have also been used in pattern matching and pattern directed invocation in various ai languages  (livesey and siekmann 1976 )",
        "prob": 0.4764705882352941
    }, {
        "ID": 1018,
        "phrase": " cross-validation is used within a wide range of machine learning approaches, such as instance based learning, artificial neural networks, or decision tree induction",
        "prob": 0.5045454545454545
    }, {
        "ID": 1018,
        "phrase": "cross-validation is a useful and generally applicable technique often employed in machine learning, including decision tree induction",
        "prob": 0.39444444444444443
    }, {
        "ID": 1034,
        "phrase": " classifiers built by means of ml techniques nowadays achieve impressive levels of effectiveness (see section 7), making automatic classification a qualitatively (and not only economically) viable alternative to manual classification",
        "prob": 0.28400000000000003
    }, {
        "ID": 1156,
        "phrase": " although many studies have considered pos tagging by using machine learning methods, few studies have used the support vector machine method",
        "prob": 0.505
    }, {
        "ID": 1156,
        "phrase": ") the main machine learning methods was as follows: 10 support vector > hybrid tagger > maximum entropy > rule-based \n\t\t\t although there are also such decision-tree learning methods as c4",
        "prob": 0.41363636363636364
    }, {
        "ID": 1174,
        "phrase": " it is a well studied and widely applicable approach that fits the framework of qualitative decision-making in ai (see e",
        "prob": 0.3400000000000001
    }, {
        "ID": 1282,
        "phrase": " knowledge engineering, now widely seen as costly and hard to re-use, was superseded by machine learning techniques borrowed from ai",
        "prob": 0.4764705882352941
    }, {
        "ID": 1483,
        "phrase": " however, the three machine learning methods we employed (naive bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization",
        "prob": 0.3115384615384616
    }, {
        "ID": 1499,
        "phrase": " this is a good classification modeldespite its simplifying assumptions, see [dp97]-, which often competes successfully with the state-ofthe-art classifiers from the machine learning field, such as c4",
        "prob": 0.29047619047619044
    }, {
        "ID": 1512,
        "phrase": " section 9 employs the dfw and the related basis functions to make the kernel distance sigmoidal functions for the artificial neural network and machine learning",
        "prob": 0.505
    }, {
        "ID": 1512,
        "phrase": " the dfw and the related basis functions are also used in making the kernel distance sigmoidal functions, which are potentially useful in the artificial neural network and machine learning",
        "prob": 0.5285714285714286
    }, {
        "ID": 1564,
        "phrase": " doyle and thomason  [6]  argue that classical decision theory should be reunited with alternative decision theories in so-called qualitative decision theory (qdt), which studies qualitative versions of classical decision theory, hybrid combinations of quantitative and qualitative approaches to decision making, and decision making in the context of artificial intelligence applications such as planning, learning and collaboration",
        "prob": 0.3833333333333333
    }, {
        "ID": 1564,
        "phrase": " section 3 considers the ai solution to this problem  [12, 8] : break down the decision problem into goal generation and goal based decisions",
        "prob": 0.19375
    }, {
        "ID": 1666,
        "phrase": " in principle, the \"primitives\" themselves could be large and time-consuming software, such as, say, traditional ai planners, or theorem provers, or multiagent update procedures, or learning algorithms for neural networks represented on tapes",
        "prob": 0.28400000000000003
    }, {
        "ID": 1667,
        "phrase": " in principle, the \"primitives\" themselves could be large and time-consuming software, such as, say, traditional ai planners, or theorem provers, or multiagent update procedures, or learning algorithms for neural networks represented on tapes",
        "prob": 0.284
    }, {
        "ID": 1717,
        "phrase": " to get a criterion (cutoff) used to divide a group into subgroups, a knowledge-based method (machine learning methods such as support vector machine, neural network, decision tree etc",
        "prob": 0.6039999999999999
    }, {
        "ID": 1840,
        "phrase": " these cognitive capabilities are supported by several artificial intelligence paradigms including the following approaches: rule-based reasoning, probabilistic reasoning, artificial neural networks, genetic algorithms, boolean networks, and fuzzy logic systems",
        "prob": 0.41724137931034494
    }, {
        "ID": 1841,
        "phrase": " these cognitive capabilities are supported by several artificial intelligence paradigms including the following approaches: rule-based reasoning, probabilistic reasoning, artificial neural networks, boolean networks, fuzzy logic systems, and multidimensional logic systems",
        "prob": 0.3366666666666667
    }, {
        "ID": 1846,
        "phrase": " this experience-based skill acquisition process differs from historically studied machine learning processes concerned with alteration of the collection of pattern-directed modules, or production memory, e",
        "prob": 0.3086956521739131
    }, {
        "ID": 1869,
        "phrase": " this is the classical machine learning problem of learning from examples",
        "prob": 0.41000000000000003
    }, {
        "ID": 1880,
        "phrase": " (it is also perhaps worth noting that researchers in machine learning, neural networks, and statistics seem generally more interested in the bias/variance dilemma  (geman et al",
        "prob": 0.32105263157894737
    }, {
        "ID": 1881,
        "phrase": "  bishop (1995)  provides an excellent introduction to the use of statistical pattern recognition techniques in machine learning",
        "prob": 0.4066666666666666
    }, {
        "ID": 1881,
        "phrase": " in machine learning a common algorithm derived from non-parametric estimation is the k-nearest neighbour algorithm, which in many cases can give surprisingly accurate results",
        "prob": 0.29047619047619044
    }, {
        "ID": 1881,
        "phrase": " in nlp, two frequently used machine learning techniques that can usefully be thought of as non-parametric are memory-based learning (mbl)  (lin & vitter, 1994; zavrel & daelemans, 1999; van den bosch & daelemans, 1999) , and data-oriented parsing (dop)  (bod, 1993 (bod, , 1998 ",
        "prob": 0.5193548387096774
    }, {
        "ID": 1881,
        "phrase": " \n bayesian techniques the term bayesian is used widely to mean a variety of different things in machine learning",
        "prob": 0.5062500000000001
    }, {
        "ID": 1894,
        "phrase": " in support of this claim, table  1  lists some of the examples of contextual features that have been examined in the machine learning literature",
        "prob": 0.20666666666666667
    }, {
        "ID": 1897,
        "phrase": " this real-world application of machine learning has presented us with some interesting technical problems, which do not seem to have been considered in the machine learning literature",
        "prob": 0.2157894736842105
    }, {
        "ID": 1984,
        "phrase": " the next section describes the origins and motivation for the icmaus approach and how it relates to other work in machine learning",
        "prob": 0.2733333333333333
    }, {
        "ID": 2070,
        "phrase": " we then discuss the floor assignment subsystem, which contains the machine learning algorithm",
        "prob": 0.17500000000000002
    }, {
        "ID": 2128,
        "phrase": " once again, we are in a familiar position, ready to apply the support vector machine (or a machine learning tools such as neural network and decision tree etc",
        "prob": 0.531578947368421
    }, {
        "ID": 2203,
        "phrase": " apply a machine learning method, such as neural network, svm (support vector machine), decision tree, and others, for classification of the set of vectors obtained to get a generalized cut-off",
        "prob": 0.40399999999999997
    }, {
        "ID": 2301,
        "phrase": "  duboue and mckeown (2001)  present an unsupervised ml algorithm based on pattern matching and clustering, which is used to learn ordering constraints among facts",
        "prob": 0.40499999999999997
    }, {
        "ID": 2333,
        "phrase": " more important: when trying to make ai\u03be practically usable, some other ai methods, like genetic algorithms or neural nets, may be useful",
        "prob": 0.3588235294117647
    }, {
        "ID": 2411,
        "phrase": " decision theory  [7, 10]  provides a normative basis for metareasoning under uncertainty, and decisiontheoretic deliberation control has been widely studied in ai (e",
        "prob": 0.25625000000000003
    }, {
        "ID": 2411,
        "phrase": " decision-theoretic methods for metareasoning have been studied in ai for the last 15 years, but there are few theoretical results on the complexity of metareasoning",
        "prob": 0.20666666666666664
    }, {
        "ID": 2421,
        "phrase": " these models have been very successful but have little to say about things like learning, fuzzy pattern recognition, probabilistic reasoning and other topics in cognitive science and artificial intelligence",
        "prob": 0.24285714285714288
    }, {
        "ID": 2427,
        "phrase": " artificial intelligence-(ai-) based pattern recognition algorithms are one possible candidate: automated linear classification of vector data into a given number (or an arbitrary number) of classes is a well established technique in the field of machine learning",
        "prob": 0.7275862068965516
    }, {
        "ID": 2427,
        "phrase": " clustering is useful in several exploratory pattern analysis, grouping, decision making and machine learning situations including data mining, document retrieval, image segmentation and pattern classification",
        "prob": 0.564
    }, {
        "ID": 2428,
        "phrase": " artificial intelligence-(ai-) based pattern recognition algorithms are one possible candidate: automated linear classification of vector data into a given number (or an arbitrary number) of classes is a well established technique in the field of machine learning",
        "prob": 0.48620689655172405
    }, {
        "ID": 2428,
        "phrase": " clustering is useful in several exploratory pattern analysis, grouping, decision making and machine learning situations including data mining, document retrieval, image segmentation and pattern classification",
        "prob": 0.484
    }, {
        "ID": 2429,
        "phrase": " recently, support vector machines (svms) are an active research domain within the field of machine learning",
        "prob": 0.5062500000000001
    }, {
        "ID": 2430,
        "phrase": " recently, support vector machines (svms) are an active research domain within the field of machine learning",
        "prob": 0.44375000000000003
    }, {
        "ID": 2455,
        "phrase": " the difficulty of making these decisions seems to have been an important reason for the historic unpopularity of the bayesian approach in symbolic ai  [mh69] ",
        "prob": 0.25625000000000003
    }, {
        "ID": 2455,
        "phrase": " maximum entropy has been a popular technique for probabilistic reasoning in ai and elsewhere",
        "prob": 0.37272727272727274
    }, {
        "ID": 2480,
        "phrase": " \n classification trees the concept of interactions has been observed several times in machine learning, but with differing terminology and rarely formally defined",
        "prob": 0.22777777777777775
    }, {
        "ID": 2521,
        "phrase": " while we would hope that the machine learning algorithm we use will be able to discern this simple pattern and exploit it, most learning algorithms can easily fall into cycles that are not much complicated than this one",
        "prob": 0.3227272727272727
    }, {
        "ID": 2619,
        "phrase": " generalization is also a term in machine learning -one of the reasons of building nonlinear regressors like feedforward neural networks is their ability to generalize to unknown data, after being trained with the learning data",
        "prob": 0.2125
    }, {
        "ID": 2760,
        "phrase": "attribute efficient learning a central goal in machine learning is to design efficient, effective algorithms for learning from small amounts of data",
        "prob": 0.4263157894736842
    }, {
        "ID": 2760,
        "phrase": " \n decision lists a longstanding open problem in machine learning, posed first by  blum in 1990 [4, 6, 8, 10]  and again by valiant in 1998  [35] , is to determine whether or not there exist attribute efficient algorithms for learning decision lists",
        "prob": 0.3375
    }, {
        "ID": 2850,
        "phrase": " \u2022 in 'artificial intelligence' kinds of computing-fuzzy pattern recognition, unsupervised learning, probabilistic reasoning and so on-the process of searching is less heavily constrained and 'heuristic' kinds of constraint are favoured so that no part of the search space is ruled out a priori",
        "prob": 0.22903225806451616
    }, {
        "ID": 2873,
        "phrase": " although hebb's law represents a coarse and incomplete picture of neural plasticity, it has found countless applications in machine learning",
        "prob": 0.39444444444444443
    }, {
        "ID": 2892,
        "phrase": " artificial intelligence-(ai-) based pattern recognition algorithms are one possible candidate: automated linear classification of vector data into a given number (or an arbitrary number) of classes is a well established technique in the field of machine learning",
        "prob": 0.5896551724137931
    }, {
        "ID": 2892,
        "phrase": " clustering is useful in several exploratory pattern analysis, grouping, decision making and machine learning situations including data mining, document retrieval, image segmentation and pattern classification",
        "prob": 0.444
    }, {
        "ID": 2913,
        "phrase": " this thesis can be traced in several approaches to the implementation of memory sytems and machine learning",
        "prob": 0.4692307692307693
    }, {
        "ID": 2941,
        "phrase": " this process can be done by using ml techniques such as neural networks [?, ?, ?, ?] or bayesian classifiers [?, ?]",
        "prob": 0.3153846153846154
    }, {
        "ID": 3084,
        "phrase": " static mdl is omnipresent in machine learning and applications",
        "prob": 0.31
    }, {
        "ID": 3101,
        "phrase": " an important difference between neural networks and other ai techniques is their ability to learn",
        "prob": 0.4636363636363637
    }, {
        "ID": 3104,
        "phrase": " various artificial intelligence techniques have been utilized to automate the intrusion detection process to reduce human intervention; several such techniques include neural networks  (ghosh, 1999; cannady, 1998; ryan 1998; debar, 1992a-b) , and machine learning  (mukkamala, 2002a) ",
        "prob": 0.28928571428571426
    }, {
        "ID": 3105,
        "phrase": " same datasets were used for the different machine learning algorithms",
        "prob": 0.41000000000000003
    }, {
        "ID": 3106,
        "phrase": " \n support vector machines (svm) support vector machines (svms)  [27]  combine several techniques from statistics, machine learning and neural networks",
        "prob": 0.655
    }, {
        "ID": 3147,
        "phrase": " decision trees  [3]  have emerged as a powerful machine learning technique due to a simple, apparent, and fast reasoning process",
        "prob": 0.41764705882352937
    }, {
        "ID": 3147,
        "phrase": " \n layer 3 the output of nodes in this layer is the product of all the incoming signals which denotes o 3,n = w n = \u00b5 ai (x) x \u00b5 bi (y)  (8)  where i = 1,2 and 3, n is the number of fuzzy rule",
        "prob": 0.14
    }, {
        "ID": 3208,
        "phrase": " it can also used in other applications, such as clustering, association mining, knowledge discovery, pattern recognition, inductive machine learning, etc",
        "prob": 0.4764705882352941
    }, {
        "ID": 3346,
        "phrase": " the results apply to many machine learning tasks including classification and hypothesis testing",
        "prob": 0.3642857142857144
    }, {
        "ID": 3418,
        "phrase": " the database community has found a very elegant way to embrace and extend machine learning technology like clustering, decision trees, bayes nets, neural nets, time series analysis, etc",
        "prob": 0.5038461538461538
    }, {
        "ID": 3600,
        "phrase": " the curse of dimensionality in highdimensional classification is well-known in machine learning, which indicates that pruning the irrelevant features holds more promise for a generalized classification",
        "prob": 0.255
    }, {
        "ID": 3600,
        "phrase": " we begin by using machine learning techniques, such as the support vector machine (svm), to classify users' emotions as expressed in individual utterances",
        "prob": 0.32105263157894737
    }, {
        "ID": 3874,
        "phrase": " the supervisor capability can be used in computationally expensive simulations where a large number of robot configurations and control parameters have to be evaluated, as in genetic evolution, neural networking, machine learning, etc",
        "prob": 0.33749999999999997
    }, {
        "ID": 3894,
        "phrase": " recently renewed interest on them emerged in the connectionist literature (\"memory\" methods) and also in machine learning (\"instance-based\" methods)",
        "prob": 0.4764705882352942
    }, {
        "ID": 3898,
        "phrase": " recently renewed interest in them has emerged in the connectionist literature (\"memory\" methods) and also in machine learning (\"instance-based\" methods)",
        "prob": 0.4176470588235295
    }, {
        "ID": 3959,
        "phrase": " an automation of the pattern identification has been recently addressed in  [bergstrom00]  by applying machine learning techniques, namely the genetic algorithms",
        "prob": 0.30000000000000004
    }, {
        "ID": 4106,
        "phrase": " a review from the machine learning perspective is presented in  [35] ",
        "prob": 0.3444444444444444
    }, {
        "ID": 4326,
        "phrase": " together they cover some of the most popular functions in machine learning",
        "prob": 0.21000000000000002
    }, {
        "ID": 4404,
        "phrase": " although  [34]  advocated a learning theoretic approach to sensor networks,  [26] , in the context of kernel methods commonly used in machine learning, is the first work to consider the classical model for decentralized detection  [36]  in a nonparametric setting",
        "prob": 0.4111111111111111
    }, {
        "ID": 4405,
        "phrase": " recently,  [34]  advocated a learning theoretic approach to wireless sensor networks and  [26] , in the context of kernel methods commonly used in machine learning, considered the classical model for decentralized detection  [36]  in a nonparametric setting",
        "prob": 0.5423076923076923
    }, {
        "ID": 4406,
        "phrase": " in the context of kernel methods commonly used in machine learning, the notion of a marginalized kernel is introduced in  [17]  to derive an efficient algorithm for designing a decentralized detection system based on a collection of training data",
        "prob": 0.5038461538461538
    }, {
        "ID": 4415,
        "phrase": " a second approach to ai is the symbolic one, with its various branches, fuzzy logic (fl) among them",
        "prob": 0.23846153846153847
    }, {
        "ID": 4516,
        "phrase": " the second is that we compared the performance of our polynomial and some machine learning techniques on the eeg data",
        "prob": 0.3153846153846154
    }, {
        "ID": 4516,
        "phrase": " comparing the performances of our technique and some machine learning methods we conclude that our technique can learn well-suited polynomial models which experts can find easy-to-understand",
        "prob": 0.2772727272727273
    }, {
        "ID": 4534,
        "phrase": "introduction the symbolic machine learning techniques, the neural network approach, and genetic algorithms provide different methods of data analysis and knowledge discovery  (mooney, shavlik, et al",
        "prob": 0.5260869565217392
    }, {
        "ID": 4534,
        "phrase": " \n symbolic learning the most promising symbolic machine learning technique for knowledge discovery is learning from example as a special case of inductive learning",
        "prob": 0.4789473684210527
    }, {
        "ID": 4534,
        "phrase": " \n neural networks in symbolic machine learning, knowledge is presented in the form of symbolic descriptions of learning concepts, e",
        "prob": 0.5687500000000001
    }, {
        "ID": 4544,
        "phrase": " our algorithms are based on methods developed for different areas of artificial intelligence, such as evolutionary computing, artificial neural networks and reinforcement learning",
        "prob": 0.3210526315789474
    }, {
        "ID": 4550,
        "phrase": "introduction machine learning and neural-network techniques  [1 -6]  have been successfully used to learn classification models, or concepts, from real-world data including electroencephalograms (eegs)  [7 -13] ",
        "prob": 0.5499999999999999
    }, {
        "ID": 4550,
        "phrase": "   \n conclusion the machine learning methods such as the lms can not learn multi-class concepts well from large-scale eeg data",
        "prob": 0.44999999999999996
    }, {
        "ID": 4551,
        "phrase": " in this research we use fruitful machine learning and pattern recognition methods to induce new rules for an automated recognition of eeg the combined technique for detection of artifacts in clinical electroencephalograms of sleeping newborns vitaly schetinin and joachim schult e artifacts and then compare their performances",
        "prob": 0.36666666666666664
    }, {
        "ID": 4551,
        "phrase": " in our experiments we focus mainly on comparing the performance of our technique and the commonly used machine learning methods applied to the artifact recognition in clinical eeg presented in the frequency domain",
        "prob": 0.30869565217391315
    }, {
        "ID": 4551,
        "phrase": " experimental results in this section we describe two experiments aimed at evaluating the performance of our technique and some machine learning methods that are commonly used on eegs",
        "prob": 0.30500000000000005
    }, {
        "ID": 4551,
        "phrase": " in the experiments we compared such machine learning techniques as k-nearest neighbor (k-nn), c4",
        "prob": 0.5083333333333334
    }, {
        "ID": 4551,
        "phrase": " the second practical issue is that we compared the performance of commonly used machine learning methods on sleep eegs without using the additional information coming from channels besides eeg",
        "prob": 0.29583333333333334
    }, {
        "ID": 4551,
        "phrase": " having comparing the classification accuracy on the testing eeg data, it can be seen that our technique outperforms the commonly used machine learning methods",
        "prob": 0.45000000000000007
    }, {
        "ID": 4551,
        "phrase": " this technique is shown to outperform a number of commonly used machine learning technique applied to automatically recognize artifacts in the sleep eegs",
        "prob": 0.4789473684210526
    }, {
        "ID": 4552,
        "phrase": " an example of this is an image processing system which links decision trees developed by machine learning in an refinement structure  [kc03] ",
        "prob": 0.3588235294117647
    }, {
        "ID": 4552,
        "phrase": " machine learning (ml) based classifiers have been widely used for automatic document classification and there are various approaches such as clustering, support vector machine, probabilistic classifier, decision tree classifier, decision rule classifier, and so on  [3] ",
        "prob": 0.7535714285714284
    }, {
        "ID": 4552,
        "phrase": " though some ml techniques such as clustering techniques  [5] [6] [7]  are suggested as solutions for incremental classification, they do not sufficiently support personalized knowledge acquisition (ka)",
        "prob": 0.3736842105263158
    }, {
        "ID": 4552,
        "phrase": " rather we view our approach can be a collaborator of machine learning technique",
        "prob": 0.2818181818181818
    }, {
        "ID": 4552,
        "phrase": " \n decision tree learning algorithm decision tree learning (dtl) is a well-known propositional machine learning technique which employs the information theory to guide in searching for the best theory",
        "prob": 0.48400000000000004
    }, {
        "ID": 4552,
        "phrase": " coming up with useful suggestions based on this large set is quite hard -one might consider machine learning methods for suggesting conditions",
        "prob": 0.305
    }, {
        "ID": 4552,
        "phrase": " the initial focus was on improving the underlying algorithms or procedures used for feature extraction and using machine learning and pattern recognition to improve the classification processes",
        "prob": 0.3857142857142857
    }, {
        "ID": 4552,
        "phrase": " rdr's ability to learn incrementally on a case-by-case basis is an additional benefit to applications where the data is sparse, making it difficult to learn using statistical measures or traditional machine learning",
        "prob": 0.31153846153846154
    }, {
        "ID": 4647,
        "phrase": "the recognition of optical characters is known to be one of the earliest applications of artificial neural networks, which partially emulate human thinking in the domain of artificial intelligence",
        "prob": 0.305
    }, {
        "ID": 4687,
        "phrase": " we already have some preliminary results using a machine learning method: support vector machines",
        "prob": 0.36428571428571427
    }, {
        "ID": 4694,
        "phrase": " support vector machines is a ml tool with remarkable properties  [4] , especially useful in this case because of its ability to easily impose greater error penalty on one of the classes only",
        "prob": 0.14761904761904762
    }, {
        "ID": 4736,
        "phrase": " the mercer kernel k(p, p i ) = exp \u2212 (p \u2212 p i ) 2 4\u03c3 2 used in these experiments is known in machine learning as the gaussian kernel (in the usual parameterization 4\u03c3 2 is replaced by 2\u03c3 2 or c); however, many other mercer kernels also give reasonable results",
        "prob": 0.36400000000000005
    }, {
        "ID": 4793,
        "phrase": " tentative techniques to address this problem are experimented using many formalisms and techniques, among which situation calculus  [15] , logic programming  [16] , type matching:  [17] , coloured petri nets:  [6, 7] , linear logic:  [18] , process solving methods  [19, 20, 21] , ai planning  [22] , hierarchical task network (htn) planning  [23, 24] , markov decision processes  [25] ",
        "prob": 0.3
    }, {
        "ID": 4962,
        "phrase": " in this paper, motivated in part by the success of (reproducing) kernel methods in machine learning  [15] , we consider a nonparametric approach to distributed estimation that is based on regularized kernel least-squares regression",
        "prob": 0.4208333333333334
    }, {
        "ID": 4962,
        "phrase": " \n regularized kernel least-squares regression reproducing kernel hilbert spaces are often considered in statistical signal processing and have been popularized within the machine learning community by the success of kernel methods",
        "prob": 0.31153846153846154
    }, {
        "ID": 4969,
        "phrase": "introduction expert advice has become a well-established paradigm of machine learning in the last decade, in particular for prediction",
        "prob": 0.35882352941176476
    }, {
        "ID": 5153,
        "phrase": " the machine learning algorithms that we used where three: na\u00efve bayes, logitboost and smo",
        "prob": 0.5916666666666667
    }, {
        "ID": 5158,
        "phrase": " they have found major applications in several different research communities such as artificial intelligence  [16] , statistics  [13] , error-control coding  [11]  and neural networks",
        "prob": 0.3736842105263158
    }, {
        "ID": 5163,
        "phrase": " they have found major applications in several different research communities such as artificial intelligence  [11] , statistics  [8] , error-control coding  [6]  and neural networks",
        "prob": 0.37368421052631584
    }, {
        "ID": 5164,
        "phrase": " they have found major applications in several different research communities such as artificial intelligence  [15] , statistics  [11] , errorcorrecting codes  [7] ,  [10] ,  [16]  and neural networks",
        "prob": 0.39444444444444443
    }, {
        "ID": 5166,
        "phrase": " standard machine learning tools (mbl, c5",
        "prob": 0.4555555555555556
    }, {
        "ID": 5520,
        "phrase": " the arguments just given indicate that an integration of connectionist and symbolic approaches in artificial intelligence provides the means to address machine learning bottlenecks encountered when the paradigms are used in isolation",
        "prob": 0.3956521739130435
    }, {
        "ID": 5520,
        "phrase": " this is the reason why the importance of the efforts to bridge the gap between the connectionist and symbolic paradigms of artificial intelligence has been widely recognised",
        "prob": 0.25625000000000003
    }, {
        "ID": 5520,
        "phrase": " the general motivation for research in the field of neural-symbolic integration (just given) arises from conceptual observations on the complementary nature of symbolic and neural network based artificial intelligence described above",
        "prob": 0.2125
    }, {
        "ID": 5520,
        "phrase": " the power of machine learning using artificial neural networking was not recognized until the 80s, when in particular the backpropagation algorithm  [rumelhart et al",
        "prob": 0.25625000000000003
    }, {
        "ID": 5520,
        "phrase": " these advances indicated a breakthrough in machine learning which quickly led to industrial-strength applications in areas such as image analysis, speech and pattern recognition, investment analysis, engine monitoring, fault diagnosis, etc",
        "prob": 0.3
    }, {
        "ID": 5568,
        "phrase": " first, pattern recognition and machine learning both benefit foundationally from better, more descriptively adequate probabilistic domain models",
        "prob": 0.41764705882352937
    }, {
        "ID": 5693,
        "phrase": " \n 2 artificial immune systems (ais)  [13]  can be built, mimicking their biological counterparts, for a number of machine learning and classification tasks with practical applications ranging from network intrusion detections  [14]  to bioinformatics  [13] ",
        "prob": 0.29583333333333334
    }, {
        "ID": 5714,
        "phrase": " this then spawned more work in the area of immune network based machine learning over the next few years, notably in  [117, 121]  where the hunt and cook system was totally rewritten, simplified and applied to unsupervised learning (very similar to cluster analysis)",
        "prob": 0.1888888888888889
    }, {
        "ID": 5845,
        "phrase": " this paper is an experimental study of methodologies for evolutionary computations (ec) inspired by common practices in the machine learning (ml) and pattern recognition (pr) communities",
        "prob": 0.24285714285714283
    }, {
        "ID": 5859,
        "phrase": " in actual application, this has the effect of reducing the overall computational cost and time dramatically, in contrast to the use of complex ai algorithms such as those found in adaptive neural network, genetic algorithm or fuzzy logic systems which are indeed computationaly intensive and time consuming",
        "prob": 0.22903225806451613
    }, {
        "ID": 5894,
        "phrase": " thus, in both the aforementioned applications, a natural question arises: can the power of machine learning methods be tapped for nonparametric inference in distributed learning under communication constraints? in this paper, we address this question by formalizing a general model for distributed learning, and then deriving a distributed algorithm for collaborative training in regularized kernel leastsquares regression",
        "prob": 0.2657894736842105
    }, {
        "ID": 5930,
        "phrase": " machine learning for rssi-based localization was previously used in  [7] , where bayesian networks were trained",
        "prob": 0.29285714285714287
    }, {
        "ID": 6143,
        "phrase": " \n applications the k-armed bandit has been used as a model for a wide variety of online decision-making problems, such as combining expert advice, portfolio balancing, machine learning (boosting), network routing, and sequential auctions (among others)",
        "prob": 0.5551724137931033
    }, {
        "ID": 6308,
        "phrase": " ml description length and also with implications to the pattern entropy",
        "prob": 0.21000000000000002
    }, {
        "ID": 6308,
        "phrase": " we begin by showing that there are permutations of the pattern ml estimator that contribute negligibly to the pattern probability",
        "prob": 0.22142857142857145
    }, {
        "ID": 6408,
        "phrase": " then, we employ a novel machine learning technique to build a classification algorithm that exploits these differences to classify ases into six representative classes that reflect ases with different network properties and infrastructures",
        "prob": 0.364
    }, {
        "ID": 6499,
        "phrase": " research in cybernetics-and later in neural networks, artificial intelligence and cognitive science-has shown how such intelligence can be realized through an adaptive network of relations transforming sensory input into decisions about actions (output)",
        "prob": 0.1888888888888889
    }, {
        "ID": 6508,
        "phrase": " a genetic algorithm (ga)  [21]  is a model of machine learning inspired by the mechanisms of genetics, which has been applied to optimisation",
        "prob": 0.3642857142857143
    }, {
        "ID": 6724,
        "phrase": " in chapter 3 the data replication method is mapped into two important machine learning algorithms: support vector machines and neural networks",
        "prob": 0.5842105263157894
    }, {
        "ID": 6724,
        "phrase": " introduced in the machine learning community the data replication method, a nonparametric procedure for the classification of ordinal categorical data",
        "prob": 0.3
    }, {
        "ID": 6724,
        "phrase": "   chapter 9 \n conclusion this study focuses on the application of machine learning methods, and in particular of neural networks and support vector machines, to the problem of classifying ordinal data",
        "prob": 0.41363636363636364
    }, {
        "ID": 6786,
        "phrase": " in the presented study, a new simulation technique based on genetics-based machine learning is proposed and applied to support decision-making during completing schedules for a flow shop environment with finite and infinite buffers",
        "prob": 0.5222222222222223
    }, {
        "ID": 6786,
        "phrase": " \n gbml approach we apply a genetics-based machine learning (gbml) technique (see  goldberg, 1989)   an individual is represented through encoding the corresponding rule-set as a linear array of integers so that an attribute weight is ranged as an integer",
        "prob": 0.18214285714285716
    }, {
        "ID": 6786,
        "phrase": " the approach is generative but not adaptive, and it employs a genetics-based machine learning technique to build feasible schedules",
        "prob": 0.25625000000000003
    }, {
        "ID": 6786,
        "phrase": " this paper proposes an approach based on genetics-based machine learning (gbml) to treat the problem of flow shop scheduling",
        "prob": 0.2833333333333334
    }, {
        "ID": 7000,
        "phrase": " from a software standpoint ai can be seen heroic pattern modeling",
        "prob": 0.31
    }, {
        "ID": 7022,
        "phrase": " one might think that there would be general binary classifiers similar to rbfs in the domain of machine learning",
        "prob": 0.20666666666666667
    }, {
        "ID": 7022,
        "phrase": " it is usual in artificial intelligence to make use of classifiers, such as neural networks, bayesian classifiers (naive or not), or support vector machines (svms)  [8] ,  [9] ",
        "prob": 0.531578947368421
    }, {
        "ID": 7023,
        "phrase": " it is usual in artificial intelligence to make use of classifiers, such as neural networks, bayesian classifiers (naive or not), or support vector machines (svms)  [32] ,  [33] ",
        "prob": 0.531578947368421
    }, {
        "ID": 7059,
        "phrase": " in the games of prediction traditionally considered in machine learning there is no infinite past",
        "prob": 0.2583333333333333
    }, {
        "ID": 7231,
        "phrase": " there has been a great deal of work in the ai community showing how bayesian networks can be used for efficient probabilistic reasoning (see  [pearl 1988 ] for an overview)",
        "prob": 0.2833333333333334
    }, {
        "ID": 7327,
        "phrase": " recently several algorithms for the computation for ai of boolean functions were given in  [4] ",
        "prob": 0.37272727272727274
    }, {
        "ID": 7328,
        "phrase": " recently several algorithms for the computation for ai of boolean functions were given in  [4] ",
        "prob": 0.2818181818181818
    }, {
        "ID": 7429,
        "phrase": " the information gain based criterion was used in a number of machine learning studies",
        "prob": 0.23846153846153847
    }, {
        "ID": 7429,
        "phrase": " webb lazy learning of bayesian rules machine learning, 1:53-84, 2000   table i ",
        "prob": 0.3416666666666667
    }, {
        "ID": 7439,
        "phrase": " this is for instance the case in the problem of tree pattern matching and in machine learning problems like grammatical inference",
        "prob": 0.38125000000000003
    }, {
        "ID": 7921,
        "phrase": "introduction the two main varieties of the problem of prediction, classification and regression, are standard subjects in statistics and machine learning",
        "prob": 0.3
    }, {
        "ID": 7921,
        "phrase": " several new techniques, first of all support vector machines  [18, 19]  and other kernel methods, have been developed in machine learning recently with the explicit goal of dealing with high-dimensional data sets with large numbers of objects",
        "prob": 0.37407407407407406
    }, {
        "ID": 7921,
        "phrase": " virtually any classification or regression algorithm can be transformed into a conformal predictor, and so most of the arsenal of methods of modern machine learning can be brought to bear on the design of efficient conformal predictors",
        "prob": 0.5499999999999999
    }, {
        "ID": 7921,
        "phrase": " we show how some popular methods of machine learning can be used as underlying algorithms for hedged prediction",
        "prob": 0.5071428571428572
    }, {
        "ID": 7921,
        "phrase": " \n bayesian approach to conformal prediction bayesian methods have become very popular in both machine learning and statistics thanks to their power and versatility, and in this section we will see how bayesian ideas can be used for designing efficient conformal predictors",
        "prob": 0.5592592592592592
    }, {
        "ID": 7921,
        "phrase": "5,  [17] ) and nearest neighbours algorithms in machine learning",
        "prob": 0.4555555555555556
    }, {
        "ID": 7921,
        "phrase": " this can be done successfully using the powerful machinery of modern machine learning",
        "prob": 0.42500000000000004
    }, {
        "ID": 8059,
        "phrase": "introduction in the scope of pattern recognition and machine learning, artificial neural networks have proved to be computationally efficient tools",
        "prob": 0.4764705882352941
    }, {
        "ID": 8087,
        "phrase": " for many loss functions the problem (2) boils down to classical machine learning algorithms such as support vector machines, kernel logistic regression or kernel ridge regression, which can be solved by usual implementations with the product kernel (1)",
        "prob": 0.6703703703703703
    }, {
        "ID": 8108,
        "phrase": "support vector machines (svms) are well-established machine learning (ml) algorithms",
        "prob": 0.5785714285714286
    }, {
        "ID": 8116,
        "phrase": " kriging is also known as the best linear unbiased prediction (blup) in statistics, and has been more recently designated as gaussian processes (gp) in the 90s in the machine learning community",
        "prob": 0.505
    }, {
        "ID": 8117,
        "phrase": " kriging is also known as the best linear unbiased prediction (blup) in statistics, and has been more recently designated as gaussian processes (gp) in the 90s in the machine learning community",
        "prob": 0.605
    }, {
        "ID": 8214,
        "phrase": " the same weakness is characteristic of several heuristic methods developed from parzen's estimator in the fields of neural networks and artificial intelligence  [8] ,  [9] ",
        "prob": 0.24117647058823527
    }, {
        "ID": 8420,
        "phrase": " this problem arises in statistical decision theory, pattern recognition, and machine learning, see  [25] ",
        "prob": 0.36428571428571427
    }, {
        "ID": 8421,
        "phrase": " this problem arises in statistical decision theory, pattern recognition, and machine learning, see  [25] ",
        "prob": 0.3642857142857143
    }, {
        "ID": 8634,
        "phrase": " other approaches (rule-based; machine learning approaches, etc",
        "prob": 0.4636363636363637
    }, {
        "ID": 8903,
        "phrase": " some are based on linear algebra (svd, pca, or eigenvectors)  [3, 6, 7, 10, 15, 16] ; or on techniques borrowed more directly from artificial intelligence such as bayes methods, latent classes, and neural networks  [1, 2, 9] ; or on clustering  [4, 5] ",
        "prob": 0.5045454545454545
    }, {
        "ID": 8904,
        "phrase": " some are based on linear algebra (svd, pca, or eigenvectors)  [3, 6, 7, 10, 15, 16] ; or on techniques borrowed more directly from artificial intelligence such as bayes methods, latent classes, and neural networks  [1, 2, 9] ; or on clustering  [4, 5] ",
        "prob": 0.5045454545454545
    }, {
        "ID": 9177,
        "phrase": " re-encoding large lists of small molecules from pbd-like format into grammarlike representation would allow for a very efficient candidate filtering at the top levels of hierarchy with the added benefit of creating structural descriptors to be matched to functional features with machine learning approaches",
        "prob": 0.2676470588235294
    }, {
        "ID": 9249,
        "phrase": "introduction the top-down induction of decision trees is an approach to machine learning that has been used on a variety of real world tasks",
        "prob": 0.22777777777777775
    }, {
        "ID": 9254,
        "phrase": "'s book on classi cation and regression trees (cart) and quinlan's work on id3  (quinlan, 1983 (quinlan, , 1986  provided the foundations for what has become a large body of research on one of the central techniques of experimental machine learning",
        "prob": 0.19615384615384615
    }, {
        "ID": 9254,
        "phrase": " many studies have found that judicious pruning results in both smaller and more accurate classi ers, for decision trees as well as other types of machine learning systems  (quinlan, 1987; niblett, 1986; cestnik, kononenko, & bratko, 1987; kodrato & manago, 1987; cohen, 1993; hassibi & stork, 1993; wolpert, 1992; scha er, 1993) ",
        "prob": 0.396969696969697
    }, {
        "ID": 9256,
        "phrase": " we implemented wrap-up with the id3 decision tree algorithm  (quinlan, 1986) , although other machine learning algorithms could have been selected",
        "prob": 0.39444444444444443
    }, {
        "ID": 9256,
        "phrase": " the id3 decision tree algorithm  (quinlan, 1986)  was used in these experiments, although any machine learning classi er could be plugged into the wrap-up architecture",
        "prob": 0.255
    }, {
        "ID": 9256,
        "phrase": " \n con dence thresholds and tree pruning with any machine learning technique there is a tendency toward \\over tting\", making generalizations based on accidental properties of the training data",
        "prob": 0.33809523809523806
    }, {
        "ID": 9263,
        "phrase": " \n decision trees and cost-sensitive classification the decision trees used in decision theory  (pearl, 1988)  are somewhat different from the classification decision trees that are typically used in machine learning  (quinlan, 1992) ",
        "prob": 0.6439999999999999
    }, {
        "ID": 9263,
        "phrase": " when we refer to decision trees in this paper, we mean the standard classification decision trees of machine learning",
        "prob": 0.47333333333333333
    }, {
        "ID": 9269,
        "phrase": " these results contribute to machine learning in several ways",
        "prob": 0.30999999999999994
    }, {
        "ID": 9273,
        "phrase": " the above methods are commonly used in ai systems",
        "prob": 0.3875
    }, {
        "ID": 9274,
        "phrase": " their studies within ai have been separated historically, learning being the topic of machine learning and neural networks, and reasoning falling under classical (or symbolic) ai",
        "prob": 0.5611111111111111
    }, {
        "ID": 9277,
        "phrase": " due to the system constraints imposed by gruff, general-purpose machine learning algorithms, such as neural networks, genetic algorithms, or decision trees, are not readily applicable",
        "prob": 0.41363636363636364
    }, {
        "ID": 9277,
        "phrase": " techniques from other areas of machine learning have been used to represent and learn probabilistic and fuzzy membership functions",
        "prob": 0.6066666666666667
    }, {
        "ID": 9277,
        "phrase": " this project represents a new direction in computer vision and machine learning research; namely, the integration of machine learning and computer vision methods to learn fuzzy membership functions for a function-based object recognition system",
        "prob": 0.4172413793103449
    }, {
        "ID": 9281,
        "phrase": " opus s has been used in a machine learning context to search the space of all generalizations that may be formed through deletion of conjuncts from a highly specific classification rule",
        "prob": 0.255
    }, {
        "ID": 9281,
        "phrase": " it would be interesting to see if the techniques can be extended to more powerful machine learning paradigms such as continuous attribute-value and first-order logic domains",
        "prob": 0.255
    }, {
        "ID": 9287,
        "phrase": " some machine learning researchers have emphasized this connection by describing regression as \\learning how to classify among continuous classes\"  (quinlan, 1993) ",
        "prob": 0.41764705882352937
    }, {
        "ID": 9294,
        "phrase": " \n mixtures of gaussians the mixture of gaussians model is a powerful estimation and prediction technique with roots in the statistics literature  (titterington, smith, & makov, 1985) ; it has, over the last few years, been adopted by researchers in machine learning  (cheeseman et al",
        "prob": 0.31153846153846154
    }, {
        "ID": 9296,
        "phrase": " \n an example: graph specialization graph structures are used in ai for many applications, such as the representation of relations, situations or problems (see e",
        "prob": 0.24117647058823527
    }, {
        "ID": 9298,
        "phrase": " many modern machine learning systems incorporate learning biases that tolerate small levels of misclassi cation of the training data  (clark & niblett, 1989; michalski, 1984; quinlan, 1986 quinlan, , 1990 ",
        "prob": 0.5875
    }, {
        "ID": 9298,
        "phrase": " this result raises considerable doubt about the utility of occam's razor as it is commonly applied in modern machine learning",
        "prob": 0.31875000000000003
    }, {
        "ID": 9305,
        "phrase": " we wish to emphasize that although bql is a bit less sophisticated than \\real\" reinforcement learners discussed in the ai literature (which is de ned below), it is a popular and powerful type of learning rule, which is much discussed and used in the literature  (narendra & thathachar, 1989) ",
        "prob": 0.262962962962963
    }, {
        "ID": 9318,
        "phrase": " distance functions are also used in many fields besides machine learning and neural networks, including statistics  (atkeson, moore & schaal, 1996) , pattern recognition  (diday, 1974; michalski, stepp & diday, 1981) , and cognitive psychology  (tversky, 1977; nosofsky, 1986) ",
        "prob": 0.6931034482758619
    }, {
        "ID": 9343,
        "phrase": " many machine learning algorithms operating on datasets of symbolic attributes need to do frequent counting",
        "prob": 0.34
    }, {
        "ID": 9343,
        "phrase": " for example, ct(a1; a3 j a2 = 3) = a1 a3 # 1 1 2 1 2 0 2 1 2 2 2 0 contingency tables are used in a variety of machine learning applications, including building the probability tables for bayes nets and evaluating candidate conjunctive rules in rule learning algorithms  (quinlan, 1990; clark & niblett, 1989) ",
        "prob": 0.3827586206896552
    }, {
        "ID": 9343,
        "phrase": " how can machine learning and statistical algorithms take advantage of this? here we provide three examples: feature selection, bayes net scoring and rule learning",
        "prob": 0.26842105263157895
    }, {
        "ID": 9468,
        "phrase": " class-based and similarity-based methods for cooccurrence modeling may at first sight seem to be special cases of clustering and weighted nearest-neighbor approaches used widely in machine learning and pattern recognition  (aha, kibler, & albert, 1991; cover & hart, 1967; duda & hart, 1973; stanfill & waltz, 1986; devroye, gy\u00f6rfi, & lugosi, 1996; atkeson, moore, & schaal, 1997) ",
        "prob": 0.5604651162790697
    }, {
        "ID": 9480,
        "phrase": " one of the core applications of machine learning to knowledge discovery consists of building a function from a given amount data (for instance a decision tree or a neural network) such that we can later use it to predict the behavior of new instances of the data",
        "prob": 0.325
    }, {
        "ID": 9480,
        "phrase": " most of the previous research in machine learning has focused on developing efficient techniques for obtaining highly accurate predictors",
        "prob": 0.25625
    }, {
        "ID": 9480,
        "phrase": " for achieving high accuracy, it is better that learning algorithms can handle complicated predictors, and developing efficient algorithms for complicated predictors has been studied intensively in machine learning",
        "prob": 0.5045454545454545
    }, {
        "ID": 9480,
        "phrase": "one of the core applications of machine learning to knowledge discovery consists on building a function (a hypothesis) from a given amount of data (for instance a decision tree or a neural network) such that we can use it afterwards to predict new instances of the data",
        "prob": 0.3964285714285714
    }, {
        "ID": 9528,
        "phrase": " \n conclusion we presented an analysis of a few of the commonly used statistics based and machine learning algorithms for ambiguity resolution tasks",
        "prob": 0.5352941176470588
    }, {
        "ID": 9552,
        "phrase": " he also introduced me to many useful machine learning techniques, that have broadened my outlook toward the field",
        "prob": 0.65
    }, {
        "ID": 9553,
        "phrase": " he also introduced me to many useful machine learning techniques, that have broadened my outlook toward the field",
        "prob": 0.7214285714285715
    }, {
        "ID": 9554,
        "phrase": " he also introduced me to many useful machine learning techniques, that have broadened my outlook toward the field",
        "prob": 0.7214285714285715
    }, {
        "ID": 9564,
        "phrase": " simple rule-based or classifier systems could also be used, but the non-parametric machine learning agents are much more flexible to dynamic environmental change  [27] ",
        "prob": 0.29047619047619044
    }, {
        "ID": 9564,
        "phrase": " other useful agent architectures could be behavior based q-learning, artificial neural networks, and memory based machine learning agents  [17] ",
        "prob": 0.4789473684210526
    }, {
        "ID": 9571,
        "phrase": " in the machine learning literature, the problem of small disjuncts in concept learning has been studied before by  quinlan (1991) , who proposed more accurate error estimation methods for small disjuncts, and by  holte, acker, and porter (1989) ",
        "prob": 0.46249999999999997
    }, {
        "ID": 9585,
        "phrase": " nearest neighbor searching has applications in many areas, including knowledge discovery and data mining  [18] , pattern recognition and classification  [14, 17] , machine learning [13], data compression  [22] , multimedia databases [19], document retrieval  [15] , and statistics  [16] ",
        "prob": 0.4111111111111111
    }, {
        "ID": 9595,
        "phrase": " we have experimented with a number of different machine learning schemes; kea uses the na\u00efve bayes technique (e",
        "prob": 0.4066666666666666
    }, {
        "ID": 9595,
        "phrase": " it uses the na\u00efve bayes machine learning algorithm for training and keyphrase extraction",
        "prob": 0.3923076923076923
    }, {
        "ID": 9637,
        "phrase": " in the fields of ai and machine learning context-dependent learning and reasoning are increasingly seen to be powerful tools (e",
        "prob": 0.4066666666666667
    }, {
        "ID": 9679,
        "phrase": " the fact that dop employs a memory of past experience relates dop to a machine learning tradition with many names (and subtle differences): memory-based learning, analogy-based reasoning, instance-based learning and similarity-based learn-ing (see (?; ?; ?; ?))",
        "prob": 0.6696969696969696
    }, {
        "ID": 9679,
        "phrase": " the chapter mainly contains a brief description of probabilistic grammars, the dop model, and some relevant paradigms of machine learning (bayesian learning and explanation-based learning)",
        "prob": 0.3227272727272727
    }, {
        "ID": 9679,
        "phrase": " machine learning paradigms, data oriented parsing and probabilistic grammars play a central role in this thesis",
        "prob": 0.31875000000000003
    }, {
        "ID": 9679,
        "phrase": "4 briefly discusses machine learning and provides short introductions to bayesian learning, explanation-based learning and the notion of entropy",
        "prob": 0.45000000000000007
    }, {
        "ID": 9680,
        "phrase": " the fact that dop employs a memory of past experience relates dop to a machine learning tradition with many names (and subtle differences): memory-based learning, analogy-based reasoning, instance-based learning and similarity-based learning (see  (stanfill and waltz, 1986; aha et al",
        "prob": 0.6314285714285713
    }, {
        "ID": 9680,
        "phrase": " the chapter mainly contains a brief description of probabilistic grammars, the dop model, and some relevant paradigms of machine learning (bayesian learning and explanation-based learning)",
        "prob": 0.4136363636363637
    }, {
        "ID": 9680,
        "phrase": " machine learning paradigms, data oriented parsing and probabilistic grammars play a central role in this thesis",
        "prob": 0.31875000000000003
    }, {
        "ID": 9680,
        "phrase": "4 briefly discusses machine learning and provides short introductions to bayesian learning, explanation-based learning and the notion of entropy",
        "prob": 0.45000000000000007
    }, {
        "ID": 9680,
        "phrase": " \n inductive learning many well known machine learning algorithms belong to the paradigm of inductive learning; decision-tree learning, neural network learning and bayesian learning are the most prominent examples of inductive learning",
        "prob": 0.43214285714285716
    }, {
        "ID": 9694,
        "phrase": " \n conclusions in the work presented here we have applied a popular machine learning technique, the transformation-based error-driven learning, to the task of part-of-speech tagging in the context of the greek language",
        "prob": 0.24400000000000002
    }, {
        "ID": 9718,
        "phrase": " the machine learning algorithm we used was a memory-based learning algorithm (mbl)",
        "prob": 0.3923076923076924
    }, {
        "ID": 9869,
        "phrase": " at each router, this algorithm uses a memory based (mb) machine learning algorithm to estimate the value that a private utility (provided by coin theory) would take on under the different candidate routing decisions",
        "prob": 0.204
    }, {
        "ID": 9869,
        "phrase": ") formally, for routing based on ml agents, other variables must also be included in \u03b6, to capture the (deterministically evolving) internal parameters used by those agents to make their routing decisions",
        "prob": 0.23181818181818184
    }]
}, {
    "topic_id": 4,
    "top_words": ["problem", "new", "general", "still", "much", "level", "cases", "optimal", "however", "hand", "less", "well", "although", "due", "efficient"],
    "phrases": [{
        "ID": 141,
        "phrase": " it seems that nearly every ai problem could be brought into the form of a game",
        "prob": 0.42500000000000004
    }, {
        "ID": 141,
        "phrase": " the ai\u00b5 model is optimal by construction of \u00b5 ai ",
        "prob": 0.15714285714285714
    }, {
        "ID": 141,
        "phrase": " we seem to have transferred the ai problem just to a different level",
        "prob": 0.4555555555555556
    }, {
        "ID": 141,
        "phrase": " nevertheless, we want to stress that we have reduced the ai problem to (mere) computational questions",
        "prob": 0.6454545454545455
    }, {
        "ID": 141,
        "phrase": " the big questions: this subsection is devoted to the big questions of ai in general and the ai\u03be model in particular with a personal touch",
        "prob": 0.6066666666666667
    }, {
        "ID": 141,
        "phrase": " as evolution has already taken place, we could add the information from our genes or brain structure to any/our ai system, but this means that the important part is still missing and a simple formal definition of ai is principally impossible",
        "prob": 0.8499999999999999
    }, {
        "ID": 307,
        "phrase": "\" we are still far away from intelligent web sites in the conventional ai sense",
        "prob": 0.25833333333333336
    }, {
        "ID": 448,
        "phrase": " a different viewpoint is taken in elements of machine learning  [langley, 1996] ",
        "prob": 0.19090909090909092
    }, {
        "ID": 477,
        "phrase": " \n computability: we seem to have transferred the ai problem just to a different level",
        "prob": 0.31
    }, {
        "ID": 477,
        "phrase": " nevertheless, we want to stress that we have reduced the ai problem to (mere) computational questions",
        "prob": 0.6454545454545455
    }, {
        "ID": 704,
        "phrase": " the motivation for this has been twofold: on the one hand there have been opportunities for developing advisory systems for legal practitioners; on the other hand the law is a complex domain in which diverse modes of reasoning are employed, offering ample opportunity to test existing artificial intelligence techniques as well as to develop new ones",
        "prob": 0.15454545454545454
    }, {
        "ID": 713,
        "phrase": " kuzin analyzed the advances and perspectives in an area of the information systems which could be treated as the artificial intelligence systems (ais)",
        "prob": 0.35882352941176476
    }, {
        "ID": 725,
        "phrase": " in fact, turning this around, the problem of information integration over the web is providing an excellent opportunity for a new experimental arena where ai theory and techniques can be applied and tested",
        "prob": 0.4333333333333333
    }, {
        "ID": 978,
        "phrase": " it was revived mostly by philosophers in 1970's  [1, 31]  with a view towards artificial intelligence reasoning",
        "prob": 0.42500000000000004
    }, {
        "ID": 979,
        "phrase": " it was revived mostly by philosophers in 1970's  [ada86, vf77]  with a view towards artificial intelligence reasoning",
        "prob": 0.3923076923076923
    }, {
        "ID": 1276,
        "phrase": "1 (2) [ [ f (t) ] ] ai id = f ai (t) we obtain t \u2208 f ai (t) and t \u2208 f \u2294ar (t)",
        "prob": 0.18333333333333335
    }, {
        "ID": 1635,
        "phrase": " the new agent-based approach to ai  [5]  is interactive",
        "prob": 0.2333333333333333
    }, {
        "ID": 1666,
        "phrase": " (previous reinforcement learners and nonlearning ai planners tend to fail for solution sizes exceeding 10 2 and 10 5 , respectively",
        "prob": 0.4066666666666667
    }, {
        "ID": 1666,
        "phrase": " \n incremental search? since newell & simon's early attempts at building a \"general problem solver\"  [32, 35] , much work has been done to develop mostly heuristic machine learning algorithms that solve new problems based on experience with previous problems, by incrementally shifting the inductive bias  [55] ",
        "prob": 0.5742857142857142
    }, {
        "ID": 1666,
        "phrase": " on current personal computers ai planners tend to fail to solve hanoi problem instances with n > 15 due to the exploding search space (jana koehler, ibm research, personal communication, 2002)",
        "prob": 0.6708333333333332
    }, {
        "ID": 1667,
        "phrase": " previous, less general reinforcement learners and nonlearning ai planners tend to fail for much smaller instances",
        "prob": 0.7562500000000001
    }, {
        "ID": 1667,
        "phrase": " (1993) -much work has been done to develop mostly heuristic machine learning algorithms that solve new problems based on experience with previous problems, by incrementally shifting the inductive bias in the sense of  utgoff (1986) ",
        "prob": 0.5038461538461539
    }, {
        "ID": 1667,
        "phrase": " on current personal computers ai planners tend to fail to solve hanoi problem instances with n > 15 due to the exploding search space (jana  koehler, ibm research, personal communication, 2002) ",
        "prob": 0.6708333333333332
    }, {
        "ID": 1667,
        "phrase": " oops can solve tasks unsolvable by traditional reinforcement learners and ai planners, such as towers of hanoi with 30 disks (minimal solution size > 10 9 )",
        "prob": 0.33888888888888896
    }, {
        "ID": 1881,
        "phrase": " one of the few lessons that has been learnt from the first 30 years of artificial intelligence is that techniques that may work well on small toy domains, in general do not scale up well to realistically sized tasks",
        "prob": 0.13478260869565217
    }, {
        "ID": 1881,
        "phrase": " however the ml estimator does have some nice formal properties to go with its intuitive appeal",
        "prob": 0.23846153846153847
    }, {
        "ID": 1881,
        "phrase": " in particular for large sample sizes, and subject to various regularity conditions  (silvey, 1975) , ml estimators are nearly unbiased and nearly are minimum variance, i",
        "prob": 0.255
    }, {
        "ID": 1980,
        "phrase": " for example, since the early attempts at building a \"general problem solver\"  [36, 43]  much work has been done to develop mostly heuristic machine learning algorithms that solve new problems based on experience with previous problems",
        "prob": 0.5392857142857143
    }, {
        "ID": 1980,
        "phrase": " previous, less general reinforcement learners and nonlearning ai planners tend to fail for much smaller instances",
        "prob": 0.7562500000000001
    }, {
        "ID": 1980,
        "phrase": " a new kind of ai is emerging",
        "prob": 0.15714285714285717
    }, {
        "ID": 1980,
        "phrase": " the \"new\" ai is new in the sense that it abandons the mostly heuristic or non-general approaches of the past decades, offering methods that are both general and theoretically sound, and provably optimal in a sense that does make sense in the real world",
        "prob": 0.7444444444444444
    }, {
        "ID": 1981,
        "phrase": " for example, since the early attempts at building a \"general problem solver\"  [36, 43]  much work has been done to develop mostly heuristic machine learning algorithms that solve new problems based on experience with previous problems",
        "prob": 0.6107142857142857
    }, {
        "ID": 1981,
        "phrase": " previous, less general reinforcement learners and nonlearning ai planners tend to fail for much smaller instances",
        "prob": 0.7562500000000001
    }, {
        "ID": 1981,
        "phrase": " the \"new\" ai is new in the sense that it abandons the mostly heuristic or nongeneral approaches of the past decades, offering methods that are both general and theoretically sound, and provably optimal in a sense that does make sense in the real world",
        "prob": 0.7346153846153844
    }, {
        "ID": 2079,
        "phrase": " this leads us to a second possible improvement: with the recent amazing expansion of artificial intelligence techniques, a new class of models, called \"agent models\" appeared",
        "prob": 0.2318181818181818
    }, {
        "ID": 2333,
        "phrase": " we seem to have transferred the ai problem just to a different level",
        "prob": 0.4555555555555556
    }, {
        "ID": 2333,
        "phrase": " nevertheless, we want to stress that we have reduced the ai problem to (mere) computational questions",
        "prob": 0.5545454545454546
    }, {
        "ID": 2333,
        "phrase": " it seems that nearly every ai problem could be brought into the form of a game",
        "prob": 0.42500000000000004
    }, {
        "ID": 2333,
        "phrase": "1, is general enough to include any ai system (and also less intelligent systems)",
        "prob": 0.19090909090909092
    }, {
        "ID": 2333,
        "phrase": " the establishment of a formal version of occam's razor would give machine learning in particular, and maybe even science in general, a significant boost",
        "prob": 0.255
    }, {
        "ID": 2333,
        "phrase": " we seem to have transferred the ai problem just to a different level, to proving va(p)",
        "prob": 0.3727272727272727
    }, {
        "ID": 2333,
        "phrase": " nevertheless, we want to stress that we have reduced the ai problem to (mere) computational questions",
        "prob": 0.6454545454545455
    }, {
        "ID": 2333,
        "phrase": " as evolution has already taken place we could add the information from our genes or brain structure to any/our ai system, but this means that the important part is still missing and that it is principally impossible to derive an efficient algorithm from a simple formal definition of ai",
        "prob": 0.8310344827586206
    }, {
        "ID": 2600,
        "phrase": " to attack this \"grand problem of artificial intelligence,\" we introduce a novel class of optimal, fully self-referential  [11]  general problem solvers called g\u00f6del machines  [45, 46] ",
        "prob": 0.41363636363636364
    }, {
        "ID": 2797,
        "phrase": " : themonitor : \u00acpc \u00acmonitor [x] \u2192 : \u00acobjectreference \u00d7 (objectreference x) bag x \u21c0 : \u00acobjectreference \u00d7 (objectreference x) x \u2022 : \u00acobjectreference \u00d7 (\u00ac objectreference \u00acx) \u00acx : objectreference \u00d7 (\u00ac objectreference \u00acx) \u00acx \u2200 s : \u00acobjectreference; r : objectreference x \u2022 s \u2192 r = bagof (r)(s) \u2200 s : \u00acobjectreference; r : objectreference x \u2022 s \u21c0 r = (\u00b5 t : bagof (r)(s) \u2022 first t) \u2200 s : \u00acobjectreference; r : \u00acobjectreference \u00acx \u2022 s \u2022 r = r(s) \u2200 o : objectreference; r : \u00acobjectreference \u00acx \u2022 o r = r({o}) \u2200 p : pc \u2022 p thepowersupply \u21c0 getpower \u2265 p themonitor \u21c0 getpowerused+ p themainboard \u21c0 getpowerused+ bagsum(p themainboard \u2022 theprocessor \u2192 getpowerused) \n an ai example we wish to illustrate the use of the specification utilities and frameworks presented so far with a simple yet very general artificial intelligence problem",
        "prob": 0.6333333333333333
    }, {
        "ID": 2909,
        "phrase": " by replacing variation operators inspired by genetics with machine learning techniques that allow automatic discovery of problem regularities from populations of promising solutions, pmbgas provide quick, accurate, and reliable solution to broad classes of difficult problems, many of which are intractable using other optimizers  [1, 2] ",
        "prob": 0.17941176470588238
    }, {
        "ID": 3010,
        "phrase": " unlike complex deliberative agents, the subject of much of ai research of the past two decades, simple agents have no, or limited, capacity to reason about data, plan action or negotiate with other agents",
        "prob": 0.37916666666666665
    }, {
        "ID": 3650,
        "phrase": " perhaps the bestknown approach in the ai literature involves fuzzy logic, but fuzzy logic represents only a small part of the picture; the number of recent book-length treatments, including  [keefe 2000; keefe and smith 1996; sorenson 2001; williamson 1994] , give a sense of the activity in the area",
        "prob": 0.22187500000000004
    }, {
        "ID": 3894,
        "phrase": " holland in the 1960's to allow computers to evolve solutions to difficult search and combinatorial problems, such as function optimisation and machine learning",
        "prob": 0.5352941176470588
    }, {
        "ID": 3898,
        "phrase": " holland in the 1960s to allow computers to evolve solutions to difficult search and combinatorial problems, such as function optimisation and machine learning",
        "prob": 0.4764705882352941
    }, {
        "ID": 3907,
        "phrase": " on the other hand, it has become widely recognized that the past symbol-oriented community in ai only supported models in research that were far too rigid and specialized, focussing on well-defined problems that generally are rare to found in the real-world, that is, being too inflexible to function well outside the domains for which they were designed",
        "prob": 0.24545454545454545
    }, {
        "ID": 4102,
        "phrase": " then the new estimate is \u03c1 c = n c + n \u2032 c ml = 1 m n c l + m \u2212 1 m n \u2032 c (m \u2212 1) l = \u03c1 \u2032 c + 1 m n c l \u2212 \u03c1 \u2032 c ",
        "prob": 0.15714285714285717
    }, {
        "ID": 4389,
        "phrase": "q \u2208 q m \u2203 } clearly, c \u2208 ai for odd i means that c",
        "prob": 0.15714285714285717
    }, {
        "ID": 4390,
        "phrase": "q \u2208 q m \u2203 } clearly, c \u2208 ai for odd i means that c",
        "prob": 0.15714285714285717
    }, {
        "ID": 4552,
        "phrase": " however machine learning systems depend on well classified examples in sufficient numbers whereas an expert can provide a rule for a single case and a working system will start to evolve",
        "prob": 0.25416666666666665
    }, {
        "ID": 4552,
        "phrase": " we also believe that it will be more portable and applicable to a wider range of domains by making the architecture more domain-neutral, allowing the expert flexibility in reducing search space dimensionality (more structure by identifying higher level operators, and the use of strategic knowledge through probabilisitic weights) and supporting more speculative exploration by the expert (easier revision of rules, hierarchical rdr and potentially introducing limited machine learning in probabilistic selection)",
        "prob": 0.19361702127659575
    }, {
        "ID": 4786,
        "phrase": " the result shows that the fano decoder, unlike other heuristic algorithms like nulling-andcanceling, does not lead to a lower diversity than the ml decoder",
        "prob": 0.1631578947368421
    }, {
        "ID": 4900,
        "phrase": " in cases 2 -4 and 5a, \u03c1(s ) consists of two sets, a 1 and a 2 , and \u00b5(s ai ) \u2264 \u00b5(s )\u22122, i = 1, 2",
        "prob": 0.1375
    }, {
        "ID": 4981,
        "phrase": " however, it is of interest to instead attempt to mimic human sudoku solvers, and derive rules that solve sudoku puzzles without backtracking, first for the standard ai reason that such attempts can teach us much about the power of human and machine reasoning, and second because human-like problem solving capabilities allow us to automatically estimate the difficulty of sudoku puzzles for human solvers by examining the rules necessary to solve each puzzle",
        "prob": 0.46199999999999997
    }, {
        "ID": 5087,
        "phrase": " it seems likely that some schemes are easier for machine learning than others",
        "prob": 0.2818181818181818
    }, {
        "ID": 5196,
        "phrase": " \u2022 increase ml by, for example, using storage media less subject to data corruption, or formats less subject to obsolescence",
        "prob": 0.22777777777777786
    }, {
        "ID": 5380,
        "phrase": " in this work, we develop an efficient approximate ml decoder for mimo systems based on sdp",
        "prob": 0.16153846153846152
    }, {
        "ID": 5485,
        "phrase": " however, the real connection between ai conception and our own acausal understandings of human cognition can be seen only when we view the central thesis of ai in the following manner: since a programmed computer's operation can be visualized at the most fundamental level as due to a complex (and immense) sequence of electromagnetic pulses changing states within the computer's hardware and causing its performance, its operation is qualitatively not different from that of our brain, which also seems to work due to a similar complex sequence of physico-electro-chemical impulses",
        "prob": 0.3673076923076923
    }, {
        "ID": 5485,
        "phrase": " armer argued, surely an airplane does not fly on the same principles that a bird does, but do we deny 'flying' to planes on that count? but to the ai researchers themselves, the source for the \"force in their assumptions\" seems wellknown",
        "prob": 0.1952380952380952
    }, {
        "ID": 5818,
        "phrase": " they provide experimental evidence that practically ml decoding is achieved for the  (8, 4)  hamming code with five rounds of the tail-biting trellis",
        "prob": 0.17222222222222222
    }, {
        "ID": 5854,
        "phrase": "\" on the other hand, ai machines based on classical computing principles have a fixed universe of discourse so they are unable to adapt in a flexible manner to a changing universe",
        "prob": 0.32105263157894737
    }, {
        "ID": 5900,
        "phrase": " for large constellations, the exact ml decoding can be very complex and practically infeasible",
        "prob": 0.25833333333333336
    }, {
        "ID": 6176,
        "phrase": " m in the ml sense",
        "prob": 0.18333333333333332
    }, {
        "ID": 6344,
        "phrase": " we tried to solve the proposed problems using the following systems: \u2022 opl studio -a world leading modeling tool from ilog \u2022 ampl -a well known modeling language able to interact with numerous solvers \u2022 gams -another modeling language \u2022 mathematica -a famous computer algebra system from wolfram research \u2022 unicalc -a system developed at the russian institute for artificial intelligence \n baby example the baby example (be) is a very simple example we used to test various features of the benchmarked systems",
        "prob": 0.24736842105263157
    }, {
        "ID": 6859,
        "phrase": " in particular, it should provide new insights on the famous difficulty of accommodating first-class continuations in ml type system  [11] ",
        "prob": 0.5941176470588235
    }, {
        "ID": 6860,
        "phrase": " in particular, it should provide new insights on the famous difficulty of accommodating first-class continuations in ml type system  [11] ",
        "prob": 0.4764705882352941
    }, {
        "ID": 6872,
        "phrase": " in fact, the new millennium has already brought fundamental new insights into the problem of constructing theoretically optimal rational agents or universal artificial intelligences (ais, more on this below)",
        "prob": 0.7772727272727271
    }, {
        "ID": 6872,
        "phrase": " although the universal approach above is practically infeasible due to the incomputability of solomonoff's prior, it does provide, for the first time, a mathematically sound theory of ai and optimal decision making based on experience, identifying the limits of both human and artificial intelligence, and providing a yardstick for any future approach to general ai",
        "prob": 0.5617647058823528
    }, {
        "ID": 6872,
        "phrase": " we have argued that algorithmic advances are keeping up with the hardware development, pointing to new-millennium theoretical insights on universal problem solvers that are optimal in various mathematical senses (thus making general ai a real formal science), as well as practical progress in program learning through brain-inspired recurrent neural nets (as opposed to mere pattern association through traditional reactive devices)",
        "prob": 0.5577777777777778
    }, {
        "ID": 6872,
        "phrase": "artificial intelligence (ai) has recently become a real formal science: the new millennium brought the first mathematically sound, asymptotically optimal, universal problem solvers, providing a new, rigorous foundation for the previously largely heuristic field of general ai and embedded agents",
        "prob": 0.6999999999999998
    }, {
        "ID": 6873,
        "phrase": " in fact, the new millennium has already brought fundamental new insights into the problem of constructing theoretically optimal rational agents or universal artificial intelligences (ais, more on this below)",
        "prob": 0.7772727272727271
    }, {
        "ID": 6873,
        "phrase": " although the universal approach above is practically infeasible due to the incomputability of solomonoff's prior, it does provide, for the first time, a mathematically sound theory of ai and optimal decision making based on experience, identifying the limits of both human and artificial intelligence, and providing a yardstick for any future approach to general ai",
        "prob": 0.5323529411764705
    }, {
        "ID": 6873,
        "phrase": " we have argued that algorithmic advances are keeping up with the hardware development, pointing to new-millennium theoretical insights on universal problem solvers that are optimal in various mathematical senses (thus making general ai a real formal science), as well as practical progress in program learning through brain-inspired recurrent neural nets (as opposed to mere pattern association through traditional reactive devices)",
        "prob": 0.5577777777777778
    }, {
        "ID": 6873,
        "phrase": "artificial intelligence (ai) has recently become a real formal science: the new millennium brought the first mathematically sound, asymptotically optimal, universal problem solvers, providing a new, rigorous foundation for the previously largely heuristic field of general ai and embedded agents",
        "prob": 0.6999999999999998
    }, {
        "ID": 6874,
        "phrase": " in fact, the new millennium has already brought fundamental new insights into the problem of constructing theoretically optimal rational agents or universal artificial intelligences (ais, more on this below)",
        "prob": 0.7318181818181817
    }, {
        "ID": 6874,
        "phrase": " although the universal approach above is practically infeasible due to the incomputability of solomonoff's prior, it does provide, for the first time, a mathematically sound theory of ai and optimal decision making based on experience, identifying the limits of both human and artificial intelligence, and providing a yardstick for any future approach to general ai",
        "prob": 0.5323529411764705
    }, {
        "ID": 6874,
        "phrase": " we have argued that algorithmic advances are keeping up with the hardware development, pointing to new-millennium theoretical insights on universal problem solvers that are optimal in various mathematical senses (thus making general ai a real formal science), as well as practical progress in program learning through brain-inspired recurrent neural nets (as opposed to mere pattern association through traditional reactive devices)",
        "prob": 0.5355555555555556
    }, {
        "ID": 6874,
        "phrase": "artificial intelligence (ai) has recently become a real formal science: the new millennium brought the first mathematically sound, asymptotically optimal, universal problem solvers, providing a new, rigorous foundation for the previously largely heuristic field of general ai and embedded agents",
        "prob": 0.6999999999999998
    }, {
        "ID": 6969,
        "phrase": "4 db, so there is still room for further improvement in the tightness of the bounds under ml decoding",
        "prob": 0.25833333333333336
    }, {
        "ID": 6969,
        "phrase": " however, in some cases, the new bounds under ml decoding happen to be a bit pessimistic as compared to computer simulations of sub-optimal iterative decoding, thus indicating that there is room for further improvement",
        "prob": 0.29583333333333334
    }, {
        "ID": 7000,
        "phrase": " the feat resulted from classic methods of heroic heuristic hard ai modeling",
        "prob": 0.3416666666666667
    }, {
        "ID": 7363,
        "phrase": " it seems likely that some schemes are easier for machine learning than others",
        "prob": 0.2818181818181818
    }, {
        "ID": 7408,
        "phrase": " if \u2192 ai is confluent for all i \u2265 0, we say that \u2192 a is level confluent",
        "prob": 0.3875
    }, {
        "ID": 7409,
        "phrase": " if \u2192 ai is confluent for all i \u2265 0, we say that \u2192 a is level confluent",
        "prob": 0.3875
    }, {
        "ID": 7858,
        "phrase": " maximum-likelihood decoding to show theorems 2 and 3, we first develop the common core of the proof in the context of ml decoding",
        "prob": 0.1823529411764706
    }, {
        "ID": 8169,
        "phrase": " complete binary decision trees are not very likely to occur in a practical machine learning context, but they offer theoretical insight and have been nevertheless studied as an example of the very difficult xor concept  (pagallo, 1989) ",
        "prob": 0.2125
    }, {
        "ID": 8247,
        "phrase": " this however means that unlike usual ai entities, natural learning entities cannot switch off power once their online response demands are over",
        "prob": 0.3
    }, {
        "ID": 8248,
        "phrase": " such a facility which does not exist for ai entities at present cannot however be ruled out in the future",
        "prob": 0.2818181818181818
    }, {
        "ID": 8248,
        "phrase": " it is this knowledge that we seek to embed in our ai entities",
        "prob": 0.13749999999999998
    }, {
        "ID": 8248,
        "phrase": " if the author's understanding is correct, there are no ai entities presently available or under construction that are embedded with such enfolded learning processes or mind based communication needs",
        "prob": 0.1631578947368421
    }, {
        "ID": 8248,
        "phrase": " it is obvious that such a process, once its roots are understood, is not very difficult to implement in ai entities",
        "prob": 0.19090909090909092
    }, {
        "ID": 8490,
        "phrase": ") the big advantage of the lp comes from its discrete nature and simplicity, leading in particular to the remarkable ml certificate property  [7] : if lp decodes to a codeword the result is already optimal and cannot be improved as optimal block-map would decode to the same codeword",
        "prob": 0.26999999999999996
    }, {
        "ID": 8555,
        "phrase": " it seems that nearly every ai problem could be brought into the form of a game",
        "prob": 0.42500000000000004
    }, {
        "ID": 8555,
        "phrase": " the ai\u00b5 model is optimal by construction of \u00b5 ai ",
        "prob": 0.15714285714285714
    }, {
        "ID": 8555,
        "phrase": "4, is general enough to include any ai system (and also less intelligent systems)",
        "prob": 0.19090909090909092
    }, {
        "ID": 8555,
        "phrase": " we seem to have transferred the ai problem just to a different level",
        "prob": 0.4555555555555556
    }, {
        "ID": 8555,
        "phrase": " nevertheless, we want to stress that we have reduced the ai problem to (mere) computational questions",
        "prob": 0.6454545454545455
    }, {
        "ID": 8555,
        "phrase": " \n the big questions this subsection is devoted to the big questions of ai in general and the aixi model in particular with a personal touch",
        "prob": 0.5062500000000001
    }, {
        "ID": 8555,
        "phrase": " as evolution has already taken place, we could add the information from our genes or brain structure to any/our ai system, but this means that the important part is still missing, and that it is principally impossible to derive an efficient algorithm from a simple formal definition of ai",
        "prob": 0.8655172413793102
    }, {
        "ID": 8622,
        "phrase": " still, our problem does not lie at the core of planning in the ai sense  (hendler et al",
        "prob": 0.4636363636363637
    }, {
        "ID": 8623,
        "phrase": "  8  still, our problem does not lie at the core of planning in the ai sense, since we are not interested (yet) in computing optimal plans to a goal",
        "prob": 0.3588235294117647
    }, {
        "ID": 8882,
        "phrase": " however, the complex shapes of the voronoi cells are difficult to handle by algebraic methods, which means that known ml decoders generally possess a computational complexity, which grows exponentially in n",
        "prob": 0.30869565217391304
    }, {
        "ID": 9004,
        "phrase": " we add two more points at the far end: p 1 = a n+1 + ( 4 n 9 \u2212 179 1800 ) 3 \u22124 p 2 = a n+1 + 4( 4 n 9 \u2212 179 1800 ) 3 \u22124 9 \u2022 4 i\u22121 + \u03b1i ai+1 ai 11 \u2022 4 i\u22121 1 \u2022 4 i\u22121 3 \u2022 4 i\u22121 2 \u2022 4 i\u22121 bi ci di figure 6: the construction between a i and a i+1 both points lie on the line through a n+1 with slope \u22124/3, and so \u2220a 1 a n+1 p 2 is a right angle",
        "prob": 0.19375
    }, {
        "ID": 9228,
        "phrase": " the current ml compiler generates poor code, though efficient implementations are being developed [$cardelli83]",
        "prob": 0.20666666666666667
    }, {
        "ID": 9230,
        "phrase": "5 times smaller than the ml one",
        "prob": 0.3
    }, {
        "ID": 9256,
        "phrase": " the university of massachusetts has been moving in the direction of machine learning to create a fully trainable ie system",
        "prob": 0.2733333333333333
    }, {
        "ID": 9256,
        "phrase": " this paper presents a novel approach that uses machine learning to acquire knowledge for some of the higher level ie processing",
        "prob": 0.24117647058823527
    }, {
        "ID": 9267,
        "phrase": " if ai can be said to have had a theoretical foundation, then this de nition of rationality has provided it",
        "prob": 0.21000000000000002
    }, {
        "ID": 9267,
        "phrase": " the intuitive notion of bounded optimality seems to have become current in the ai community in the mid-1980's",
        "prob": 0.3153846153846154
    }, {
        "ID": 9298,
        "phrase": " the implicit assumption underlying much machine learning research appears to be that, all other things being equal, less complex classi ers will be, in general, more accurate  (blumer et al",
        "prob": 0.2904761904761905
    }, {
        "ID": 9324,
        "phrase": " what explains zlifo's performance? gerevini and schubert answer this question as follows: based on experience with search processes in ai in general, a lifo] strategy has much to recommend it, as a simple default",
        "prob": 0.2652173913043478
    }, {
        "ID": 9334,
        "phrase": " in particular, much work in other areas in ai and in economics have dealt with non-probabilistic settings in which the environment changes in an unpredictable manner 2 ",
        "prob": 0.18235294117647055
    }, {
        "ID": 9564,
        "phrase": " that is to say machine learning solutions that perform reasonably well in lower complexities can be applied to problems with higher magnitudes of complexity, and still be expected to converge in a relatively reasonable manner",
        "prob": 0.2125
    }, {
        "ID": 9565,
        "phrase": " another ai technique that could readily be incorporated into the agents is artificial evolution  [11] ",
        "prob": 0.3416666666666667
    }, {
        "ID": 9641,
        "phrase": " this paper has argued that both types can be processed using basic ai reasoning techniques which have already been applied to cases of straight metaphor, and in particular, the nesting of simulation and metaphor-pretence cocoons",
        "prob": 0.1782608695652174
    }, {
        "ID": 9672,
        "phrase": " this brief review shows that the economic approach is very expressive-a difficult research challenge, however, is to develop efficient and scalable methods for reasoning, planning, and learning within the economic ai framework",
        "prob": 0.17083333333333334
    }, {
        "ID": 9704,
        "phrase": " its slogan at this level was \"big data, small program\" which is much more the current trend in language processing and artificial intelligence generally than the opposite slogan, one which had ruled for decades and seen all such simulations as forms of complex reasoning, rather than the assembly of a vast array of cases and data",
        "prob": 0.30606060606060603
    }, {
        "ID": 9779,
        "phrase": " despite this evolution, dai maintains the traditional ai concern with a pre-fixed set of particular aspects of intelligent behavior (e",
        "prob": 0.19375
    }, {
        "ID": 9845,
        "phrase": " we are still in ai winter",
        "prob": 0.18333333333333332
    }, {
        "ID": 9845,
        "phrase": " the ai community promised breakthroughs, but they did not deliver",
        "prob": 0.3875
    }, {
        "ID": 9845,
        "phrase": " it is probably ai complete, but it an excellent goal, probably simpler and more useful than a computer that plays the imitation game as well as a human",
        "prob": 0.12352941176470589
    }]
}, {
    "topic_id": 5,
    "top_words": ["ml", "decoding", "lp", "code", "distance", "problem", "codewords", "solution", "codeword", "weight", "hamming", "pseudo", "linear", "called", "binary"],
    "phrases": [{
        "ID": 542,
        "phrase": " , b ml , b 1r , ",
        "prob": 0.22000000000000003
    }, {
        "ID": 777,
        "phrase": " this yields t |u,b [t ai (a, i)] = z |u a, z |b (i) ",
        "prob": 0.18333333333333335
    }, {
        "ID": 1464,
        "phrase": " ml ling",
        "prob": 0.18333333333333332
    }, {
        "ID": 1557,
        "phrase": " the corresponding rbf is \u2207 2 u \u2212 \u03bb 2 u = 0 , ( 18 ) \u03c6 r j ( ) = 6 r j 2 + c j 2 ( ) + 3r 2 r j 2 + c j 2 + r j 2 + c j 2 ( ) 3 2 , (12) the non-singular particular solution is u * = ai 0 \u03bbr ( ), (19) \n boundary rbf using non-singular general solution where i 0 is the zero-order modified bessel function of the first kind",
        "prob": 0.17083333333333336
    }, {
        "ID": 2558,
        "phrase": " in machine learning, the phenotype is a candidate solution to some optimization problem, while the genotype is an encoding, or description, of that solution by means of a domain independent representation, namely, binary symbol strings (or chromosomes)",
        "prob": 0.2541666666666667
    }, {
        "ID": 3263,
        "phrase": " is in lr ai and thus the \u03c6 i",
        "prob": 0.18333333333333332
    }, {
        "ID": 3630,
        "phrase": " by regarding the ideal received points as lattice points, the ml decoding problem is reduced to the classical closest lattice point search problem",
        "prob": 0.355
    }, {
        "ID": 3630,
        "phrase": " we also remark that when we use linear spacetime coding, the ml decoding problem is reduced to the closest lattice point search problem by describing the channel as eq",
        "prob": 0.24285714285714283
    }, {
        "ID": 3892,
        "phrase": " our last explanation for ci derives from ai research into multi-agent problem solving",
        "prob": 0.17500000000000002
    }, {
        "ID": 4061,
        "phrase": " fortunately, it can be demonstrated that no performance loss is incurred (asymptotically) by replacing the ml estimates with the ls estimates, and an efficient algorithm for computing the ls estimates exists",
        "prob": 0.1952380952380952
    }, {
        "ID": 4061,
        "phrase": " the best estimates, in both the ml sense and the least squares (ls) sense (see appendix iv), are \u03c3 1 n,q = 1 p \u2212 q p i=q+1 l i (9) a 1 q r 1 s,q a 1 q h = q i=1 l i \u2212 \u03c3 1 n,q 2 v i v h i ( 10 ) where l 1 > \u2022 \u2022 \u2022 > l p and v 1 , ",
        "prob": 0.2157894736842105
    }, {
        "ID": 4061,
        "phrase": " (11) next, w 1 q is estimated from e, and the best estimate in both the ml and ls sense is, w 1 q = diag (e) ",
        "prob": 0.3416666666666667
    }, {
        "ID": 4208,
        "phrase": " an ml decoder will output a codeword that has the closest euclidean distance  [5]  to the received block",
        "prob": 0.3923076923076924
    }, {
        "ID": 4208,
        "phrase": " the significance of the mrl codewords is that an ml decoder either outputs correct codewords or mrl codewords",
        "prob": 0.34
    }, {
        "ID": 4383,
        "phrase": " obviously, \u03c8 ml (w) = 0 for w 7 and \u03c8 ml (w) = (  24 w ) for w 13 (any 13 columns of a parity-check matrix for g 24 are linearly dependent)",
        "prob": 0.6230769230769231
    }, {
        "ID": 4384,
        "phrase": " then obviously, \u03c8 ml (w) = 0 for w 7 and \u03c8 ml (w) = (  24 w ) for w 13 (any 13 columns of a parity-check matrix for g 24 are linearly dependent)",
        "prob": 0.4692307692307693
    }, {
        "ID": 4454,
        "phrase": " namely, \u00b5 1 is the hamming weight of a vector (s ai ) i\u2208i1 and \u00b5 2 is the hamming weight of (s ai ) i\u2208i2 ",
        "prob": 0.51
    }, {
        "ID": 4456,
        "phrase": " clearly, b, having the best pseudocodeword weight distribution among the three representations, yields the best performance with minsum iterative decoding, with performance almost matching that of the optimal ml decoder",
        "prob": 0.5041666666666667
    }, {
        "ID": 4456,
        "phrase": " here again, representation b, having the best pseudocodeword-weight distribution among the three representations, yields the best performance with min-sum iterative decoding and is closest in performance to that of the ml decoder",
        "prob": 0.43913043478260866
    }, {
        "ID": 4457,
        "phrase": " clearly, b, having the best pseudocodeword weight distribution among the three representations, yields the best performance with min-sum iterative decoding, with performance almost matching that of the optimal ml decoder",
        "prob": 0.444
    }, {
        "ID": 4458,
        "phrase": " in the case where the all-zeros codeword is the ml codeword, it is equivalent to say that a pseudocodeword p is bad if there is a weight vector w such that for all codewords c, cw t \u2265 0 but pw t < 0",
        "prob": 0.6894736842105263
    }, {
        "ID": 4458,
        "phrase": " clearly, b, having the best pseudocodeword weight distribution among the three representations, yields the best performance with ms decoding, with performance almost matching that of the optimal ml decoder",
        "prob": 0.43913043478260866
    }, {
        "ID": 4459,
        "phrase": " in the case where the all-zeros codeword is the ml codeword, it is equivalent to say that a pseudocodeword p is bad if there is a weight vector w such that for all codewords c, cw t \u2265 0 but pw t < 0",
        "prob": 0.6368421052631579
    }, {
        "ID": 4459,
        "phrase": " clearly, b, having the best pseudocodeword weight distribution among the three representations, yields the best performance with ms decoding, with performance almost matching that of the optimal ml decoder",
        "prob": 0.5260869565217391
    }, {
        "ID": 4786,
        "phrase": " assuming h and v known to the receiver, the ml decoding rule is given by x = arg min x\u2208u |r \u2212 hv \u2212 hgx|  2  (5) the constraint u \u2282 z m implies that the optimization problem in  (5)  can be viewed as a constrained version of the clps with lattice generator matrix given by hg and constraint set u",
        "prob": 0.2366666666666667
    }, {
        "ID": 4786,
        "phrase": " left preprocessing can be seen as an effort to tackle the first problem: it modifies the channel matrix and the noise vector such that the resulting clps problem is non-equivalent to ml (therefore, it is suboptimal), but it has a much better conditioned \"channel\" matrix",
        "prob": 0.2103448275862069
    }, {
        "ID": 4786,
        "phrase": " fortunately, it turns out that an appropriate combination of these elements yields very significant saving in complexity with very small degradation with respect to the ml performance",
        "prob": 0.22777777777777775
    }, {
        "ID": 4856,
        "phrase": " in conclusion, for the bec, gradient descent without adaptation tends to get stuck at a pseudo-equilibrium point, while the reliability based adaptation will help gradient descent to converge to the ml solution in one iteration",
        "prob": 0.19615384615384615
    }, {
        "ID": 4900,
        "phrase": " in case 5b, s has two children in t t , s ai , i = 1, 2",
        "prob": 0.3
    }, {
        "ID": 4951,
        "phrase": " ml decoding (which generally requires an exponentially large number, 2 k , of steps) corresponds to finding the most probable transmitted codeword given x x x",
        "prob": 0.2833333333333334
    }, {
        "ID": 4951,
        "phrase": "6, and to the ideal ml decoding with the hamming distance, l ml;l = 20, respectively",
        "prob": 0.5545454545454546
    }, {
        "ID": 4952,
        "phrase": "6, and to the ideal ml decoding with the hamming distance, l ml;l = 20, respectively",
        "prob": 0.4636363636363637
    }, {
        "ID": 5031,
        "phrase": " lp decoding ml decoding as in (1) can also be formulated as x \u03c6 ml (\u03bb \u2032 ) arg max x\u2208conv( c) n i=1 xi \u03bb \u2032 i , (3) where conv( c) is the convex hull of c and where the mapping \u00b5 is the trivial mapping \u00b5 triv ",
        "prob": 0.5285714285714287
    }, {
        "ID": 5037,
        "phrase": " ml and lp decoding in this section we briefly review ml and lp decoding",
        "prob": 0.39230769230769236
    }, {
        "ID": 5037,
        "phrase": " ml decoding can then be cast as x arg min x\u2208c n i=1 x i \u03bb i , (1) letting conv(c) be the convex hull of c in r n , the above ml decoding rule can also be formulated as x arg min x\u2208conv(c) n i=1 x i \u03bb i ",
        "prob": 0.6894736842105263
    }, {
        "ID": 5037,
        "phrase": " therefore, knowing the minimal codewords of the code c is sufficient in order to assess its ml decoding performance",
        "prob": 0.4066666666666667
    }, {
        "ID": 5046,
        "phrase": " an ml decoder now finds the codeword x that is closest to y in the euclidean sense",
        "prob": 0.37272727272727274
    }, {
        "ID": 5046,
        "phrase": " the case m = 1 serves as the induction anchor, since it is obvious that algorithm 2 is an ml decoder for rm q (1, 1)",
        "prob": 0.22142857142857145
    }, {
        "ID": 5075,
        "phrase": " thus ml decoding is equivalent to solving the problem: minimize \u03b3 t x subject to x \u2208 c",
        "prob": 0.5083333333333334
    }, {
        "ID": 5075,
        "phrase": " thus, if a 0-1 vector is a solution to the linear program, it must be an ml codeword",
        "prob": 0.5083333333333334
    }, {
        "ID": 5075,
        "phrase": " pseudo-weight on the awgn channel for ml decoding over a memoryless channel, the probability of error of a code is largely determined by its hamming weight spectrum",
        "prob": 0.605
    }, {
        "ID": 5076,
        "phrase": " , l m , q (nm) ml = x ml \u2212 y m(l\u22121) + y ml ",
        "prob": 0.1222222222222222
    }, {
        "ID": 5076,
        "phrase": " , l m , and y ml (\u03c4 ) = 0 (5) for all l = 1, 2, ",
        "prob": 0.22000000000000003
    }, {
        "ID": 5196,
        "phrase": " for example, if ml = 1",
        "prob": 0.18333333333333335
    }, {
        "ID": 5208,
        "phrase": " using the sphere bound, the error event of ml decoding conditioned on a channel realization h is where d 2 min is the minimum euclidean distance between two codewords in x , w is the exponential order of w 2 f (\u223c \u03c7 2 2n r n t ) and \u03b7 is that of 1/d 2 min ",
        "prob": 0.2904761904761905
    }, {
        "ID": 5379,
        "phrase": " the columns of the channel matrix are nearly orthogonal and short, it is most likely that the ml solution of the lattice decoding problem is around s \u2032 ",
        "prob": 0.5352941176470588
    }, {
        "ID": 5380,
        "phrase": " the columns of the channel matrix are nearly orthogonal and short, it is most likely that the ml solution of the lattice decoding problem is around  5  without loss of generality, we assume that n = m ",
        "prob": 0.29047619047619044
    }, {
        "ID": 5396,
        "phrase": " in addition, because the awgnc pseudo-weight spectrum gap seems to be large for the codes considered in this paper, reflecting the fact that lp decoding performs closely to ml decoding, lp decoding might be an interesting starting point for obtaining a complete decoder for these codes, i",
        "prob": 0.24545454545454545
    }, {
        "ID": 5404,
        "phrase": " , n, we can view ml decoding as the optimization problem x arg min x\u2208c n i=1 x i \u03bb i = arg min x\u2208conv(c) n i=1 x i \u03bb i , (2",
        "prob": 0.46923076923076923
    }, {
        "ID": 5404,
        "phrase": " among the codewords, the significant ones for ml decoding turn out to be the minimal ones, m(c), i",
        "prob": 0.29285714285714287
    }, {
        "ID": 5404,
        "phrase": " hence the set of minimal codewords are of particular interest and are worth studying, as their patterns characterize the behavior of the code under ml decoding",
        "prob": 0.22777777777777775
    }, {
        "ID": 5404,
        "phrase": " d ml x \u03bb \u2208 r n x \u2032 \u2022 \u03bb t \u2265 x \u2022 \u03bb t for all x \u2032 \u2208 c \\ {x} , for most codes of interest, the description complexity of conv(c) grows exponentially in the block length, therefore finding the minimum in (2",
        "prob": 0.1823529411764706
    }, {
        "ID": 5404,
        "phrase": " mimicking the parallel ml discussion above, we will call these minimal pseudo-codewords",
        "prob": 0.25833333333333336
    }, {
        "ID": 5404,
        "phrase": " in this context, we will define an important parameter in lp decoding: the pseudo-weight of a pseudo-codeword, which corresponds to the hamming weight of a codeword in ml decoding",
        "prob": 0.605
    }, {
        "ID": 5817,
        "phrase": " then ml decoding is achieved by decoding a received vector r into the codeword y + e where e is a binary vector that satisfies s = eh t and has the property that if e \u2032 is any other binary vector such that s = e \u2032 h t then e",
        "prob": 0.33888888888888896
    }, {
        "ID": 5900,
        "phrase": " as a simple approximation of ml decoding, zero-forcing can be used, which selects x as the closest integer point to h \u22121 y",
        "prob": 0.54
    }, {
        "ID": 5903,
        "phrase": "  9 , the performance of soft and hard ml decoding of various hamming and extended hamming codes are studied and compared",
        "prob": 0.19375
    }, {
        "ID": 5908,
        "phrase": " more specifically, the decoder always gives either the ml codeword, or a nonintegral pseudo-codeword as the solution",
        "prob": 0.4733333333333334
    }, {
        "ID": 5908,
        "phrase": " lp relaxation of ml decoding consider a binary linear code c of length n",
        "prob": 0.4692307692307693
    }, {
        "ID": 5908,
        "phrase": " if a codeword y \u2208 c is transmitted through a binary-input memoryless channel, the ml codeword given the received vector r \u2208 r n is the solution to the optimization problem minimize \u03b3 t x subject to x \u2208 c , ( 1 ) where \u03b3 is the vector of log-likelihood ratios defined as \u03b3 i = log pr(r i |y i = 0) pr(r i |y i = 1) ",
        "prob": 0.39642857142857146
    }, {
        "ID": 5908,
        "phrase": " ( 2 ) as an approximation to ml decoding, feldman et al",
        "prob": 0.5125000000000001
    }, {
        "ID": 5908,
        "phrase": " therefore, whenever lp gives an integral solution, it is guaranteed to be the ml codeword",
        "prob": 0.5461538461538462
    }, {
        "ID": 5908,
        "phrase": "  [1]  have mentioned some ways to tighten the relaxation of the ml decoding, including adding redundant parity checks (rpc), and using lift-andproject methods",
        "prob": 0.555
    }, {
        "ID": 5908,
        "phrase": " on the other hand, ml decoding may also fail in some of the cases where lp decoding does not converge to an integral solution",
        "prob": 0.4066666666666667
    }, {
        "ID": 5932,
        "phrase": " karger  [1]  in a bit different but absolutely equivalent way -as a relaxation of the ml decoding",
        "prob": 0.4357142857142857
    }, {
        "ID": 5932,
        "phrase": " actual asymptotics of the two curves for the awgn channel are fer ml \u223c exp[\u2212d ml \u2022 s 2 /2] and fer lp \u223c exp[\u2212d lp \u2022 s 2 /2] , where d ml is the so-called hamming distance of the code and the d lp is the effective distance of the code, specific for the lp decoding",
        "prob": 0.8741935483870966
    }, {
        "ID": 5932,
        "phrase": " the hamming distance of the code is known to be d ml = 20",
        "prob": 0.5666666666666668
    }, {
        "ID": 5932,
        "phrase": " in particular, one finds a codeword closest to the all zeros one with d = d ml = 20",
        "prob": 0.51
    }, {
        "ID": 5933,
        "phrase": " lp decoding was introduced by feldman, wainwright and karger  [1]  as a computationally efficient approximation to ml decoding",
        "prob": 0.7400000000000001
    }, {
        "ID": 5933,
        "phrase": " looking for \u03c3 \u2032 in terms of a linear combination of all possible codewords of the code, \u03c3 v : \u03c3 \u2032 = v \u03bb v \u03c3 v , where \u03bb v \u2265 0 and v \u03bb v = 1, one finds that ml turns into a linear optimization problem",
        "prob": 0.5941176470588235
    }, {
        "ID": 5933,
        "phrase": " for an idealized code containing no loops (the path connecting any two bits through a sequence of other bits and their neighboring checks is unique), the sum-product algorithm (with sufficient number of iterations) is exactly equivalent to the so-called maximum-a-posteriori (map) decoding, which is reduced to ml in the asymptotic limit of infinite snr",
        "prob": 0.327027027027027
    }, {
        "ID": 5933,
        "phrase": " the actual asymptotics of the two curves for the awgn channel are fer ml \u223c exp[\u22122d ml \u2022 s 2 ] and fer lp \u223c exp[\u22122d lp \u2022 s 2 ], where d ml is the so-called hamming distance of the code and the d lp is the effective distance of the code, specific for the lp decoding",
        "prob": 0.8419354838709676
    }, {
        "ID": 5933,
        "phrase": " the hamming distance of the code is known to be d ml = 20",
        "prob": 0.4555555555555556
    }, {
        "ID": 5934,
        "phrase": " lp decoding was introduced by feldman, wainwright and karger  [1]  as a computationally efficient approximation to the ml decoding",
        "prob": 0.7400000000000001
    }, {
        "ID": 5934,
        "phrase": " looking for \u03c3 \u2032 in terms of a linear combination of all possible codewords of the code, \u03c3 v : \u03c3 \u2032 = v \u03bb v \u03c3 v , where \u03bb v \u2265 0 and v \u03bb v = 1, one finds that ml turns into a linear optimization problem",
        "prob": 0.6529411764705882
    }, {
        "ID": 5934,
        "phrase": " introduction ii: pseudo codewords, frame error rate and effective distance as it was shown in  [1]  the lp decoding has ml certificate, i",
        "prob": 0.3588235294117647
    }, {
        "ID": 5934,
        "phrase": " the actual asymptotics of the two curves for the awgn channel are fer ml \u223c exp(\u22122d ml \u2022 s 2 ) and fer lp \u223c exp(\u22122d lp \u2022 s 2 ), where d ml is the so-called hamming distance of the code and the d lp is the effective distance of the code, specific for the lp decoding",
        "prob": 0.8741935483870966
    }, {
        "ID": 5934,
        "phrase": " the hamming distance of the code is known to be d ml = 20",
        "prob": 0.34444444444444444
    }, {
        "ID": 5934,
        "phrase": " since the pseudo-weight spectrum gap is positive in this case, the lp decoding approaches the ml decoding performance for snr \u2192 \u221e",
        "prob": 0.44999999999999996
    }, {
        "ID": 5935,
        "phrase": " lp decoding was introduced by feldman, wainwright and karger  [1]  as a computationally efficient approximation to the ml decoding",
        "prob": 0.7400000000000001
    }, {
        "ID": 5935,
        "phrase": " looking for \u03c3 \u2032 in terms of a linear combination of all possible codewords of the code, \u03c3 v : \u03c3 \u2032 = v \u03bb v \u03c3 v , where \u03bb v \u2265 0 and v \u03bb v = 1, one finds that ml turns into a linear optimization problem",
        "prob": 0.6529411764705882
    }, {
        "ID": 5935,
        "phrase": " introduction ii: pseudo codewords, frame error rate and effective distance as it was shown in  [1]  the lp decoding has ml certificate, i",
        "prob": 0.3588235294117647
    }, {
        "ID": 5935,
        "phrase": " in the so-called error-floor domain, splitting of the two (fer vs snr) curves, representing the ml decoding and an approximate decoding (say lp decoding) is due to pseudo-codewords  [13] ",
        "prob": 0.38846153846153847
    }, {
        "ID": 5935,
        "phrase": " the actual asymptotics of the two curves for the awgn channel are fer ml \u223c exp(\u2212d ml \u2022s 2 /2) and fer lp \u223c exp(\u2212d lp \u2022 s 2 /2), where d ml is the so-called hamming distance of the code and the d lp is the effective distance of the code, specific for the lp decoding",
        "prob": 0.8741935483870966
    }, {
        "ID": 5935,
        "phrase": " the hamming distance of the code is known to be d ml = 20",
        "prob": 0.4555555555555556
    }, {
        "ID": 5935,
        "phrase": " since the pseudo-weight spectrum gap is positive in this case, the lp decoding approaches the ml decoding performance for snr \u2192 \u221e",
        "prob": 0.44999999999999996
    }, {
        "ID": 5953,
        "phrase": " when the edges are given weights corresponding to the log-likelihood values, ml decoding corresponds to finding the minimum weight codeword path in the tbt",
        "prob": 0.355
    }, {
        "ID": 5969,
        "phrase": " thus, m does not implement l ai \u2264 p lnd-t a i ",
        "prob": 0.15714285714285714
    }, {
        "ID": 6100,
        "phrase": " \u2227 \u03b1 n , obtained by taking the conjunction of all consequents of equations in the system, is a negmif (negmif * ) in ml + ",
        "prob": 0.6230769230769231
    }, {
        "ID": 6101,
        "phrase": " \u2227 \u03b1 n , obtained by taking the conjunction of all consequents of equations in the system, is a negmif (negmif * ) in ml + ",
        "prob": 0.6230769230769231
    }, {
        "ID": 6102,
        "phrase": " \u2227 \u03b1 n , obtained by taking the conjunction of all consequents of equations in the system, is a negmif (negmif * ) in ml + ",
        "prob": 0.5461538461538462
    }, {
        "ID": 6103,
        "phrase": " \u2227 \u03b1 n , obtained by taking the conjunction of all consequents of equations in the system, is a negmif (negmif * ) in ml + ",
        "prob": 0.6230769230769231
    }, {
        "ID": 6165,
        "phrase": " the obvious polytope for lp decoding is the convex hull of all codewords, in which case lp decoding is equivalent to ml decoding",
        "prob": 0.6529411764705882
    }, {
        "ID": 6176,
        "phrase": " unfortunately, for the modulo-m problem, slicing the unconstrained ls ml solution is generally not optimal w",
        "prob": 0.5785714285714286
    }, {
        "ID": 6176,
        "phrase": " nevertheless, ml optimality is preserved by reduction modulo m (rounding, or 'slicing'), to a limited extent, in some cases-i",
        "prob": 0.33999999999999997
    }, {
        "ID": 6176,
        "phrase": " proposition 1: [ml optimality of m-constrained solution to  (57) ] if h in (57) has orthogonal columns then finding the closest m point to the unconstrained ls ml solution to  (57)  preserves optimality in the constrained ml sense",
        "prob": 0.8304347826086954
    }, {
        "ID": 6176,
        "phrase": " = w t \u03bb is not a sub-lattice, the ls ml solution constrained to m ",
        "prob": 0.51
    }, {
        "ID": 6176,
        "phrase": " more importantly, the coordinates of the constrained ml point in p w \u03bb are, thereby, obtained-as in sec",
        "prob": 0.6230769230769231
    }, {
        "ID": 6176,
        "phrase": " ii-c1-simply as the closest points in p wi (\u03bb) to the respective projections on w i of some unconstrained ml statistic (e",
        "prob": 0.3642857142857144
    }, {
        "ID": 6176,
        "phrase": " since y = ww h \u03bb + n = w p w \u03bb + n, with w orthogonal, the ls ml solution constrained to p w \u03bb is simply the closest point from p w \u03bb to the projection of y onto w",
        "prob": 0.6312500000000001
    }, {
        "ID": 6176,
        "phrase": " thus the minimum in (77) corresponds to the constrained ml solution (closest s\u2208m to the sufficient statistic \u03c7), obtainable as the closest s\u2208m to the unconstrained ls solution \u015dml (76); should m be a lattice, rounding \u015dml to nearest integers (babai estimate) yields the exact integer ls solution to  (57) ",
        "prob": 0.8212121212121211
    }, {
        "ID": 6176,
        "phrase": " \n\t\t\t even if the likelihood order for the remaining points (other than the ml one) is spoiled by the constrained ls solution, the redundancy present in the lattice and/or fec will iteratively restore the a posteriori order, as long as the algorithm proceeds with the correct search scope",
        "prob": 0.2793103448275862
    }, {
        "ID": 6177,
        "phrase": " unfortunately, for the modulo-m problem, slicing the unconstrained ls ml solution is generally not optimal w",
        "prob": 0.5785714285714286
    }, {
        "ID": 6177,
        "phrase": " nevertheless, ml optimality is preserved by reduction modulo m (rounding, or 'slicing'), to a limited extent, in some cases-i",
        "prob": 0.47333333333333344
    }, {
        "ID": 6177,
        "phrase": " proposition 1: [ml optimality of m-constrained solution to  (57) ] if h in (57) has orthogonal columns then finding the closest m point to the unconstrained ls ml solution to  (57)  preserves optimality in the constrained ml sense",
        "prob": 0.8304347826086954
    }, {
        "ID": 6177,
        "phrase": " = w t \u03bb is not a sublattice, the ls ml solution constrained to m ",
        "prob": 0.4555555555555556
    }, {
        "ID": 6177,
        "phrase": " more importantly, the coordinates of the constrained ml point in pw \u03bb are, thereby, obtained-as in sec",
        "prob": 0.65
    }, {
        "ID": 6177,
        "phrase": " ii-c1-simply as the closest points in pw i (\u03bb) to the respective projections on wi of some unconstrained ml statistic (e",
        "prob": 0.54
    }, {
        "ID": 6177,
        "phrase": " since y = ww h \u03bb + n = w p w \u03bb + n, with w orthogonal, the ls ml solution constrained to p w \u03bb is simply the closest point from p w \u03bb to the projection of y onto w",
        "prob": 0.6937500000000001
    }, {
        "ID": 6177,
        "phrase": " by svd, h = v\u03c3w h , where v \u2208 c n\u00d7n , w \u2208 c m\u00d7m are unitary, and \u03c3 \u2208 r n\u00d7m is diagonal with non-negative diagonal entries (non-negative square roots of eigenvalues of hh  the minimum in (77) corresponds to the constrained ml solution (closest s\u2208m to the sufficient statistic \u03c7), obtainable as the closest s\u2208m to the unconstrained ls solution \u015dml (76); should m be a lattice, rounding \u015dml to nearest integers (babai estimate) yields the exact integer ls solution to  (57) ",
        "prob": 0.5530612244897959
    }, {
        "ID": 6177,
        "phrase": " \n\t\t\t even if the likelihood order for the remaining points (other than the ml one) is spoiled by the constrained ls solution, the redundancy present in the lattice and/or fec will iteratively restore the a posteriori order, as long as the algorithm proceeds with the correct search scope",
        "prob": 0.3482758620689655
    }, {
        "ID": 6188,
        "phrase": " after having concluded this introduction with some remarks about our notation, we will review ml and lp decoding in sec",
        "prob": 0.3923076923076923
    }, {
        "ID": 6190,
        "phrase": " 4 and 5 we will explain why minimal codewords and minimal pseudo-codewords are important in the understanding of the performance of ml and lp decoding, respectively",
        "prob": 0.4764705882352941
    }, {
        "ID": 6190,
        "phrase": " (1) letting conv(c) be the convex hull of c in r n , the above ml decoding rule can also be formulated as x arg min x\u2208conv(c) x, \u03bb ",
        "prob": 0.5785714285714286
    }, {
        "ID": 6190,
        "phrase": " \n minimal codewords in this section we will discuss minimal codewords and explain their importance with respect to ml decoding",
        "prob": 0.4066666666666667
    }, {
        "ID": 6190,
        "phrase": " therefore, knowing the minimal codewords of the code c is sufficient in order to assess its ml decoding performance",
        "prob": 0.4066666666666667
    }, {
        "ID": 6190,
        "phrase": " this influence will be measured by a channel-dependent pseudo-weight of pseudo-codewords; these pseudo-weights can be seen as generalizations of the hamming weight that has traditionally been used to assess the performance of a code under ml decoding",
        "prob": 0.484
    }, {
        "ID": 6190,
        "phrase": " \n\t\t\t of course, the pseudo-weight spectrum gap is only a first approximation to how quickly the lp decoding performance approaches the ml decoding performance as the snr goes to infinity",
        "prob": 0.2772727272727273
    }, {
        "ID": 6308,
        "phrase": " let \u03b8 be the ml estimator of \u03b8 from x n , and \u03b8\u03c9 the closest point in \u03c9 to \u03b8 that is used to estimate \u03b8 in the standard i",
        "prob": 0.17500000000000002
    }, {
        "ID": 6308,
        "phrase": " this lemma is necessary, because the ordered ml estimator \u03c8 \u03b8 obtained directly from \u03c8 (x n ) simply performs this projection over the i",
        "prob": 0.22142857142857145
    }, {
        "ID": 6308,
        "phrase": " ml probability",
        "prob": 0.18333333333333335
    }, {
        "ID": 6519,
        "phrase": "  (12)  from (  12 ), we construct by linear algebra a linear difference equation with minimal order, say, l(z1) = \u03c6 k (z1) + a k\u22121 \u03c6 k\u22121 (z1) + \u2022 \u2022 \u2022 + a0z1 = 0 where ai \u2208 c \u2032 (f )",
        "prob": 0.15
    }, {
        "ID": 6624,
        "phrase": " if a true ml decoder were available, a simple technique can be utilized to find the minimum distance of a code  [15] , which is similar to our problem of finding the low-weight ts spectrum for a code",
        "prob": 0.5695652173913043
    }, {
        "ID": 6624,
        "phrase": " for an ml decoder this is not an issue because the hamming weight, w h , is enough information to determine the two-codeword error probability: p (x 1 \u2192 x 2 ) = q( 2w h e s /n o )",
        "prob": 0.38125000000000003
    }, {
        "ID": 6829,
        "phrase": " the ml decoding is equivalent to the optimization problem  [3] [4]: finding x \u2208 conv(c) to minimize \u03bbx t ",
        "prob": 0.5916666666666667
    }, {
        "ID": 6829,
        "phrase": " just like the minimum hamming weight d and a d of a linear code for the performance of ml decoding, the minimum pseudo-weight d p (h) and b p (h) are crucial for the performance of lp decoding",
        "prob": 0.605
    }, {
        "ID": 6829,
        "phrase": " it is well known that the minimum distance d and a d play an important role to evaluate the performance of the linear code c with ml decoding",
        "prob": 0.3588235294117647
    }, {
        "ID": 6830,
        "phrase": " \n definition 3 the (awgn) pseudo-weight of a non-zero real vector x \u2208 r n is defined by w p (x) = x 2 1 / x 2 2 , where x 1 = |x 1 | + \u2022 \u2022 \u2022 + |x n | and x 2 = x 2 1 + \u2022 \u2022 \u2022 + x just like d and a d of a linear code are important for characterizing the performance of ml decoding, d p (h) and b p (h) are crucial for characterizing the performance of lp decoding",
        "prob": 0.5038461538461538
    }, {
        "ID": 6970,
        "phrase": " the tsb on the block error probability under ml decoding depends on the distance spectrum {a l } n l=0 of the block code c, and by invoking the smoothing theorem w",
        "prob": 0.2277777777777778
    }, {
        "ID": 6971,
        "phrase": " let {a h } be the distance spectrum of the linear code c, and let e h (z 1 ) be the event of deciding under ml decoding in favor of other codeword c i whose hamming weight is h, given the value of z 1 ",
        "prob": 0.33809523809523806
    }, {
        "ID": 6972,
        "phrase": " let {a h } be the distance spectrum of the linear code c, and let e h (z 1 ) be the event of deciding under ml decoding in favor of other codeword c i whose hamming weight is h, given the value of z 1 ",
        "prob": 0.2904761904761905
    }, {
        "ID": 7000,
        "phrase": " so-called \"hard\" ai is the science fiction interpretation of ai",
        "prob": 0.31
    }, {
        "ID": 7232,
        "phrase": "  [7]  introduced the lp decoding method, which is based on solving a linearprogramming relaxation of the ml decoder method",
        "prob": 0.3400000000000001
    }, {
        "ID": 7232,
        "phrase": " these observations highlight the distinction between lp decoding and ml decoding",
        "prob": 0.2818181818181818
    }, {
        "ID": 7233,
        "phrase": "  [7]  introduced the lp decoding method, which is based on solving a linearprogramming relaxation of the ml decoder method",
        "prob": 0.54
    }, {
        "ID": 7233,
        "phrase": " we begin with some simple observations: (i) ml decoding corresponds to finding the vertex in the relaxed polytope that has the highest likelihood and integral coordinates; and (ii) standard lp decoding succeeds if and only if the ml codeword has the highest likelihood over all pseudocodewords",
        "prob": 0.48518518518518516
    }, {
        "ID": 7233,
        "phrase": " these observations highlight the distinction between lp decoding and ml decoding",
        "prob": 0.37272727272727274
    }, {
        "ID": 7614,
        "phrase": " ml decoding (that generally requires an exponentially large number 2 k of steps) corresponds to finding \u03c3 maximizing the following weight (probability distribution) function w (\u03c3) = z \u22121 \u03b1 \u03b4 i\u2208\u03b1 \u03c3 i , +1 exp i \u03c3 i h i , (1) where the normalization factor z that enforces the \u03c3 w (\u03c3) = 1 condition is called the partition function in the statistical physics literature",
        "prob": 0.1967741935483871
    }, {
        "ID": 7736,
        "phrase": " this means that whenever the decoder does not fail, then it yields the ml solution, i",
        "prob": 0.2818181818181818
    }, {
        "ID": 7737,
        "phrase": " this means that whenever the decoder does not fail, then it yields the ml solution, i",
        "prob": 0.2818181818181818
    }, {
        "ID": 7780,
        "phrase": " these codes have a similar generator matrix to that in (4) except that for this subclass of codes [i] = q ai with a being an integer prime to m",
        "prob": 0.3153846153846154
    }, {
        "ID": 7781,
        "phrase": " these codes have a similar generator matrix to that in (4) except that for this subclass of codes [i] = q ai with a being an integer prime to m",
        "prob": 0.3153846153846154
    }, {
        "ID": 7791,
        "phrase": " thus by setting e 1 (r 1 , t ) \u2192 0, as suggested by intuitive reasoning, we find that memoryless decoding does not give any improvement over ml decoding without feedback",
        "prob": 0.17222222222222222
    }, {
        "ID": 7889,
        "phrase": " now we will illustrate how the code given in example 1 is in fact a 4-group ml decodable code when used in gnaf-ii protocol",
        "prob": 0.24117647058823533
    }, {
        "ID": 7939,
        "phrase": " showed that the ml decoding problem for a length-n binary linear code c over a discrete memoryless channel can be formulated as a minimization problem min i \u03b3 i c i , where \u03b3 = (\u03b3 1 , ",
        "prob": 0.7833333333333333
    }, {
        "ID": 7939,
        "phrase": " \n application: lp decoding the recent work of feldman, wainwright and karger  [13]  shows that ml decoding of a binary linear code c over a discrete memoryless channel can be formulated as a linear program (lp)",
        "prob": 0.604
    }, {
        "ID": 7939,
        "phrase": " thus, ml decoding is in fact equivalent to the minimization of a linear function over a polytope, which is a classic lp",
        "prob": 0.3400000000000001
    }, {
        "ID": 7939,
        "phrase": " for example, it is known  [27] ,  [24]  that the ml decoding problem over a memoryless binary symmetric channel can be solved in polynomial time for the family of graphic codes using edmonds' matching algorithm  [11] ,  [12] ",
        "prob": 0.3521739130434782
    }, {
        "ID": 7939,
        "phrase": " as mentioned earlier, ml decoding over a discrete memoryless channel can be formulated as a linear program  [13] ",
        "prob": 0.7214285714285715
    }, {
        "ID": 7940,
        "phrase": " showed that the ml decoding problem for a length-n binary linear code c over a discrete memoryless channel can be formulated as a minimization problem min i \u03b3 i c i , where \u03b3 = (\u03b3 1 , ",
        "prob": 0.5611111111111111
    }, {
        "ID": 7940,
        "phrase": " thus, the ml decoding problem can be solved in polynomial time for almost-graphic codes",
        "prob": 0.2928571428571429
    }, {
        "ID": 7940,
        "phrase": " \n application: ml decoding the recent work of feldman, wainwright and karger  [15]  shows that ml decoding of a binary linear code c over a discrete memoryless channel can be formulated as a linear program (lp)",
        "prob": 0.6439999999999999
    }, {
        "ID": 7940,
        "phrase": " in particular, min x\u2208c \u03b3, x = min x\u2208p (c) \u03b3, x , thus, ml decoding is equivalent to finding a vertex of the polytope p (c) that achieves min x\u2208p (c) \u03b3, x , which is a classic lp",
        "prob": 0.39444444444444443
    }, {
        "ID": 7940,
        "phrase": " consequently the lp min x\u2208q(h) \u03b3, x , where \u03b3 is the vector defined via  (9) , constitutes a relaxation of the lp that represents ml decoding",
        "prob": 0.38125000000000003
    }, {
        "ID": 7940,
        "phrase": " however, as we explain next, this lp is no longer equivalent to ml decoding in general",
        "prob": 0.16153846153846155
    }, {
        "ID": 7940,
        "phrase": " while it would then be true that the lp min x\u2208q(c \u22a5 ) \u03b3, x is equivalent to ml decoding, no known lp-solving algorithm could be guaranteed to efficiently solve this lp",
        "prob": 0.40499999999999997
    }, {
        "ID": 7940,
        "phrase": " as mentioned earlier, ml decoding over a discrete memoryless channel can be formulated as a linear program  [15] ",
        "prob": 0.7214285714285715
    }, {
        "ID": 7959,
        "phrase": " (t : w ) in ml notation)",
        "prob": 0.18333333333333335
    }, {
        "ID": 8404,
        "phrase": " , \u03c6 n\u22121 ) rather than the received vector r is sufficient in ml decoding",
        "prob": 0.31
    }, {
        "ID": 8451,
        "phrase": " the second optimization method is so called the sum-product algorithm  [22] , a generalized belief propagation algorithm developed in ai  [23] ",
        "prob": 0.19375
    }, {
        "ID": 8478,
        "phrase": "s)] and we use the ml notation fn x \u21d2 ",
        "prob": 0.1375
    }, {
        "ID": 8489,
        "phrase": " the actual asymptotics of the two curves for the awgn channel at the largest snrs, in the so-called error-floor domain, are fer ml \u223c exp(\u2212d ml \u2022 s 2 /2) and fer lp \u223c exp(\u2212d lp \u2022 s 2 /2), where d ml is the hamming distance of the code and the d lp is the effective distance of the code, specific for the lp decoding",
        "prob": 0.8638888888888887
    }, {
        "ID": 8489,
        "phrase": " looking, first, at the pseudo-codeword spectra we find that configuration with the lowest effective distance is actually a codeword, d ml = 16",
        "prob": 0.6529411764705882
    }, {
        "ID": 8490,
        "phrase": " the actual asymptotics of the two curves for the awgn channel at the largest snrs, in the so-called errorfloor domain, are fer ml \u223c exp(\u2212d ml \u2022 s 2 /2) and fer lp \u223c exp(\u2212d lp \u2022 s 2 /2), where d ml is the hamming distance of the code and the d lp is the effective distance of the code, specific for the lp decoding",
        "prob": 0.8314285714285713
    }, {
        "ID": 8490,
        "phrase": " looking, first, at the pseudo-codeword spectra, we find that the configuration with the lowest effective distance is actually a codeword with d ml = 16",
        "prob": 0.711764705882353
    }, {
        "ID": 8518,
        "phrase": " g [k\u22121] n\u22121 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (3) where [i] def = q ai with a being an integer prime to m, is called a generalized gabidulin code generated by g = (g 0 , g 1 , ",
        "prob": 0.5916666666666667
    }, {
        "ID": 8519,
        "phrase": " g [k\u22121] n\u22121 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (3) where [i] def = q ai with a being an integer prime to m, is called a generalized gabidulin code generated by g = (g 0 , g 1 , ",
        "prob": 0.675
    }, {
        "ID": 8562,
        "phrase": "  3  plots the ser curves for m = 16 and n = 1 for different ml decoding complexities",
        "prob": 0.2818181818181818
    }, {
        "ID": 8686,
        "phrase": " without changing the outcome of the maximization, we can replace the code c by its convex conv(c), and thus express ml decoding as the linear program y ml = argmin y\u2208conv(c) n i=1 \u03b3 i y i ",
        "prob": 0.5761904761904761
    }, {
        "ID": 8687,
        "phrase": " (1) without changing the outcome of the maximization, we can replace the code c by its convex hull conv(c), and thus express ml decoding as the linear program y ml = arg min y\u2208conv(c) n i=1 \u03b3 i y i ",
        "prob": 0.6409090909090909
    }, {
        "ID": 8706,
        "phrase": " (5) it is clear that there are gk i=1 |a i | different codewords and, in general, the ml decoding requires gk i=1 |a i | computations, one for each codeword",
        "prob": 0.14
    }, {
        "ID": 8707,
        "phrase": " effective distance, d inst , characterizing an instanton and its respective pseudo-codeword, should be compared with the hamming distance of the code, d ml , which measures minimal number of flips (from 0 to 1 and vice versa) required for changing from the all zero codeword to another codeword of the code",
        "prob": 0.5366666666666666
    }, {
        "ID": 8707,
        "phrase": " instanton/pseudo-codeword with d < d ml will completely screen contribution of the respective codeword into fer at the largest snrs",
        "prob": 0.7400000000000001
    }, {
        "ID": 8707,
        "phrase": " looking, first, at the pseudo-codeword lp spectra we find that configuration with the lowest effective distance is actually a codeword, d ml = 16",
        "prob": 0.7277777777777777
    }, {
        "ID": 8708,
        "phrase": " originally, lp decoding was introduced as a relaxation of ml decoding  [4] ",
        "prob": 0.37272727272727274
    }, {
        "ID": 8708,
        "phrase": " effective distance, d inst , characterizing an instanton and its respective pseudo-codeword, should be compared with the hamming distance of the code, d ml , which measures minimal number of flips (from 0 to 1 and vice versa) required for changing from the all zero codeword to another codeword of the code",
        "prob": 0.57
    }, {
        "ID": 8708,
        "phrase": " instanton/pseudo-codeword with d < d ml will completely screen contribution of the respective codeword into fer at the largest snrs",
        "prob": 0.7400000000000001
    }, {
        "ID": 8708,
        "phrase": " looking, first, at the pseudo-codeword lp spectra we find that configuration with the lowest effective distance is actually a codeword, d ml = 16",
        "prob": 0.7277777777777777
    }, {
        "ID": 8756,
        "phrase": " ml refers to the erasure patterns that cannot be recovered by a ml decoder, while h agd a corresponds to the matrix described in this section",
        "prob": 0.31875000000000003
    }, {
        "ID": 8757,
        "phrase": " ml refers to the erasure patterns that cannot be recovered by a ml decoder, while h agd a corresponds to the matrix described in this section",
        "prob": 0.25625000000000003
    }, {
        "ID": 8793,
        "phrase": " g [k\u22121] n\u22121 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (3) where [i] = q ai with a being an integer prime to m, is called a generalized gabidulin code, generated by g = (g 0 , g 1 , ",
        "prob": 0.6454545454545455
    }, {
        "ID": 8794,
        "phrase": " g [k\u22121] n\u22121 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (3) where [i] = q ai with a being an integer prime to m, is called a generalized gabidulin code, generated by g = (g 0 , g 1 , ",
        "prob": 0.6454545454545455
    }, {
        "ID": 8795,
        "phrase": " g [k\u22121] n\u22121 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (3) where [i] = q ai with a being an integer prime to m, is called a generalized gabidulin code generated by g = (g 0 , g 1 , ",
        "prob": 0.6454545454545455
    }, {
        "ID": 8882,
        "phrase": " hence, an ml decoder covers the complete space f n q , and consequently never yields a decoding failure",
        "prob": 0.2733333333333333
    }, {
        "ID": 8907,
        "phrase": " here is an ml certificate algorithm,where d h (\u2022, \u2022) denotes the hamming distance",
        "prob": 0.31
    }, {
        "ID": 8907,
        "phrase": " then we send the hard-decided sequence r to an exact ml decoder as in bsc channels except we change the hamming distance to the euclidean distance",
        "prob": 0.26842105263157895
    }, {
        "ID": 8907,
        "phrase": " the lp decoder has the ml certificate property: if the solution to the relaxed lp is integral it is the ml codeword",
        "prob": 0.4066666666666667
    }, {
        "ID": 8907,
        "phrase": " then the lp decoder succeeds and gives the ml solution, as long as at most 3\u03b4\u22122 2\u03b4\u22121 (\u03b1n \u2212 1) bits are flipped by the channel",
        "prob": 0.29285714285714287
    }, {
        "ID": 8907,
        "phrase": " we reduce the k dimensional matching problem (k-dm) to the ml decoding problem, where k = c",
        "prob": 0.25833333333333336
    }, {
        "ID": 8907,
        "phrase": " suppose we have a polynomialtime algorithm for the ml decoding of the considered family of codes, we just run the putative ml decoding algorithm with the parity check matrix as m \u2032\u2032 , the syndrome as y, and w = |t |, we will know the answer to the k-dimensional matching problem",
        "prob": 0.35
    }, {
        "ID": 9163,
        "phrase": " more specifically, the decoder always gives either an ml codeword or a nonintegral pseudocodeword as the solution",
        "prob": 0.5785714285714286
    }, {
        "ID": 9163,
        "phrase": " lp relaxation of ml decoding consider a binary linear code c of length n",
        "prob": 0.6230769230769231
    }, {
        "ID": 9163,
        "phrase": " if a codeword y \u2208 c is transmitted through a memoryless binary-input output-symmetric (mbios) channel, the ml codeword given the received vector r \u2208 r n is the solution to the optimization problem minimize \u03b3 t x subject to x \u2208 c , (1) where \u03b3 is the vector of log-likelihood ratios defined as \u03b3 i = log pr(r i |y i = 0) pr(r i |y i = 1) ",
        "prob": 0.3580645161290323
    }, {
        "ID": 9163,
        "phrase": " as an approximation to ml decoding,  feldman et   then intersecting them to obtain what is called the fundamental polytope, p, by koetter et al",
        "prob": 0.5785714285714286
    }, {
        "ID": 9163,
        "phrase": " therefore, whenever lp decoding gives an integral solution, it is guaranteed to be an ml codeword",
        "prob": 0.65
    }, {
        "ID": 9163,
        "phrase": "  [1]  have mentioned some ways to tighten the relaxation of the ml decoding, including adding redundant parity checks (rpc), and using lift-andproject methods",
        "prob": 0.5549999999999999
    }, {
        "ID": 9163,
        "phrase": " on the other hand, ml decoding may also fail in some of the cases where lp decoding does not converge to an integral solution",
        "prob": 0.4066666666666667
    }, {
        "ID": 9163,
        "phrase": " therefore, as an alternative, we used the performance of the box-and-match soft decision decoding algorithm (bma) developed by valembois and fossorier  [8]  as an approximation of the ml decoder performance",
        "prob": 0.2217391304347826
    }, {
        "ID": 9450,
        "phrase": " t h e f o l l o w i n g di s cus s i on expl ai ns why",
        "prob": 0.15714285714285717
    }, {
        "ID": 9517,
        "phrase": " ap for some left ideal divisors then since each ai is finitely generated (see  [4] ): ai = |li1, ",
        "prob": 0.3416666666666667
    }, {
        "ID": 9748,
        "phrase": " a \u03b4\u22122 0 \u03b4\u22121 i=2 \uf8eb \uf8ed 1 \u2212 ai ai\u22121 2 \uf8f6 \uf8f8 i\u22121 dai since the latter integral does not depends on v , its value is another constant, which we denote i \u03b4 and which depends only on \u03b4",
        "prob": 0.16153846153846155
    }, {
        "ID": 9799,
        "phrase": " this gives us the the best plan for computing \u22b2\u22b3i\u2208s ai as well as its cost",
        "prob": 0.19090909090909092
    }]
}, {
    "topic_id": 6,
    "top_words": ["error", "probability", "ml", "decoding", "bound", "code", "given", "upper", "transmitted", "bit", "channel", "block", "codeword", "ln", "decoder"],
    "phrases": [{
        "ID": 1046,
        "phrase": " each stack word w corresponds to an integer tuple # = (# a1 , \u2022 \u2022 \u2022 , # an ), where {a 1 , \u2022 \u2022 \u2022 , a n } is the stack alphabet and each count # ai stands for the number of symbol a i in w",
        "prob": 0.2733333333333334
    }, {
        "ID": 1698,
        "phrase": ", 1996) , references in ml  (milner et al",
        "prob": 0.15714285714285714
    }, {
        "ID": 2053,
        "phrase": "1), the proof parameters ei and li, and the proof si (included in the message) and constructs the output value ai (see section a",
        "prob": 0.22142857142857145
    }, {
        "ID": 2333,
        "phrase": "2) reduces roughly to 1 2 ln2 \u2022 k(\u00b5 ai |z) when x 1 \u2261z, i",
        "prob": 0.3
    }, {
        "ID": 2333,
        "phrase": "1 (actions as random variables) [c35oi] instead of defining \u03be ai (yx 1:n ) as a universal distribution over observations x 1:n conditioned under actions y 1:n as in (5",
        "prob": 0.20666666666666667
    }, {
        "ID": 2333,
        "phrase": " the prior probability then is \u00b5 ai (yx 1 ",
        "prob": 0.15714285714285717
    }, {
        "ID": 2713,
        "phrase": " as, where each ai is a positive integer (representing the corresponding atom \u03b1 i ), or an expression of the form {k m c1 ",
        "prob": 0.19090909090909092
    }, {
        "ID": 3286,
        "phrase": " the ml block decoder will succeed if and only if h e has rank e := |e |",
        "prob": 0.2333333333333333
    }, {
        "ID": 3289,
        "phrase": " , n, f i \u2190 r i \u2190 \u03bb while \u03c6(p ) := n i=1 min{l, |f i | + |r i |} < ml do nl \u2212 \u03c6({p 1 , ",
        "prob": 0.15714285714285717
    }, {
        "ID": 3512,
        "phrase": ", ml decoding) so that the average bit erasure probability of the code c m goes to zero as we let m tend to infinity, and  lim m\u2192\u221e r m \u2265 (1 \u2212 \u03b5)(1 \u2212 p)",
        "prob": 0.711764705882353
    }, {
        "ID": 3630,
        "phrase": " in this paper, we use qr factorization with sort for decreasing the complexity of ml decoder without changing the error probability",
        "prob": 0.30000000000000004
    }, {
        "ID": 3698,
        "phrase": " ( 2 ) let define an auxiliary measure t as follows, \u2200 e \u2208 b y , t (e) = 1 \u03b2\u03c0 ml \u03c3 2ml e e \u2212 \u03b1 2 y p 2 \u03c3 2 d\u00b5 y , (3) where 1 < p \u2264 2 and 0 < \u03b1 < 1 are free variables and \u03b2 > 0 is chosen such that t has a unit norm",
        "prob": 0.19375
    }, {
        "ID": 4115,
        "phrase": " it immediately follows that in practical data compression tasks, whenever p \u2208 m, the redundancy of the prequential ml code can be both smaller and larger than that of the bayesian code, depending on the situation",
        "prob": 0.1952380952380952
    }, {
        "ID": 4115,
        "phrase": " thus the redundancy (4) of the prequential ml code is given by r u (n) = n\u22121 i=0 [\u2212 ln m \u03bci (4) + ln m \u00b5 * (4)] = \u2212 ln m \u03bc0 (4) + ln m 4 (4) + n\u22121 i=1 [\u2212 ln m 4 (4) + ln m 4 (4)] = \u2212 ln m \u03bc0 (4) + ln m 4 (4) = o(1), (6) assuming an appropriate definition of \u03bc0 ",
        "prob": 0.480952380952381
    }, {
        "ID": 4115,
        "phrase": " finally let u denote the prequential ml model with respect to m",
        "prob": 0.3727272727272727
    }, {
        "ID": 4208,
        "phrase": " an ml decoder is the optimum decoder in terms of minimising the frame-error-rate (fer)",
        "prob": 0.3642857142857143
    }, {
        "ID": 4208,
        "phrase": " ml decision criterion the transmitted codeword",
        "prob": 0.23333333333333334
    }, {
        "ID": 4208,
        "phrase": " if the iterative decoder outputs codeword b then a decoding error is produced, but an ml decoder will also make an error",
        "prob": 0.33999999999999997
    }, {
        "ID": 4459,
        "phrase": "55 for the m = 10 code, while the ml decoder corrected all five-bit error patterns for both the codes",
        "prob": 0.4692307692307693
    }, {
        "ID": 4459,
        "phrase": "5 for the m = 10 code, whereas the ml decoder corrected all six bit errors for the m = 11 code and yielded an average number of output bit errors of 4",
        "prob": 0.531578947368421
    }, {
        "ID": 4535,
        "phrase": " (5) if this inequality is not satisfied, then the current weight vector w k-1 is updated in accordance to the following learning rule w k = w k -1 -\u03c7|| u a || -2 u a \u03b7 \u03b7 \u03b7 \u03b7 a k-1 , ( 6 ) where \u03c7 is the learning rate, u a is the p\u00d7n a matrix of the input data, ||u a || = (\u03c3 i p u ai (1)2 + \u03c3 i p u ai (2)2 + \u2026) 1/2 is an euclidian norm of u a ",
        "prob": 0.2772727272727273
    }, {
        "ID": 4695,
        "phrase": " in case the binary image of an rs code is transmitted, tight bounds on the cep of the optimum ml decoder are obtained by using the average binary weight enumerator in conjunction with well-known bounds  [6] ",
        "prob": 0.23461538461538464
    }, {
        "ID": 4698,
        "phrase": ", ml decoding) so that the average bit error probability of the code c m tends to zero as m goes to infinity, and lim m\u2192\u221e r m = (1 \u2212 \u03b5)c",
        "prob": 0.7562500000000001
    }, {
        "ID": 4698,
        "phrase": " then, under ml decoding (or any other decoding algorithm), the bit error probability (p b ) of the code satisfies h 2 (p b ) \u2265 1 \u2212 c r + 1 \u2212 r 2 ln(2)r \u221e p=1 1 p(2p \u2212 1) k d k \u221e 0 a(l)(1 + e \u2212l ) tanh 2p l 2 dl k ",
        "prob": 0.41764705882352937
    }, {
        "ID": 4717,
        "phrase": " then the average distortion (change density) of this code is 1 2 k t i=1 ai i n ",
        "prob": 0.23333333333333334
    }, {
        "ID": 4769,
        "phrase": " the pairwise error probability (pep) of the ml decoder, denoted as p p e , averaged over the ensemble of random gaussian codes, is upper bounded by p p e \u2264 det(i n + 1 2 \u03c3 s \u03c3 \u22121 n ) \u22121 , (7) where s \u2208 c n and n \u2208 c n denote the signal and noise components of the observed vector, respectively (i",
        "prob": 0.5423076923076923
    }, {
        "ID": 4769,
        "phrase": " the error probability of the ml decoder, p e (\u03c1), can be upper bounded using bayes' rule: p e (\u03c1) = p o (r)p e|o + p e,o c p e (\u03c1) \u2264 p o (r) + p e,o c , where o denotes the outage event",
        "prob": 0.505
    }, {
        "ID": 4769,
        "phrase": " (39) in order to characterize o, we note that, since the destination observations during different frames are independent, the upper-bound on the ml conditional pep [recalling  (7) ], assuming l to be even, changes to p p e|g 1 ,g 2 ,h \u2264 det i 2 + 1 2 \u03c3 s \u03c3 \u22121 n \u2212l/2 , (40) where \u03c3 s and \u03c3 n denote the covariance matrices of destination observation's signal and noise components during a single frame: \u03c3 s = |g 1 | 2 g 1 g * 2 b * h * g * 1 g 2 bh |g 1 | 2 + |g 2 | 2 |bh| 2 e (41) \u03c3 n = \u03c3 2 v 0 0 \u03c3 2 v + |g 2 | 2 |b| 2 \u03c3 2 w ",
        "prob": 0.20882352941176474
    }, {
        "ID": 4769,
        "phrase": " for the single relay ddf protocol, the error probability of the ml decoder, averaged over the ensemble of gaussian code-books and conditioned on a certain channel realization, can be upper bounded using bayes' rule to give p e|g 1 ,g 2 ,h = p e,e c r |g 1 ,g 2 ,h + p e,er|g 1 ,g 2 ,h p e|g 1 ,g 2 ,h \u2264 p e|e c r ,g 1 ,g 2 ,h + p er|g 1 ,g 2 ,h , where e r and e c r denote the events that the relay decodes source's message erroneously and its complement, respectively",
        "prob": 0.7774999999999999
    }, {
        "ID": 4769,
        "phrase": ", destination's ml error probability assuming error-free decoding at the relay, provides a lower-bound on the diversity gain achieved by the protocol",
        "prob": 0.5050000000000001
    }, {
        "ID": 4769,
        "phrase": " we then use bayes' rule to upper bound the error probability of the ml decoder, averaged over the ensemble of gaussian code-books and conditioned on a certain channel realization, to get p e|g j ,h ji \u2264 p e|{e c p } n p=2 ,g j ,h ji + n n=2 p en|{e c p }p<n,g j ,h ji , (55) where e n , n \u2208 {2, \u2022 \u2022 \u2022 , n} denotes the event that node n decodes the source message in error, while e c n denotes its complement",
        "prob": 0.7970588235294116
    }, {
        "ID": 4769,
        "phrase": ", destination's ml error probability assuming error-free decoding at all of the relays, provides a lower-bound on the diversity gain achieved by the protocol",
        "prob": 0.45499999999999996
    }, {
        "ID": 4769,
        "phrase": ", destination j's ml error probability, averaged over the ensemble of gaussian code-books and conditioned on a certain channel realization, under the assumption that it started transmission before the end of the codeword",
        "prob": 0.6409090909090909
    }, {
        "ID": 4769,
        "phrase": " we then characterize the joint ml decoder's error probability p e (\u03c1)",
        "prob": 0.41000000000000003
    }, {
        "ID": 4769,
        "phrase": " note that the error probability of the joint ml decoder upper-bounds the error probabilities of the sourcespecific ml decoders and thus provides a lower-bound on the achievable overall diversity gain (as a function of r)",
        "prob": 0.31153846153846154
    }, {
        "ID": 4769,
        "phrase": ", n} and e i (referred to as a \"type-i error\") is the event that the joint ml decoder incorrectly decodes the messages from                super \n defining \u1e7dj min{v 1 , 1 \u2022 \u2022 \u2022 , v j }, j = 1, \u2022 \u2022 \u2022 , n lets us simplify (58) and ( \n figure 1 : 1 figure 2 : 112 figure 1: the super-frame in the naf protocol with n \u2212 1 relays",
        "prob": 0.2535714285714286
    }, {
        "ID": 4847,
        "phrase": "37%), ml (0",
        "prob": 0.22000000000000003
    }, {
        "ID": 4855,
        "phrase": " when the received vector is closer to the estimated codeword than to the transmitted codeword, an error is counted for the ml decoder",
        "prob": 0.6733333333333333
    }, {
        "ID": 4855,
        "phrase": " in figure  2 , we plot the performance of the ml upper bound over grse, hdd with error correction radius t = (d min \u2212 1)/2 and a hypothetical \"genie decoder\", which can correct up to t = (d min \u2212 1) symbol errors",
        "prob": 0.4333333333333333
    }, {
        "ID": 4855,
        "phrase": " these errors cannot be corrected by an ml decoder either",
        "prob": 0.34444444444444444
    }, {
        "ID": 4856,
        "phrase": " in figure  3 , we plot the upper bound on the performance of rs ensemble under ml decoding, hdd with error correction radius t = (d min \u2212 1)/2 and a hypothetical decoder which can correct up to t = (d min \u2212 1) symbol errors (that is we assume the genie decoder can decode the received vector as long as it is within the distance of t = (d min \u22121) at symbol-level from the transmitted codeword)",
        "prob": 0.3457142857142857
    }, {
        "ID": 4952,
        "phrase": " ml decoding (which generally requires an exponentially large number, 2 k , of steps) corresponds to finding the most probable transmitted codeword given x x x",
        "prob": 0.33888888888888885
    }, {
        "ID": 5046,
        "phrase": " by hypothesis algorithm 2 is an ml decoder for rm q (1, m \u2212 1), which is now used to get \u1e91(i) according to \u1e91(i) = arg max w\u2208rmq(1,m\u22121) re{z(i) \u2022 w h }",
        "prob": 0.25625000000000003
    }, {
        "ID": 5054,
        "phrase": "2]  shows that the probability of ml (maximum-likelihood) decoding error p e over a (n, 2 n r , q) block code ensemble is upperbounded by 2 \u2212n er(r,q,w ) ",
        "prob": 0.38125000000000003
    }, {
        "ID": 5075,
        "phrase": " in ml decoding, the voronoi region for the all-zeros codeword is defined by the hyperplanes separating the all-ones vector and the transmitted vectors of the other codewords",
        "prob": 0.45500000000000007
    }, {
        "ID": 5129,
        "phrase": " if in the limit where r tends to infinity, the bit error probability of this sequence under ml decoding vanishes, then the common design rate r d of these ensembles satisfies r d \u2264 1 \u2212 1 \u2212 j j=1 p j c j 1 \u2212 1 2 ln 2 \u221e p=1 1 p(2p \u2212 1) \u03b3 j j=1 q j g j,p (32) where \u03b3, as introduced in (3), denotes the right degree distribution from the node perspective, and g j,p is introduced in (8)",
        "prob": 0.5193548387096774
    }, {
        "ID": 5129,
        "phrase": " denote the rate of the code c r by r r , and let p b,r be its bit error probability under ml decoding",
        "prob": 0.5785714285714286
    }, {
        "ID": 5129,
        "phrase": " if the asymptotic bit error probability of this sequence vanishes under ml decoding (or any sub-optimal decoding algorithm) as r \u2192 \u221e, then in probability 1 w",
        "prob": 0.4764705882352941
    }, {
        "ID": 5210,
        "phrase": " after k iterations the snr can be estimated by \u03b3 = \u03bc2 k 2(m 2 \u2212 \u03bc2 k ) , (35) which will be referred to as the ml estimator",
        "prob": 0.31
    }, {
        "ID": 5233,
        "phrase": " in particular, the converse is obtained by lower-bounding the error probability of the arq protocol with that of a ml decoder that operates on the whole codeword {x p } l p=1 ",
        "prob": 0.6166666666666667
    }, {
        "ID": 5233,
        "phrase": " (56) towards this end, let us denote the ml error probability, conditioned on a certain channel realization h, by p e|h ",
        "prob": 0.6937500000000001
    }, {
        "ID": 5233,
        "phrase": " let us define c \u01eb as the set of channel realizations for which the conditional ml error probability cannot be made smaller than \u01eb, i",
        "prob": 0.44375000000000003
    }, {
        "ID": 5233,
        "phrase": " it is straightforward to verify that the ml error probability, conditioned on a certain channel realization, is upper-bounded by p e|h (r, \u03c1) \u2264 2 rl det(i n + \u03c1 2m hh h ) \u2212l , = 2 rl min{m,n} i=1 (1 + \u03c1 2m \u00b5 i ) \u2212l , (63) where \u00b5 min{m,n} \u2265 \u2022 \u2022 \u2022 \u2265 \u00b5 1 \u2265 0 represent the ordered eigenvalues of hh h ",
        "prob": 0.4653846153846154
    }, {
        "ID": 5233,
        "phrase": " referring to (64) reveals that d consists of those channel realizations for which the upperbound on the ml error probability cannot be made arbitrarily small, even through the use of infinitely long codewords",
        "prob": 0.4809523809523809
    }, {
        "ID": 5233,
        "phrase": " ( 75 ) we prove this by showing that the error probability of the joint ml decoder, averaged over the ensemble of gaussian codes, satisfies (75)",
        "prob": 0.56875
    }, {
        "ID": 5288,
        "phrase": " moreover, for the given channel, the average block error probability p b of the ldpc-gm ensembles with k > m, j \u2265 4 and r < c is vanishingly small when ml decoding is used",
        "prob": 0.531578947368421
    }, {
        "ID": 5288,
        "phrase": " the following upper bound on the average block error probability under ml decoding is given in [9]  p b \u2264 l\u2208u {n(l)d l } + 2 \u2212ner(r+ ln \u03b1 n ln e r (\u2022)is the random coding exponent, andd y p(y|0)p(y|1) \u2264 1 (46)where p(y|0) and p(y|1) are the conditional probability density functions of the output of the mbios channel given the input",
        "prob": 0.8028571428571427
    }, {
        "ID": 5289,
        "phrase": " moreover, for the given channel, the average block error probability p b of the ldpc-gm ensembles with k > m, j \u2265 4 and r < c is vanishingly small when ml decoding is used",
        "prob": 0.4789473684210526
    }, {
        "ID": 5289,
        "phrase": " the following upper bound on the average block error probability under ml decoding is given in [9]  p b \u2264 l\u2208u {n(l)d l } + 2 \u2212ner(r+ ln \u03b1 n ln e r (\u2022)is the random coding exponent, andd y p(y|0)p(y|1) \u2264 1 (46)where p(y|0) and p(y|1) are the conditional probability density functions of the output of the mbios channel given the input",
        "prob": 0.8028571428571427
    }, {
        "ID": 5290,
        "phrase": " the ml performance bound given in  [10]  is then used to prove our main result",
        "prob": 0.17500000000000002
    }, {
        "ID": 5290,
        "phrase": " moreover, for the given channel, the average block error probability p b of the ldpc-gm ensembles with k > m, j \u2265 4 and r < c is vanishingly small when ml decoding is used",
        "prob": 0.4263157894736842
    }, {
        "ID": 5290,
        "phrase": " the following upper bound on the average block error probability under ml decoding is given in [10]  p b \u2264 l\u2208u {n(l)d l } + 2 \u2212ner(r+ ln \u03b1 n ln 2 ) e r (\u2022)is the random coding exponent, and d y p(y|0)p(y|1) \u2264 1 (46) where p(y|0) and p(y|1) are the conditional probability density functions of the output of the mbios channel given the input",
        "prob": 0.826470588235294
    }, {
        "ID": 5334,
        "phrase": " bounds on the error probability of the ml decoder are then discussed",
        "prob": 0.21000000000000002
    }, {
        "ID": 5334,
        "phrase": " in case of an ml decoder success and the transmitted codeword is added to the global list at a certain iteration, which presumably could be checked, then it would be the closest codeword to the received word and thus the list decoder's choice",
        "prob": 0.3
    }, {
        "ID": 5334,
        "phrase": " alternatively the averaged binary weight enumerator could be used in conjunction with other tight bounds such as the divsalar simple bound  [35]  to bound the ml error probability",
        "prob": 0.29047619047619044
    }, {
        "ID": 5606,
        "phrase": " actually, the ai is upper bounded by \u23a5 \u23a5 \u23a4 \u23a2 \u23a2 \u23a1 2 n which has been shown in  [5, 9] ",
        "prob": 0.2625
    }, {
        "ID": 5645,
        "phrase": " (66) under the joint ml decoder, inter-stream interference is not the typical error event",
        "prob": 0.6230769230769231
    }, {
        "ID": 5646,
        "phrase": " there we conclude: under the joint ml decoder, inter-stream interference is not the typical error event",
        "prob": 0.5785714285714286
    }, {
        "ID": 5727,
        "phrase": "  2 , the ensemble performance of these turbo codes (associated with the ml decoding) is sufficiently robust in case of mismatched decoding, even in a portion of the rate region exceeding the chan- nel matched cutoff rate",
        "prob": 0.28400000000000003
    }, {
        "ID": 5728,
        "phrase": " from fano's inequality and since the code is binary, the conditional entropy of the transmitted codeword given the received sequence satisfies h(x|y) n \u2264 rh(p b ) (2) where r is the rate of the code, p b is the bit-error probability of the ml decoder, and h(x ) = \u2212x log 2 (x) \u2212 (1 \u2212 x) log 2 (1 \u2212 x) is the binary entropy function to base two",
        "prob": 0.4441176470588235
    }, {
        "ID": 5728,
        "phrase": " then, under ml decoding (or any other decoding algorithm), the bit error probability (p b ) of the code satisfies h 2 (p b ) \u2265 1 \u2212 c r + 1 \u2212 r 2r ln(2) \u221e p=1 \u03b3(g p ) p(2p \u2212 1) ",
        "prob": 0.6066666666666667
    }, {
        "ID": 5729,
        "phrase": " if in the limit where r tends to infinity, the bit error probability of this sequence under ml decoding vanishes, then the common design rate r d of these ensembles satisfies r d \u2264 1 \u2212 1 \u2212 j j=1 pjcj 1 \u2212 1 2 ln 2 \u221e p=1 1 p(2p \u2212 1) \u03b3 j j=1 qj gj,p (4) where \u03b3 denotes the right degree distribution from the node perspective, and for all j \u2208 {1, ",
        "prob": 0.57
    }, {
        "ID": 5729,
        "phrase": "1 relies on upper and lower bounds on the conditional entropy of the transmitted codeword given the received sequence at the output of the parallel channels (see [10, section 3]), and it is valid under optimal ml decoding (or any sub-optimal decoding algorithm)",
        "prob": 0.3607142857142857
    }, {
        "ID": 5789,
        "phrase": " to delay as the ml decoder  [45] ,  [46] ",
        "prob": 0.4428571428571429
    }, {
        "ID": 5817,
        "phrase": "11: if the all-zero codeword is the ml codeword for an error pattern e then e",
        "prob": 0.37272727272727274
    }, {
        "ID": 5818,
        "phrase": " then ml decoding is achieved by decoding a received vector r into the codeword y + e where e is a binary vector that satisfies s = eh t and has the property that if e \u2032 is any other binary vector such that s = e \u2032 h t then e",
        "prob": 0.44999999999999996
    }, {
        "ID": 5818,
        "phrase": "11: if the all-zero codeword is the ml codeword for an error pattern e then e",
        "prob": 0.2818181818181818
    }, {
        "ID": 5888,
        "phrase": " \u015dn, each of a given length l = m, such that ai \u2264 fe( \u015di) \u2264 bi for some ai, bi such that bi \u2212 ai \u2264 \u2206",
        "prob": 0.3
    }, {
        "ID": 5888,
        "phrase": " \u015dn each of length l and respective energy ei such that ai \u2264 ei \u2264 bi",
        "prob": 0.3
    }, {
        "ID": 5903,
        "phrase": " these ml performance can be estimated by computing analytical bounds based on the code enumerators",
        "prob": 0.23846153846153847
    }, {
        "ID": 5953,
        "phrase": " proof: without loss of generality, assume that the all zero codeword was transmitted and an ideal ml decoder will output the all zero codeword",
        "prob": 0.33888888888888896
    }, {
        "ID": 5953,
        "phrase": " it is seen that the bit error rate of the algorithm approaches that of the ideal ml decoder",
        "prob": 0.4692307692307693
    }, {
        "ID": 6100,
        "phrase": " let m be a model and \u03d5 a formula from ml + ",
        "prob": 0.1375
    }, {
        "ID": 6109,
        "phrase": " 4) the ml metric (3) can again be represented as  (6)  with the code word s replaced by the excm, s i",
        "prob": 0.2818181818181818
    }, {
        "ID": 6135,
        "phrase": " ( 32 ) we identify the right hand side of (32), as the union bound on the ml error probability, conditioned on transmission of m 0 (refer to equation (  17 ) in  [5] , for a very similar expression)",
        "prob": 0.3736842105263158
    }, {
        "ID": 6135,
        "phrase": " in order to derive a lower bound on the diversity gain achieved by the ddf mar protocol, we upper bound the source-specific ml error probabilities, with that of the joint ml decoder",
        "prob": 0.43913043478260866
    }, {
        "ID": 6135,
        "phrase": " where i denotes any nonempty subset of {1, 2} and e i (referred to as type-i error) is the event that the joint ml decoder incorrectly decodes the messages from sources whose indices belong to i while correctly decoding all other messages",
        "prob": 0.37916666666666665
    }, {
        "ID": 6135,
        "phrase": ", the joint ml decoder's type-i pairwise error probability (pep), conditioned on a particular channel realization and averaged over the ensemble of random gaussian codes",
        "prob": 0.6238095238095238
    }, {
        "ID": 6136,
        "phrase": " consider a family of codes {c \u03c1 } indexed by operating snr \u03c1, such that the code c \u03c1 has a rate of r(\u03c1) bits per channel use (bpcu) and ml error probability p e (\u03c1)",
        "prob": 0.21578947368421056
    }, {
        "ID": 6137,
        "phrase": " consider a family of codes {c \u03c1 } indexed by operating snr \u03c1, such that the code c \u03c1 has a rate of r(\u03c1) bits per channel use (bpcu) and ml error probability p e (\u03c1)",
        "prob": 0.32105263157894737
    }, {
        "ID": 6148,
        "phrase": ", if the received snr is larger than the punctured code threshold, the average ml decoding word error probability of [c j ] decays to zero as the codeword length n \u2192 \u221e",
        "prob": 0.755
    }, {
        "ID": 6148,
        "phrase": " if \u03b3 < exp(\u2212c [c] \u22c6 ) where \u03b3 q\u22121 j=0 \u03c4 j \u03b3 j is the average bhattacharyya noise parameter, then the average ml decoding word error probability p  (13/15, 17/15)",
        "prob": 0.6066666666666667
    }, {
        "ID": 6148,
        "phrase": ", the received snr at an awgn channel) is larger than \u03c7 [c] (\u03c4 ), the average ml decoding word error probability approaches zero as n \u2192 \u221e",
        "prob": 0.711764705882353
    }, {
        "ID": 6148,
        "phrase": " more precisely, the average ml decoding word error probability for a good code ensemble [c] transmitted over a q-block fading channel can be bounded as follows: p [c] w (\u03b3) e p [c] w (\u03b3) = p{error(n), \u2212 ln \u03b3(\u03bd) \u2264 c [c] \u22c6 } + p{error(n), \u2212 ln \u03b3(\u03bd) > c [c] \u22c6 } \u2264 p{\u2212 ln \u03b3(\u03bd) \u2264 c [c] \u22c6 } + o(1)",
        "prob": 0.8439999999999999
    }, {
        "ID": 6148,
        "phrase": " [3, theorem 5]) let's consider a good code ensemble [c] of rate r transmitted over q binary-input symmetric-output parallel channels with a set of mutual information {i q }, bhattacharyya noise parameters {\u03b3 q }, and assignment rate {\u03c4 q }, if \u03b3 < exp \u2212c [c] p and i > r + \u03be [c] p (54) where i = q q=1 \u03c4 q i q and \u03b3 = q q=1 \u03c4 q i q denote the average mutual information and bhattacharyya noise parameter of the q parallel channels, then, the average ml decoding word error probability decays to zero as the codeword length approaches infinity",
        "prob": 0.43958333333333327
    }, {
        "ID": 6149,
        "phrase": " \n 1) ub code threshold: in  [17] , jin and mceliece have shown that, for a binary-input memoryless channel, if \u03b3 < exp(\u2212c 0 ), (14) the average ml decoding word error probability approaches zero",
        "prob": 0.43913043478260866
    }, {
        "ID": 6149,
        "phrase": " if \u03b3 < exp(\u2212c \u22c6 ), (19) then the average ml decoding word error probability p w (\u03b3, n ) n \u2212\u2192 0",
        "prob": 0.6454545454545455
    }, {
        "ID": 6149,
        "phrase": " if \u03c4 > 1 \u2212 exp(\u2212c \u22c6 ) , there exists a punctured code threshold \u03c7(\u03c4 ) = ln \u03c4 exp(\u2212c \u22c6 ) \u2212 (1 \u2212 \u03c4 ) (21) such that, if \u2212 ln \u03b3 > \u03c7(\u03c4 ), (22) the average ml decoding word error probability approaches zero as n \u2192 \u221e",
        "prob": 0.755
    }, {
        "ID": 6149,
        "phrase": ", if the received snr is larger than the punctured code threshold \u03c7(\u03c4 ), the average ml decoding word error probability decays to zero as the codeword length n tends to infinity",
        "prob": 0.7772727272727271
    }, {
        "ID": 6149,
        "phrase": ", if the received snr is larger than the punctured code threshold \u03c7(\u03c4 j ), the average ml decoding word error probability decays to zero as the codeword length n tends to infinity",
        "prob": 0.8227272727272725
    }, {
        "ID": 6149,
        "phrase": " more precisely, the average ml decoding word error probability for a good code ensemble [c] transmitted over a q-block fading channel can be bounded as follows: pw (\u03b3, n ) e p w (\u03b3, n ) = p{error(n ), \u2212 ln \u03b3(\u03bd) \u2264 c \u22c6 } + p{error(n ), \u2212 ln \u03b3(\u03bd) > c \u22c6 } \u2264 p{\u2212 ln \u03b3(\u03bd) \u2264 c \u22c6 } + p{error(n ) | \u2212 ln \u03b3(\u03bd) > c \u22c6 } (24) where error(n ) stands for the event of the decoding error for the code of length n ",
        "prob": 0.8599999999999999
    }, {
        "ID": 6165,
        "phrase": " an ml decoder will not be able to determine the transmitted codeword in the latter case either, since both codewords c and c + c \u2032 where c denotes the transmitted codeword are equally likely to have been transmitted",
        "prob": 0.24285714285714283
    }, {
        "ID": 6188,
        "phrase": " ml and lp decoding let us use the above-mentioned code c for data transmission over a binary-input discrete memoryless channel with input alphabet x {0, 1}, output alphabet y, and channel law p y |x (y|x)",
        "prob": 0.3740740740740741
    }, {
        "ID": 6190,
        "phrase": " this is witnessed by the fast decreasing line labeled \"lp uub minus ml slb\" which shows the difference between the union upper bound on    the lp decoder word error rate and the s\u00e9guin lower bound on the ml decoder word error rate",
        "prob": 0.471875
    }, {
        "ID": 6190,
        "phrase": " under block-wise ml decoding we define a block error to be the event that there is a tie among at least two codewords",
        "prob": 0.3
    }, {
        "ID": 6190,
        "phrase": " if for all minimal pseudo-codewords there exists an associated pseudo-codeword with at least one odd component then the block error rate of block-wise ml decoding coincides with the block error rate of lp decoding",
        "prob": 0.41111111111111115
    }, {
        "ID": 6190,
        "phrase": " it follows that for these two codes block-wise ml and lp decoding yield the same block error rate (under the above definition of block error rate)",
        "prob": 0.45499999999999996
    }, {
        "ID": 6190,
        "phrase": " 256 iterations) eg(2,4)\u2212based code: lp\u2212union upper bound eg(2,4)\u2212based code: lp eg(2,4)\u2212based code: ml\u2212union upper bound eg(2,4)\u2212based code: ml eg(2,4)\u2212based code: ml seguin lower bound eg(2,4)\u2212based code: lp uub minus ml slb \n figure 3 : 3 figure 3: word error rate for various decoding algorithms together with some upper and lower bounds",
        "prob": 0.5456521739130434
    }, {
        "ID": 6308,
        "phrase": ",  [40] ) of a code with length function l (\u2022) per sequence x n as r n (l, x n ) \u25b3 = 1 n {l (x n ) + log p m l (x n )} , (2) where the logarithm function is taken to the base of 2, here and elsewhere, and p m l (x n ) \u25b3 = p \u03b8 (x n ) is the probability of x n given by the ml estimator \u03b8 of the governing parameters",
        "prob": 0.355
    }, {
        "ID": 6308,
        "phrase": " for standard sequence compression, this approach assigns to an n-symbols sequence x n probability q (x n ) that equals its ml probability normalized by the sum of the ml probabilities over all possible sequences, i",
        "prob": 0.29047619047619044
    }, {
        "ID": 6308,
        "phrase": " the approach above was modified for patterns by modifying  (16)  to q [\u03c8 (x n )] \u25b3 = p \u03c8(\u03b8) [\u03c8 (x n )] \u03c8(y n ):\u03b8\u2208\u03c8(\u03bb k ) p \u03c8(\u03b8) [\u03c8 (y n )] , (18) where p \u03c8(\u03b8) [\u03c8 (x n )] is the ml pattern probability for the pattern of the sequence x n , and the normalization factor is the sum of all ml probabilities for all possible patterns of sequences generated by sources \u03b8 \u2208 \u03bb k ",
        "prob": 0.2217391304347826
    }, {
        "ID": 6308,
        "phrase": " then, only the quantized version of the ml parameters is relayed to the decoder, and entropy coding is used w",
        "prob": 0.3153846153846154
    }, {
        "ID": 6308,
        "phrase": " given the type, the pattern ml probability vector \u03c8 u (\u03b8) can be computed, as well as its ml probability, which is used to then encode the sequence using a number of bits that equals its negative logarithm",
        "prob": 0.26521739130434785
    }, {
        "ID": 6308,
        "phrase": " the ml probability of x n ",
        "prob": 0.18333333333333335
    }, {
        "ID": 6308,
        "phrase": " however, a pattern probability can be expressed as a sum of all permutations of its ml estimator",
        "prob": 0.3416666666666667
    }, {
        "ID": 6308,
        "phrase": ", the bernoulli probability mass function induced by the ml estimator \u03b8i of \u03b8 i on the random vector y i ",
        "prob": 0.23846153846153847
    }, {
        "ID": 6308,
        "phrase": " ml probability component \u03b8i using \u03c8(\u03c3) by a probability that is roughly smaller than its half (since \u03c8(\u03c3 i ) is asymptotically much closer to \u03d5(\u03c3 i ))",
        "prob": 0.31875
    }, {
        "ID": 6308,
        "phrase": " ml estimator with k non-zero components of the probability vector that governs x n ",
        "prob": 0.2583333333333333
    }, {
        "ID": 6308,
        "phrase": "1let us first bound the logarithm of the ratio between the probability given by the parameter vector \u03c6 and the ml probability of x n ",
        "prob": 0.38125000000000003
    }, {
        "ID": 6340,
        "phrase": ") zero-mean gaussian random variables (rvs) with a common variance, as typical of communication systems, then the ml decoding rule corresponds to solving the minimization problem: xr = arg min xr\u2208 c y r \u2212 bx r 2 (2) where \u2022 denotes the vector norm",
        "prob": 0.17586206896551726
    }, {
        "ID": 6435,
        "phrase": " using fact 4 above and the relationship s s s s \u1ebd e i = + + ( ) [ ] \u25ca d k 2 4 1 , we can then conclude that similarly, if we let i h d k e d k k k k k \u02c6; log ! ln \u02dc\u02dc, \u02dc\u02dc, , , , y y y y u y y = \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u02d8= = \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u02d8= * 1 2 1 2 1 2 m m k k i i i il y y y i k, represent an equivalent transformed channel output, then the conditional transformed output distribution given that symbol x was transmitted is given by p e kl k l \u02c6\u02dc\u02dc\u02c6\u02c6re \u02dc\u00e2 a e e a a a a a a s s y   - * * - * - 1 2 1 2 2 1 1 1 p s s e now, e = 2 2 mls for m l > 1 2 2 s , x 0 0 = , p p 0 0 1 1 = ( )= - \u00e2 a x e , d b i i i i i l p p k i k 2 1 1 2 \u222b = = ( )= = , , x i x y b y h b h y b h x x x x x x ( ) = + - ( ) - - + ( ) * ( ) = ( ) + \u25ca ( ) ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00a3 + ( ) \u00ea \u00eb \u00e1 \u02c6+ ( ) = \u03c0 = = \u00e2 \u00fa \u00e2 \u00e2 \u00fa 1 1 1 0 0 0 0 1 ln ln \u02dc\u02dc\u02dcl n \u02c6\u02c6\u02c61 1 1 2 2 2 1 1 2 0 0 1 1 2 2 2 2 + \u25ca ( ) ( ) + \u25ca ( ) ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed = - \u00e8 \u00ee \u00ed \u02d8-\u00e8 \u00ee \u00ed \u00ed + = \u03c0 = \u00e2 \u00fa \u00e2 \u00ed \u00ed \u00ed = \u03c0 = \u00e2 \u00fa \u00e2 1 2 0 2 0 1 1 ) ( ) + ( ) ( ) \u00e8 \u00ee s hence, we have   i ml k ml k p pk m l p p p p i i j i j j i k i k \u02c6\u02c6\u02c6\u02c6\u02c6; l n \u02dcln \u02dc\u02dc\u02dc\u00e3 a a a a a a a a a a a x y y x y x y x y x y x y ( )\u2265 [ ] - ( ) + ( ) ( ) + ( ) ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 = \u03c0 = \u00e2 \u00fa \u00e2 1 2 2 1 1 2 2 2 0 2 0 1 1 s s s ",
        "prob": 0.5911764705882352
    }, {
        "ID": 6435,
        "phrase": " a a k note that y is a lognormal random variable and w is the sum of   + \u00e8 \u00ee \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00ef \u00ec \u00f4 \u00f3 \u00f4 \u00f4 \u01eb = + - ( ) + ( ) + \u00e8 \u00ee \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u02c6( ) ( ) \u2022 s b s b b b a a a a \u00fa \u00fa \u00fa \u00fa \u00fa \u00fa \u2022 + - ( ) + ( ) + \u00ea \u00eb \u00e1 \u00e8 \u00ee \u00ed \u00ed \u2022 \u2022 = \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u02c6( ) ( ) = + - ( ) + ( ) \u00ea \u00eb \u00e1 \u00e1 0 0 1 1 2 1 2 1 0 0 2 + - + + \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed l l e k m m l l m l m m b b b b b b \u00e2 a a a a a a a 2 1 2 2 1 1 1 2 1 1 2 2 2 2 2 2 \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u02c6( ) - + - ( ) + ( ) \u00ea \u00eb \u00e1 \u00e8 \u00ee \u00ed \u00ed \u2022 \u2022 \u00fa \u00fa k y k ml m e y dx p y dy l l 1 1 1 2 1 2 1 0 2 2 ln \u02c6, s b b a a where the final inequality follows from the upper bound given in  [22]  for the complementary cdf of the sum of k -1 lognormal random variables",
        "prob": 0.444
    }, {
        "ID": 6435,
        "phrase": " to establish a second bound, which is not as tight, but easier to analyze, we note that  1 2 1 2 1 2 1 1 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 p s b s b b b b b b e k m l m e dx k ml m e l m x l ml x m l m m l l ml - - + ( ) - + + ( ) -\u2022 \u2022 - + ( ) ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed \u00a3 + - ( ) + ( ) \u00e8 \u00ee \u00ed \u02d8- \u00fa ln ln \u02c6\u00e2 a a a a a + + + ( ) = + - ( ) + ( ) \u00e8 \u00ee \u00ed \u02d8+ + + ( ) - -\u2022 - + ( ) \u00fa 2 1 2 1 2 1 2 + - ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00a3 + - ( ) + - -- + + + + -\u2022 \u2022 + \u00fa 1 2 1 1 2 1 2 1 1 1 2 2 2 2 2 1 2 2 1 2 2 2 1 2 2 2 2 2 p s b s b b b b b b f ln ln \u00e2 a 1 1 2 1 2 2 1 1 2 1 1 2 1 2 1 2 2 2 2 2 2 2 0 2 2 1 2 2 ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u02d8+ + + - ( ) ( ) [ ] \u00a3 + - ( ) - ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u02d8+ - - \u2022 + \u00fa m m m l ml k x xe dx k e k ml m l k x m l m l b b b p s b b b ln a a f m m m l ml a a a k e k k a b b p + + ( ) [ ] - + - \u00ea \u00eb \u00e1 - - - 1 2 1 2 2 2 2 1 1 2 2 \u02c6, a a f for all a > 0",
        "prob": 0.40399999999999997
    }, {
        "ID": 6617,
        "phrase": " for the arbitrarily small fixed \u03b5 > 0, let the set of typical sequences x n be defined as t x \u25b3 = x n : \u2200i, \u03b8i \u2212 \u03b8 i < \u221a \u03b8 i 2 \u221a n 1\u2212\u03b5 , ( 59 ) where \u03b8i is the ml estimator of \u03b8 i from x n , i",
        "prob": 0.22142857142857142
    }, {
        "ID": 6624,
        "phrase": " since the error contribution of a ts is not given by a simple q-function, as in the case of the two-codeword problem for an ml decoder, it is not clear how the list of error events (mainly ts) returned by the search technique of  [3] , henceforth referred to as the 'decoder search,' should be utilized to provide a complete picture of a code's low bit error rate performance",
        "prob": 0.22749999999999998
    }, {
        "ID": 6624,
        "phrase": " the idea is to introduce a very unnatural noise, called an 'error impulse,' in a single bit position as input to the ml decoder",
        "prob": 0.3
    }, {
        "ID": 6624,
        "phrase": " unfortunately, the single-bit error impulse method cannot be used with the mpa to find dominant error events  [16]  mainly because the mpa's objective is to perform a bit ml decision rule and not the vector ml rule",
        "prob": 0.37407407407407406
    }, {
        "ID": 6658,
        "phrase": "  5  now, we give following lemma that upper bounds the relative entropy rate between p z and the ml estimator",
        "prob": 0.29285714285714287
    }, {
        "ID": 6676,
        "phrase": " using the following two lemmas, we establish that this procedure has arbitrarily small probability of error, whence ml decoding (which is at least as good) also has arbitrarily small error probability",
        "prob": 0.6565217391304348
    }, {
        "ID": 6862,
        "phrase": " (81) where (a) follows from the chain rule and because (x 1ai , x 1bi ) is a function of (y i\u22121 1a , y i\u22121 1b ), (b) follows because conditioning does not increase entropy, and (c) follows from the following markov chain conditions: (w 0 , w 1 , y i\u22121 1a , y i\u22121 1b ) \u2192 (x ai , x 1ai ) \u2192 y 1ai , (w 0 , w 1 , y i 1a , y i\u22121 1b ) \u2192 (x 1bi , x bi ) \u2192 y 1bi ",
        "prob": 0.35882352941176476
    }, {
        "ID": 6876,
        "phrase": " an error is declared whenever \u015dml = s and it well known that the ml detector is optimal in the sense that it minimizes the probability of error",
        "prob": 0.24117647058823527
    }, {
        "ID": 6876,
        "phrase": " by comparing the ml detector and minimum mean square error (mmse) detector  [2]  it can be seen that not only is the mmse suboptimal, but the rate at which the probability of error tends to zero with increasing snr is significantly lower than that of the optimal ml detector",
        "prob": 0.3607142857142857
    }, {
        "ID": 6876,
        "phrase": " the rate at which the error probability vanishes, or more precisely the slope (in log-log scale) of the error probability curve in the high snr regime, is commonly referred to as the diversity of the detector and it is well known that the mmse detector has a significantly lower diversity than the ml detector  [2] ",
        "prob": 0.34687500000000004
    }, {
        "ID": 6876,
        "phrase": " next, note that the error probability of the sdr receiver is lower bounded by p (\u015d sdr = e) \u2265 p (\u015d ml = e) ",
        "prob": 0.2928571428571429
    }, {
        "ID": 6876,
        "phrase": " = \u03c1 \u2212 n 2 since the ml detector achieves the minimum probability of error",
        "prob": 0.19090909090909092
    }, {
        "ID": 6876,
        "phrase": "  4  where the error probability of the sdr is significantly larger than that of the ml detector",
        "prob": 0.2818181818181818
    }, {
        "ID": 6969,
        "phrase": " derived upper bounds on the ml decoding error probability which solely depend on the weight enumerator of the overall code, instead of a specific split weight enumerator which follows from the partitioning of a codeword into several subsets of bits and the individual transmission of these subsets over different channels",
        "prob": 0.30606060606060603
    }, {
        "ID": 6969,
        "phrase": ", for given sets i(j)), the problem of upper-bounding the ml decoding error probability is exceedingly difficult",
        "prob": 0.44375
    }, {
        "ID": 6969,
        "phrase": " \n the ds2 bound for a single mbios channel the bounding technique of duman and salehi  [9, 10]  originates from the 1965 gallager bound  [13]  which states that the conditional ml decoding error probability p e|m given that a codeword x m (of block length n) is transmitted is upper-bounded by p e|m \u2264 y p n y|x m \uf8eb \uf8ed m \u2032 =m p n (y|x m \u2032 ) p n (y|x m ) \u03bb \uf8f6 \uf8f8 \u03c1 \u03bb, \u03c1 \u2265 0 ( 18 ) where p n (y|x) designates the conditional pdf of the communication channel to obtain an n-length sequence y at the channel output, given the n-length input sequence x",
        "prob": 0.6404255319148936
    }, {
        "ID": 6969,
        "phrase": " we apply the ds2 bound on the conditional ml decoding error probability (given the all-zero codeword is transmitted), and finally use the union bound w",
        "prob": 0.6714285714285714
    }, {
        "ID": 6969,
        "phrase": " the subcodes {c h } in order to obtain an upper bound on the ml decoding error probability of the code c",
        "prob": 0.65
    }, {
        "ID": 6969,
        "phrase": " since the code c is the union of the subcodes {c h }, the union bound provides an upper bound on the ml decoding error probability of c which is expressed as the sum of the conditional decoding error probabilities of the subcodes c h given that the all-zero codeword is transmitted",
        "prob": 0.8310344827586206
    }, {
        "ID": 6969,
        "phrase": " averaging  (27)  with respect to all possible channel assignments, we get the following bound on the average ml decoding error probability: p e \u2264 e \uf8f1 \uf8f2 \uf8f3 n 1 h 1 =0 ",
        "prob": 0.6529411764705882
    }, {
        "ID": 6969,
        "phrase": " in this case, the average ml decoding error probability p e is obtained by replacing a h in (31) with a h ",
        "prob": 0.25833333333333336
    }, {
        "ID": 6969,
        "phrase": " following the algebraic steps in (  27 )-  (31)  and averaging as before also over all the codebooks of the ensemble, we obtain the following upper bound on the ml decoding error probability: p e = p e|0 \u2264 \uf8f1 \uf8f2 \uf8f3 n h=0 a h \uf8ee \uf8f0 j j=1 \u03b1 j y g(y; j) 1\u2212 1 \u03c1 p(y|0; j) 1\u2212\u03bb p(y|1; j) \u03bb y g(y; j)p(y|0; j) 1\u2212\u03c1 \u03c1 \uf8f9 \uf8fb h \uf8ee \uf8f0 j j=1 \u03b1 j y g(y; j) 1\u2212 1 \u03c1 p(y|0; j) y g(y; j)p(y|0; j) 1\u2212\u03c1 \u03c1 \uf8f9 \uf8fb n\u2212h \uf8fc \uf8f4 \uf8fd \uf8f4 \uf8fe \u03c1 , 0 \u2264 \u03c1 \u2264 1 \u03bb \u2265 0 ",
        "prob": 0.5392857142857143
    }, {
        "ID": 6969,
        "phrase": " let p e|0 (h) denote the conditional block error probability of the subcode c h under ml decoding, given that the all-zero codeword is transmitted",
        "prob": 0.7833333333333333
    }, {
        "ID": 6969,
        "phrase": " then, the generalization of the ds2 bound in  (31)  provides an upper bound on the ml decoding error probability when the bound is taken over the whole code",
        "prob": 0.5055555555555555
    }, {
        "ID": 6969,
        "phrase": " by partitioning the code into constant hamming-weight subcodes,  (35)  forms an upper bound on the conditional ml decoding error probability for each of these subcodes, given that the all-zero codeword is transmitted, and (  34 ) forms an upper bound on the block error probability of the whole code (or ensemble)",
        "prob": 0.8212121212121211
    }, {
        "ID": 6969,
        "phrase": " let x m be the transmitted codeword and define the tilted ml metric d m (x m \u2032 , y) ln f (m) n (y) p n (y|x m \u2032 ) ( 45 ) where f (m) n (y) is an arbitrary function which is positive if there exists m \u2032 = m such that p n (y|x m \u2032 ) is positive",
        "prob": 0.37368421052631584
    }, {
        "ID": 6969,
        "phrase": " it is used here as a conceptual tool to evaluate the upper bound on the ml decoding error probability",
        "prob": 0.3642857142857143
    }, {
        "ID": 6969,
        "phrase": " the conditional ml decoding error probability can be expressed as the sum of two terms p e|m = prob(error, y \u2208 y n b ) + prob(error, y \u2208 y n g ) which is upper bounded by p e|m \u2264 prob(y \u2208 y n b ) + prob(error, y \u2208 y n g ) ",
        "prob": 0.5842105263157894
    }, {
        "ID": 6969,
        "phrase": " since the conditional error probability under ml decoding does not depend on the transmitted codeword, one can assume without loss of generality that the all-zero codeword is transmitted",
        "prob": 0.5285714285714287
    }, {
        "ID": 6969,
        "phrase": " following the notation in theorem 1, the generalization of the 1961 gallager bound in (59) provides an upper bound on the ml decoding error probability when the bound is taken over the whole code (as originally derived in  [21] )",
        "prob": 0.5695652173913043
    }, {
        "ID": 6969,
        "phrase": " by partitioning the code into constant hamming-weight subcodes, the generalized 1961 gallager bound on the conditional ml decoding error probability of an arbitrary subcode (given the all-zero codeword is transmitted) is provided by (71), and (34) forms an upper bound on the block error probability of the whole code (or ensemble)",
        "prob": 0.6885714285714285
    }, {
        "ID": 6969,
        "phrase": " a j-tuple of transition probabilities characterizing a parallel channel is said to be an attainable channel point with respect to a code ensemble c if the average ml decoding error probability vanishes as we let the block length tend to infinity",
        "prob": 0.575
    }, {
        "ID": 6969,
        "phrase": " then, the j-tuple vector of parameters characterizing these channels lies within the attainable channel region under ml decoding",
        "prob": 0.44375000000000003
    }, {
        "ID": 6969,
        "phrase": " it is important to note that the low hamming weight codewords which are addressed by the requirement in (88) may yield that the error probability under ml decoding does not necessarily vanish exponentially with the block length (see, e",
        "prob": 0.2541666666666667
    }, {
        "ID": 6969,
        "phrase": ", the bisection method) in order to find the smallest value of \u03bd * j for which the lower bound on the error exponent (as obtained by an upper bound on the ml decoding error probability) vanishes",
        "prob": 0.45909090909090916
    }, {
        "ID": 6969,
        "phrase": "1) from (87), it follows that lim sup \u03b4\u21920 r  [c]  (\u03b4) \u2264 0, so in the limit where \u03b4 \u2192 0, the bhattacharyya union bound becomes tight for the conditional ml decoding error probability (given that the all-zero codeword is transmitted) w",
        "prob": 0.743478260869565
    }, {
        "ID": 6969,
        "phrase": " by combining it with the requirement in (86), we obtain that the ml decoding error probability vanishes as we let n \u2192 \u221e, as long as we exclude the codewords whose hamming weights behave sub-linearly with the block length n",
        "prob": 0.3375
    }, {
        "ID": 6969,
        "phrase": " by showing that the error exponent of the generalized ds2 bound grows linearly with \u03b4 as we let \u03b4 \u2192 0 and due to the requirement in (88), it follows that asymptotically in the limit where the block length tends to infinity, these codewords contribute a vanishing effect to the ml decoding error probability (similarly to the proofs of  [20, theorem 2",
        "prob": 0.5484848484848485
    }, {
        "ID": 6969,
        "phrase": " in this appendix, we derive the union bound on the ml decoding error probability of binary linear block codes transmitted over parallel gaussian channels",
        "prob": 0.45499999999999996
    }, {
        "ID": 6970,
        "phrase": " another approach is the gallager bounding technique which provides a conditional upper bound on the ml decoding error probability given an arbitrary transmitted (length-n) codeword c m (p e|m )",
        "prob": 0.6409090909090909
    }, {
        "ID": 6970,
        "phrase": " the substitution of (5) into (4) yields the following upper bound on the conditional ml decoding error probability p e|m \u2264 y g m n (y) p n (y|c m ) 1\u2212\u03c1 \u2022 m \u2032 =m y p n (y|c m ) g m n (y) 1\u2212 1 \u03c1 p n (y|c m \u2032 ) p n (y|c m ) \u03bb \u03c1 , 0 \u2264 \u03c1 \u2264 1, \u03bb \u2265 0",
        "prob": 0.3944444444444445
    }, {
        "ID": 6970,
        "phrase": " the analysis refers to the decoding error probability under soft-decision ml decoding",
        "prob": 0.3153846153846154
    }, {
        "ID": 6970,
        "phrase": " hence, the upper bound on the conditional ml decoding error probability given in (  6 ) can be rewritten as p e = p e|0 \u2264 y g(y) p(y|0) n (1\u2212\u03c1) \u2022 \uf8f1 \uf8f2 \uf8f3 n l=1 a l y g(y) 1\u2212 1 \u03c1 p(y|0) n \u2212l y g(y) 1\u2212 1 \u03c1 p(y|0) 1\u2212\u03bb p(y|1) \u03bb l \uf8fc \uf8fd \uf8fe \u03c1 \u03bb \u2265 0, 0 \u2264 \u03c1 \u2264 1 \u2264 max 0<l\u2264n a l 2 \u2212n (1\u2212r) n l \u03c1 y g(y) p(y|0) n (1\u2212\u03c1) 2 \u2212n (1\u2212r)\u03c1 \u2022 y g(y) 1\u2212 1 \u03c1 p(y|0) + y g(y) 1\u2212 1 \u03c1 p(y|0) 1\u2212\u03bb p(y|1) \u03bb n \u03c1 ",
        "prob": 0.6366666666666666
    }, {
        "ID": 6970,
        "phrase": " from the symmetry of the channel, the union bound provides the following upper bound on the ml decoding error probability: p e = p e|0 \u2264 p e|0 (c \u2032 ) + p e|0 (c \u2032\u2032 ) ( 23 ) where p e|0 (c \u2032 ) and p e|0 (c \u2032\u2032 ) designate the conditional ml decoding error probabilities of c \u2032 and c \u2032\u2032 , respectively, given that the all zero codeword is transmitted",
        "prob": 0.8185185185185183
    }, {
        "ID": 6970,
        "phrase": " the following algorithm is suggested for the calculation of the upper bound on the block error probability under ml decoding: algorithm 1 1",
        "prob": 0.38125000000000003
    }, {
        "ID": 6970,
        "phrase": " then, the block error probability of c under ml decoding is upper bounded by p e \u2264 p e|0 (c \u2032 ) + p e|0 (c \u2032\u2032 ) where p e|0 (c \u2032 ) \u2264 sfb(\u03c1) \u2022 l\u2208u n l a(\u03c1) a(\u03c1) + b(\u03c1) l b(\u03c1) a(\u03c1) + b(\u03c1) n \u2212l \u03c1 , 0 \u2264 \u03c1 \u2264 1 (25) a(\u03c1) y [p(y|0)p(y|1)] 1 1+\u03c1 1 2 p(y|0) 1 1+\u03c1 + 1 2 p(y|1) 1 1+\u03c1 \u03c1\u22121 (26) b(\u03c1) y p(y|0) 2 1+\u03c1 1 2 p(y|0) 1 1+\u03c1 + 1 2 p(y|1) 1 1+\u03c1 \u03c1\u22121 ",
        "prob": 0.6894736842105263
    }, {
        "ID": 6970,
        "phrase": " then, we get from (  6 ) and (  11 ) the following upper bound on the conditional ml decoding error probability of the subcode c \u2032 : p e|0 (c \u2032 ) \u2264 y g(y) p(y|0) n (1\u2212\u03c1) \u2022 \uf8f1 \uf8f2 \uf8f3 l a l (c \u2032 ) y g(y) 1\u2212 1 \u03c1 p(y|0) n \u2212l y g(y) 1\u2212 1 \u03c1 p(y|0) 1\u2212\u03bb p(y|1) \u03bb l \uf8fc \uf8fd \uf8fe \u03c1 \u03bb \u2265 0, 0 \u2264 \u03c1 \u2264 1 = y g(y) p(y|0) n (1\u2212\u03c1) 2 \u2212n (1\u2212r)\u03c1 \u2022 \uf8f1 \uf8f2 \uf8f3 l\u2208u a l 2 \u2212n (1\u2212r) n l n l y g(y) 1\u2212 1 \u03c1 p(y|0) n \u2212l y g(y) 1\u2212 1 \u03c1 p(y|0) 1\u2212\u03bb p(y|1) \u03bb l \uf8fc \uf8fd \uf8fe \u03c1 \u2264 max l\u2208u a l 2 \u2212n (1\u2212r) n l \u03c1 y g(y) p(y|0) n (1\u2212\u03c1) 2 \u2212n (1\u2212r)\u03c1 \u2022 \uf8f1 \uf8f2 \uf8f3 l\u2208u n l y g(y) 1\u2212 1 \u03c1 p(y|0) n \u2212l y g(y) 1\u2212 1 \u03c1 p(y|0) 1\u2212\u03bb p(y|1) \u03bb l \uf8fc \uf8fd \uf8fe \u03c1 ",
        "prob": 0.6179487179487179
    }, {
        "ID": 6970,
        "phrase": " ( 33 ) substituting (  30 )-(  33 ) into (29) gives the following conditional upper bound on the ml decoding error probability of the subcode c \u2032 : p e|0 (c \u2032 ) \u2264 \u03b1(c \u2032 ) \u03c1 a(\u03c1) + b(\u03c1) 2 n (1\u2212\u03c1) 2 \u2212n (1\u2212r)\u03c1 \u2022 l\u2208u n l a l (\u03c1)b n \u2212l (\u03c1) \u03c1 ( 34 ) where we use the notation \u03b1(c \u2032 ) max l\u2208u a l 2 \u2212n (1\u2212r) n l ",
        "prob": 0.5549999999999999
    }, {
        "ID": 6970,
        "phrase": " \n upper bounds on bit error probability let c be a binary linear block code whose transmission takes place over an arbitrary mbios channel, and let p b designate the bit error probability of c under ml decoding",
        "prob": 0.4321428571428571
    }, {
        "ID": 6970,
        "phrase": " then the conditional bit error probability of c under ml decoding, given that the all-zero codeword is transmitted, is upper bounded by p b|0 \u2264 y p n (y|0) 1\u2212\u03bb\u03c1 \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 k w=1 w k c \u2208 c(w) c = 0 p n (y|c) \u03bb \uf8fc \uf8f4 \uf8fd \uf8f4 \uf8fe \u03c1 , \u03bb > 0, 0 \u2264 \u03c1 \u2264 1",
        "prob": 0.6894736842105263
    }, {
        "ID": 6970,
        "phrase": " the conditional bit error probability under ml decoding admits the form p b|0 = y w 0 (y) k p n (y|0) ( 38 ) where w 0 (y) \u2208 {0, 1, ",
        "prob": 0.5083333333333334
    }, {
        "ID": 6970,
        "phrase": " then, the bit error probability of c under ml decoding is upper bounded by p b \u2264 2 \u2212n er(r+ log \u03b1 b (c) n ) ( 40 ) where r = k n is the code rate of c, and \u03b1 b (c) max 0<l\u2264n a \u2032 l 2 \u2212n (1\u2212r) n l , a \u2032 l k w=1 w k a w,l ",
        "prob": 0.5611111111111111
    }, {
        "ID": 6970,
        "phrase": " by the union bound p b = p b|0 \u2264 p b|0 (c \u2032 ) + p b|0 (c \u2032\u2032 ) ( 44 ) where p b|0 (c \u2032 ) and p b|0 (c \u2032\u2032 ) denote the conditional ml decoding bit error probabilities of two disjoint subcodes c \u2032 and c \u2032\u2032 which partition the block code c (except that these two subcodes have the all-zero vector in common), given that the all-zero codeword is transmitted",
        "prob": 0.6806451612903225
    }, {
        "ID": 6970,
        "phrase": " then, the bit error probability of c under ml decoding is upper bounded by p b \u2264 p b|0 (c \u2032 ) + p b|0 (c \u2032\u2032 ) where p b|0 (c \u2032 ) \u2264 2 \u2212n e 0 (\u03c1)\u2212\u03c1(r+ log(\u03b1 b (c \u2032 )) n ) l\u2208u n l a(\u03c1) a(\u03c1) + b(\u03c1) l b(\u03c1) a(\u03c1) + b(\u03c1) n \u2212l \u03c1 , 0 \u2264 \u03c1 \u2264 1 (50) \u03b1 b (c \u2032 ) max l\u2208u a \u2032 l 2 \u2212n (1\u2212r) n l , a \u2032 l n r w=1 w nr a w,l and the functions a, b, e 0 are introduced in (  26 ), (  27 ) and (  9 ), respectively",
        "prob": 0.40499999999999997
    }, {
        "ID": 6970,
        "phrase": " then, under ml decoding, the bit error probability of c, is upper bounded by p b \u2264 p b|0 (c \u2032 ) + p b|0 (c \u2032\u2032 ) where p b|0 (c \u2032 ) \u2264 2 \u2212n e 0 (\u03c1)\u2212\u03c1 r+ log \u1fb1\u03c1(c \u2032 ) n , 0 \u2264 \u03c1 \u2264 1 (51) \u1fb1\u03c1 (c \u2032 ) n l=0 a \u2032 l (c \u2032 ) 2 \u2212n (1\u2212r) n l \u2022 n l a(\u03c1) a(\u03c1) + b(\u03c1) l b(\u03c1) a(\u03c1) + b(\u03c1) n \u2212l ",
        "prob": 0.5083333333333334
    }, {
        "ID": 6970,
        "phrase": " the decoding is assumed to be performed in two stages: the inner (8, 7) binary linear block code is soft-decision ml decoded, and then a hard decision ml decoding is used for the outer (129, 99, 29) rs code",
        "prob": 0.27307692307692305
    }, {
        "ID": 6970,
        "phrase": " hence, an upper bound on the average block error probability of the considered serially concatenated ensemble is given by p e \u2264 127 i=t+1 127 i p i s (1 \u2212 p s ) 127\u2212i (61) where p s is the average symbol error probability of the inner code under soft-decision ml decoding",
        "prob": 0.5807692307692307
    }, {
        "ID": 6971,
        "phrase": " let e be the event of deciding erroneously (under ml decoding) on a codeword other than the transmitted codeword",
        "prob": 0.5461538461538462
    }, {
        "ID": 6971,
        "phrase": " since we deal with linear codes, the conditional error probability under ml decoding does not depend on the transmitted codeword of the code c, so without any loss of generality, one can assume that the all-zero codeword, s 0 , is transmitted",
        "prob": 0.564
    }, {
        "ID": 6972,
        "phrase": " let e be the event of deciding erroneously (under ml decoding) on a codeword other than the transmitted codeword",
        "prob": 0.7000000000000001
    }, {
        "ID": 6972,
        "phrase": " since we deal with linear codes, the conditional error probability under ml decoding does not depend on the transmitted codeword of the code c, so without any loss of generality, one can assume that the all-zero codeword, s 0 , is transmitted",
        "prob": 0.524
    }, {
        "ID": 6972,
        "phrase": " this results in the following upper bound on the decoding error probability under ml decoding pr(e) \u2264 + \u221a nes \u2212\u221e e \u2212 z 2 2 2\u03c3 2 \u221a 2\u03c0\u03c3 h: \u03b4 h 2 <\u03b1 h a h rz 1 \u03b2 h (z 1 ) e \u2212 z 2 2 2\u03c3 2 \u221a 2\u03c0\u03c3 r 2 z 1 \u2212z 2 2 0 f v (v)dv dz 2 +1 \u2212 \u03b3 n\u22121 2 , r 2 z 1 2\u03c3 2 dz 1 + q 2nre b n 0 ",
        "prob": 0.40499999999999997
    }, {
        "ID": 6996,
        "phrase": " when ms decoding is performed on this tree code, we upper bound the probability of the root bit being in error by the probability of sequence error under ml decoding of a subcode of the tree code",
        "prob": 0.743478260869565
    }, {
        "ID": 6996,
        "phrase": " a recursive equation describing the evolution of the weight enumerator of this subcode after each iteration is then derived and used in a union bound to bound the ml decoded sequence error of this subcode",
        "prob": 0.6863636363636364
    }, {
        "ID": 6997,
        "phrase": " assuming that the all-zero codeword is transmitted, we have the following lemma describing the relationship between the probability of ml decoding errors associated with the incoming and outgoing messages of a check node",
        "prob": 0.8304347826086954
    }, {
        "ID": 6997,
        "phrase": " theorem 3 for the (\u03bb, \u03c1) ldpc ensemble used on an mbios channel, the probability of bit error p l associated with the outgoing message of any variable node after the lth decoding iteration asymptotically satisfies 2p l \u2265 2p 0 \u03bb (1 \u2212 \u03c1 (1 \u2212 2p l\u22121 )) ( 26 ) where p 0 is the uncoded bit error probability under ml decoding of the channel",
        "prob": 0.6033333333333333
    }, {
        "ID": 6997,
        "phrase": " when ms decoding is performed on this tree code, we upper bound the probability of the root bit being in error by the probability of sequence error under ml decoding of a subcode of the tree code",
        "prob": 0.6999999999999998
    }, {
        "ID": 6997,
        "phrase": " a recursive equation describing the evolution of the weight enumerator of this subcode after each iteration is then derived and used in a union bound to bound the ml decoded sequence error of this subcode",
        "prob": 0.6409090909090909
    }, {
        "ID": 6998,
        "phrase": " assuming that the all-zero codeword is transmitted, we have the following lemma describing the relationship between the probability of ml decoding errors associated with the incoming and outgoing messages of a check node",
        "prob": 0.8304347826086954
    }, {
        "ID": 6998,
        "phrase": " theorem 3 for the (\u03bb, \u03c1) ldpc ensemble used on an mbios channel, the probability of bit error p l associated with the outgoing message of any variable node after the lth decoding iteration asymptotically satisfies 2p l \u2265 2p 0 \u03bb (1 \u2212 \u03c1 (1 \u2212 2p l\u22121 )) ( 26 ) where p 0 is the uncoded bit error probability under ml decoding of the channel",
        "prob": 0.6366666666666666
    }, {
        "ID": 6998,
        "phrase": " when ms decoding is performed on this tree code, we upper bound the probability of the root bit being in error by the probability of sequence error under ml decoding of a subcode of the tree code",
        "prob": 0.7869565217391302
    }, {
        "ID": 6998,
        "phrase": " a recursive equation describing the evolution of the weight enumerator of this subcode after each iteration is then derived and used in a union bound to bound the ml decoded sequence error of this subcode",
        "prob": 0.6409090909090909
    }, {
        "ID": 7117,
        "phrase": " 7] , we obtain the random coding bound on the error probability of ml decoding over block-fading mimo channels as 3 p e \u2264 2e r\u03b4 \u03be 2 e \u2212n b nc er(p x x x (x x x),r,nc) (9) 3 when x x x = (xij ) is an m \u00d7 n matrix of complex variables that do not depend functionally on each other, dx x x = m i=1 n j=1 d\u211cxij d\u2111xij ",
        "prob": 0.48518518518518516
    }, {
        "ID": 7210,
        "phrase": " at first, calculate the error probability equation for the ml decision when the noise source state is known in the receiver",
        "prob": 0.25625000000000003
    }, {
        "ID": 7249,
        "phrase": " then, under ml decoding, the error probability is lower bounded by p e (ml) > p spb (n, \u03b8, a) , a 2e s n 0 ( 68 ) where e s is the average energy per symbol, \u03b8 \u2208 [0, \u03c0] satisfies the inequality 2 \u2212n r \u2264 \u03c9 n (\u03b8) \u03c9 n (\u03c0) , p spb (n, \u03b8, a) (n \u2212 1)e \u2212 na 2 2 \u221a 2\u03c0 \u03c0 2 \u03b8 (sin \u03c6) n \u22122 f n ( \u221a n a cos \u03c6) d\u03c6 +q( \u221a n a)",
        "prob": 0.7947368421052632
    }, {
        "ID": 7250,
        "phrase": " then, under ml decoding, the error probability is lower bounded by p e (ml) > p spb (n, \u03b8, a) , a 2e s n 0 where e s is the average energy per symbol, \u03b8 \u2208 [0, \u03c0] satisfies the inequality 2 \u2212n r \u2264 \u03c9 n (\u03b8) \u03c9 n (\u03c0) , p spb (n, \u03b8, a) (n \u2212 1)e \u2212 na 2 2 \u221a 2\u03c0 \u03c0 2 \u03b8 (sin \u03c6) n \u22122 f n ( \u221a n a cos \u03c6) d\u03c6 +q( \u221a n a)",
        "prob": 0.7421052631578947
    }, {
        "ID": 7251,
        "phrase": " then, under ml decoding, the block error probability is lower bounded by p e (ml) > p spb (n, \u03b8, a) , a 2e s n 0 ( 65 ) where e s is the average energy per symbol, \u03b8 \u2208 [0, \u03c0] satisfies the inequality exp(\u2212n r) \u2264 \u03c9n (\u03b8) \u03c9n (\u03c0) , p spb (n, \u03b8, a) (n \u2212 1)e \u2212 n a 2 2 \u221a 2\u03c0 \u03c0 2 \u03b8 (sin \u03c6) n \u22122 f n ( \u221a n a cos \u03c6) d\u03c6 + q( \u221a n a) (66) and f n (x) 1 2 n \u22121 2 \u03b3( n +1 2 ) \u221e 0 z n \u22121 exp \u2212 z 2 2 + zx dz , \u2200 x \u2208 r, n \u2208 n",
        "prob": 0.6291666666666667
    }, {
        "ID": 7251,
        "phrase": " similarly, by fixing these parameters, the random coding bound of gallager  [11]  is transformed into an upper bound on the block length required for ml decoded random codes to achieve a desired block error probability on a given communication channel",
        "prob": 0.5896551724137931
    }, {
        "ID": 7311,
        "phrase": " ml decoding error bound the next theorem, which is proved in appendix ii, is a bound on the expected ml decoding error probability with respect to the random coding",
        "prob": 0.6238095238095238
    }, {
        "ID": 7311,
        "phrase": "2], denote the probability of error using the ml decoder when message m is sent",
        "prob": 0.25833333333333336
    }, {
        "ID": 7311,
        "phrase": " thus, assuming that s 0 is uniformly distributed the bound on error probability under ml decoding given in theorem 8 becomes where p e (s 0 ) is the probability of error over all messages given that the initial state is s 0 and the expectation is w",
        "prob": 0.30869565217391304
    }, {
        "ID": 7337,
        "phrase": " the probability of information bit error under hard-decision ml decoding when the code is used over a bsc with crossover probability of p is upper bounded by: p e n \u2211 m= d\u22121 2 +1 m n n m p m (1 \u2212 p) n\u2212m (2) using the expression for p(i, \u03c3) for the crossover probability p, we get, for the i th level, the information bit error is upper bounded as: p e (i, \u03c3) n \u2211 m= d\u22121 2 +1 m n n m p(i, \u03c3) m (1 \u2212 p(i, \u03c3)) n\u2212m the average distortion due to the i th level is given by, d(i, \u03c3) = 2 b\u22121 \u2211 j=0 a 2 (bi\u2212j) p e (i, \u03c3) = 2 b\u22121 \u2211 j=0 ( \u221a 3 2 (bi\u2212j) ) 2 p e (i, \u03c3) = 2(4 b \u2212 1) 4 bi p e (i, \u03c3) the summation above over j was because errors in the i th coded bit level cause errors in the source bits planes {(bi \u2212 j) : j \u2208 {0, ",
        "prob": 0.5113207547169811
    }, {
        "ID": 7408,
        "phrase": " that is, there is a rule d = c \u2283 l \u2192 r \u2208 r such that u = l\u03c3, v = r\u03b8, \u03c3 \u2704 ai \u03b8 and l\u03c3 \u2192 ai r\u03c3",
        "prob": 0.22000000000000003
    }, {
        "ID": 7539,
        "phrase": ") by theorem 6, with probability at least 1 \u2212 \u03b4 the ml algorithm outputs a hypothesis z ml such that kl(z m ||z ml ) \u2264 28\u01eb",
        "prob": 0.22142857142857145
    }, {
        "ID": 7547,
        "phrase": " we have the following results: \u2022 the ml decoding error probability is upper-bounded by p e \u2264 \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 n h=0 a h \uf8eb \uf8ed j j=1 \u03b1 j a(\u03bb, \u03c1; j, \u03c8(\u2022; j)) \uf8f6 \uf8f8 h \uf8eb \uf8ed j j=1 \u03b1 j b(\u03c1; j, \u03c8(\u2022; j)) \uf8f6 \uf8f8 n\u2212h \uf8fc \uf8f4 \uf8fd \uf8f4 \uf8fe \u03c1 (2) where 0 \u2264 \u03c1 \u2264 1, \u03bb \u2265 0, a(\u03bb, \u03c1; j, \u03c8(\u2022; j)) y \u03c8(y; j) 1\u2212 1 \u03c1 p(y|0; j) 1\u2212\u03bb\u03c1 \u03c1 p(y|1; j) \u03bb b(\u03c1; j, \u03c8(\u2022; j)) y \u03c8(y; j) 1\u2212 1 \u03c1 p(y|0; j) 1 \u03c1 and \u03c8(\u2022; j), j = 1, ",
        "prob": 0.6937500000000001
    }, {
        "ID": 7547,
        "phrase": " the conditional ml decoding error probability of the constant-weight subcode c h is therefore upper-bounded by p e|0 (h) \u2264 (a h ) \u03c1 \uf8eb \uf8ed j j=1 \u03b1 j a(\u03bb, \u03c1; j, \u03c8(\u2022; j)) \uf8f6 \uf8f8 h\u03c1 \uf8eb \uf8ed j j=1 \u03b1 j b(\u03c1; j, \u03c8(\u2022; j)) \uf8f6 \uf8f8 (n\u2212h)\u03c1 (4) which can be written equivalently in the exponential form p e|0 (h) \u2264 e \u2212ne ds2 \u03b4 (\u03bb,\u03c1,j,{\u03b1j }) where e ds2 \u03b4 (\u03bb, \u03c1, j, {\u03b1 j }) \u2212\u03c1r c (\u03b4) \u2212\u03c1\u03b4 ln \uf8eb \uf8ed j j=1 \u03b1 j a(\u03bb, \u03c1; j, \u03c8(\u2022; j)) \uf8f6 \uf8f8 \u2212\u03c1(1 \u2212 \u03b4) ln \uf8eb \uf8ed j j=1 \u03b1 j b(\u03c1; j, \u03c8(\u2022; j)) \uf8f6 \uf8f8 ",
        "prob": 0.48400000000000004
    }, {
        "ID": 7547,
        "phrase": " inner bounds on attainable channel regions a j-tuple of transition probabilities characterizing a parallel channel is said to be an attainable channel point with respect to a code ensemble c if the average ml decoding error probability vanishes as we let the block length tend to infinity",
        "prob": 0.4878787878787878
    }, {
        "ID": 7547,
        "phrase": " then, the j-tuple vector of parameters characterizing these channels lies within the attainable channel region under ml decoding",
        "prob": 0.31875000000000003
    }, {
        "ID": 7736,
        "phrase": " one of the easiest and most widely known techniques to overbound the ml decoding error probability is the union bound",
        "prob": 0.54
    }, {
        "ID": 7737,
        "phrase": " due to theorem 4, algorithm 2 exhibits the ml certificate property, and hence  (13)  provides us with an upper bound on the error probability p e (t)",
        "prob": 0.39444444444444443
    }, {
        "ID": 7737,
        "phrase": " one of the easiest and most widely known techniques to overbound the ml decoding error probability is the union bound",
        "prob": 0.54
    }, {
        "ID": 7791,
        "phrase": " we denote the probability of error of the ml decoder by pr (m l) (\u03b5)",
        "prob": 0.51
    }, {
        "ID": 7791,
        "phrase": " the average probability of error is given by pr m d (e) = l\u22121 k=1 [pr(x)] (k\u22121) pr(\u03b5) + [pr(x)] (l\u22121) pr (m l) (\u03b5) = pr(\u03b5) [1 + o(1)] + [pr(x)] (l\u22121) pr (m l) (\u03b5) (14) \u2264 e \u2212n [e 1 (r 1 ,t )+t ] [1 + o(1)] + e \u2212n [er(r 1 )+(l\u22121)e 1 (r 1 ,t )] , (15) where the inequality follows from (3) and the random coding upper bound on the ml decoding error probability  [3] ",
        "prob": 0.5592592592592593
    }, {
        "ID": 7791,
        "phrase": " these exponents are further equal to the exponent of the ml decoding error probability since pr(\u03b5) \u2264 pr (m l) (\u03b5) \u2264 pr(\u03b5) + pr(x)",
        "prob": 0.25625000000000003
    }, {
        "ID": 7856,
        "phrase": " the theory of both ml and sequential decoding tells us that generically, the probability of bit error on bit i approaches zero exponentially with increasing delay",
        "prob": 0.705
    }, {
        "ID": 7857,
        "phrase": " the theory of both ml and sequential decoding tells us that generically, the probability of bit error on bit i approaches zero exponentially with increasing delay",
        "prob": 0.755
    }, {
        "ID": 7858,
        "phrase": " remark: the error exponents of theorems 2 and 3 both equal their respective random block-coding exponents for ml and universal decoders",
        "prob": 0.41764705882352937
    }, {
        "ID": 7858,
        "phrase": " (23) where e block sw,x (r x , r y ) = min{e ml x (r x , r y , 0), e ml x (r x , r y , 1 )} as shown in  [9] ",
        "prob": 0.23333333333333334
    }, {
        "ID": 7858,
        "phrase": " error events and sequential decoding to better understand the dominant error event in the sum (36), consider constructing the ml estimate in a symbol-by-symbol sequential manner",
        "prob": 0.30869565217391304
    }, {
        "ID": 7858,
        "phrase": " for ml decoding, we need to pick the sequence with the maximum conditional probability given y n ",
        "prob": 0.4692307692307693
    }, {
        "ID": 7858,
        "phrase": " the following lemma, analogous to (50) for ml decoding, tells us that the \"suffix weighted entropy\" decoding rule is a good one",
        "prob": 0.5352941176470588
    }, {
        "ID": 7858,
        "phrase": " a sequential random binning argument is used to derive a lower bound on the error exponent with delay and show that both ml decoding and universal decoding achieve the same positive error exponents inside the traditional slepian-wolf rate region",
        "prob": 0.5033333333333333
    }, {
        "ID": 7870,
        "phrase": " ml decoding results in an exponentially small probability of error as a function of tolerated receiver delay and thus eventually a zero probability of error on every transmitted bit",
        "prob": 0.5260869565217391
    }, {
        "ID": 7889,
        "phrase": " lim snr\u2192\u221e r(sn r) log sn r = r and lim snr\u2192\u221e log p e(sn r) log sn r = \u2212dwhere, r(sn r) is the data rate measured by bits per channel use (pcu) and p e(sn r) is the average error probability using the ml decoder",
        "prob": 0.5838709677419354
    }, {
        "ID": 7890,
        "phrase": " , r and if m = (\u2206s) h d \u22121 (\u2206s) has rank \u2264 (r + 1) , then for large r and large p , the pairwise error probability (pep) that a ml receiver erroneously decodes to s j can be upper bounded as  where, \u03c3 2 min is the minimum non-zero eigen value of m ",
        "prob": 0.4136363636363637
    }, {
        "ID": 7890,
        "phrase": "  2  shows the ml decoder's symbol error rate and codeword error rate performance comparison for both protocols",
        "prob": 0.5062500000000001
    }, {
        "ID": 7891,
        "phrase": " then the ml decoding of x k can further be separated into g k subgroups, for each 1 \u2264 k \u2264 g",
        "prob": 0.2625
    }, {
        "ID": 7939,
        "phrase": " recall that the ml decoding problem is: given a received word y at the channel output, find a codeword x \u2208 c that maximizes the probability, pr[y|x], of receiving y conditioned on the event that x was transmitted",
        "prob": 0.5045454545454545
    }, {
        "ID": 7940,
        "phrase": " recall that the ml decoding problem is: given a received word y at the channel output, find a codeword x \u2208 c that maximizes the probability, pr[y|x], of receiving y conditioned on the event that x was transmitted",
        "prob": 0.6409090909090909
    }, {
        "ID": 8041,
        "phrase": " \n definition 1 the sum of multiplicities in m that are assigned to the transmitted symbols is defined as the score: s = m, [x ] (6) \n definition 2 the number of linear constraints imposed in order to satisfy the multiplicities as specified by m is defined as the cost: c = 1 2 q i=1 n i=1 m i,j (m i,j + 1) = m, m+1 /2 (7) similar to other list decoding algorithms, the probability of error of asd can be upper bounded using the union bound: p asd \u2264 p list + p ml (8) where p list is the probability that the transmitted codeword is not in the list and p ml is the probability that the maximum likelihood decision is not the transmitted codeword",
        "prob": 0.32884615384615384
    }, {
        "ID": 8042,
        "phrase": " similar to other list decoding algorithms, the probability of error of asd can be upper bounded using the union bound: p asd \u2264 p list + p ml (8) where p list is the probability that the transmitted codeword is not on the list and p ml is the probability that the maximum likelihood decision is not the transmitted codeword",
        "prob": 0.39032258064516134
    }, {
        "ID": 8403,
        "phrase": " , \u03c6 n\u22121 ) rather than the received vector r is sufficient in ml decoding",
        "prob": 0.30999999999999994
    }, {
        "ID": 8447,
        "phrase": " we consider a joint ml decoder at the base station and denote the error probability as p e (\u03c1)",
        "prob": 0.5461538461538462
    }, {
        "ID": 8462,
        "phrase": " since the performance of rate-1/3 pcccs gradually converges to the ml bound, this bound can be used to predict the bep error floor region of the corresponding code",
        "prob": 0.29047619047619044
    }, {
        "ID": 8556,
        "phrase": " decoding we will make use of the arq decoder proposed in  [18] , which behaves as a typical set decoder for the first l \u2212 1 arq round and finally performs ml decoding at the last arq round",
        "prob": 0.4208333333333334
    }, {
        "ID": 8556,
        "phrase": " based on the events defined above, the probability of error p e (\u03c1) is given by p e (\u03c1) = e \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 pr (a 1 , e 1 ) + l\u22121 \u2113=2 pr (d \u2113\u22121 , a \u2113 , e \u2113 ) undetected errors + pr (d l\u22121 , e l ) ml decoding errors \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb , (11) where the expectation is with respect to the joint distribution of the fading gain matrix and received signal matrix",
        "prob": 0.46785714285714286
    }, {
        "ID": 8556,
        "phrase": " from the error expression in  (11)  it is clear that the arq decoder suffers from undetected errors and ml decoding errors",
        "prob": 0.6066666666666667
    }, {
        "ID": 8556,
        "phrase": " ml decoding errors occur at the last arq round and reflects the inability of the decoder to resolve atypical channel and noise realizations",
        "prob": 0.32105263157894737
    }, {
        "ID": 8556,
        "phrase": " we shall see later that the probability of undetected errors can be made arbitrarily small using appropriate codebooks, leaving ml decoding errors to dominate the error probability",
        "prob": 0.5695652173913043
    }, {
        "ID": 8556,
        "phrase": " we start following the arguments in [18, appendix i] and conclude that by fano's inequality we can obtain a lower bound to the error probability of the arq decoder at any arq round \u2113 by using an ml decoder that operates over the l arq rounds",
        "prob": 0.7346153846153844
    }, {
        "ID": 8556,
        "phrase": " , l \u2212 1, and as an ml decoder at round l  [38] ",
        "prob": 0.4428571428571429
    }, {
        "ID": 8556,
        "phrase": " (60) therefore, p e (\u03c1|h l ) \u2264 (l \u2212 1)\u03b4 + p ml e (\u03c1|h l ) where p ml e (\u03c1|h l ) \u2206 = pr d l\u22121 , m =m \u03c8 l ( y l , h l ) = m (62) is the error probability of an ml decoding error at the lth arq round",
        "prob": 0.5062500000000001
    }, {
        "ID": 8556,
        "phrase": " however, the specific analysis of the ml decoding error probability for round l using random codes encompasses the standard quasistatic and block-fading mimo channels with no arq as special cases, and therefore is of broader interest",
        "prob": 0.26296296296296295
    }, {
        "ID": 8561,
        "phrase": " but this will give the determinant of the error code matrix as  symbol ml decoding and we give a constructive proof",
        "prob": 0.47333333333333333
    }, {
        "ID": 8784,
        "phrase": " the resulting encoding efficiency \u03b7 (measured in source samples per channel use) is given by \u03b7 = k n = r c r s (2) in the limit of large k, assuming stationarity and ergodicity of the source and a ml probability estimator such that \u03b8 \u2192 \u03b8, we have that b \u2192 kh \u03b8 (u)",
        "prob": 0.43913043478260866
    }, {
        "ID": 8882,
        "phrase": " error probability of syndrome extension it immediately follows from theorem 1, that the error probability p e is not larger than the error probability of an ml decoder",
        "prob": 0.5055555555555556
    }, {
        "ID": 8907,
        "phrase": " introduction ml decoding is a central algorithmic problem in coding theory  [1] ,  [2]  since ml decoders minimize the message error probability when each codeword is transmitted with equal probability",
        "prob": 0.30869565217391304
    }, {
        "ID": 8907,
        "phrase": "thus it would be worthwhile to establish the hardness of ml decoding in the average sense, or for more narrow classes of codes\"",
        "prob": 0.25625000000000003
    }, {
        "ID": 8907,
        "phrase": " let the code length be n, the rate r, the complexity of the suboptimal decoder n (n), and the probability that the suboptimal decoder does not find the ml solution be p e (n)",
        "prob": 0.3
    }, {
        "ID": 8907,
        "phrase": " the rate region r ml is also characterized in section iii",
        "prob": 0.21000000000000002
    }, {
        "ID": 8907,
        "phrase": " for the second statement, since the ml decoder corrects up to 3\u03b1/4 fraction of errors, which is larger than p, we have an exponentially decreasing error probability from the chernoff bound",
        "prob": 0.4789473684210526
    }, {
        "ID": 8907,
        "phrase": " proof: by using the chernoff bound, the block error rate of ml decoding is upper bounded by 2 \u2212d( 3\u03b1 4 p)n , while the block error rate of iterative decoding is upper bounded by 2 \u2212d( \u03b1 2 p)n when p < \u03b1 2 ",
        "prob": 0.6708333333333332
    }, {
        "ID": 8907,
        "phrase": " for a bsc channel with fixed bit flipping probability p, let us denote r ml (p) as the set of rates t in which there exists a family of asymptotically good codes whose error probability goes to zero exponentially in the coding length under an expected polynomial complexity exact ml decoding algorithm without preprocessing",
        "prob": 0.5026315789473683
    }, {
        "ID": 8907,
        "phrase": " lemma 9: if p is sufficiently close to zero but remains positive, the gap between the channel capacity and the supremum of the rate region r ml (p) is arbitrarily small",
        "prob": 0.531578947368421
    }, {
        "ID": 8907,
        "phrase": " more precisely, for any bit-flipping probability, p, in a nontrivial range, there exists a rate region of non-zero support and a family of asymptotically good codes, whose error probability decays exponentially in coding length n, for which ml decoding is feasible in expected polynomial time",
        "prob": 0.4878787878787878
    }, {
        "ID": 9163,
        "phrase": " however, this method for computing the ml lower bound could not be applied to the codes of length greater that 32 bits",
        "prob": 0.19375
    }, {
        "ID": 9197,
        "phrase": " given the transmitted codeword c, the pep, that is the probability that the ml decoder chooses the codeword g = c, conditional to the set of fading levels z, can be written as p c \u2192 g|z = 1 2 erfc e s 4n 0 d 2 c, g|z , (4) where erfc(x) 2 \u221a \u03c0 \u221e x e \u2212t 2 dt is the complementary gaussian error function, and the conditional euclidean squared distance at the channel output, d 2 c, g|z , is given by  [8]   d 2 c, g|z = n t=1 m s=1 n i=1 h (t) i,s \u2022 c (t) i \u2212 g (t) i 2 ",
        "prob": 0.39166666666666666
    }, {
        "ID": 9259,
        "phrase": " this error-correcting code approach suggests that we view machine learning as a kind of communications problem in which the identity of the correct output class for a new example is being \\transmitted\" over a channel",
        "prob": 0.2217391304347826
    }, {
        "ID": 9286,
        "phrase": " again the parameter vector can be estimated using the ml approach",
        "prob": 0.31
    }, {
        "ID": 9380,
        "phrase": " let trev = ( a, 0) where ai = \u22121 for i = 1, \u2022 \u2022 \u2022 , 128 and 0 is a zero vector of size 128",
        "prob": 0.4555555555555556
    }, {
        "ID": 9381,
        "phrase": " let trev = ( a, 0) where ai = \u22121 for i = 1, \u2022 \u2022 \u2022 , 128 and 0 is a zero vector of size 128",
        "prob": 0.4555555555555556
    }, {
        "ID": 9748,
        "phrase": " referring next to the observations at the end of the preceding subsection, the conditional probability density p(ai | ai\u22121)dai of ai after p1, p2, ",
        "prob": 0.23846153846153847
    }]
}, {
    "topic_id": 7,
    "top_words": ["lr", "every", "wn", "iff", "ml", "form", "order", "case", "frame", "first", "rule", "hence", "terms", "note", "formula"],
    "phrases": [{
        "ID": 131,
        "phrase": "009 seconds the variable domains to af \u2208 [+,-, l], ai \u2208 [+,-], ab \u2208 [+,-,r], ij \u2208 [+,-,l,r], ih \u2208 [+,-,l,r], jh \u2208 [+,-,l,r], gh \u2208 [+,-,l,r], gc \u2208 [+,-,l,r], ge \u2208 [+,-,l,r], ef \u2208 [+,-], ed \u2208 [+,-,l], cd \u2208 [+,-,r], and cb \u2208 [+,-,l]",
        "prob": 0.45909090909090916
    }, {
        "ID": 132,
        "phrase": "009 seconds the variable domains to af \u2208 [+,-, l], ai \u2208 [+,-], ab \u2208 [+,-,r], ij \u2208 [+,-,l,r], ih \u2208 [+,-,l,r], jh \u2208 [+,-,l,r], gh \u2208 [+,-,l,r], gc \u2208 [+,-,l,r], ge \u2208 [+,-,l,r], ef \u2208 [+,-], ed \u2208 [+,-,l], cd \u2208 [+,-,r], and cb \u2208 [+,-,l]",
        "prob": 0.45909090909090916
    }, {
        "ID": 141,
        "phrase": " as every ai problem can be brought into this form, the problem of maximizing utility is hence being formally solved, if \u00b5 is known",
        "prob": 0.4733333333333334
    }, {
        "ID": 141,
        "phrase": " although factorizable \u00b5 are too restrictive to cover all ai problems, it often occurs in practice in the form of repeated problem solving, and hence, is worth being studied",
        "prob": 0.4789473684210526
    }, {
        "ID": 141,
        "phrase": " we will see that in the ai case, there are no useful bounds in terms of k(\u00b5) only",
        "prob": 0.34444444444444444
    }, {
        "ID": 424,
        "phrase": "1 has the following form: ml l f u figure 1: a simple causal network",
        "prob": 0.19090909090909092
    }, {
        "ID": 477,
        "phrase": " in the ai case, there are no useful bounds in terms of k(\u00b5) only",
        "prob": 0.2625
    }, {
        "ID": 1064,
        "phrase": " , b n sono le relazioni risultato della valutazione delle regole bound associate ai predicati dove compare x i nella stessa regola in esame",
        "prob": 0.20666666666666667
    }, {
        "ID": 1064,
        "phrase": " possiamo invece pensare di creare il circuito in base a dei circuiti parziali, in cui le ramificazioni dell'albero di ricerca corrispondono ai possibili nodi che possono essere aggiunti ad una data iterazione nella ricerca di un circuito completo: ciclo(x, 1) \u2190 any[node(x)] ciclo(x, n + 1) \u2190 ciclo(y, n ), range(n )[edge(y, x)] in questo caso c'\u00e8 da osservare che bisogna mantenere il vincolo 8, poich\u00e8 l'iteratore range sceglie uno tra tutti i possibili archi, per poi verificare eventualmente che questo non pu\u00f2 legarsi a nessuna delle tuple di ciclo",
        "prob": 0.7666666666666666
    }, {
        "ID": 1158,
        "phrase": " in the ai literature this has been studied intensively and is referred to as the frame problem  [51, 62] ",
        "prob": 0.21000000000000002
    }, {
        "ID": 1538,
        "phrase": " the ml segmentation t = ( t 0 , t 1 , ",
        "prob": 0.18333333333333335
    }, {
        "ID": 1881,
        "phrase": "  klein and manning (2001)  note that traditional arguments for phrase structure have nothing to do with the independence assumptions of the pcfg, and that it could be that the ml and linguistic criteria align, but in practice they do not always seem to, and one should not expect that, by maximizing the former, one will also maximise the latter",
        "prob": 0.325
    }, {
        "ID": 2333,
        "phrase": " in the ai case, there are no useful bounds in terms of k(\u00b5) only",
        "prob": 0.3875
    }, {
        "ID": 2333,
        "phrase": " as every ai problem can be brought into this form, the problem of maximizing utility is hence being formally solved, if \u00b5 is known",
        "prob": 0.4066666666666667
    }, {
        "ID": 2333,
        "phrase": " although factorizable \u00b5 are too restrictive to cover all ai problems, it often occurs in practice in the form of repeated problem solving, and hence, is worth being studied",
        "prob": 0.4789473684210527
    }, {
        "ID": 2333,
        "phrase": " we will see that in the ai case, there are no useful bounds in terms of k(\u00b5) only",
        "prob": 0.34444444444444444
    }, {
        "ID": 2363,
        "phrase": " roughly speaking, v i is equal to v i\u22121 extended to the unary predicate symbols of the form q \u03c8i with q a state of a ai ",
        "prob": 0.3923076923076923
    }, {
        "ID": 2364,
        "phrase": " roughly speaking, v i is equal to v i\u22121 extended to the unary predicate symbols of the form q \u03c8i with q a state of a ai ",
        "prob": 0.3923076923076923
    }, {
        "ID": 2742,
        "phrase": " m, i, h v |= true m, i, h v |= false m, i, h v |= p(x 1 , \u2022 \u2022 \u2022, x n ) iff h p (i, p)(\u03c4 vh (x 1 ), \u2022 \u2022 \u2022, \u03c4 vh (x n )) = true m, i, h v |= \u00ac\u03d5 iff m, i, h v |= \u03d5 m, i, h v |= \u03d5 \u2228 \u03c8 iff m, i, h v |= \u03d5 or m, i, h v |= \u03c8 m, i, h v |= \u03d5 u\u03c8 iff for some k such that i < k , m, k , h v |= \u03c8 and for all j , if i < j < k then m, j , h v |= \u03d5 m, i, h v |= \u03d5 s\u03c8 iff for some k such that 0 \u2264 k < i, m, k , h v |= \u03c8 and for all j , if k < j < i then m, j , h v |= \u03d5 m, i, h v |= \u2200x \u2022 \u03d5 iff for all d \u2208 d, m, i, h v [d /x ] |= \u03d5 m, i, h v |= \u2203x \u2022 \u03d5 iff there exists d \u2208 d such that m, i, h v [d /x ] |= \u03d5 \n concurrent metatem concurrent metatem  (fisher and barringer 1991; fisher 1993; fisher and wooldridge 1993 ) is a programming language for distributed artificial intelligence based on fml",
        "prob": 0.3852941176470589
    }, {
        "ID": 3037,
        "phrase": " \u2208 lr ai e ; \u2022 wn a1\u2227",
        "prob": 0.35000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n}, wn ai e \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n} and \u2118\u03b2 \u2208 lr ai ; (b) \u2118i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n} and \u2118\u03b2 \u2208 lr ai ; (b) \u2118i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3037,
        "phrase": " \u2208 lr ai e ; \u2022 wn a1\u2228",
        "prob": 0.35000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n}, wn ai e \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n} and \u03c8 \u2208 lr ai e ; \u2022 wn a1\u2293",
        "prob": 0.35000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n} and wn ai e \u2206 = \u22a5",
        "prob": 0.22000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n} and \u03c8 \u2208 lr ai e ; \u2022 wn a1\u2294",
        "prob": 0.35000000000000003
    }, {
        "ID": 3037,
        "phrase": " , n} and wn ai e \u2206 = \u22a4",
        "prob": 0.22000000000000003
    }, {
        "ID": 3038,
        "phrase": " , n} and \u2118\u03b2 \u2208 lr ai ; (b) \u2118i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3038,
        "phrase": " , n} and \u2118\u03b2 \u2208 lr ai ; (b) \u2118i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3038,
        "phrase": " \u2208 lr ai e ; \u2022 wn a1\u2227",
        "prob": 0.35000000000000003
    }, {
        "ID": 3038,
        "phrase": " , n}, wn ai e \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3038,
        "phrase": " \u2208 lr ai e ; \u2022 wn a1\u2228",
        "prob": 0.35000000000000003
    }, {
        "ID": 3038,
        "phrase": " , n}, wn ai e \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3038,
        "phrase": " , n} and \u03c8 \u2208 lr ai e ; \u2022 wn a1\u2293",
        "prob": 0.35000000000000003
    }, {
        "ID": 3038,
        "phrase": " , n} and \u03c8 \u2208 lr ai e ; \u2022 wn a1\u2294",
        "prob": 0.35000000000000003
    }, {
        "ID": 3038,
        "phrase": " , n} and wn ai e \u2206 = \u22a4",
        "prob": 0.22000000000000003
    }, {
        "ID": 3039,
        "phrase": " \u2208 lr ai ; \u2022 wn a1\u2227a2 \u03b3 = \u22a4 iff, for each i \u2208 {1, 2}, wn ai \u03b3 i",
        "prob": 0.5666666666666668
    }, {
        "ID": 3039,
        "phrase": " \u2208 lr ai ; \u2022 wn a1\u2228a2 \u03b3 = \u22a5 iff, for each i \u2208 {1, 2}, wn ai \u03b3 i",
        "prob": 0.5666666666666668
    }, {
        "ID": 3039,
        "phrase": " \n choice conjunction a 1 \u2293 a 2 : \u2022 \u03c6 \u2208 lr a1\u2293a2 iff \u03c6 = \u22a5i, \u03c8 , where i \u2208 {1, 2} and \u03c8 \u2208 lr ai ; \u2022 wn a1\u2293a2 \u03b3 = \u22a5 iff \u03b3 = \u22a5i, \u03c5 , where i \u2208 {1, 2} and wn ai \u03c5 = \u22a5",
        "prob": 0.7214285714285715
    }, {
        "ID": 3039,
        "phrase": " \n choice disjunction a 1 \u2294 a 2 : \u2022 \u03c6 \u2208 lr a1\u2294a2 iff \u03c6 = \u22a4i, \u03c8 , where i \u2208 {1, 2} and \u03c8 \u2208 lr ai ; \u2022 wn a1\u2294a2 \u03b3 = \u22a4 iff \u03b3 = \u22a4i, \u03c5 , where i \u2208 {1, 2} and wn ai \u03c5 = \u22a4",
        "prob": 0.7214285714285715
    }, {
        "ID": 3040,
        "phrase": " \u2208 lr ai ; \u2022 wn a1\u2227a2 \u03b3 = \u22a4 iff, for each i \u2208 {1, 2}, wn ai \u03b3 i",
        "prob": 0.5666666666666668
    }, {
        "ID": 3040,
        "phrase": " \u2208 lr ai ; \u2022 wn a1\u2228a2 \u03b3 = \u22a5 iff, for each i \u2208 {1, 2}, wn ai \u03b3 i",
        "prob": 0.5666666666666668
    }, {
        "ID": 3040,
        "phrase": " \n choice conjunction a 1 \u2293 a 2 : \u2022 \u03c6 \u2208 lr a1\u2293a2 iff \u03c6 = \u22a5i, \u03c8 , where i \u2208 {1, 2} and \u03c8 \u2208 lr ai ; \u2022 wn a1\u2293a2 \u03b3 = \u22a5 iff \u03b3 = \u22a5i, \u03c5 , where i \u2208 {1, 2} and wn ai \u03c5 = \u22a5",
        "prob": 0.7214285714285715
    }, {
        "ID": 3040,
        "phrase": "  \u03c5  , where i \u2208 {1, 2} and wn ai \u03c5 = \u22a4",
        "prob": 0.22000000000000003
    }, {
        "ID": 3040,
        "phrase": " \n choice disjunction a 1 \u2294 a 2 : \u2022 \u03c6 \u2208 lr a1\u2294a2 iff \u03c6 = \u22a4i, \u03c8 , where i \u2208 {1, 2} and \u03c8 \u2208 lr ai ; \u2022 wn a1\u2294a2 \u03b3 = \u22a4 iff \u03b3 = \u22a4i, \n parallel implication, or reduction a 1 \u2192 a 2 is defined as (\u00aca 1 ) \u2228 a 2 ",
        "prob": 0.7705882352941176
    }, {
        "ID": 3041,
        "phrase": " \u2208 lr ai ; \u2022 wn a1\u2227a2 \u03b3 = \u22a4 iff, for each i \u2208 {1, 2}, wn ai \u03b3 i",
        "prob": 0.5666666666666668
    }, {
        "ID": 3041,
        "phrase": " \u2208 lr ai ; \u2022 wn a1\u2228a2 \u03b3 = \u22a5 iff, for each i \u2208 {1, 2}, wn ai \u03b3 i",
        "prob": 0.5666666666666668
    }, {
        "ID": 3041,
        "phrase": " \n choice conjunction a 1 \u2293 a 2 : \u2022 \u03c6 \u2208 lr a1\u2293a2 iff \u03c6 = \u22a5i, \u03c8 , where i \u2208 {1, 2} and \u03c8 \u2208 lr ai ; \u2022 wn a1\u2293a2 \u03b3 = \u22a5 iff \u03b3 = \u22a5i, \u03c5 , where i \u2208 {1, 2} and wn ai \u03c5 = \u22a5",
        "prob": 0.7214285714285715
    }, {
        "ID": 3041,
        "phrase": "  \u03c5  , where i \u2208 {1, 2} and wn ai \u03c5 = \u22a4",
        "prob": 0.22000000000000003
    }, {
        "ID": 3041,
        "phrase": " \n choice disjunction a 1 \u2294 a 2 : \u2022 \u03c6 \u2208 lr a1\u2294a2 iff \u03c6 = \u22a4i, \u03c8 , where i \u2208 {1, 2} and \u03c8 \u2208 lr ai ; \u2022 wn a1\u2294a2 \u03b3 = \u22a4 iff \u03b3 = \u22a4i, \n parallel implication, or reduction a 1 \u2192 a 2 is defined as (\u00aca 1 ) \u2228 a 2 ",
        "prob": 0.7705882352941176
    }, {
        "ID": 3097,
        "phrase": " fis nn ec symbolic ai mathematical model sg b b sb learning ability b g sg b knowledge representation g b sb g expert knowledge g b b g nonlinearity g g g sb optimization ability b sg g b fault tolerance g g g b uncertainty tolerance g g g b real time operation g sg sb b \u2020 \n lr 1 lr 2 lr 3 lr 4 lr 8 lr 6 lr 7 lr 9 lr 5 ar 1 ar 2 ar 3 ar 4 ar 6 ar 7 ar 5 wt 1 wt 2 wt 3 parameters of learning algorithm neural network architectures initial weights wt 4 wt 5 \n fis 1 fis 2 fis 3 fis 4 fis 6 fis 7 fis 5 op 1 op 2 op 3 op 4 op 6 op 5 rule 1 rule 2 rule 3 rule 4 rule 5 fuzzy inference system fuzzy operators fuzzy rules mf 1 mf 2 mf 3 mf 4 fuzzy membership functions \n 1 fis 2 fis 3 fis 4 fis 6 fis 7 fis 5 op 1 op 2 op 3 op 4 op 6 op 5 rule 1 rule 2 rule 3 rule 4 rule 5 mf 1 mf 2 mf 3 mf 4 fis 8 lr 1 lr 2 lr 3 lr 4 lr 6 lr 7 lr 5",
        "prob": 0.6676190476190478
    }, {
        "ID": 3124,
        "phrase": " note that event ai is meaningless in this case",
        "prob": 0.3875
    }, {
        "ID": 3125,
        "phrase": " note that event ai is meaningless in this case",
        "prob": 0.3875
    }, {
        "ID": 3263,
        "phrase": " is in lr ai and hence the \u03b3 i",
        "prob": 0.18333333333333335
    }, {
        "ID": 3263,
        "phrase": " in turn, again by the definition of finalization, each wn ai \u03b3 i",
        "prob": 0.2625
    }, {
        "ID": 3264,
        "phrase": " is in lr ai and thus the \u03c6 i",
        "prob": 0.18333333333333335
    }, {
        "ID": 3264,
        "phrase": " is in lr ai and hence the \u03b3 i",
        "prob": 0.35000000000000003
    }, {
        "ID": 3264,
        "phrase": " in turn, again by the definition of finalization, each wn ai \u03b3 i",
        "prob": 0.2625
    }, {
        "ID": 3290,
        "phrase": " , n, f i \u2190 r i \u2190 \u03bb while \u03c6(p ) := n i=1 min{l, |f i | + |r i |} < ml do nl \u2212 \u03c6({p 1 , ",
        "prob": 0.15714285714285714
    }, {
        "ID": 3352,
        "phrase": " m i=1 |s i | = l i is replaced by a quantifier-free formula of the form m/2 i=1 |s \u2032 i | = l ai + l bi ",
        "prob": 0.34444444444444444
    }, {
        "ID": 3353,
        "phrase": " m i=1 |s i | = l i is replaced by a quantifier-free formula of the form m/2 i=1 |s \u2032 i | = l ai + l bi ",
        "prob": 0.4555555555555556
    }, {
        "ID": 3365,
        "phrase": " , n}, \u2206 \u2208 lr ai e }",
        "prob": 0.22000000000000003
    }, {
        "ID": 3365,
        "phrase": " , n} and wn ai e \u2206 = \u22a5",
        "prob": 0.22000000000000003
    }, {
        "ID": 3365,
        "phrase": " , n} and \u2118\u03b2 \u2208 lr ai e ; (b) \u2118i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3365,
        "phrase": " , n} and \u2118\u03b2 \u2208 lr ai e ; (b) \u2118i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3622,
        "phrase": " the left cut of figure  17  is a redex of girard's lazy cut elimination, but not of that of simple  + ai \u2212chain ! c c j z !\u2212box ?b a f + ( ) b x ",
        "prob": 0.4733333333333334
    }, {
        "ID": 3622,
        "phrase": " a ? j+1 a ? n w w !c cut ai c ( ) =a z ( ) =a = z l ! = z' l ! fig",
        "prob": 0.18333333333333332
    }, {
        "ID": 3622,
        "phrase": " a ? j+1 a ? n + ai \u2212chain ! c c j z !\u2212box ?b ",
        "prob": 0.35000000000000003
    }, {
        "ID": 3623,
        "phrase": " + ai \u2212chain ! c c j z ( ) =a = z l ! !\u2212box ?b a f + ( ) b x ",
        "prob": 0.35000000000000003
    }, {
        "ID": 3623,
        "phrase": " a ? j+1 a ? n w w !c cut ai c ( ) =a z = z' l ! fig",
        "prob": 0.18333333333333332
    }, {
        "ID": 3623,
        "phrase": " a ? j+1 a ? n + ai \u2212chain ! c c j z ( ) =a = z l ! !\u2212box ?b ",
        "prob": 0.35000000000000003
    }, {
        "ID": 3631,
        "phrase": "  [8]  proved that a receiver can execute ml decoding for each symbol u q instead of each sequence u iff eq",
        "prob": 0.22142857142857145
    }, {
        "ID": 3690,
        "phrase": " , n} and \u03b8 \u2208 lr ai ; wn a1\u2293",
        "prob": 0.35000000000000003
    }, {
        "ID": 3690,
        "phrase": " , n} and wn ai \u03b8 = \u22a5",
        "prob": 0.22000000000000003
    }, {
        "ID": 3690,
        "phrase": " \u2208 lr ai ; whenever \u03b3 \u2208 lr a1\u2227",
        "prob": 0.3
    }, {
        "ID": 3690,
        "phrase": " , n}, wn ai \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3691,
        "phrase": " , n} and \u03b8 \u2208 lr ai ; wn a1\u2293",
        "prob": 0.35000000000000003
    }, {
        "ID": 3691,
        "phrase": " , n} and wn ai \u03b8 = \u22a5",
        "prob": 0.22000000000000003
    }, {
        "ID": 3691,
        "phrase": " \u2208 lr ai ; whenever \u03b3 \u2208 lr a1\u2227",
        "prob": 0.3
    }, {
        "ID": 3691,
        "phrase": " , n}, wn ai \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 3692,
        "phrase": " , n} and \u03b8 \u2208 lr ai ; wn a1\u2293",
        "prob": 0.35000000000000003
    }, {
        "ID": 3692,
        "phrase": " , n} and wn ai \u03b8 = \u22a5",
        "prob": 0.22000000000000003
    }, {
        "ID": 3692,
        "phrase": " \u2208 lr ai ; whenever \u03b3 \u2208 lr a1\u2227",
        "prob": 0.3
    }, {
        "ID": 3692,
        "phrase": " , n}, wn ai \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": " , n}, \u03b3 \u2208 lr ai }",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": "\u2293an \u22a5i, \u03b3 = wn ai \u03b3 ",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": " , n}, \u03b3 \u2208 lr ai }",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": "\u2294an \u22a4i, \u03b3 = wn ai \u03b3 ",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": " \u2208 lr ai ",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": " , n}, wn ai \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": " \u2208 lr ai ",
        "prob": 0.22000000000000003
    }, {
        "ID": 4972,
        "phrase": " , n}, wn ai \u03b3 i",
        "prob": 0.22000000000000003
    }, {
        "ID": 5152,
        "phrase": " , a k }, \u03c3, s 1 \u2192 * bf \u2205, \u03b8, s 2 iff a i \u03b8 \u2208 b tp n and solvable(s \u2227 \u00b5 ai = v i ) and v i \u2286 bi v tp n (a i \u03b8)",
        "prob": 0.4555555555555556
    }, {
        "ID": 5152,
        "phrase": " for the base case, all the literals are reduced using the first type of transitions or the last one, that is, for each literal a i , it exits a fact h i \u2190 v i such that \u03b8 i is the mgu of a i and h i , and \u00b5 ai is the truth variable for a i , and solvable(s 1 \u2227 \u00b5 ai = v i ) or \u00b5 ai = default (a i )",
        "prob": 0.3380952380952381
    }, {
        "ID": 5152,
        "phrase": " , b mi in p such that \u03b8 i is the mgu of a i and h i \u2208 b\u03c3 2 and b ji \u03b8 i \u2208 b\u03c3 2 , by the induction hypothesis b\u03c3 2 \u2286 b tp n\u22121 and solvable(s 2 \u2227 \u00b5 bj i = v ji ) and v ji \u2286 bi v tp n\u22121 (b ji \u03c3 2 ) then b ji \u03b8 i \u2286 b tp n\u22121 and by definition of t p , a i \u03b8 i \u2208 b tp n and solvable(s 1 \u2227 \u00b5 ai = v i ) and v i =\u2286 bi v tp n (a i \u03c3 1 )",
        "prob": 0.5062500000000001
    }, {
        "ID": 5833,
        "phrase": ": the validity of an equation-free lithium query q = e 0 \u2227e 1 \u2227p \u21d2 permitted(t, t \u2032 ) with m terms in e 0 can be determined in time o((|e 0 | + t |e 1 \u2227 p | 2 ) log |e 0 |), where t = ml e1\u2227p l \u2032 e1\u2227p |permitted(t, t \u2032 )| if every literal in every conjunct c of e 1 \u2227 p mentions at most one variable that is not constrained in c relative to q; otherwise, t = m 2k l e1\u2227p l \u2032 e1\u2227p |permitted(t, t \u2032 )|, where every conjunct c of e 1 \u2227 p has at most k variables that are not constrained in c relative to q",
        "prob": 0.836111111111111
    }, {
        "ID": 5834,
        "phrase": ": the validity of an equation-free lithium query q = e 0 \u2227e 1 \u2227p \u21d2 permitted(t, t \u2032 ) with m terms in e 0 can be determined in time o((|e 0 | + t |e 1 \u2227 p | 2 ) log |e 0 |), where t = ml e1\u2227p l \u2032 e1\u2227p |permitted(t, t \u2032 )| if every literal in every conjunct c of e 1 \u2227 p mentions at most one variable that is not constrained in c relative to q; otherwise, t = m 2k l e1\u2227p l \u2032 e1\u2227p |permitted(t, t \u2032 )|, where every conjunct c of e 1 \u2227 p has at most k variables that are not constrained in c relative to q",
        "prob": 0.8638888888888887
    }, {
        "ID": 5835,
        "phrase": " the validity of an equation-free lithium query q = e 0 \u2227e 1 \u2227p \u21d2 permitted(t, t \u2032 ) with m terms in e 0 can be determined in time o(( |e 0 | + t |e 1 \u2227 p | 2 ) log |e 0 |), where t = ml e1\u2227p l \u2032 e1\u2227p |permitted(t, t \u2032 )| if every literal in every conjunct c of e 1 \u2227 p mentions at most one variable that is not constrained in c relative to q; otherwise, t = m 2k l e1\u2227p l \u2032 e1\u2227p |permitted(t, t \u2032 )|, where every conjunct c of e 1 \u2227 p has at most k variables that are not constrained in c relative to q",
        "prob": 0.8314285714285713
    }, {
        "ID": 5969,
        "phrase": " clearly, m ai (0 4 k ) accepts if and only if 0 4 k / \u2208 l ai ",
        "prob": 0.18333333333333335
    }, {
        "ID": 5969,
        "phrase": " thus, m ai (0 8 k ) accepts if and only if m a \u2032 (0 8 k ) accepts, and so m ai (0 8 k ) accepts if and only if 0 8 k / \u2208 l ai ",
        "prob": 0.3875
    }, {
        "ID": 5969,
        "phrase": " m ai (0 4 k ) accepts if and only if 0 4 k / \u2208 l ai ",
        "prob": 0.22000000000000003
    }, {
        "ID": 5969,
        "phrase": " note that m ai (0 4k ) accepts if and only if 0 4k / \u2208 l 1 ai ",
        "prob": 0.18333333333333335
    }, {
        "ID": 5969,
        "phrase": " note that m ai (0 4k+3 ) accepts if and only if 0 4k+3 / \u2208 l 1 ai ",
        "prob": 0.35000000000000003
    }, {
        "ID": 6084,
        "phrase": "}, \u03b3 \u2208 lr ai e }",
        "prob": 0.22000000000000003
    }, {
        "ID": 6084,
        "phrase": " \u2022 wn b e = \u22a4; wn b e \u22a5i, \u03b3 = wn ai e \u03b3 ",
        "prob": 0.4428571428571429
    }, {
        "ID": 6085,
        "phrase": "}, \u03b3 \u2208 lr ai e }",
        "prob": 0.22000000000000003
    }, {
        "ID": 6085,
        "phrase": " \u2022 wn b e = \u22a4; wn b e \u22a5i, \u03b3 = wn ai e \u03b3 ",
        "prob": 0.4428571428571429
    }, {
        "ID": 6100,
        "phrase": " further, for every frame f, w \u2208 f and \u03d5 \u2208 ml f, w \u03d5 iff f |= \u2200p st(\u03d5, x)(x := w), and f \u03d5 iff f |= \u2200p \u2200xst(\u03d5, x), where p is the tuple of all unary predicate symbols occurring in st(\u03d5, x)",
        "prob": 0.6722222222222222
    }, {
        "ID": 6100,
        "phrase": " a modal formula \u03d5 \u2208 ml is: \u2022 locally first-order definable, if there is a first-order formula \u03b1(x) such that for every frame f and w \u2208 f it is the case that f, w \u03d5 iff f |= \u03b1(x := w); \u2022 (globally) first-order definable, if there is a first-order sentence \u03b1 such that for every frame f it is the case that f \u03d5 iff f |= \u03b1",
        "prob": 0.8310344827586206
    }, {
        "ID": 6100,
        "phrase": " for the execution of the algorithm we enrich the language ml by adding: \u2022 the inverse modality \u2737 \u22121 with semantics m, u \u2737 \u22121 \u03d5 iff m, w \u03d5 for every w \u2208 m such that r \u22121 uw, i",
        "prob": 0.7400000000000001
    }, {
        "ID": 6100,
        "phrase": " the so extended modal language will be denoted by ml + ",
        "prob": 0.4555555555555556
    }, {
        "ID": 6100,
        "phrase": " although formally ml + is sufficient for the execution of our algorithm, it is sometimes useful to further enrich the language with the universal modality [u], with semantics m, u [u]\u03d5 iff m, w \u03d5 for every w \u2208 m, i",
        "prob": 0.7947368421052632
    }, {
        "ID": 6100,
        "phrase": "  [2] ) that (local) d-persistence implies canonicity of formulae in ml because the canonical general frame for every normal modal logic is descriptive, and hence every d-persistent axiom is valid in its canonical frame",
        "prob": 0.8439999999999999
    }, {
        "ID": 6100,
        "phrase": " then a box-form of \u266f in ml + is defined recursively as follows: (1) \u266f is a box-form of \u266f; ( ) if b(\u266f) is a box-form of \u266f and \u2737 is a box-modality then \u2737b(\u266f) is a box-form of \u266f",
        "prob": 0.5611111111111111
    }, {
        "ID": 6100,
        "phrase": " recall that with every model m = w, r, v and a modal formula \u03c8 in ml we associate the set [[\u03c8]] m denoting the extension of the formula \u03c8 in the model m",
        "prob": 0.5687500000000001
    }, {
        "ID": 6100,
        "phrase": " 41 a formula \u03c8 \u2208 ml is locally d-persistent if for every descriptive frame f = w, r, w and w \u2208 w , f, w \u03c8 iff f , w \u03c8, where f = w, r ",
        "prob": 0.675
    }, {
        "ID": 6101,
        "phrase": " further, for every frame f, w \u2208 f and \u03d5 \u2208 ml f, w \u03d5 iff f |= \u2200p st(\u03d5, x)(x := w), and f \u03d5 iff f |= \u2200p \u2200xst(\u03d5, x) , where p is the tuple of all unary predicate symbols occurring in st(\u03d5, x)",
        "prob": 0.6166666666666667
    }, {
        "ID": 6101,
        "phrase": " a modal formula \u03d5 \u2208 ml is: \u2022 locally first-order definable, if there is a first-order formula \u03b1(x) such that for every frame f and w \u2208 f it is the case that f, w \u03d5 iff f |= \u03b1(x := w); \u2022 (globally) first-order definable, if there is a first-order sentence \u03b1 such that for every frame f it is the case that f \u03d5 iff f |= \u03b1",
        "prob": 0.7965517241379308
    }, {
        "ID": 6101,
        "phrase": " for the execution of the algorithm we enrich the language ml by adding: \u2022 the inverse modality \u2737 \u22121 with semantics m, u \u2737 \u22121 \u03d5 iff m, w \u03d5 for every w \u2208 m such that r \u22121 uw, i",
        "prob": 0.7400000000000001
    }, {
        "ID": 6101,
        "phrase": " the so extended modal language will be denoted by ml + ",
        "prob": 0.4555555555555556
    }, {
        "ID": 6101,
        "phrase": " although formally ml + is sufficient for the execution of our algorithm, it is sometimes useful to further enrich the language with the universal modality [u], with semantics m, u [u]\u03d5 iff m, w \u03d5 for every w \u2208 m, i",
        "prob": 0.7947368421052632
    }, {
        "ID": 6101,
        "phrase": "  [2] ) that (local) d-persistence implies canonicity of formulae in ml because the canonical general frame for every normal modal logic is descriptive, and hence every d-persistent axiom is valid in its canonical frame",
        "prob": 0.8439999999999999
    }, {
        "ID": 6101,
        "phrase": " recall that with every model m = w, r, v and a modal formula \u03c8 in ml we associate the set [[\u03c8]] m denoting the extension of the formula \u03c8 in the model m",
        "prob": 0.5062500000000001
    }, {
        "ID": 6101,
        "phrase": " 41 a formula \u03c8 \u2208 ml is locally d-persistent if for every descriptive frame f = w, r, w and w \u2208 w , f, w \u03c8 iff f , w \u03c8, where f = w, r ",
        "prob": 0.675
    }, {
        "ID": 6102,
        "phrase": " further, for every frame f, w \u2208 f and \u03d5 \u2208 ml f, w \u03d5 iff f |= \u2200p st(\u03d5, x)(x := w), and f \u03d5 iff f |= \u2200p \u2200xst(\u03d5, x) , where p is the tuple of all unary predicate symbols occurring in st(\u03d5, x)",
        "prob": 0.6722222222222222
    }, {
        "ID": 6102,
        "phrase": " a modal formula \u03d5 \u2208 ml is: \u2022 locally first-order definable, if there is a first-order formula \u03b1(x) such that for every frame f and w \u2208 f it is the case that f, w \u03d5 iff f |= \u03b1(x := w); \u2022 (globally) first-order definable, if there is a first-order sentence \u03b1 such that for every frame f it is the case that f \u03d5 iff f |= \u03b1",
        "prob": 0.8310344827586206
    }, {
        "ID": 6102,
        "phrase": " for the execution of the algorithm we enrich the language ml by adding: \u2022 the inverse modality \u2737 \u22121 with semantics m, u \u2737 \u22121 \u03d5 iff m, w \u03d5 for every w \u2208 m such that r \u22121 uw, i",
        "prob": 0.7400000000000001
    }, {
        "ID": 6102,
        "phrase": " the so extended modal language will be denoted by ml + ",
        "prob": 0.4555555555555556
    }, {
        "ID": 6102,
        "phrase": " although formally ml + is sufficient for the execution of our algorithm, it is sometimes useful to further enrich the language with the universal modality [u], with semantics m, u [u]\u03d5 iff m, w \u03d5 for every w \u2208 m, i",
        "prob": 0.6894736842105263
    }, {
        "ID": 6102,
        "phrase": "  [2] ) that (local) d-persistence implies canonicity of formulae in ml because the canonical general frame for every normal modal logic is descriptive, and hence every d-persistent axiom is valid in its canonical frame",
        "prob": 0.8439999999999999
    }, {
        "ID": 6102,
        "phrase": " recall that with every model m = w, r, v and a modal formula \u03c8 in ml we associate the set [[\u03c8]] m denoting the extension of the formula \u03c8 in the model m",
        "prob": 0.4437500000000001
    }, {
        "ID": 6102,
        "phrase": " 41 a formula \u03c8 \u2208 ml is locally d-persistent if for every descriptive frame f = w, r, w and w \u2208 w , f, w \u03c8 iff f , w \u03c8, where f = w, r ",
        "prob": 0.675
    }, {
        "ID": 6103,
        "phrase": " further, for every frame f, w \u2208 f and \u03d5 \u2208 ml f, w \u03d5 iff f |= \u2200p st(\u03d5, x)(x := w), and f \u03d5 iff f |= \u2200p \u2200xst(\u03d5, x) , where p is the tuple of all unary predicate symbols occurring in st(\u03d5, x)",
        "prob": 0.6722222222222222
    }, {
        "ID": 6103,
        "phrase": " a modal formula \u03d5 \u2208 ml is: \u2022 locally first-order definable, if there is a first-order formula \u03b1(x) such that for every frame f and w \u2208 f it is the case that f, w \u03d5 iff f |= \u03b1(x := w); \u2022 (globally) first-order definable, if there is a first-order sentence \u03b1 such that for every frame f it is the case that f \u03d5 iff f |= \u03b1",
        "prob": 0.8310344827586206
    }, {
        "ID": 6103,
        "phrase": " for the execution of the algorithm we enrich the language ml by adding: \u2022 the inverse modality 2 \u22121 with semantics m, u 2 \u22121 \u03d5 iff m, w \u03d5 for every w \u2208 m such that r \u22121 uw, i",
        "prob": 0.7400000000000001
    }, {
        "ID": 6103,
        "phrase": " the so extended modal language will be denoted by ml + ",
        "prob": 0.4555555555555556
    }, {
        "ID": 6103,
        "phrase": " although formally ml + is sufficient for the execution of our algorithm, it is sometimes useful to further enrich the language with the universal modality [u], with semantics m, u [u]\u03d5 iff m, w \u03d5 for every w \u2208 m, i",
        "prob": 0.7421052631578947
    }, {
        "ID": 6103,
        "phrase": "  [2] ) that (local) d-persistence implies canonicity of formulae in ml because the canonical general frame for every normal modal logic is descriptive, and hence every d-persistent axiom is valid in its canonical frame",
        "prob": 0.8439999999999999
    }, {
        "ID": 6103,
        "phrase": " recall that with every model m = w, r, v and a modal formula \u03c8 in ml we associate the set [[\u03c8]] m denoting the extension of the formula \u03c8 in the model m",
        "prob": 0.5062500000000001
    }, {
        "ID": 6103,
        "phrase": " 41 a formula \u03c8 \u2208 ml is locally d-persistent if for every descriptive frame f = w, r, w and w \u2208 w , f, w \u03c8 iff f , w \u03c8, where f = w, r ",
        "prob": 0.675
    }, {
        "ID": 6109,
        "phrase": " ( 83 ) now as every gciod is a rfsdd (theorem 25), it is sd and the receiver uses  (21)  to form an estimate of each s i resulting in the ml rule for each s i , i = 0, \u2022 \u2022 \u2022 , k \u2212 1, given by min si\u2208a m i (s i ) = min si\u2208a v \u2212 (a 2i s ii + a 2i+1 s iq )h 2 ",
        "prob": 0.2833333333333333
    }, {
        "ID": 6308,
        "phrase": " by definition of \u03c8 (a) and (  42 ), event \u03c8 (a) implies that the ordered version \u03c8 \u03b8 of the ml estimator \u03b8 is outside the portion in \u03c8 (\u03bb k ) of the box with edges \u2206 (\u03c4 b i ), for every i, centered at \u03b8",
        "prob": 0.24117647058823538
    }, {
        "ID": 6308,
        "phrase": " a rectangular box surrounding a dot contains all the ml estimator points that are in event \u0101i \u2229 \u0101j if (\u03b8 i , \u03b8 j ) is on the dot",
        "prob": 0.22142857142857145
    }, {
        "ID": 6308,
        "phrase": " note that p \u03b8 {\u03c8 (a i ) \u222a \u03c8 (a j )} \u2264 p \u03b8 (a i \u222a a j ) , where a possible decrease is because some un-typical sequences that have ml estimates \u03b8 \u2208 \u03c8 (\u03bb k ) will be projected into the same box around \u03b8 by estimating out of \u03c8 (x n ) and will (insignificantly) increase the probability of \u03c8 (a i ) \u222a \u03c8 (a j ) from that of a i \u222a a j ",
        "prob": 0.2157894736842105
    }, {
        "ID": 6785,
        "phrase": " in order to have primary consciousness, an ai should possess some mechanisms provided by the human brain",
        "prob": 0.25833333333333336
    }, {
        "ID": 7408,
        "phrase": " the last one implies commutation of \u2704 ai and \u2192 h ",
        "prob": 0.15714285714285717
    }, {
        "ID": 7408,
        "phrase": " otherwise, u \u2704 ai v is obtained by (rule)",
        "prob": 0.3
    }, {
        "ID": 7409,
        "phrase": " otherwise, u \u2704 ai v is obtained by (rule)",
        "prob": 0.3
    }, {
        "ID": 7409,
        "phrase": " that is, there is a rule d = c \u2283 l \u2192 r \u2208 r such that u = l\u03c3, v = r\u03b8, \u03c3 \u2704 ai \u03b8 and l\u03c3 \u2192 ai r\u03c3",
        "prob": 0.22000000000000003
    }, {
        "ID": 8172,
        "phrase": " \n organisation of case memory the organisation of a case base is of course important from an ai architectural viewpoint, but also from a user's viewpoint",
        "prob": 0.31875000000000003
    }, {
        "ID": 8340,
        "phrase": " extended facile is an extension of facile, a strongly typed functional programming language based on standard ml with support for concurrency and distribution",
        "prob": 0.1631578947368421
    }, {
        "ID": 8555,
        "phrase": " as every ai problem can be brought into this form, the problem of maximizing utility is hence being formally solved, if \u00b5 is known",
        "prob": 0.4733333333333334
    }, {
        "ID": 8555,
        "phrase": " although factorizable \u00b5 are too restrictive to cover all ai problems, they often occur in practice in the form of repeated problem solving, and hence, are worthy of study",
        "prob": 0.4263157894736842
    }, {
        "ID": 8555,
        "phrase": " we will see that in the ai case, there are no useful bounds in terms of k(\u00b5) only",
        "prob": 0.34444444444444444
    }, {
        "ID": 8634,
        "phrase": " for the artificial intelligence text, 36% of the triplets were equilateral; 50% of the triplets were isosceles with small base; hence 86% of the triplets respected the ultrametric inequality",
        "prob": 0.5611111111111111
    }, {
        "ID": 8634,
        "phrase": " if we wished to look at each and every isosceles triangle, then in the case of the artificial intelligence text this means, out of a total of 2,027,795 triplets (i",
        "prob": 0.38125
    }, {
        "ID": 8634,
        "phrase": " for the artificial intelligence text, we find 45% of the triplets to be equilateral; 37% of the triplets are isosceles; and 18% of the triplets are non-ultrametric",
        "prob": 0.4733333333333334
    }, {
        "ID": 8765,
        "phrase": " for the only if part, it is sufficient to show that the systems w g , w g * ai , and also the systems  w g , w g\u2022 b i are locally equivalent",
        "prob": 0.1909090909090909
    }, {
        "ID": 8765,
        "phrase": " first, note that the rows of i | g * a i form a basis for w g * ai ",
        "prob": 0.34444444444444444
    }, {
        "ID": 8766,
        "phrase": " first, note that the rows of i | g * a i form a basis for w g * ai ",
        "prob": 0.23333333333333334
    }, {
        "ID": 9221,
        "phrase": " the \"discharge rule\" for implication introduction, [p ] q p =\u21d2 q , is provided by the ml function disch",
        "prob": 0.5083333333333334
    }, {
        "ID": 9228,
        "phrase": " a fine point: without the abstraction over t, repeatc would always loop, because ml uses applicative order (eager) evaluation rather than normal order (lazy) evaluation",
        "prob": 0.3521739130434782
    }, {
        "ID": 9336,
        "phrase": " we refer to object-logic rules such as (\u2192i) by ml identifiers such as impi",
        "prob": 0.19090909090909092
    }, {
        "ID": 9449,
        "phrase": " t he r e m ai ni n g p art of t he t o k en and f r a m e f orma tsa resh o w n i n f i g u re s1a n d2re sp ectively ",
        "prob": 0.19090909090909092
    }, {
        "ID": 9615,
        "phrase": " an issue over which ai researchers have differed is whether this knowledge of normal or default use is stored in a lexical entry or in some other computational knowledge form such as one that was sometimes called a script (schank and abelson, 1997) and thought of as indexed by words but was much more than a lexical entry",
        "prob": 0.21034482758620687
    }, {
        "ID": 9793,
        "phrase": "009 seconds the variable domains to af \u2208 [+,-, l], ai \u2208 [+,-], ab \u2208 [+,-,r], ij \u2208 [+,-,l,r], ih \u2208 [+,-,l,r], jh \u2208 [+,-,l,r], gh \u2208 [+,-,l,r], gc \u2208 [+,-,l,r], ge \u2208 [+,-,l,r], ef \u2208 [+,-], ed \u2208 [+,-,l], cd \u2208 [+,-,r], and cb \u2208 [+,-,l]",
        "prob": 0.5045454545454546
    }, {
        "ID": 9826,
        "phrase": "  \u03c7 : [ai 1 , ai 2 ], \u2297 , denoted o |= [ai1,ai2] \u03c7 : [ai 1 , ai 2 ], \u2297 iff: \u2022 \u03c7 is of the form o = o (where o is an object), or \u2022 \u03c7 is of the form r 1 < r 2 , where r 1 , r 2 are real numbers (or integers) such that r 1 is less than r 2 , or \u2022 \u03c7 is of the form in(x, a : rv f (d 1 , ",
        "prob": 0.3588235294117647
    }, {
        "ID": 9826,
        "phrase": " , d n )), or \u2022 \u03c7 is of the form \u03c7 1 \u2227 \u03c7 2 and [\u2113 1 , u 1 ], [\u2113 2 , u 2 ] are the tightest intervals such that o |= [\u21131,u1] \u03c7 1 and o |= [\u21132,u2] \u03c7 2 and [ai 1 , ai 2 ] \u2287 [\u2113 1 , u 1 ] \u2297 [\u2113 2 , u 2 ]",
        "prob": 0.15714285714285714
    }]
}, {
    "topic_id": 8,
    "top_words": ["artificial", "intelligence", "time", "approach", "practical", "systems", "traditional", "conference", "future", "input", "international", "joint", "program", "thus", "still"],
    "phrases": [{
        "ID": 141,
        "phrase": " \n credit bounds and separability concepts: the credits c km associated with the ai systems correspond roughly to the negative error measure \u2212e n\u03c1 of the sp systems",
        "prob": 0.21578947368421056
    }, {
        "ID": 141,
        "phrase": " despite the fact that the ai model has only a credit feedback c k , it is able to learn by teaching, as will be shown in section 8",
        "prob": 0.22142857142857145
    }, {
        "ID": 141,
        "phrase": " the number of interesting applications makes this restricted class of ai problems, with time and space bounded environment \u00b5 tl , worth being studied",
        "prob": 0.39444444444444443
    }, {
        "ID": 141,
        "phrase": " in the following, we construct a policy p * , or more precisely, policies p * k for every cycle k that outperform all time and length limited ai systems p",
        "prob": 0.6312500000000001
    }, {
        "ID": 141,
        "phrase": " effective intelligence order relation: in section 4 we have introduced an intelligence order relation on ai systems, based on the expected credit c km k (p)",
        "prob": 0.39444444444444443
    }, {
        "ID": 345,
        "phrase": "  1  proceedings of the workshop \"machine learning and textual information access\", h",
        "prob": 0.19090909090909092
    }, {
        "ID": 692,
        "phrase": " we can consider two kinds of controllers: a joint controller is a policy mapping observations to the complete joint distribution \u03c0( a); a factored controller is made up of independent sub-policies \u00b5 ai : o i \u2192 p(a i ) (possibly with a dependence on individual internal state) for each action component",
        "prob": 0.3137931034482758
    }, {
        "ID": 692,
        "phrase": " obviously, any product of policies for the factored controller i \u00b5 ai can be represented by a joint controller \u00b5 a , for which pr( a) = n i=1 pr(a i )",
        "prob": 0.3642857142857143
    }, {
        "ID": 692,
        "phrase": " whether a factored controller is being executed by a single agent, or it is implemented by agents individually executing policies \u00b5 ai in parallel, joint histories are generated from the same distribution pr( h | \u00b5 a1 , ",
        "prob": 0.1952380952380952
    }, {
        "ID": 713,
        "phrase": " in fact, this was a premier workshop in ussr in this direction which was aimed to disseminate the ai ideas all over the country",
        "prob": 0.3923076923076923
    }, {
        "ID": 826,
        "phrase": " kephart, shopbots and pricebots, 16 int'l joint conference on artificial intelligence 506 (1999); infra notes 33 & 61",
        "prob": 0.5071428571428572
    }, {
        "ID": 873,
        "phrase": " engcon was introduced in the \"workshop on configuration\" during the national conference on artificial intelligence (aaai) 1999 (see  [arlt et al",
        "prob": 0.33999999999999997
    }, {
        "ID": 1034,
        "phrase": " it is the ml approach to tc that this paper concentrates on",
        "prob": 0.23333333333333334
    }, {
        "ID": 1161,
        "phrase": " the new technique is aimed at better utilization of numerical computations for artificial intelligence, especially in the case when uncertainty of computation is multiplied by the uncertainty of input information",
        "prob": 0.19523809523809527
    }, {
        "ID": 1398,
        "phrase": " a second goal is the development of true ai, or \"artificial intelligence\"",
        "prob": 0.21000000000000002
    }, {
        "ID": 1398,
        "phrase": " thus, i define artificial intelligence as being constructed systems which can reason and interact both syntactically and semantically",
        "prob": 0.15
    }, {
        "ID": 1398,
        "phrase": " rather, i predict that progress in artificial intelligence will be a long, slow process of incremental gains",
        "prob": 0.2928571428571429
    }, {
        "ID": 1666,
        "phrase": ") traditional ai planning procedures (e",
        "prob": 0.4428571428571429
    }, {
        "ID": 1853,
        "phrase": " proceeding of the international joint conference on artificial intelligence (ijcai'89), 1989, pp",
        "prob": 0.5916666666666667
    }, {
        "ID": 1980,
        "phrase": " once there is an optimal, formally describable way of predicting the future, we should be able to construct a machine that continually computes and executes action sequences that maximize expected or predicted reward, thus solving an ancient goal of ai research",
        "prob": 0.4111111111111111
    }, {
        "ID": 1981,
        "phrase": " once there is an optimal, formally describable way of predicting the future, we should be able to construct a machine that continually computes and executes action sequences that maximize expected or predicted reward, thus solving an ancient goal of ai research",
        "prob": 0.4111111111111111
    }, {
        "ID": 1981,
        "phrase": "most traditional artificial intelligence (ai) systems of the past 50 years are either very limited, or based on heuristics, or both",
        "prob": 0.29285714285714287
    }, {
        "ID": 2333,
        "phrase": " v p \u03be (yx <k ) is the \u03be ai expected future reward under policy p",
        "prob": 0.4555555555555556
    }, {
        "ID": 2333,
        "phrase": " one can downscale the ai\u03be model by using more restricted forms of \u03be ai ",
        "prob": 0.34444444444444444
    }, {
        "ID": 2333,
        "phrase": "15) is bounded by e ai n\u03be < 1 \u03b1 = 2 km( \u017c)+o(1) < \u221e (6",
        "prob": 0.18333333333333335
    }, {
        "ID": 2333,
        "phrase": " in the following, we construct a policy p * , or more precisely, policies p * k for every cycle k that outperform all time and length limited ai systems p",
        "prob": 0.56875
    }, {
        "ID": 2333,
        "phrase": "1 we have introduced an intelligence order relation on ai systems, based on the expected reward v p\u03be km k ",
        "prob": 0.5461538461538462
    }, {
        "ID": 2333,
        "phrase": " all in all, the results show that artificial intelligence can be framed by an elegant mathematical theory",
        "prob": 0.425
    }, {
        "ID": 2333,
        "phrase": " * ai algorithmic intelligence (most general computable env",
        "prob": 0.2333333333333333
    }, {
        "ID": 2387,
        "phrase": " in proceedings of the configuration workshop, 15th european conference on artificial intelligence, pages 5-10, lyon, france, 2002",
        "prob": 0.4733333333333334
    }, {
        "ID": 2480,
        "phrase": " judging from these illustrations, most machine learning procedures are not treating interactions appropriately",
        "prob": 0.175
    }, {
        "ID": 2749,
        "phrase": " it is true that this construct is not provided in most object-oriented database systems but it has been introduced in some artificial intelligence systems so that classes can be derived from metaclasses in the same way that objects are derived from classes",
        "prob": 0.2772727272727273
    }, {
        "ID": 2814,
        "phrase": " while probability is certainly still the most a preliminary version of this paper appeared in the proceedings of the eighteenth conference on uncertainty in artificial intelligence  [halpern and pucella 2002b] ",
        "prob": 0.26842105263157895
    }, {
        "ID": 3548,
        "phrase": " it is below the standard necessary for a general international audience of ai researchers, and this virtually debars it from the possibility of a measured technical evaluation",
        "prob": 0.5062500000000001
    }, {
        "ID": 3548,
        "phrase": " the interpretation function also associates with each node of t an alc(d) interpretation, which is a tree-like structure representing structured data consisting of the situation (snapshot) of the world at the node (but excluding the situation of \n\t\t\t european conference on artificial intelligence",
        "prob": 0.15185185185185185
    }, {
        "ID": 3549,
        "phrase": " 2  european conference on artificial intelligence",
        "prob": 0.5125000000000001
    }, {
        "ID": 3550,
        "phrase": " it is below the standard necessary for a general international audience of ai researchers, and this virtually debars it from the possibility of a measured technical evaluation",
        "prob": 0.5062500000000001
    }, {
        "ID": 3715,
        "phrase": " the use of artificial intelligence, effective artificial muscles and other biomimetic technologies are expected to make the possibility of realistically looking and behaving robots into more practical engineering models  [bar-cohen and breazeal, 2003] ",
        "prob": 0.284
    }, {
        "ID": 4383,
        "phrase": " for the other values of w, we have \u03c8 ml (w) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 16 w\u22128 759 8 w 11 1771(20 + 720) + 2576 w = 12 where we made use of table  iv  of  [3]  (for w = 12, we have \u03c8 ml (w) = |x 12 | + |s 12 | + |u 12 | in the notation of  [3] )",
        "prob": 0.17500000000000002
    }, {
        "ID": 4389,
        "phrase": " ai\u22121 {$x/ai\u22121/ * } /ai\u22121 ai {$y} /ai ai+1 {$x/ai+1/ * } /ai+1 ",
        "prob": 0.35000000000000003
    }, {
        "ID": 4390,
        "phrase": " ai\u22121 {$x/ai\u22121/ * } /ai\u22121 ai {$y} /ai ai+1 {$x/ai+1/ * } /ai+1 ",
        "prob": 0.35000000000000003
    }, {
        "ID": 4473,
        "phrase": "introduction qualitative reasoning was introduced in ai to abstract from numeric quantities, such as the precise time of an event or the location or trajectory of an object in space, and to reason instead on the level of appropriate abstractions",
        "prob": 0.5260869565217391
    }, {
        "ID": 4751,
        "phrase": " also published in the proceedings of the tenth international workshop on artificial intelligence and statistics, january 6-8, 2005, sa- vannah hotel, barbados",
        "prob": 0.31875
    }, {
        "ID": 5046,
        "phrase": " the fast hadamard transform (fht) can be used to obtain an ml decoder  [4] ",
        "prob": 0.25833333333333336
    }, {
        "ID": 5434,
        "phrase": " the guards of the involved actions attached to the output places of the fired transition are enabled (\u2200 ai \u2208 placesafter [{ti}]",
        "prob": 0.29285714285714287
    }, {
        "ID": 5485,
        "phrase": " this is a remarkable echo of the assertion made by laplace two centuries ago when he claimed that, given the exact location and velocity of each and every atom in the universe at any one moment, one could calculate, in principle, the past and future history of the universe! in the same article, however denning admits to the implications of the very limited success that this thesis has produced: it is disquieting to a growing number of ai researchers that the fundamental question of their field is so slippery",
        "prob": 0.2911111111111111
    }, {
        "ID": 5631,
        "phrase": " \n remark the ubiquity of this sort of situation from a categorical viewpoint was the main theme of  [11]  and some attempts to assess the relevance of such approximations to general problems in ai was made in  [12, 13] ",
        "prob": 0.2157894736842105
    }, {
        "ID": 5645,
        "phrase": " we study the joint ml decoder in some detail in the next section",
        "prob": 0.19090909090909092
    }, {
        "ID": 5707,
        "phrase": " type-safe languages such as ml and java represent an opposite philosophy, providing restricted forms of generics with strong safety guarantees",
        "prob": 0.2157894736842105
    }, {
        "ID": 5801,
        "phrase": ", haskell, ml or curry, are inductively sequential",
        "prob": 0.12222222222222223
    }, {
        "ID": 5817,
        "phrase": " thus we get virtually ml performance for an explicit linearly bounded update complexity at all values of signal to noise ratio",
        "prob": 0.17222222222222222
    }, {
        "ID": 6486,
        "phrase": " future directions fuzzy sets are an eminently practical tool, familiar to ai engineers and software designers alike",
        "prob": 0.25625
    }, {
        "ID": 6779,
        "phrase": " an example of the former strategy applied to ml sequence detection in uncertain environments is proposed in  [25] ; called per-survivor processing, tentative decisions are immediately fed back to the channel estimation algorithm and the corresponding estimates are used for the detection of future symbols",
        "prob": 0.19062500000000002
    }, {
        "ID": 6779,
        "phrase": " it is not an exact ml estimate since the distribution of the decision feedback error is not considered",
        "prob": 0.16153846153846155
    }, {
        "ID": 6872,
        "phrase": " on the other hand, on a more practical level, there has been rapid progress in learning algorithms for agents interacting with a dynamic environment, autonomously discovering true sequenceprocessing, problem-solving programs, as opposed to the reactive mappings from stationary inputs to outputs studied in most traditional machine learning (ml) research",
        "prob": 0.4735294117647058
    }, {
        "ID": 6872,
        "phrase": "\" \n overview since virtually all realistic sensory inputs of robots and other cognitive systems are sequential by nature, the future of machine learning and ai in general lies in sequence processing as opposed to processing of stationary input patterns",
        "prob": 0.7074074074074073
    }, {
        "ID": 6872,
        "phrase": " most traditional methods for learning time series and mappings from sequences to sequences, however, are based on simple time windows: one of the numerous feedforward ml techniques such as feedforward neural nets (nn)  [4]  or support vector machines  [112]  is used to map a restricted, fixed time window of sequential input values to desired target values",
        "prob": 0.6024999999999999
    }, {
        "ID": 6872,
        "phrase": " in the next sections we will deal with already quite practical, non-optimal and non-universal, but still rather general searchers in program space, as opposed to the space of reactive, feedforward input / output mappings, which still attracts the bulk of current machine learning research",
        "prob": 0.6794117647058823
    }, {
        "ID": 6872,
        "phrase": " a mathematical theory of universal ai emerges (see sections above) -will this be considered a milestone in the future? 12",
        "prob": 0.5785714285714286
    }, {
        "ID": 6873,
        "phrase": " on the other hand, on a more practical level, there has been rapid progress in learning algorithms for agents interacting with a dynamic environment, autonomously discovering true sequenceprocessing, problem-solving programs, as opposed to the reactive mappings from stationary inputs to outputs studied in most traditional machine learning (ml) research",
        "prob": 0.4735294117647058
    }, {
        "ID": 6873,
        "phrase": "\" \n overview since virtually all realistic sensory inputs of robots and other cognitive systems are sequential by nature, the future of machine learning and ai in general lies in sequence processing as opposed to processing of stationary input patterns",
        "prob": 0.7074074074074073
    }, {
        "ID": 6873,
        "phrase": " most traditional methods for learning time series and mappings from sequences to sequences, however, are based on simple time windows: one of the numerous feedforward ml techniques such as feedforward neural nets (nn)  [4]  or support vector machines  [112]  is used to map a restricted, fixed time window of sequential input values to desired target values",
        "prob": 0.5525
    }, {
        "ID": 6873,
        "phrase": " in the next sections we will deal with already quite practical, non-optimal and non-universal, but still rather general searchers in program space, as opposed to the space of reactive, feedforward input / output mappings, which still attracts the bulk of current machine learning research",
        "prob": 0.6794117647058823
    }, {
        "ID": 6873,
        "phrase": " a mathematical theory of universal ai emerges (see sections above) -will this be considered a milestone in the future? 12",
        "prob": 0.5785714285714286
    }, {
        "ID": 6874,
        "phrase": " on the other hand, on a more practical level, there has been rapid progress in learning algorithms for agents interacting with a dynamic environment, autonomously discovering true sequenceprocessing, problem-solving programs, as opposed to the reactive mappings from stationary inputs to outputs studied in most traditional machine learning (ml) research",
        "prob": 0.4735294117647058
    }, {
        "ID": 6874,
        "phrase": "\" \n overview since virtually all realistic sensory inputs of robots and other cognitive systems are sequential by nature, the future of machine learning and ai in general lies in sequence processing as opposed to processing of stationary input patterns",
        "prob": 0.6703703703703703
    }, {
        "ID": 6874,
        "phrase": " most traditional methods for learning time series and mappings from sequences to sequences, however, are based on simple time windows: one of the numerous feedforward ml techniques such as feedforward neural nets (nn)  [4]  or support vector machines  [112]  is used to map a restricted, fixed time window of sequential input values to desired target values",
        "prob": 0.6024999999999999
    }, {
        "ID": 6874,
        "phrase": " in the next sections we will deal with already quite practical, non-optimal and non-universal, but still rather general searchers in program space, as opposed to the space of reactive, feedforward input / output mappings, which still attracts the bulk of current machine learning research",
        "prob": 0.6794117647058823
    }, {
        "ID": 6874,
        "phrase": " a mathematical theory of universal ai emerges (see sections above) -will this be considered a milestone in the future? 12",
        "prob": 0.65
    }, {
        "ID": 7000,
        "phrase": " artificial intelligence is what practical people everywhere fear and dread",
        "prob": 0.2818181818181818
    }, {
        "ID": 7220,
        "phrase": "introduction \n background qualitative reasoning was introduced in ai to abstract from numeric quantities, such as the precise time of an event, or the location or trajectory of an object in space, and to reason instead on the level of appropriate abstractions",
        "prob": 0.5458333333333333
    }, {
        "ID": 7505,
        "phrase": " thus, the monster exhibits a degree of artificial intelligence, albeit rather limited",
        "prob": 0.39230769230769236
    }, {
        "ID": 7506,
        "phrase": " thus, the monster exhibits a degree of artificial intelligence, albeit rather limited",
        "prob": 0.4692307692307693
    }, {
        "ID": 7897,
        "phrase": " rather than the detection of events as they occur, the event calculus approach on events concentrates on what inferences can be made from the fact that certain events are known to have occurred (or are planned to happen in future, thus providing a link to ai planning)",
        "prob": 0.7074074074074073
    }, {
        "ID": 7898,
        "phrase": " rather than the detection of events as they occur, the event calculus approach on events concentrates on what inferences can be made from the fact that certain events are known to have occurred (or are planned to happen in future, thus providing a link to ai planning)",
        "prob": 0.7074074074074073
    }, {
        "ID": 7941,
        "phrase": " the use of sat procedures as a practical implementation technique to search for bounded length executions of systems has also been used in the context of sat-based artificial intelligence (ai) planning  [ks92, ks96]  and in sequential atpg  [kl93] ",
        "prob": 0.7444444444444444
    }, {
        "ID": 7942,
        "phrase": " the use of sat procedures as a practical implementation technique to search for bounded length executions of systems has also been used in the context of sat-based artificial intelligence (ai) planning  [ks92, ks96]  and in sequential atpg  [kl93] ",
        "prob": 0.7074074074074073
    }, {
        "ID": 7943,
        "phrase": " the use of sat procedures as a practical implementation technique to search for bounded length executions of systems has also been used in the context of sat-based artificial intelligence (ai) planning  [ks92, ks96]  and in sequential atpg  [kl93] ",
        "prob": 0.7444444444444444
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.7772727272727271
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.7772727272727271
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": "), proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": "), proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8172,
        "phrase": ") , proceedings of the ijcai thirteenth international joint conference on artificial intelligence workshop \"reuse of designs: an interdisciplinary cognitive approach\", chamb\u00e9ry, france,  august 29, 1993 (pp",
        "prob": 0.8227272727272725
    }, {
        "ID": 8555,
        "phrase": " the number of interesting applications makes this restricted class of ai problems, with time-and space-bounded environment \u00b5 tl , worthy of study",
        "prob": 0.32105263157894737
    }, {
        "ID": 8555,
        "phrase": " in the following, we construct a policy p * , or more precisely, policies p * k for every cycle k that outperform all time-and length-limited ai systems p",
        "prob": 0.6529411764705882
    }, {
        "ID": 8555,
        "phrase": "1 we introduced an intelligence order relation on ai systems, based on the expected reward v p\u03be km k ",
        "prob": 0.3153846153846154
    }, {
        "ID": 8555,
        "phrase": " one of the key insights in this article that allowed for an elegant theory of ai was this separation of data efficiency from computation time efficiency",
        "prob": 0.25625
    }, {
        "ID": 8555,
        "phrase": " all in all, the results show that artificial intelligence can be framed by an elegant mathematical theory",
        "prob": 0.425
    }, {
        "ID": 9228,
        "phrase": " the ml programs below omit most pplambda inferences, as well as code for optimization and debugging",
        "prob": 0.23846153846153847
    }, {
        "ID": 9302,
        "phrase": " in the future, we plan to extend this work to ai planning domains with richer representations and to real-time problem solving",
        "prob": 0.25625000000000003
    }, {
        "ID": 9306,
        "phrase": " funt's whisper program is the rst ai program that uses primarily perceptual primitives to predict dynamical events in a simple blocks world  (funt, 1980) ",
        "prob": 0.305
    }, {
        "ID": 9439,
        "phrase": " \n parameters the osu scheme requires just three parameters: the switch averaging interval ai , the target link utilization u , and the half-width of the target utilization band ",
        "prob": 0.3857142857142857
    }, {
        "ID": 9439,
        "phrase": " the ai eld is not required with the countbased approach",
        "prob": 0.1375
    }, {
        "ID": 9445,
        "phrase": " i n s t e a d , i t i s d i st r ib u t e du n i f or ml y o v er aran ge of f r equen cies",
        "prob": 0.10999999999999999
    }, {
        "ID": 9504,
        "phrase": " however, as table  1  shows, the different nature of traditional ai planners and our gp-based planner (i",
        "prob": 0.22142857142857145
    }, {
        "ID": 9572,
        "phrase": " the main classes of polynomially solvable bounded-width queries considered in database theory and in artificial intelligence are: \u2022 the queries of bounded treewidth  [7]  (see also  [20, 13] )",
        "prob": 0.505
    }, {
        "ID": 9572,
        "phrase": " fact 7: for 1 \u2264 i < j \u2264 s it holds that v ai lies on the unique path in t from v ci to v cj ",
        "prob": 0.21000000000000002
    }, {
        "ID": 9572,
        "phrase": " the main classes of bounded-width queries considered in database theory and in artificial intelligence are the following: \u2022 queries of bounded treewidth",
        "prob": 0.5055555555555555
    }, {
        "ID": 9594,
        "phrase": " 7th int'nl workshop on algorithmic learning theory, lecture notes in artificial intelligence, vol",
        "prob": 0.4066666666666667
    }, {
        "ID": 9619,
        "phrase": " utterance utterance 8 intonational intonational 7 l% intermediate intermediate 5 l- 42 l- 74 l- word word accent text 2 f w the 13 c s price 26 c s range 39 f w is 47 c s smaller 62 f w than 71 f s any 84 f w of 92 f w us 99 c s expected syllable syllable pitch_accent 4 w 15 s h* 28 s !h* 41 w 49 s h* 57 w 64 w 73 s 79 w h* 86 w 94 w 101 w 108 s h* 119 w phoneme phoneme 1 d 10 @ 12 p 18 r 21 ai 23 s 25 r 32 ei 34 n 36 z 38 i 45 z 46 s 51 m 54 o: 56 l 59 @ 61 d 66 @ 68 n 70 e 78 n 81 i: 83 @ 89 v 91 @ 96 s 98 i 103 k 106 s 110 p 113 e 115 k 118 t 122 @ 124 d \n node identifiers and time references have been omitted",
        "prob": 0.14137931034482756
    }, {
        "ID": 9845,
        "phrase": " vernor vinge calls this ia (intelligence amplification) as opposed to ai  [11] ",
        "prob": 0.31
    }, {
        "ID": 9845,
        "phrase": " despite this progress, there is general pessimism about machine intelligence, and artificial intelligence (ai)",
        "prob": 0.25833333333333336
    }, {
        "ID": 9869,
        "phrase": "  7  the data collected in this stage provides us with initial input-output training sets to be used by the machine learning algorithm on each node: for each router-destination node, inputs are identified with windowed loads on outgoing links, and the associated wlr values for the destination in question are the outputs",
        "prob": 0.20882352941176469
    }]
}, {
    "topic_id": 9,
    "top_words": ["yi", "hi", "xf", "gf", "ff", "xi", "ac", "xe", "vq", "fe", "ix", "gc", "cc", "pi", "oe"],
    "phrases": [{
        "ID": 471,
        "phrase": "e j v \u00b5 \u00b6 \u00b8\u2022 \u00b9 \u00ae\u00ba \u00bb \u00bc \u00bd \u00bf\u00be \u00e0 \u00e0 \u00e1 \u00e2 t\u00e3 \u00e2 \u00e4 3\u00e5 ae \u00e7 \u00a6\u00e8 \u00e9 \u00bd \u00e2 \u00e2 \u00bf\u00e4 \u00ea \u2022 \u00eb \u00e0 \u00e9 \u00ec \u00ed \u00ee \u00e2 9\u00ef \u00a6\u00e9 \u00bc \u00e8 \u00ed \u00f0\u00ee \u00b6 \u00b8\u2022 \u00ed \u00e2 \u00e8 \u2022 \u00a6\u00be \u00ed \u00ea \u00f1\u00e9 \u2022 \u00be \u00f2 \u00a6\u00f3 \u00e9 \u00e8 \u00f4 \u00e0 \u00ee \u00e9 \u00e7 n\u00e9 \u2022 \u00f5 \u00bc \u00ed \u00e9 \u00f6 \u00be \u00ed \u00f0\u00e2 \u00bf\u00e4 \u00bb \u00e2 \u00bf\u00d7 \u00bc \u00eb \u00eb \u00ea \u2022 \u00eb \u00e3 \u00f5 \u00f5 \u00bb \u00f8 g\u00f9 \u00a4\u00fa e\u00fb \u00b3\u00fc \u00fd \u00fd \u00fd \u00e5 \u00f0ae \u00f5 \u00bc \u00eb \u00bc \u00a6\u00e0 \u00ed \u00fc \u00fd \u00fd \u00fd ae \u00b9 \u00bc \u2022 \u00ea \u00bd \u00ee \u00ba \u00a2\u00fe \u00e0\u00df \u00f6 e\u00e7 \u00bc \u00ed \u00e2 \u00e8 a\u00e1 9\u00e2 \u00e0 \u00e2 \u00be \u00e8 \u00bd \u00ee \u00e1 w\u00e2 \u00bf\u00e7 u\u00e9 \u00e0 \u00ea \u00f1\u00ed \u00e9 \u00e8 \u00e2 \u00e3 \u00ee \u00ed \u00ed \u00f0\u00e7 \u00e3 \u00e4 \u00e4 \u00e5 \u00e0\u00e5 \u00e0\u00e5 \u00ba \u00be \u00bd \u00f6 \u00ba \u00e9 \u00e8 \u00eb \u00e4 \u00bd \u00e9 \u00e8 \u00e8 \u00e4 x\u00e5 \u00f0ae \u00bd \u00e0 t\u00ba ae \u00f8 \u00e4 \u00e2 \u00ac\u00e2 \u00f6 e\u00f6 \u2022 \u2022 \u00a6\u2022 3\u00e7 \u00e5 \u00e0\u00ee \u00e9 \u00f2 \u00e2 p\u00e7 \u00e8 \u00e9 \u00bd \u00e2 \u00e2 \u00e4 \u00a6\u00ea \u2022 \u00a6\u00eb \u00e0 \u00e3 \u00bd \u00e0 \u00a7 \u00a9 ! #\" $ % & (' ) % 0 \u00a11 \u00eb 32 $4 ' ) 5 6 # %& 87 9 a@ b 69 c a !' ) 60 d @ e9 gf h c a9 if h 87 p7 8q r %r \" $r @ s 6 r % 9 %c t 8 6 6& uq 9 & 87 v %\u1e85& xf y9 3f y\" a`4 8 & xf y 69 \" a\u00fff 6b cq 9 & 87 w 6 r % 9 %c t9 9 %d fe g& \" a& u\" $\u1e27f yi 9 q & 88 p %@ q %r 69 c ac h 8 & r s7 88d $9 % 9 3f y\" a & t vu i v@ b 69 c a !' ) 60 \u00a6' )9 & wf yi 8\u1e8d\" ac h d a 8c h 8\u1e27f y 87 \" $5y \" ac h9 4 9 %\u1e8d9 gf h c a9 if h 87 x 8 6 % 8 6 8!f y\" a & e #& f h 8c @ b % e8 8 6 8\u1e27f vd $ %r \" ap 6 r % 9 %c h& 4 ' xi \" ai @ b 89 3f y 6 87 & ! 8 9 %d \" $c a c 8c h 8\u1e27f h& ef y xc h9 %0 f hi & e #& f h 8c c a 6 69 !f h\" $89 %d w9 7 8 h8\" a 8\u00fff ht u i dc h 8i 9 \" a& c @ 8 6 % 8 6 8!f h\" $ %\" $y \" ac h9 \u00a1\" a& dq 9 & 87 \u1e85f yi dc a e7 d9 7 f \u00a9e g d& xe g& xf h 8c f @ g w e7 87 \u00a1h id $9 3f dj 5k ul m1 on 2 1 \u00eb 3p 2 t g w e7 87 \u00a3h id $9 3f aj 5k ul q\" a& r9 d8 8 6 8\u1e27f d $ %r \" a5s x9 %7 8 & 8t e 8\u1e27f yd oe 4 9 58 %8 6 8\u00fff 8 %& xf y 69 \" a\u00fff hu pd $9 %r 9 %r i' x\" of yi h9 8 %& f h 9 %\" $\u1e27f b q 9 & 87 vc a e7 p& e #& f h 8c q7 8& \" ar 87 xq he % v %@ gf yi v9 gf hi 6& ct pw 9 %r 9 %r 8& i 8t e \" a # 87 ' 5\" ff hi & xf y 6 r \u00a6f \u00a9e # \" $r 5 (& xf y 6 r 5c h e7 \" ar yx 89 %q d $ if yi 7 !f y 8!f h\" $ % %@ sf \u00a9e g 8z c a e7 8 6 % & q he i 80 e\" ar p % r 88 & xf h !f h\" $r f \u00a9e g # 8& rc a e7 8& t du i aq 8& xf b c0 e c' 5{@ b 9 %c h !' ) % 0 v@ b % f \u00a9e g 88 %& f h !f h\" $ %|\" a& f hi }k \" $7 d a !e eb cg \u00a3\" ad $ 8 f \u00a9e g & xe g& xf y 8c 1 f~2 $4 ' xi \" ai |9 %d $d a c' x& x & f y d& %d f r9 d& !f @ f \u00a9e g # r8 & xf h 9 \" a\u1e27f y& q gf h9 \" $ 87 d@ b %c %r 69 c f y ! sf 8 h8\" $ 8\u1e27f yd oe \u00a39 & 9 \" $ 89 3f y\" a %q d a 8c ht \" $c a\" $d a9 6d fe 4 f yi c a e7 v& xe g& xf h 8c t %@ sg \u00a3 e7 87 vh id $9 3f dj 5k ul 9 d ad $ c' 5& ) & pf y }& %d f v9 & !f @ ec h e7 8 %& f h 9 %\" $\u1e27f y& q gf h9 \" a 87 @ b %c 6 r % 9 %c f h ! ef x9 & 9 h8 %& xf y 69 \" a\u00fff x& c9 3f y\" a& @ b9 !f h\" $ % %q d $ 8c at \u00a6g w 7 6 88 & xf y 6 !f y\" a }& xf y9 3f y\" a89 d $d oe v7 !f h 8 c a\" $ 8& ef yi 89 %7 z i' 5 \" of y 89 % 9 q \" ad $\" ob f y\" a 8& ( %@ y 9 % \" a9 q d a e88 6 88 8& s9 7 d 8& xf h9 q d a\" $& i 8& gf yi 8 %& \" $& xf y 8!e @ w8 c ac v \" $89 3f y\" a 3f y e8 %d $& 5q # !f \u00a9' ) 8 88 8 6 8\u1e27f e8 8& & h& }1 \u00eb 3p 2 t \u00a3 u& ' ) ' 5\" $d ad p& 8 }d a9 if h 8 4 f \u00a9e g # 8& 5\" $g w e7 87 h id $9 3f pj 5k l 9 d a& \u00a189 q d 88 %& f h !f h 87 & \" ar 9 \u00a3& \" ac h\" ad $9 % ps 9 7 & \" $c a d $ 8 6u f y 8i \" $t s 8t qi 89 8 8 6 8\u1e27f pd $ %r \" ap 6 r % 9 %c 8 \u1e27f y9 %\" $& q r %& 4 \" ff p\" a& 8 xe dd a\" $0 % 8d fe uf yi 9 3f pc h e7 e88 6 88 ys & u \" $f hi r %r 69 c f hi 9 if 5\" $c a # %& 87 vf yi 8 %& f h 9 %\" $\u1e27f 4 9 ac a\" $\" ac h9 %d g& c q & !f f y 8d ad $& & & \" $q d a & 68 8& xs x\" at $ 8t 4 & xe gc vq d e88 6 88 8& u %@ \u00abc h e7 8 6 % & t \u00ac u& \" $r f yi \" $@ 6c h9 3f y\" a \u1e27 %@ # & & \" $q d a d $ e89 3f y\" a & @ q r & 4 9 % gf y %c h9 3f y 87 h8 6 8!f h\" $ %\" $& 9 if 6f y 8c h gf h 87 q 9 & \" a89 d $d oe pq ye vr 8 8 69 if h !b c9 7 gb f h 8& f r& 89 % i 4 9 %c h 8d oe hf yi ur 8 8 69 if h\" $ % @ # %& c& \" aq d $ !' 5 \" of y\" ar & v9 %7 pf yi 8 c a gf y9 3f y\" a @ \u00abf hi 8\" $ v \" a8\" $ 9 %d pc a e7 }9 %7 pf \u00a9e g 8t 89 6i {& 9 %8 h\" a& x0 % 8 gf & c h9 %d $d sq # 889 % & rf yi ad $ e89 3f y\" a & @ pq r & 5i 9 c hq # 8 8d $\" ac h\" of y 87 f y a& c h9 %d $d 8r %\" $ %& @ \u00ab 6 r % 9 %c f h ! ef ht & \" ar \" $ 89 %\u00fff @ b 89 3f y 6 v %@ q e@ b 69 c a !' ) 60 \" $& f yi 9 3f v\" ff \" $& e9 d a\" $89 %q d $ f y 9 u@ b 69 r %c h 8\u1e27f @ \u00a69 w 6 r % 9 %c \u00ae& i 9 & v9 p& c !f @ \u00a6 87 \" a89 if h }7 8 \" ff h\" $ %& v\" a|9 v 9 % xf h\" $8 d a9 xc h e7 d a 8t u i 9 3f )\" $& 4 v@ b 9 %c h !' ) % 0 h\" a& t e \" of y u 8 8!f h\" f 4 @ b % v ! g9 c a d $ 4 \" a\u1e8df yi & \" ff h 9 if h\" $ %v' xi 8 6 9 w %r 69 c \u00b0\" $& x if d8 %c h d a !f y 8d oe 8 & xf h !f y 87 t u i \" a& v\" $& x7 xf h hf yi @ b9 %!f vf yi 9 3f vf hi c v d ff h\" $& !f r @ c h e7 u8 & xf h 9 \" a\u1e27f y& \" $c a # %& 87 dq ye v9 6 r % 9 %c & 9 d ad fe pi 9 & \u00a6 6 87 7 9 !e %t \u00b1 87 7 9 %!e \u00a18 %c h 8& @ b 6 c qf \u00a9' ) 89 %& & \u00b2 \u00eb t \u00b3 gb f h \" o g\" $9 %d %r 9 %c \u00b48 \u1e27f y9 %\" $& x8 7 \" of y\" a 9 %d (q 9 %i 8& 5 7 !f h 8 c a\" $gb \" $& xf h\" $di %\" $8 8& t \u00a7 \u00a9s x8 %8 6 8\u00fff hu d $ %r \" ad $9 %r 9 r % 8& 4 f hi !e 9 % d ! g 6 8& c& 87 \u00a39 & r9 & !f } %@ v 6 !' x 6\" ff h h d a 8& s \" $t a 8t 4 %r 9 %c \u00b08d a9 & 8& u f yi 9 3f }c a9 ce \" $c a # %& rf hi a& c9 %c h c h e7 8 %& xf y 69 \" a\u00fff h& f yi & 9 %c h 5 6 87 \" $89 3f y 8t \u00ec t gb f h \" o g\" a9 d \u00a6 6 r % 9 %c 8 %\u00fff h9 \" a& a 87 \" a89 if h 8& uf yi 9 3f 9 6 89 %d $d a 87 @ %c \u00b5c a 6 f yi 9 % d $9 %8 4 & c %c h r @ ' xi \" ai c h9 e \u00a1q # r 6 88 & \" o w 89 d ad $& t u i r& 9 c a c a e7 8 & xf h 9 %\" $\u1e27f xc a9 ce q # \" ac h & 87 q he 7 \" $ 8 8\u1e27f x89 d ad $& t ud ff hi r %i pf yi @ b 69 c a !' ) 60 \u00a1\" $& 5t e \" of y }r % 8 8 9 %d 4 ' xi !f hi 8 x\" ff }\" $& x 9 %!f y\" a89 d ( x 3f c h9 ce d7 8 # 87 a \u00fcf hi i %\" $8 @ 9 rd $9 %r 9 %r 8t y \" ac h9 8 % 6 8!f y& g' x 6 r e88 6 88 8& s @ 9 6\" $9 %q d a \u00a6& xe gc vq # %d $& i\" $9 ry w \u00eb 1 o \u00b6 2 %r 9 %c q9 & & c a\" $r )& f h %r )c a e7 \" $r )9 7 uf \u00a9e g \" ar ) @ g w 7 87 h id $9 3f rj 5k ul t #y w \u00eb \" $& 7 8& c\" ar 87 q 9 & 87 d h id $9 3f rj 5k ul f yi 9 3f \" $& \u00a6 3f r 8t e \" a # 87 ' x\" of yi d& f h %r c h e7 \" ar z 3f \u00a9e g \" $r 4 q gf (f hi 7 8q r r %\" $r r @ wy w \u00eb 6 r % 9 %c h& gf y 6& ( gf if y q # 8 8 gf h@ %c c a e7 \" $r 9 %7 f \u00a9e g \" $r %t h w f yi 8 6c h 6 4 \" ff h& 8 c a \" $d a 8 y w e \u00a7 \u00a9l q c #\" $7 8& 9 a\" $8 r d $9 3f y@ b % c \u2022@ b % % ! g # 8 6\" $c a 8\u00fff h& x1 \u00ec %2 t i i 9 c w r q gf h9 \" a 87 %c h\" $& \" ar a 8& d ff h& @ b 6 c ! # # 8 \" ac h 8\u1e27f y& ' 5\" ff hi |f hi \u00a19 & & \" $& xf h9 8 \u00a1 %@ 5 3f yi 8 & e #\u00fff h9 !f h\" $89 %d r8 & xf h 9 %\" $\u1e27f y& s 8!f ht %u t \u00b9 \u00ba \u00fd \u00fe (\u00ff \u00fc }\u00bb \u00bc \u00ff w\u00a5 \u00fc }\u00bb \u00bd \u00fc w \u00be \u00e0\u00bf {\u00e1 w\u00a5 \u00fc }\u00bb \u00a5 \u00fc \u00e2 q\u00ff 2\u00fc \u00a3\u00a4 \u00a2 5\u00fe \u00fe \u00e3 z\u00fc \u00fd \u00e4 \u00ff a\u00bb p\u00a5 h\u00a4 \u00e5 \u00fe (\u00ff a\u00bb \u00fe p\u00bd vae ae \u00a5 \u00fc }\u00bb \u00e7 v gf hd $\" $ f yi vc h e7 v& e #& f h 8c f %@ g w e7 87 wh sd a9 if dj 5k l t \u00abu i 89 %7 8 & u9 6 8@ b 8 6 87 f y p1 \u00eb 3p 2 9 7 {1 o\u00e8 2 @ b % 7 !f h9 \" ad $& t ~\u00ed w\u00ed 0\u00ee c\u00ef \u00f0 \u00f1 t\u00f2 \u00f4\u00f3 \u00b4\u00f5 x\u00f5 \u00f5 \u00a7 \u00a9v8 %8 6 h\u1e27f d $ %r \" av 6 r % 9 %c hc h\" ar 4 c h e7 8& d $9 ce 9 @ b 7 9 c a 8\u00fff h9 d s %d $ v\" a5 8& f h9 q gb d $\" a& i \" $r f yi & 9 @ b !f \u00a9e @ 9 v 6 r % 9 %c \u00b3\" $5f y 8 6c h& v %@ f yi 8 & \" $& xf h 8!e p @ 8 c ac v \" $89 3f y\" a 3f y e8 %d $& t ru i vc h e7 5& xe g& xf y 8c @ sg w e7 87 vh id $9 3f j 5k ul r \" o 8& u9 } # %d $9 % \" of \u00a9e & f h !f h s \u00e9f hi 9 if 7 !f y 8 6c h\" a 8& f yi \" a@ b % c h9 3f y\" a }\u00ea c' \u00eb @ g 89 %i 9 % xf @ g7 9 3f y9 5& xf y 6 !f y 8& v8 6 89 if h 87 7 \" ar h ! g 88 gf h\" $ %u sf h )f yi 59 6r c a 8\u00fff h& @ e 87 \" $89 3f y 8& sf hi 9 if x7 !f y 8 6c h\" a \u00a6f yi q 8i 9 c eb \" $ % u %@ pr % 9 %d $& t d \u00ecc h e7 v ! g 8& & 8& vf yi \" a& r # %d $9 % \" of \u00a9e |& xf h !f y 6 4 ' 5i \" $i \u00a1\" $& u 8 8& 8\u1e27f y 87 9 & x9 wc h9 % \" $r w@ b 6 c \u2022f yi & !f d %@ \u00ab\u00ed g\u00ee y\u00ef \u00f1\u00f0 y\u00f2 af y f hi xf \u00a9' ) 3b q9 %d $ 87 |8 7 %c h9 %\" $|\u00f3 \u00f4 b\u00f5 i\u00f6 \u00d7 8\u00f8 \u00ef \u00fa\u00f9 t \u00fb i9 if hi & i 8 9 6 & xf h \" $r %& e @ e 9 \" a & 4 %@ \u00fcf yi @ 6c \u00fd \u00f2 \u00fe g\u00df \u00e0 \u00d7 y\u00e1 \u00f6 \u00ee 8\u00e2 !\u00e3 y\u00e4 4 %@ 6 87 \" $89 3f y 8z @ !f y\" a & xe gc vq # %d $& )9 7 \u00a19 6r c a 8\u00fff a # %& \" ff h\" $ %& 4 9 7 \u00a19 6 & c 87 f h d& c 88\" $@ \u00e5e | & & \" $q d a d # %& \" ff h\" $ %& \" $7 9 if h9 v& xf y 6 !f y 6 8& ct h w 6c h9 d ad fe 4 f yi & !f ae \u00e7 c\u00e8 \u00e9 b\u00ea %@ \u00a6 9 if hi & x@ b % f y 8 6c h& v9 7 pf hi }& !f ae s\u00eb s\u00ec \u00e5\u00ed !\u00ea %@ \u00ab 9 if hi & @ b % 9 if h c a\" $@ b % c v d a9 9 6 57 8 87 & \" $r a7 \" $& x\u00ee \u00fa \" $\u1e27f 5 \" $ 9 %& \u00b2 ae \u00e7 c\u00e8 \u00ef\u00e9 b\u00ea \u00f0 \u00ecs \u00f1 \u00f2 g\u00f3 \u00f4 \u00f5 \u00f6 \u00f1 u c\u00f7 w\u00f6 ae i\u00eb s\u00ec \u00f8\u00ed !\u00ea |\u00f0 \u00ecs \u00f9 \u00f2 \u00fb\u00fa \u00e9 \u00f1\u00e8 \u00fc \u00f6 \u00f9 u v\u00fd ae \u00e7 \u00e8 \u00e9 b\u00ea \u00f6 ' xi 8 6 \u00fe #\u00f8 \u00f5 ez %\u00ff \u00e2 \u00a1 \u00a3\u00a2 9 6 f yi 5& !f y& @ \u00ab@ b !f y\" a z % 87 \" $89 3f y 5& xe gc vq d a& 4 9 %7 v\u00f6 \u00f1 z \u00f6 \u00f9 9 % f yi a& !f h& 5 %@ v # %& & c\" aq d $ d9 6r c h 8\u1e27f } & \" ff h\" $ %& }s xs c vq # 8 6 87 @ b 6 c \u00eb u r@ b % f yi a& xe gc vq d a& \u00a4 z \u00a6\u00a5 t u i r7 \" $& x\u00ee ! %\" $\u1e27f v \" $ % 8 9 3f y % c a 89 & \u00b2 \u00f1 \u00f2 \u00fb\u00f3 \u00f4 \u00f5 \u00f6 \u00f1 \u00f0 \u00eb\u00f3 \u00fd \u00a4 \u00f6 \u00a8 \u00a7 \u00e4 \u00a9 \u00a4 \u00fe \u00f8 \u00f5 \u00ab\u00f6 \u00a7 \u00f6 \u00f1 \u00f9 u i 6 # %& c @ c a e7 9 %9 d oe g& \" $& p\" $& f y x 7 5f hi u& !f u @ g9 %d $d wc h e7 8& )s 89 i %@ f \u00a9e g # ae s\u00eb s\u00ec \u00e5\u00ed !\u00ea \u00f3 \u00f4 b\u00f5 i\u00f6 \u00d7 8\u00f8 \u00ef \u00fa\u00f9 u x 7 8 ' xi \" ai | ! 8 e \u00e7 \" a 88 } %@ \u00a68 c hc x \" a89 if h\" $ %|\" a& v8 e % # 8 9 3b f y\" o 8t i |9 wc a e7 \" a& 89 d ad $ 87 |9 y\u00e1 \u00e1 ! \u00a9\u00df \u00d7 \"\u00a2 i\u00f4 b\u00f5 \u00e3 yt { \u00a7 \u00a9\u00fff h \" ff h\" f 8d oe 4 \u00f4 \u00f5 c h 89 %& f yi \" ad $ !f @ \" $@ 6c h9 3f y\" a 9 %7 \u00d7 8\u00f8 \u00ef xc a 89 & uf yi % gf yd a !f @ \" $@ b % c a9 if h\" $ %t %r 69 c 7 e 8& if 5 & 9 %d $d oe {7 8 9 a \" $t e \u00a6' ) 8d ad fb cc a e7 \" $r hq gf xi 9 & c a9 \u1e27e @ wf yi 8c ht )f yi 5 b # %& x @ sc h e7 v9 9 %d fe g& \" a& u\" $& f y }8 c h gf h f hi & !f %@ 9 %d $d ' ) 8d ad fb cc h e7 \" ar & u\" a}f yi x@ b % c @ 9 \u00ed \u00e2 \u00f4 b\u00f5 $# \u00f4 \u00e5\u00ed g\u00ee y\u00e1 s \" $t a 8t 4 c h %& xf r 8 8 69 d au rc a e7 8t d\u00fb \" a8\" $ 9 %d sc h e7 8& r89 \u00a1q # a ! # 8& & 87 9 if h 9 %d $d oe \u00a1q he \u00a1c h e7 r % 9 % i & 4 9 & 7 8& 8 \" aq # 87 d $9 3f y 8 \" a\u00e4f hi \" $& & 8!f h\" $ %t j 5\" f 8d9 rc h e7 &% 4 ' ) 7 8 9 r\u00f2 \u00f8 \u00e0 \u00df \u00d7 \"\u00a2 ' (% 0) 1\u00a5 4 9 c a 8d fe % g\" a !' ) 87 h9 3f sf yi 9 if hi \u00a5 4 9 & )9 @ b !f h\" $ %\u00a3& 9 if h\" $& @ e g\" $r \u00a3s 2% 3) \u00a6\u00a5 u ys 54 \u00fbu \u00f0 6% s 2\u00a5 74 \u00fbu 6t 9 d a& 7 8 98 \u00a8@ 9 7 ba dc fe 9 & 5& q c h e7 8& x !f h \" ar p\u00f4 b\u00f5 \u00e09 7 \u00e7\u00d7 8\u00f8 \u00ef 4 6 8& c 8!f y\" o 8d fe 4 @ 59 %\u00ffe 9 3f yi t w | c 8 d a\" $ g r \" $\u1e27 8 xf h& sf yi # %d $9 % \" of \u00a9e \u00a1 @ e9 hc a e7 4 9 h& q c h e7 4 9 ac h e7 \u00a6 9 d a 8t \u00ebh sd a9 if 5j 5k ul 6 r % 9 %c m\" a& 9 h& !f 5 @ e8d $9 % & h& @ f yi @ b % c ih qp sr t vu xw 4 ' xi 8 6 yh \" $& 9 \u00a39 3f y %c h\" av@ b % c v d $9 }9 7 `t \u00b39 7 aw 9 6 dc v d of y\" a& !f y& u @ (9 if h c a\" $x@ b 6c v d $9 % 8t g w e7 \u015fxk h su g% s h\u00a5 u \u00f0 \u00f4 b\u00f5 4 @ b % 9 h@ b !f y\" a & xe gc vq d 88 6 \" ar d\" $\u00efh v9 if \u00a5 t s xk qp du r% 0) 1\u00a5 \u00f0 s8 \u00a8@ 4 @ b 9 a 9 6\" $9 %q d $ h& xe gc vq # %d ( e88 6\" $r c h % rf yi 9 %{ %8 h\" $0h 9 if \u00a5 9 7 & c a !' xi 8 6 5 8d a& c 8t s xj tp u \u00a7 \u00a9@ i& %c h q9 % \" a9 q d a 5 e88 6& q if hi p\" $\u00fch p9 if \u00a5 v9 %7 \" $\u00eft \u00ec9 if \u00a5 'v 4 w 4 ae \u00e7 c\u00e8 \u00ef\u00e9 b\u00ea s 2% s 2\u00a5 xv y4 \u00fcu p\u00f0 \u00f4 b\u00f5 ` % s 2\u00a5 74 \u00fcu p\u00f0 \u00f4 b\u00f5 \u00abu 6t s 5e \u00a6\u00ac u d% 3) w\u00fd d ' g\u00f6 \u00eb \u00e4 \u00f0 % 0) \u00fd ' %\u00f6 \u00ec \u00e4 4 @ b % 9 a \" $ 89 3f y\" a q # e7 ge \u00a1r % 9 %d ' gt s 5e \u00a6h iu r% s 2\u00a5 u \u00f0 \u00f4 b\u00f5 4 @ b % 9 h@ b !f y\" a & xe gc vq d e88 6 \" ar a\" a\u00efw 9 3f \u00a5 t s 5e p u pw !f wq # 59 9 % \" a9 q d a x e88 6\" $r a ! g9 !f hd fe ps 5 \u00eb u sf y\" ac h 8& \" ah w9 %7 w 9 if \u00a5 x \u00f6 \u00a1 8\u00f6 \u00a5 4 @ #' 5i \" $i f hi e88 6 88 8& \" $h \u00a39 6 v9 if \u00a5 x \u00f6 i\u00f6 \u00a8\u00a5 ps p u t u i 8\u00a8d s \u00ef\u00f3 \u00a6% 0) 1\u00a5 x \u00f6 \u00a1 8\u00f6 \u00a8% 3) \u00a6\u00a5 ' e\u00f9 %u c\u00f6 \" $@ x a\u00f0 p xe d s \u00ef\u00f3 % 0) 1\u00a5 x \u00f6 \u00a8% 3) \u00a6\u00a5 ' gf x \u00f6 \u00a1 8\u00f6 \u00a8% 3) \u00a6\u00a5 ' \u00f9 %u c\u00f6 \" $@ x dh p xe ' xi 8 6 f hi u 9 % xe 6 87 \" $89 3f y d c 8 v \" ff h \u00df d\u00f8 \u00e1 \u00e9\u00ef \u00f1\u00f4 \u00f2 i y\u00ef \u00f1\u00f2 @ & q c h e7 8& v 8 gb 8& 8\u1e27f y& gj \u00a98 e # 8 69 if h\" f 8 %c hc v \" a89 if y\" a lk xq !f \u00a9' ) 8 8} 9 if hi & p9 %7 }\" $& p7 8 87 9 & d s 5m (u on qp 5r \u00f0 w 4 ae \u00e7 c\u00e8 \u00ef\u00e9 b\u00ea s 7t m s t es 4 \u00fcu (\u00f0 \u00d7 8\u00f8 g\u00ef vu w t v m w c\u00f3 xt \u00fb\u00f9 s 5t v s 4 \u00fcu (\u00f0 \u00f4 b\u00f5 \u00abu 6u q h s\" ar 6 \u00eb \u00b2 g w e7 a8 & xf h 9 \" a\u1e27f y& x\" ac h & 87 q ye 9 %r 69 c 8d $9 % & qh 0p sr t u fw 9 r %9 d 8d $9 % & xp sr w xt & xe g& xf y 8c m9 d ad $ ' x& 7 \" $ 8 8\u1e27f vq # e7 ge \u00a1 \" a 89 if h\" $ r %9 d $& sf y hi 9 c w 7 \" $ 8 8\u1e27f c a e7 8& ct u i \" $& \" $& v9 v& # 88\" a9 d v89 & %@ c a e7 } d oe gc h % i \" a& c f yi 9 3f d89 q # \" $\u1e27f y 6 e7 8 87 \" $\u1e27f y v if hi h 87 \" a89 if h 8& v9 %& ' ) 8d $d u1 f 2 $4 q gf d\" apf hi \" $& x 9 8 ' ) ' x\" ad $d p 3f d8 %& c\" a7 8 xr 8 8 69 d pc a e7 # %d fe gc a 6 i \" $& c q 889 & v' 5i !f yi 8 ef y vi 9 c w ) # %d fe #c h 6 i \" $& c \" a& \u00a6\" a7 8 # 87 8\u00fff ) %@ f hi 8& & c 88 %@ wf hi \" $& (' ) % 0 et u i 58 %& xf 5 %@ \u00abc a e7 r9 9 %d fe g& \" a& \" a& 9 d ac h %& xf x % # % xf h\" $ 9 %d ef y )f yi 6 r % 9 %c m& \" yc 8 r@ b f yi @ b %d $d $ ' x\" $r v 89 %& t g w e7 u9 %9 d oe g& \" $& v e8 8 87 & q he pc h 8 6r \" ar vc h9 %\u00ffe p& \" ac h d a uc a e7 r 69 i & 8 6 8& 8\u00fff h\" $r a\" $7 \" o g\" a7 9 d c a e7 r8 & xf h 9 %\" $\u1e27f y& t h w \u00a6 ! g9 %c h d a 4 f hi r 8& d of y\" ar c h e7 5r 69 i v %@ #f yi 59 87 v %r 69 c \u00aes x8@ bt r # 87 \" f #u \" $& & i c' 5\u1e85\" $ph s\" ar t \u00ec t ru i c h e7 hr 69 i & @ w 8 e d $9 % r % h %r 69 c a& 59 % 4 \" $r 8 8 69 d 4 c v i ' x\" a7 8 \u00a6f yi 9 %f yi 9 3f @ qf yi 9 87 %r 9 %c \u00b3q gf r9 6 u if )c v i 7 8 8 # 8 4 ' xi \" ai d\" a& ef h & 9 ce vc h %& xf ) 7 8& z \u00ed w\u00ed 0\u00ee c\u00ef \u00f0 \u00f1 t\u00f2 \u00f4\u00f3 \u00b4\u00f5 x\u00f5 \u00f5 <a,1> <a,2> <a,3> < ",
        "prob": 0.9268839103869652
    }, {
        "ID": 471,
        "phrase": " ,2> h i\" $r % \u00ec \u00b2 hu i hc a e7 dr 69 i { %@ 9 9 # 87 %r 9 %c ht {j q| }k p& xf h9 7 & 5@ g| g e j k \u00a3& xf y9 %7 & a@ b % d $\" a& f 8 & xf h !f h e 9 7 wf yi 7 c' x\u1e27' )9 67 9 % 6 c' c h 89 & uf yi c h e7 9 d a \u00f4 b\u00f5 \u00abt u i c a e7 \" $@ b % c a9 if h\" $ % @ f yi df y % d $ ! 8d 6 87 \" $89 3f y p9 %7 \" a 89 if h\" $ %r %9 d a& \" a& c a\" ff f h 87 t 89 q d 89 %i 9 %q d $ v' x\" of yi \" a\u00a8& c ! 8 69 d \u00a6& f h 8 & d@ b 6 c f yi e if ht u i d8 & xf @ c h 8 6r \" ar rc a e7 r8 & xf h 9 %\" $\u1e27f \u00a6' x\" of yi 9 dc a e7 )r 69 i \" $& 9 %d $c a & xf 5 6 f y\" a 9 d ef h )f yi r7 8 gf hi @ f yi c h e7 dr % 9 % i 4 q gf h7 e 8& r 3f h7 8 # 87 \u00a3 %df hi u' x\" a7 gf yi \u00a3 @ f yi dr % 9 % i 1 o\u00e8 2 t f yi xf y 3f y9 d 8 %& f \" a& a % # f y\" a 9 %d ef y }f yi \u00eb c vq 8 d @ 8 & xf y 69 \" a\u00fff h& )f hi 9 if \" a\u1e85f y 6\" $& % # % xf h\" $ %9 d f y )f yi 6 r % 9 %c m& \" yc 8 8t qf \u00a9e g & e # & f h 8c @ v8 8 6 8\u1e27f d $ %r \" ad 6 r % 9 %c hc a\" $r v89 \u00a8q }\" a\u00fff h e7 8 87 q he 8d $9 %& & \" $@ \u00e5e #\" $r if yi (& !f p\u00fe \u00f8 \u00f5 @ s@ b !f y\" a 5& xe gc vq d a& \" $\u1e27f h c v gf y 9 %d $d fe d7 \" a& x\u00ee ! \" a\u00fff p& !f y& x \u00f6 i\u00f6 st \u00e7f \u00a9e g # i 8 5\" a& 9 @ !f y\" a p@ b 6 c ae s\u00eb s\u00ec \u00f8\u00ed \u00fa\u00ea {f y )f yi 5& !f \u00f3 x x \u00f6 \u00a1 8\u00f6 \u00f9 t w \" $0 % x 6\" $8\" a 9 d c h e7 8& 4 \" a8\" $ 9 %d f \u00a9e g 8& u89 %\u1e85q # 58 %c h gf h h7 vq ye { \" a 89 if h\" $ %\u00a3 c 8 @ 89 if h vr % 9 % i & t l %& xf y 69 \" a\u00fff h& %9 ' ) 8d ad fb f \u00a9e g \" ar g 9 6 d& c c ac h9 % \" yc 8 87 \" a\u00a1h s\" ar t \u00b0 t }u i ai \" a8 a %@ v9 @ b9 %c h\" ad fe w @ & c !f h& x \u00f6 \u00a1 i\u00f6 }\" $& \u00a6& c %c h !' 5i 9 if 9 6q \" ff y 69 e yt u i \" a& \" a& i' xi he \u00a3c h e7 \" ar a\" a& c h % @ b 7 9 %c h 8\u1e27f y9 %d qf hi 9 df \u00a9e g \" ar h\" ap8 %8 6 8\u00fff xd a r %\" $ %r 69 c ac h\" ar %t u i )f \u00a9e g # a& e #& f h 8c 8c h d a ce 87 {q ye y \" ac h9 8d a9 & & \" $ 8& 5@ b !f y\" a & xe gc vq d a& 5\" $\u1e27f y p& \" f 7 \" $& x\u00ee \u00fa \" $\u1e27f & c !f h& \" $\u1e27f y 8r % 8 & 4 \u00ea 9 3f y\" ar ib c # %\" $\u1e27f ps c vq # 8 6& 4 & xf y 6\" $r %& 4 8!f y % & 4 d a\" $& xf y& d9 7 @ b !f h & xf h !f h 8& 4 9 %7 x 6 i \" aq \" ff h& 9 \u1e27e )f \u00a9' ) @ \u00fcf hi 8c @ b %c & ci 9 % \" ar (f hi (& 9 c a 9 if hi t ud of yi % r i f yi \" a& e\" $& e9 ui 8 6\" $& xf y\" ap8d $9 %& & c\" a 89 if h\" $ %\u1e8dq 9 & 87 x %f yi p@ b9 %!f f yi 9 3f \u00abf yi 8& 7 \" $ 8 6 8\u00fff f \u00a9e g 8& 7 } if v& c\" ac v d ff h9 8 % & d fe {9 89 \" $\u00e4f yi x& 9 c a x 9 if hi w\" $pc h %& xf %r 9 %c h& 4 9 ! g 8 \" $c a 8\u00fff a c 8& f yi 9 3f h\" ff a\" a& q # 8 8 8\" a9 d iq # 3f yi }f y f hi d # c' ) 8 ) %@ v 8 6 u7 !f y 8!f y\" a 9 7 f h f hi t e 9 d a\" ff \u00a9e \u00a1 @ e 8 6 8 % 6 8!f y\" a \u00a84 9 & s' ) ' x\" ad $d & 8 \" $\u00a8 8!f yt z t $ a h h % \u00ed \u00a1 x\u00a2 h \u00a1 \u00a3 8\u00a4 2\u00ef p\u00a5 6\u00a5 \u00a2 %\u00a5 5\u00a6 s\u00a2 %\u00a5 \u00a5 \u00a3 8 \u00a7 y\u00a1 \u00a2 g\u00a9 g\u00aa \u00a1 \u00a3 \u00e8 s k e \u00a6h gu r s 2\u00a5 u p\u00f0 4 @ 9 h@ !f y\" a & xe gc vq # %d e88 6\" $r a9 if \u00a5 \" $\u00efh v % w vt s k e p \u00fbu d ) \u00a6\u00a5 w\u00f0 ) \u00a6\u00a5 v 4 @ b % r9 v 9 % \" a9 q d a 88 6 \" ar q # 3f yi \u00a39 if \u00a5 \u00a19 7 \u00a5 v \" a\u00a8h % w xt s j tp \u00fbu w 4 ae \u00e7 c\u00e8 \u00ef\u00e9 b\u00ea s 2% s 2\u00a5 v 4 \u00fbu u\u00f0 \u00f4 b\u00f5 (s 2\u00a5 4 \u00fcu r\u00f0 (s 2\u00a5 v 4 \u00fbu 6u 4 @ b % 9 9 6\" $9 %q d a a !b 8 6 \" ar hq if hi 9 3f \u00a5 p\" $\u00efh 9 7 9   if \u00a5 v \" $\u00eft t s fe \u00a6\u00ac \u00fbu d ) w\u00fd d %\u00f6 \u00eb \u00e4 (\u00f0 ) \u00fd \u00fb\u00f6 \u00ec \u00e4 4 @ b % 9 a \" $ 89 3f y\" a pq 7 ge wr %9 d \u00fct h s\" ar 6 \u00b2 u e # # h8 & xf h 9 \" a\u1e27f y& v\" $c a # %& 87 q he 9 v 6 r % 9 %c \u00ae8d $9 % & h bp \u00a8r it u xw f % x9 r %9 d 8d $9 % & xp sr w xt \u00fb p \u00e3 w\u00fc \u00fd \u00a5 g i\u00bf \u00a5 \u00fc \u00bb \u00e5 q\u00fe (\u00ff a\u00bb 2\u00fe \u00bd vae \u00fe \u00fe (\u00ff 2\u00fe q qi 8d9 d8 %8 6 h\u1e27f rd $ %r \" a 6 r % 9 %c 8 \u1e27f y9 %\" $& 9 %d 8 6 4 \" ff \" a& \u00ab 8 xe wd $\" a0 8d oe s \u00f8f yi % r i if h9 %d f' )9 ce #& f yi d89 %& 8u f yi 9 3f \" of y& r8 %c hc v \" a89 if h\" $ %{ 6 if h e8 d a& q 88 c a d\" $8 & \" a& xf y 8\u1e27f 9 7 }f hi v& !f d %@ \" of y& uc h e7 8 %& xf y 69 \" a\u00fff h& uq # 88 c a 8& ) & 9 3f y\" a& c 9 %q d $ 8t \u00e0' x 6 r d& xe gc vq d e88 6\" $r \u00a19 if & c a 9 if hi \" $& ad $\" a0 % 8d fe f y \u00a1\" $c a # %& c 9 \u00a1c h e7 d8 %& xf y 69 \" a\u00fff p\" $8 & \" a& xf y 8\u1e27f ' x\" of yi 8 %& xf y 69 \" a\u00fff h& 8 6 8& 8\u00fff h\" $r rf yi \" a\u00fff h 87 87 & c 88\" $ 89 3f y\" a t u i 8\u00a84 & & \" $8\" a & & xe gc vq # %d $& \u00a689 q rd $ e89 3f y 87 q he \u00a38 %c h gf h\" $r a9 dc h\" a\" $c a9 d \" a8 gb & \" $& xf y 8\u1e27f d& q & c !f d %@ sc h e7 v8 & xf y 69 \" a\u00fff h& 4 q 889 & f yi c a\" $\" ac h9 %d \u00ab\" $8 %& \" $& xf y 8\u1e27f & c q & !f c v & xf a\" $ & t c h\" a\" $c a9 d \" $8 %& \" $& xf y 8\u1e27f )& c q & !f 89 q # 8 c h gf h 87 } 8 a8\" $ 8\u1e27f yd oe p & \" ar v9 5& c\" ac h d a 9 d ar % \" of yi c & i c' xv\" avh i\" $r %t s ht pw !f \u00f0 \u00f3 ' x \u00f6 i\u00f6 \u00f9 q # p9 c v d of y\" a& !f @ e8 & xf y 69 \" a\u00fff h& t u i v9 %d $r % 6\" ff hi c 7 & 9 & \" ar %d $ 5c h\" a\" $c h9 %d e\" a8 & \" a& f h 8\u00fff & q & !f gm @ b %c ' xi 8 \" $& \" a8 & \" $& xf h 8\u00fff ht \u00ab qi 8 \" a& 8 & \" $& xf h 8\u00fff 4 f hi 9 d ar % \" of yi c f y 8 6c h\" a9 if h 8& ' 5\" ff hi qm \u00f0 \u00f3 y\u00f9 t \u00a4 t \"\u00a1 5\" $& 9 a& 8d $@ b \" a8 & \" a& f h 8\u1e27f v8 & xf y 69 \" a\u00fff 5 & 87 p9 %& 9 a& 8\u1e27f y\" a 8d at u i 89 %7 8 & i9 % 6 8@ b 8 6 87 f y d1 o 2 @ b % \u00ab9 ) e %@ %@ gf yi c h\" a\" $c h9 %d $\" of \u00a9e @ 7m 4 9 & w' ) 8d $d e9 & 9 6\" $ % & ! ef y 8& \" a & @ f hi x9 %d $r % 6\" ff hi c ht \u00a2 if h f hi 9 if f yi 59 d ar % \" of yi c 89 q # 5 6 89 7 \" ad fe ! ef y 87 87 pf h v 7 \" ar vc v d ff h\" $ d a }q r & x9 if 8 8t u i 9 if \" a& 4 %8 ' ) i 9 c }@ b % 7 9 c h\" a\" $c a9 d \u00ab& q & !f a8 c 8 \" ar 9 dq r 4 ' ) 89 \u1e85 6 89 d oe pf yi v9 d ar 6\" ff hi c f h xf yi v 8& xf d @ f yi 8 %& f h 9 %\" $\u1e27f y& t \u00a3 \u00a8\u00a4 \u00ee \u00a6\u00e2 \u00be \u00f2 \u00eb \u00e9 \u00e8 \u00ea \u00f1\u00ed \u00ee \u00f6 \u00b3\u00e4 \u00a6\u00e2 \u00e0 \u00bd \u00e8 \u00ea \u00f1\u00d7 x\u00e2 \u00e4 0\u00ee \u00a6\u00e2 \u00e8 \u00e2 \u00ea \u00e0 \u00be \u00e8 \u00e2 ! \u00ea \u00e0 \u00e2 \u00e4 \u00e2 \u00e8 \u00e0 \u00ea \u00f1\u00e9 \u2022 \u00e9 \u00ec \u00ed \u00ee \u00e2 p\u00e9 \u2022 \u00e2 \u00e7 \u00e8 \u00e9 \u00e7 x\u00e9 \u00e0 \u00e2 \u00e4 0\u00ea \u2022 9\u00a5 \u00e9 \u00a3\u00a6 \u00be \u2022 \u00e4 0\u00ed \u00be \u00f4 d\u00e2 \u00e0 \u00ea \u2022 \u00ed \u00e9 \u00be \u00bd \u00bd \u00e9 \u00bc \u2022 \u00ed \u00e0\u00ed \u00ee \u00e2 \u00bd \u00be \u00e0 \u00e2 \u00a8\u00e5 \u00e0\u00ee \u00e2 \u2022 \u00a8 \u00a7 \u00ea \u00e0 \u00e0\u00bd \u00e9 \u2022 \u00e0 \u00ea \u00e0 \u00ed \u00e2 \u2022 \u00ed \u00ba \u00b6 \u00ed w\u00ed 0\u00ee c\u00ef \u00f0 \u00f1 t\u00f2 \u00f4\u00f3 \u00b4\u00f5 x\u00f5 \u00f5 \u00a8 \u00a9f x q\u00aa \u00a4 t \"\u00a1 e m \u00aa \u00f3 y\u00f9 e \u00ab d\u00ac $ 5\u00ae f\u00afm \" a& 8 & \" $& xf h 8\u00fff y\u00b0\u00b1 \u00b2 \u00aa m e \u00a7 \u00aa p xe \u00ab d\u00ac $ 5\u00ae f\u00af\u00b2 \" $& 8 & \" a& xf y 8\u1e27f \u00b0\u00b1 \u00a7 \u00aa \u00a7 o\u00b3 \u00eb 1e \u00b2 \u00aa \u00b2 \u1e55\u00f3 ' \u00a8 \u00f9 \u00b5 \u00b0\u00ab r\u00ac f\u00ae 5\u00afe m \u00aa m \u1e83\u00f3 ' \u00ef\u00f9 \u00b5 \u00b0\u00ab r\u00ac f\u00ae 5\u00afe 5 \u00b6 \u00a7 p\u00f0 \u2022 \u00b3 \u00eb x\u00b8\u00ac \u00b5 m \u00aa \u00f3 y\u00f9 g\u00b9 h i\" $r % \u00b2 ud ar 6\" ff hi c m@ b % 8 %c h gf h\" $r a9 ac h\" a\" $c h9 %d \" $8 & \" a& xf y 8\u1e27f x& c q & !f \u00ba \u00a6 ! g 8 \" $c a 8\u00fff r& i c' x& if hi 9 if \u00a6f hi r9 c 8 9 %r r& \" yc h u @ c h\" a\" $c h9 %d g\" $8 %& \" $& xf y 8\u1e27f & q gb & !f y& 5\" $& 5 9 3f yi 8 & c h9 %d $d 4 9 %7 f yi h& q & !f y& x8 %\u00fff h9 \" a\" $r pc a 6 f hi 9 \u00a8\u00eb ip 8d a 8c h 8\u1e27f y& x9 % & 89 68 8d fe @ b % 7 t vu i v& \" dc 8 v %@ sc h\" a\" $c a9 d \u00ab& q & !f y& pf h & u gf f y q v\" a7 8 # 87 8\u00fff %@ f yi )f h if h9 d s\u00eb c vq 8 @ p8 & xf y 69 \" a\u00fff h& 4 9 7 \u00a1c h %& xf \" $8 %& \" $& xf y 88\" a 8& 89 q # a ! g d a9 \" a 87 q he \u00a38 %& f h 9 %\" $\u1e27f y& \" $c a # %& 87 dq ye w9 d& c h9 %d $d g 69 r % r %@ e 6 r % 9 %c f y ! ef ht u i \" $& \u00a6\" a& 7 f h uf yi 87 7 9 %!e \u00a1 %@ \u00abc a e7 r9 7 df \u00a9e g # r8 & xf h 9 \" a\u1e27f y& t \u00bb \u00bc \u00a2 \u00fd \u00ff ae \u00bd \u00fd \u00ab\u00e3 a \u00bd t\u00e3 r\u00be w\u00a2 }\u00bb a\u00bb p\u00a5 \u00fc }\u00bb l %& # %d y' x\" of yi c h % \u00a6 e88 6 88 8& t v c h\" a\" $c a9 d e\" $8 & \" a& xf y 8\u1e27f & q & !f \" $8d a 7 8& i 8\" of yi 8 s x % q # if hi u @ f yi 8c at y \" $c a9 @ b e8 & 8& \u1e8d 6 r % 9 %c h& q' x\" of yi 59 & c h9 %d $d %s c vq # 8 %@ 8 6 % & \" $ 9 6\" $9 %q d $ 8& t u i \" a& c h9 e }& % 7 x 8& xf h \" a6f h\" f 4 q gf 8 %8 6 8\u00fff d a r %\" $v 6 r % 9 %c h& \u00abi 9 c t e \" of y v\u00ea 9 3f \u00a6& xe g\u1e27f y9 %!f y\" a& xf y 6 !f y 6 8& as 8 c a 9 87 }' x\" of yi w if hi 8 )d a9 r % 9 r % 8& u )9 %7 \u00a3\" $& xf y 89 %7 \u00a3c h9 %0 i 89 c ee & c %@ $ a h h % \u00ed \u00a1 x\u00a2 h \u00a1 \u00a3 8\u00a4 2\u00ef p\u00a5 6\u00a5 \u00a2 %\u00a5 5\u00a6 s\u00a2 %\u00a5 \u00a5 \u00a3 8 \u00a7 y\u00a1 \u00a2 g\u00a9 g\u00aa \u00a1 \u00a3 n l c a gf y 9 hc a\" $\" ac h9 %d \" $8 & \" a& xf y 8\u1e27f x& c q & !f 5 @ ec h e7 8z if \u00a9e # # 8 & xf h 9 \" a\u1e27f y& e \u00e0 ef y 69 !f 5& & \" $8\" a & s q9 % \" a9 q d a 5& xe gc vq d a& @ b 6 c qf yi & q & !f e \u00e1 \u00aa \u00eb \u00a6e m \u00aa \u00f3 y\u00f9 e \u00ab r\u00ac f\u00ae f\u00afg w \u00e2 \u00e3 \u00e1 \u00b0\u00b1 \u00b6 \u00b1 \u00e4 \u00e5 lae i\u00ac ' )9 ce \u00a1 @ \u00ab 6 !' x 6\" ff h\" $r \u00e1 & xe gc vq # %d e88 6 88 8& \u00e7\u00b0\u00b1 f \u00b6 f yi !' 5 \" of f h 8p 6 r % 9 %c mq 88 c a 8& s' ) 8d $d ob cc h e7 87 z if e g # 87 \u00b8\u00ac $\u00b5 u7 7 df hi \u00a6' )9 ce %@ \u00ab !' 5 \" of y\" ar    )f y dm \u00e8\u00b9 \u00b5 \u00b0 \u00b6 \u00b1 \u00e4 e \u00e1 \u00aa \u00e1 \u00b3 \u00eb \u00b5 \u00b0\u00ab d\u00ac $ 5\u00ae fh i\" $r % \u00b2 u i rq 9 & \" a59 d ar % \" of yi c \u2022@ b % 9 % gf y %c h9 3f y 87 8 6 8 % 6 8!f y\" a \u00a8 9 6\" $9 %q d a 8& t \u00ba e ! g # 8 6\" $ 88 f h 8d $d a& f yi 9 3f \u00a69 c h9 \u00fb\u00ee ! % \" ff e @ e& \" $c a d $ p %r 69 c 8 6 & e9 6\" $& 8& @ b 6 c \u00b3f yi v 8 6 8 % & r & @ g 9 6\" $9 %q d $ 8& 4 @ b % ' 5i \" $i }f yi v& # f d @ 9 & xf h9 if y\" adc a e7 9 7 df \u00a9e g # r& xe g& xf y 8c m9 %7 p7 8q r %r \" $r )f y e %d $& 9 6 \" a\u00ff e9 d a 9 q d $ 8t u i \" a& f y 8i \" $t e 5\" $& 9 % d $\" a89 q d $ 59 d a& rf y hc v gf y9 3f y\" a & q # !f \u00a9' ) 8 8v9 h8 & xf h9 \u1e27f v9 7 9 9 6\" $9 %q d a \u00a6& xe gc vq # %d 4 q # 889 % & c c h e7 9 7 f \u00a9e # # \u00a68 & xf h 9 \" a\u1e27f y& s9 6 \u00a6\" $c a # & 87 d9 %d $& ) 8 gb & xf y9 %\u00fff & e #c vq # %d $& t \u00e0 8\u00e4c v gf y9 3f y\" a & q !f \u00a9' ) 8 8\u1e278 %& f h9 \u1e27f & xe gc vq # %d $& 8 % d $7 dq # 8 % 6 8!f y 87 q ye pf & c h9 %d $d r 8r %\" $ \u00e0 %@ v %r 69 c f y ! ef s 8!f yt r u 6t t \u00b0d a9 6r 8 @ b % c a9 8 \u00a3\" $c a c !b c h 8\u1e27f x' 5\" $d ad f hi 8 8@ q 9 %i \" a ! 87 q ye 9 %9 d oe c 8\" $r af yi %& }8 %& xf y 69 \" a\u00fff h& x\" $c a # %& c 87 {q he f yi v& & c 8!f y 87 \u00a1 6 87 \" $89 3f y 8& r9 %7 \u00a3\" ff h& r8d $ %& 8d fe | 8d a9 if y 87 \u00a3 87 \" a89 if h 8& rq # 8@ b % f yi u' 5i $& xf y 8\u1e27f v& q & c !f h& \" $7 \" a89 if h\" $r f yi & 9 c a r8d a9 & s x9 %& \" ah s\" ar t z u 4 9 7 c a9 0 % 8& if yi 8c \u2022q # 8d a r uf y uf hi & c9 %c h )r 6 ' xi \" ai d $9 e g& (f yi 6 d a r @ \u00ab9 h \" ff 5 @ e& c 89 % i \" $r h9 %d ff h 8 9 3f y\" o w 8& 9 %r 9 %\" $& xf 5 8 6 6& t \u00e2 r 8 gf hi gb \u00e1 & 89 6i v @ 9 %d ff h 8 9 3f y\" f 8& e\" $& \u00ab89 6 \" a 87 x gf \" $7 8 # 87 8\u1e27f yd oe @ b % \u00ab 89 i vr 6 t  \u00a7 f {\" $& # %& & c\" aq d $ }f y 87 8 \u00a18 c a gf y9 3f y\" a f y\" ac h q he qi 80 e\" ar ' 5i !f yi 8 9 8 8 xf h9 \" a !' 5 \" of y\" ar 89 %\u00a8 & & \" $q d oe q7 \" a& c& %d f \" a8 & \" a& f h 88\" $ 8& @ v9 %d $d c h\" a\" $c a9 d r\" $8 %& \" $& xf y 8\u1e27f & q & !f y& d\" $\u00e09 r 6 q # 8@ b % \u00a39 %!f y 9 %d $d oe 8 %c h gf h\" $r c h e7 8& 9 7 |f \u00a9e g 8& 4 ' 5i \" $i \u00e0\" $& 89 d ad $ 87 u\u00e3 \u00f8 e\u00f4 # s\u00e4 g! 1# \u00f0 \u00e5# s\u00e4 yt vu i \" $& (\" $& ( 8 8!f h\" f q 889 & i' 5i 8\u00e4& c %c h \u00a6& q ye \u00a3 @ f yi r % % & 9 %7 8 %& \" $& xf y 8\u1e27f x 9 f yt u i 8 & \" a& f h 8\u00fff 5 9 % xf \" a& if yi r& !f %@ e9 %d $d 8 %& f h 9 %\" $\u1e27f y& i' xi \" ai 7 if 5q # 8d a r f y a9 %\u00ffe wc h\" a\" fb c h9 %d #\" a8 & \" a& f h 8\u00fff u& q & !f yt u i 8 6 8@ b 6 4 if u9 d ad #8 & xf h 9 %\" $\u1e27f y& v\" ac h & 87 q he af yi ' xi %d $ %r 69 c f y ! ef 9 6 8 & \" a7 8 87 \" a} 8 6 % 8 6 8!f y\" a t \u00a6y \" ac h9 5 8c h d a ce g& v& i 9 9 %d $r % ib \" of yi c & )f yi 9 3f \u00a6f yi u& 89 6i @ 9 d of y 8 69 if h\" f 8& @ b % % rr 6 dc h9 ce w if q r\" $\u00ea 88 87 q ye |f yi 9 3f v@ b % h9 % if hi 8 r % % t ud of y 8 69 if h\" f 8& @ b % 7 @ b % h9 r 6 7 if p9 %d f' )9 ce #& \" $8d a 7 9 p\" a\u00fff h 87 87 8t  \u00e7 \u00e2 \u00ff 2\u00fc a g\u00fd \u00fe \u00bd v\u00a5 \u00fc \u00fd t i\u00e8 \u00fd \u00e9 }\u00e3 z\u00fe \u00be \u00ea\u00e9 w\u00bd \u00fc \u00bc \u00ff \u00e3 r m\u00bd \u00fc w \u00be \u00bf \u00e1 p\u00e3 g \u00eb \u00f8\u00ea \u00a8\u00eb \u00ec 0\u00d7 7\u00f0 \u00f6 \u00f8\u00d7 7\u00f0 \u00a8\u00f9 \u00f0 \u00ed \u00f0 \u00a8\u00e0 v\u00f5 \u00ea\u00f2 \u00f4\u00f3 \u00a8\u00f9 \u00ee $\u00d7 7\u00e0 v\u00ed (\u00f9 \u00f0 \u00a8\u00ef \u00ee $\u00ef y \" $c a9 w& 89 6i 8& 9 d of y 8 69 if h\" f }& d a gf y\" a & v & \" $r wc a e7 }9 %7 vf \u00a9e g # }\" a@ b % c h9 3f y\" a \u00a84 q gf @ b f y 9 3f y 8d oe 4 c v d %7 z % sf hi q # e7 ge w @ \u00ab9 h8d $9 % & 4 t \u00a6f \u00a9' ) h % c a 6 \u00a6f y\" ac h 8& 9 %& 9 6r c h 8\u1e27f y& @ wf hi & 9 c a 5q # e7 ge wr %9 d $t \u00f2 \u00f3 \u00e4 5\u00f4 \u00b8 fae i\u00f5 \u00f3 \u00ae f\u00f8 \u00f7 \u00a7 f \" $& hd $ 8& & ad $\" a0 % 8d fe |f hi 9 if p9 \u00a1d $\" a& xf v9 7 \" of y& h 8d $ 8c a 8\u00fff h& h9 6 d @ pf hi & 9 c a f \u00a9e g # 4 f hi 9 if x\" $& 4 \" of v\" $& d $ 8& & d $\" a0 8d oe f yi 9 3f v9 9 6\" $9 %q d a x e88 6& q # 3f yi \" $p& c %c h 9 if hi d\u00a5 9 %7 p\" a\u00e4f hi 9 if hi %@ \u00ab\" of y& 8d $ 8c a 8\u00fff h& q\u00a5 \u00ab\u00fd } \u00fa\u00f6 \u00eb \u00e4 6t  \u00d7 8\u00f5 \u00f2 \u00fc\u00ef \u00f1\u00e2 8\u00ee i\u00f4 b\u00f5 e\u00ef \u00f1\u00f2 d\u00f4 b\u00f2 \u00df \u00d7 8\u00e2 \u00a1 \u00a3\u00e1 \u00f4 \u00fa\u00e4 h\u00e1 \u00fe \u00ef \u00d7 \u00e0 \u00a3 \u00a3\u00ee i\u00f5 \u00f4 b\u00f5 e\u00ef 5 \u00f5 $\u00a2 ' \u00a3\u00a2 \u00a3\u00d7 8\u00f5 $ t w \u00a7 \u00a9|r 8 8 69 d 4 & xf y 6 r 8 c h e7 8z if \u00a9e # # h8 & xf y 69 \" a\u00fff h& vc h9 %0 % 9 v %r 69 c d $ 8& & r 8 8 6\" $`4 9 7 f hi 5 ! g 88 gf y\" a v @ #f hi v 6 r % 9 %c c h % xd $\" a0 % 8d fe f y 87 v\" $p@ b9 \" ad $ 6 8t u i 8 6 8@ b % \" of \" $& p 89 %& 9 %q d $ f h x\" a& c\" a& xf pf yi 9 3f vf hi 8 %& xf y 69 \" a\u00fff \" $c a # & 87 }9 5 %r 69 c & i d a7 q 9 & s' ) 89 0 9 & # %& & c\" aq d $ 8t k u 8 \" a& xf y\" a\u00a3\u00b1 d $ 8& \u00eb t \u00eb 9 7 \u00eb t $ |9 % \u00ee ! & xf h\" $ 87 \u00e09 d a& \" ${f yi w& 8& f yi 9 3f \u00a1d $ %r \" ah9 %d 9 6\" $9 %q d $ 8& a9 % & c 87 @ b % a !b f h ib c % 8 c hc x \" a89 if h\" $ %c a 6 @ b 8t s 8\u1e27f yd oe f hi 9 @ b % !b f h ib cc a9 \u1e27e % % !b f y 3b qc h 8 6 8 %c hc v \" a89 if y\" a t d $ %r \" a89 d q 9 6\" $9 %q d $ 5 & 87 p@ b % % !b f y 3b c v8 c ac v \" $89 3f y\" a \u00a3 e88 & u 8\" of yi 8 ! g9 !f hd fe f \u00a9' x\" a8 \" $\u1e27f yi 8d a9 & q 7 ge { % u ! eb 9 !f hd fe v %8 r\" $\u1e8df yi )8d a9 & ri 89 7 9 7 d %8 r\" $\u1e8df yi )8d a9 & rq # e7 ge t i 9 q 7 ge vr % 9 %d 9 & )\" a\u00a3k u 8 6\" $& xf y\" ad\u00b1 d a \u00eb t a 8\" ff hi h u 88 8\" f 8& r7 d a\" $89 3f y 7 9 if h9 d@ b 6 c f9 3f yi 8 ur %9 d i 8 c ac v \" $89 3f y 8& s' x\" of yi \" of y& 8d $@ 4 ' xi \" ai 9 6 5q if hi d a\" $0 % 8d fe gt h w k u 8 6\" $& xf h\" $\u00f9\u00b1 d a \u00ec %4 d $ !f y\u00fb {q )9 f \u00a9e # # v 9 6\" $9 %q d a )9 7 \u00a7 \u00a3t q\u00fc gs \u00fb eu vq # vf hi )d a\" $& xf \u00a6f \u00a9e g # ' xi %& d 8d $ 8c h 8\u1e27f y& a9 6 %@ f \u00a9e g u\u00fb et u i 8\u00a3f yi d a \" $& a 8t s \" f e9 %d $ 8\u1e27f hf y \u00a1& 9 ce g\" ar f hi 9 if 8 & xf h 9 %\" $\u1e27f x\u00fb w\u00f0 \u00a7 \u00a3t q\u00fc gs \u00fb eu p\" $c a # %& 8& 9 5& xf h %r f \u00a9e g # 8 & xf y 69 \" a\u00fff q\u00fb w9 7 }\" a& f yi 8 6 8@ b 6 d $\" a0 % 8d fe %t y \" $c a9 6\" $ % \" of y\" yc h 8& pc v d ff h\" $ d a u9 d of y 8 69 if h\" f 8& \u00a6q he p\" $c a # %& c\" ar v8 8 f y9 %\" $} # 89 %d ff \u00a9e p # \" a\u00fff h& d $\" a0 % hd oe & e #c vq # %d ( e88 6 88 8& t {9 %d ff h 8 9 3f y\" o w )' x\" of yi {9 d $ c' ) 8 # 89 %d ff \u00a9e # %\" $\u1e27f i 9 & 9 ai \" $r %i 8 6\" $ % \" of \u00a9e yt \u00eb \u00f8\u00ea \u00a8\u00fc \u00fd \u00fe\u00ee o\u00f0 \u00a8\u00e0 v\u00ff \u00e5\u00f6 \u00f8\u00d7 7\u00f1 \u00f0 \u00a8\u00e0 v\u00f5 \u00a1 6\u00ee $\u00f9 \u00ee o\u00f1 \u00f9 \u00f0 \u00f6 \u00f8\u00e0 v\u00ec \u00f6 \u00a3\u00a2 0\u00ee $\u00d7 u i \u00a1 q \u00ee ! 8!f h\" f { @ vy \" ac h9 \" $& df h 7 8q r 9 %r 69 c \" $f yi 9 q & 88 %@ v ! g d $\" a8\" ff 7 88d $9 % 9 3f y\" a & t pu \u00ab 8i 9 8 f yi c' ) 8 e %@ \u00fcf hi 8 6 7 !f y 8!f h\" $ %' 5\" ff hi 5\" $c a d $\" a8\" ff vc a e7 8& 9 7 f \u00a9e g 8& 4 y \" ac h9 h 8c h d a ce 87 af yi @ b %d $d a c' x\" ar \u00a5\u00a4 g y\u00ef \u00a3# y\u00ef \u00f1\u00f4 !\u00d7 8\u00f5 \u00f1 \u00f8 \u00e1 h \u00f2 \u00b2 \u00a6 \u00af\u00b8ae \u00b8 \u00b1 \u00b5 {\u00f5 \u00f3 $\u00ae 5\u00af\u00f6 \u00f7 \u00eb t 9 6\" $9 %q d $ ' 5i \" $i v e88 6& \" $v9 }8d $9 % & xr % 9 67 vc v & f v e88 9 d a& \" $\u00e4f yi i 89 %7 @ f yi 8d $9 % & 8t \u00ec t u i a& 9 %c h u q9 % \" a9 q d a dc v & f h 3f h e88 r %q if hi & \" a7 8& @ 9 \" a 89 if h\" $ %q e7 ge \u00a1r %9 d s x 9 % xf h\" $9 %d e88 b ci 80 eu t \u00a6 \u00af\u00b8ae \u00b8 \u00b1 \u00b5 {\u00f5 \u00f3 $\u00ae 5\u012b\u00f8 x\u00f7 u i }9 c a } %@ \u00a69 v& \" ar %d $ !f h p 9 6\" $9 %q d $ c v & f }q # 8r %\" $' x\" of yi |9 7 8 6& c8 % j r k t $ a h h % \u00ed \u00a1 x\u00a2 h \u00a1 \u00a3 8\u00a4 2\u00ef p\u00a5 6\u00a5 \u00a2 %\u00a5 5\u00a6 s\u00a2 %\u00a5 \u00a5 \u00a3 8 \u00a7 y\u00a1 \u00a2 g\u00a9 g\u00aa \u00a1 \u00a3 \u00eb u i rq # 3f yi \u00e2 r !f h 8!f y\" a \u00b1 d a 8& 9 6 r gf h\" $ 9 %d 9 7 89 q r & 87 & c 8d a 8!f y\" o 8d fe \u00a1\" $y \" ac h9 %t p d\" $ %d $9 3f y\" a d @ 7\u00e2 ) !f y 8!f y\" a \u00b1 d $ \u00eb t \u00eb c a 89 & s7 \" $& 9 % # 89 % 9 8 @ 9 )r % 9 67 r %9 d 9 @ f y 8 6c h9 %d $\" yc 89 if h\" $ 1 \u00eb 3p %2 a4 ' 5i \" $d a g\" $ %d $9 3f y\" a %@ x\u00e2 r !f h 8!f y\" a \u00b1 d a \u00eb t \u00ec c h 89 %& @ b9 \" ad $ 6 v @ 6c h9 %d $\" yc 89 if h\" $ t t\u00e2 r !f h 8!f y\" a \u00b1 d $ \u00ec \" $& \" a7 8\u00fff h\" $89 %d f y a 6 8t e 8& xf y\" ar f hi 7 88d $9 69 if h\" $ % @ 9 6\" $9 %q d a 8& (f yi 9 3f 5\" $c a # & & xf y 6 r ac a e7 r8 & xf y 69 \" a\u00fff h& t f\u00e2 ) !f y 8!f h\" $ %\u00b1 d $ \u00ec \" $& 8 8!f y\" o w q # 889 % & c d9 dd $ %r \" ah9 %d g 9 6\" $9 %q d a d\" $\u00a19 8 6 8!f h %r 69 c \u00b4\" $& )d $\" a0 8d oe wf h e88 vf \u00a9' 5\" $8 a\" $\u00a19 8d $9 % & xs \" $t a 8t 4 @ b % !b f h ib c % 8 c ac v \" $89 3f y\" a u 4 \" $)' xi \" ai h89 %& c 9 \u00a6 9 6\" $9 %q d a i' x\" ad $d gf y 6\" $\u1e27f y h9 a& \" $r %d $ !f h p\" a@ e 8\" ff hi h e88 6 88 5\" a& c h\" a& c& \" ar t u i \u00a6& 68 %@ 9 d 8 6 \" ff hi \u00e2 r !f h 8!f y\" a \u00b1 d a 8& 9 r %9 \" $t \u00a6 \u00a7 \u00a9d8 %\u00fff h 9 %& f 4 c h e7 u9 7 xf \u00a9e g u9 9 %d fe g& 8& c h9 ce v 8 87 889 %d fb 8 d $9 3f y\" a @ f yi \u00a6' 5i d a 5 %r 69 c \u00b0s 8!f ht t \u00ec u 6t \u00fb p \" a 6\" ff h\" dc 8\" ar ' 5\" ff hi k u 8 \" a& xf y\" a\u00b1 d $ \u00eb \" $\u1e27 w %d f 8& %d fe \u00e0& & # 8!f h 87 8d $9 % & h& 4 9 7 \" $& ui 89 % # 8 f yi 9 %vc h e7 v9 7 f \u00a9e g x9 9 %d fe #& c 8& t v\u00fb \" a \" of y\" yc 8\" $r ' x\" of yi wk u 8 \" a& xf y\" av\u00b1 d a \u00ec 8 87 & sf \u00a9e g # r9 9 %d fe g& \" a& 4 9 7 \" a& # 8 @ 6c h 87 9 %@ \u00e5f h 8 sf hi ri 80 d %@ w' ) 8d ad fb f \u00a9e g 87 8& & xs \" $t a 8t 4 u7 7 df hi \u00a6' )9 ce %@ \u00ab !' 5 \" of y\" ar )f y qm \u00a1' x\" of yi \" ff h& 6\" $ % \" of \u00a9e \u00ab7 !f y 8!f y 87 dq ye \u00e2 ) !f y 8!f h\" $ %\u00e4\u00b1 d $ 8& i\" $& i9 q9 % \" a9 q d a \u00a6& xe gc vq # %d q\" a9 a8 8 xf h9 \" $d8d $9 % & 4 9 7 \" $& \u00a6@ b 7 \" $7 8 87 8\u00fff hd fe \u00a3 @ c h\" a\" $c a9 d \" $8 %& \" $& xf y 8\u1e27f 5& q & !f y& @ \u00a6c a e7 9 %7 pf \u00a9e g # }8 %& xf y 69 \" a\u00fff h& ct y \" ac h9 v \" $@ b % c ad fe 7 89 %d $& ' x\" of yi 9 a q9 % \" a9 q d a }& xe gc rb q # %d 7 !f y 8!f y 87 vq he 3\u00e2 ) !f y 8!f y\" a p\u00b1 d a h& q ye {8 %& c\" a7 8 \" ar \" ff x9 %& 9 hc h\" a\" $c a9 d \" $8 & \" a& xf y 8\u1e27f & q & c !f ' x\" of yi 8d $ 8c a 8\u00fff 4 9 %7 r % % & \" of ' x\" of yi 3f yi 8 & q & !f y& t \u00eb \u00f8\u00ea \u00a8 \u00a7 \u00a9 b\u00df x\u00f9 \u00f0 \u00a8\u00fb \u00f0 \u00a8\u00ed \u00f0 \u00a8\u00e0 x\u00f5 \u00e7\u00ee $\u00ed (\u00d7 7\u00f1 \u00fa \u00f6 \u00ff \u00f2 \u00f4\u00f3 \u00a8\u00f9 \u00ee o\u00d7 7\u00e0 v\u00ed (\u00f9 \u00f0 \u00a8\u00ef \u00ee $\u00ef y \" $c a9 8c h d a ce g& gf \u00a9' ) r gf h\" $c h\" yc 89 if h\" $ %)f y 8i \" $t s 8& if hi h #f yi 9 %\u00a8ae \" $0 yb ci 80 et u i \u00abf \u00a9' ) f y 8i \" $t e 8& 9 6 xq 9 %& c 87 p v 6\" $ % \" of y\" yc h\" ar }9 7 i\u00e2 r !f h 8!f y\" a p\u00b1 d $ 8& & xf h9 if y 87 v\" a\u00a8 8!f ht e%t \u00eb 9 7 d%t \u00ec %4 9 7 87 8 vf hi rs c vq # 8 \u00a6 %@ ec a e7 )9 %7 vf \u00a9e g # )9 9 %d fe #& c 8& \u00a6\" $dr % 8 8 9 3f y !b c9 7 gb f y 8& xf 5& 89 6i t u i r9 d ar % \" of yi c \u2022& i c' 5p\" $h i\" $r %t \u00e8 a 7 & 9 h& !f m %@ \u00ab9 %d ff h 8 9 3f y\" f 8& sf yi 9 3f i 9 c i \" $r %i 8 r \" a 6\" ff h\" $ 8& f f \u00a9e g # 88 %& f h !f h\" $ %u t h % s9 rt e \" $0 e& % xf %r 69 c q8 %\u00fff h9 \" a\" $r f \u00a9' ) \u00a6' 5 %r 9 6\" $9 %q d $ \u00a6 e88 6 88 8& s\" $)f hi & 9 c a r8d a9 & ds f\u00e0 g9 %c h d a r \" $ u # 87 \" o gu 4 f yi )9 %q # c r % gf y\" ac h\" yc 89 if h\" $ %d\" $c a c 87 f hi 8& # %& f y\" ac h @ \u00a68 %c h gf h\" $r wi \" ar i 8& xf b c 6\" $ % \" of \u00a9e 9 d of y 8 69 if h\" f 8& v@ %c \u00ec %t $n v& 88 %7 & f y \u00eb ip t \u00ec & c \u00b9 \u00b9 \u00b5 \u00b0 \u00b6 \u00b1 \u00e4 e \u00e1 \u00aa \u00e1 \u00b3 \u00eb \u00b5 \u00b0\u00ab d\u00ac $ 5\u00ae fh i\" $r % r\u00e8 \u00b2 u i r gf h\" $c a\" dc 8 87 9 d ar % \" of yi c \u2022@ b % 9 % gf y %c h9 3f y 87 8 6 8 6 8!f h\" $ %\u00a8 $ a h h % \u00ed \u00a1 x\u00a2 h \u00a1 \u00a3 8\u00a4 2\u00ef p\u00a5 6\u00a5 \u00a2 %\u00a5 5\u00a6 s\u00a2 %\u00a5 \u00a5 \u00a3 8 \u00a7 y\u00a1 \u00a2 g\u00a9 g\u00aa \u00a1 \u00a3 \u00eb \u00e1 \u00e3 w\u00fe \u00a5 yae \u00e3 z\u00fc \u00fd \u00e7 7 \" a& c8 & & f yi 8 8!f y\" o w 8 8& & e @ % f y 8i \" $t e q 9 & 87 x %\u1e8d ! g 8 \" ac h 8\u1e27f y& t \" $\u1e27 w 8& xb f y\" ar 9 3f y 87 i c' c h9 %\u00ffe @ p %r 9 %c h& \u00a6' x\" of yi {9 @ b !' 8 6 & 9 % a7 !f y 8!f y 87 \u00a19 & 8 6 8 & q ye y \" ac h9 4 i c' \u00aec a9 \u1e27e 9 d of y 8 69 if h\" f 8& h\" ff v % # %& c 8& h@ b a 8 6 8 & a %r 9 %c h& 4 9 7 i c' mc a9 \u1e27e j \u00a9 d $9 % & \" $q d a k d %r 9 %c h& vf hi 8 a9 % \" af yi d 8\" ar i sq # 6i e e7 \u00a1 @ 9 d8 6 8!f s x % \" ar \" a9 & xf h 9 \" a\u1e27f y& pf yi 9 3f dc a\" $r %i yf dq # x\" $c a # %& c 87 vq ye f hi 89 d ad $ 8 i %@ yf hi 8& c %r 9 %c h& t \u00ba @ 8 & 4 f yi 89 %d $d a 8 i\" $@ b % c a9 if h\" $ %\u00a84 \" $@ 9 c 9 \" ad $9 %q d $ 4 ' ) d a7 8i 9 8 \u00a6f yi t s 9 d a\" ff \u00a9e \u00a1 @ e8 6 8!f y\" a 9 & s' ) 8d $d 9 & sf yi 6 87 7 9 !e \u00a3 @ e8 & xf y 69 \" a\u00fff h& t u i \u00a3 %r 9 %c h& v' ) \u00a1 & 87 \u00e09 6 wd $\" a& xf {8 %89 if h 89 3f y\" a qs x9 % # 87 u 4 f yi \u00a3r % 8 8 9 3f y % @ r9 h i\" $q # %9 88\" & 8t e 88 4 9 7 t e \" a0 s& c % xf ht \u00ecu i !e 9 6 w9 7 c h\" of f h 87 d fe & \" $c a d $ wq gf f yi 9 %\" $c \u00b5 %@ pf yi ! g 8 \" ac h 8\u1e27f p\" $& )f h {\" a\u00ff 8& xf y\" ar 9 3f y df yi @ 7 9 c h 8\u1e27f y9 %d # c' ) 8 a @ % f y 8i \" $t e vq 9 & 87 v ! #i 9 & xf y\" o ! g 8 \" $c a 8\u00fff h& t h w xf hi 8 4 @ b % wf yi v 89 %& v7 \" $& 8 & & c 87 \" $\u00a8 8!f yt (%t \u00eb 34 ' ) h& xf h %r d oe ! g # 8!f rf yi 9 3f rf yi )f h if h9 d 6 r % 9 %c & \" yc 8 h7 e 8& 3f c h9 %0 c v i 7 \" $ 8 88 5\" af yi t e 9 %d $\" of \u00a9e \u00a1 @ \u00ab9 % gf y %c h9 3f y 87 7 8q r r %\" $r %t u i {8 %d $ c a\u00a8j \u00faw ! 8d dk \" $7 \" a89 if h 8& p7 !f h 8!f y\" a \u00a8d a ! 8d $& t \u00b4\u00ac u7 8 7 !f y 8!f h\" $ %d a ! w 8d p 4 d oe c h e7 v9 7 z % f \u00a9e g v\" $@ b % c a9 if h\" $ %{' )9 & & 87 e 7 8 }7 !f h 8!f y\" a \u00e7d a ! w 8d \u00eb 34 \u00e2 r !f h 8!f y\" a \u00b1 d a \u00eb ' )9 %& ( & 87 \" ad9 7 7 \" of y\" a \u00a8e 9 %7 d 7 8 i7 !f y 8!f h\" $ %dd $ ! 8d \u00ec 4 \u00e2 ) !f y 8!f h\" $ %\u00b1 d $ 8& \u00eb 9 7 \u00ec ' ) 8 6 p & 87 f h r % !f yi 8 6t pu i f \u00a9' u \u00e2 ) !f y 8!f h\" $ %\u1e8d\u00b1 d a 8& e 9 %\" $& 87 f hi p9 c w 8 69 r % 7 !f y 8!f h\" $ %p 69 if h @ b 6 c z n %t \u00eb s x \u00ec n z %\u00e8 z u if y an %t \u00eb s % z %\u00e8 z u 6t \u00eb c' ' 5\" ff hi {j e 8& sk a\" $f hi r8 d a c h{j \u00fa\u00fb \" a 6\" ff y\" yc 8\" $r \u00a9k a& i c' 5& (f hi r\u00eb c vq 8 @ e 3b # %& c 87 9 %d ff h 8 9 3f y\" o w 8& w' x\" of yi f yi vi \" $r %i 8& f \u00a6 \" a 6\" ff \u00a9e 4 ' xi \" ai v\" $8d a 7 8& s9 %\" $\u1e27f y 87 87 v9 d of y 8 b 9 if h\" f \" ac a & xf 89 & 8& t \u00a6u i s c vq # 8 p %@ # % # %& 87 h9 d of y 8 69 if h\" f 8& 7 8 p 6\" $ % \" of y\" yc 8\" $r ' )9 & & 9 d ad fe \u00eb % t s \" ff h 5& c h9 %d $d at 88 7 4 ' ) \" a\u00ff 8& xf y\" ar 9 3f y 87 f yi 8 6 57 !f y 8!f h\" $ %| 9 3f y h@ b x 6 r % 9 %c h& ' 5\" ff hi f \u00a9' ) 9 7 \u00a6f yi 6 8 c v gf h9 if h 87 9 6\" $9 %q d a 88 6 88 8& \" $\u00a6f hi & 9 c a 8d $9 % & 8t \u00e0 p 6 6& @ hf yi \" a& 0 e\" $7 9 6 )d $ e 0 % 87 d d9 & 7 8 gf yi gb \u00ec 9 7 d7 8 gf hi gb  \" o w 8d oe gt u i \" a& v89 \u1e27q ! # d $9 %\" $ 87 q he df yi @ b9 %!f f yi 9 3f pf hi ' )9 e g& v @ # d $9 %6b \" $r v 9 6\" $9 %q d a & xe gc vq # %d $& ' 5i \" $i ac h9 %0 % 9 r %r 69 c ' ) 8d ad fb cc h e7 87 z 3f \u00a9e g # 87 a9 % \u00a6 ! ef h 8c a 8d fe d $\" ac h\" of y 87 8 c a 9 6 87 af y a9 % q \" of y 69 xe ' )9 ce #& @ e d $9 %8\" $r %t \u00a2 u c' ' ) @ b e8 & %f hi rs c vq # 8 %@ e 6 # %& 87 9 %d ff h 8 9 3f y\" o w 8& 7 8 \u00a6 6\" $ % \" of y\" yc h\" ar t # %& 4 @ b % p ! g9 c a d $ 4 9 v %r 69 c \u00ec8 \u1e27f y9 %\" $& f \u00a9' ) x 8 6 6& v %5 9 6\" $9 %q d $ 88 6 88 8& 9 7 7 8 gf yi gb \u00ec & 89 % i \" $& 5 8 @ b % c a 87 t p \u00a7 \u00a9f hi \" $& 89 %& 4 f y @ b % e88 6 88 8& 5c a9 ce q # u !' 5 \" of f h 8@ %c f yi ) % \" ar \" a9 d 4 \" $v' 5i \" $i f yi ) 6 !' x 6\" ff h\" $r %& s' 5\" ff hi \u00a2 u\u00f0 \u0169' 5\" $d ad gq # pf yi c h9 \u00fb\u00ee ! % \" of \u00a9e yt xk u ' ) ! w 8 4 & c\" a8 f \u00a9' u d @ #f hi v@ 6 !' x 6\" ff h\" $r %& ui 9 c 9 %d $ 6 89 7 ge q # 8 8p7 q he wf yi hr %\" f 8 8 6 % 8 & 5 6 r % 9 %c 4 d oe 9 f } %@ f hi a !' 5 \" ff h\" $r %& ' 5i 8 r\u00a2 \u00b3\" $& f y ah\" $& r 8 8 69 if h 87 t u i f h if h9 d s c vq # 8 %@ i !' 5 \" of y\" ar & r 8 8 69 if h 87 p9 !f h 9 d ad fe \" a& s 8 xe 8d $ %& \u00a6f h f hi \u00eb c vq 8 @ e !' 5 \" ff h\" $r %& i' x\" of yi i\u00a2 u\u00f0 \u00ec t $ a h h % \u00ed \u00a1 x\u00a2 h \u00a1 \u00a3 8\u00a4 2\u00ef p\u00a5 6\u00a5 \u00a2 %\u00a5 5\u00a6 s\u00a2 %\u00a5 \u00a5 \u00a3 8 \u00a7 y\u00a1 \u00a2 g\u00a9 g\u00aa \u00a1 \u00a3 \u00eb n uc h %r xf hi v d a9 & \" aq d $ x %r 9 %c h& 4 f yi x # 8 68 8\u00fff h9 r % x %@ s %r 9 %c h& pf hi 9 if v 8\" ff hi 8 7 \" f 8 6r \u00a6 e@ b9 %\" $d 7 8 h7 & i %f yi 6\" $r %\" $9 d e %r 9 %c 9 %7 \" ff h& s ! g 8!f y 87 \" a gf yt v \u00a7 \u00a9\u00fcf hi 89 & } @ \u00a6t s \" $0 e& f 4 9 q gf @ \u00e5f \u00a9e # 8 8 8\u1e27f d @ \u00a6 d $9 % & \" $q d a } 6 r % 9 %c h& ' ) 8 } 6 r % 9 %c h& f yi 9 3f 8\" of yi 8 7 \" f 8 6r \u00a1 @ b9 %\" $d $t \u00b3 \u00e7 if h df hi 9 if 4 @ f hi 8& c \u00a1 6 r % 9 %c h& 4 @ b !' \u00b4' ) 8 8 & \" a7 8 6 87 {c a 89 \" ar @ b d 4 f hi 9 if \" $& 4 @ !' 6 r % 9 %c h& ' ) 8 6 & i f hi 9 if 9 d ad ( # 8 69 if h\" $ %& 8 \u1e27f y 6\" $q gf h f y )f hi 8& d ff x %@ \u00ab8 c a gf y9 3f y\" a t  c a 8 6 6& \u00a6\" $f hi )& 9 c a rr % % 4 8& # 8!f h\" f 8d oe 4 \u00b6 \u00b8\u2022 w\u00be \u00e0 \u00ea \u00f1\u00f6 e\u00ea \u00f2 \u00f1\u00be \u00e8 f\u00e2 \u00ac\u00e7 x\u00e2 \u00e8 {\u00ea \u00f6 e\u00e2 \u2022 \u00ed \u00e0 \u00ee \u00e9 t\u00e5 \u2022 \u00ea \u2022 \u00e9 \u00bc \u00e8 f\u00e7 \u00e8 \u00e2 6 \u00ac\u00ea \u00f1\u00e9 \u00bc \u00e0 \u00e7 \u00be \u00e7 x\u00e2 \u00e8 \u00a5 \u00e8 \u00a6 ae \u00ed \u00ee \u00e2 \u2022 \u00bc \u00f6 f\u00d7 x\u00e2 \u00e8 \u00e0 f\u00be \u00e8 \u00e2 0\u00e4 \u00ea \"! x\u00e2 \u00e8 \u00e2 \u2022 \u00ed \u00d7 x\u00e2 \u00bd \u00bf\u00be \u00bc \u00a6\u00e0 \u00e2 \u00a4\u00e2 \u00bf\u00e8 \u00e8 \u00e9 \u00e8 \u00e0 \u00ea \u2022 \u00ed \u00ee \u00e2 \u00bd \u00f2 \u00f1\u00be \u00bc \u00e0 \u00e2 \u00eb \u00bc \u00be \u00e8 \u00e4 \u00be \u2022 \u00e4 f\u00ed \u00ee \u00e9 \u00e0 \u00e2 \u00bd \u00e9 \u2022 \u00a6\u00bd \u00e2 \u00e8 \u2022 \u00ea \u2022 \u00a6\u00eb \u00bb \u00e2 \u00ed \u00e2 \u00bd \u00ed \u00f0\u00ea \u00f1\u00e9 \u2022 \u00e1 \u00bc \u00f2 \u00e2 \u00e8 \u00e5 \u00e2 \u00e8 \u00e2 \u2022 \u00e9 \u00ed \u00bd \u00e9 \u00bc \u2022 \u00ed \u00e2 \u00e4 \u00be \u2022 \u00e4 a\u00e2 \u00bf\u00e8 \u00e8 \u00e9 \u00e8 \u00e0 \u00e4 \u00e2 \u00ed \u00e2 \u00bd \u00ed \u00f0\u00e2 \u00bf\u00e4 f\u00d7 \u00e2 \u00ed \u00b8\u00e2 \u00e7 u\u00e2 \u00e0 \u00d7 \u00bc \u00ed \u2022 \u00e9 \u00ed \u00e4 \u00a6\u00e2 \u00ed \u00e2 \u00bd \u00ed \u00e2 \u00e4 e\u00d7 \u00e2 p\u00f6 e\u00e9 \u00e4 \u00e2 \u00e0 \u00e5 \u00e2 \u00e8 \u00e2 \u2022 \u00e9 \u00ed \u00bd \u00e9 \u2022 \u00a6\u00e0 \u00ea \u00f1\u00e4 \u00e2 \u00e8 \u00e2 \u00bf\u00e4 f\u00d7 \u00e2 \u00be \u00bc \u00ed \u00f0\u00e9 \u00f6 \u00be \u00ed \u00e2 \u00e4 \u00e4 \u00a6\u00e2 \u00d7 \u00bc \u00a6\u00eb \u00eb \u00ea \u2022 \u00eb x\u00ba \u00eb \u00a6z \u00ed w\u00ed 0\u00ee c\u00ef \u00f0 \u00f1 t\u00f2 \u00f4\u00f3 \u00b4\u00f5 x\u00f5 \u00f5 u e9 q d a \u00eb \u00b2 \" $r d a !b c 8 6 7 !f h 8!f y\" a 9 7 8 6 8!f h\" $ %# \u00b4x vu x d \u00b2 ah f } u| d | $ \u00a6f %# yx d u x t\u00f6 u j f '& ij e i~# yx eu d u | e uk w\u00b2 cf j v x vh tj | j d \u00b0u h y i t| e | y j v uk ( ) 0 1 2 3 54 76 8 @9 a9 @b @c ad eu yk u h f } e h u 2 gf 0 h3 ( 0 f 0 3 2 ( ge j \u00f0} xd u h f } e h u 2 gf e e e e e e e e eu yk \u00ac pi \u00b3j } ud e h u 2 gf 0 h3 ( 0 f 0 3 2 ( ge eu yk \u00ac pi \u00b3j } ud e } | 2 gf 0 h3 ) g6 q e e e e e eu yk \u00ac pi \u00b3j } ud ( } | 2 gf 1 re ) gq 5( g( e e e e e eu yk \u00ac pi \u00b3j } ud ) } | 2 gf 2 hf 0 gq 5( gq e e e e e s ut v @w c @8 yx @x t eu yk u h f } e h u ( g( hf 2 h6 ( ge 6 q 3 1 ( ) ge j \u00f0} xd u h f } e h u ( g( hf 1 r6 e e 1 `) ge e a( hf 2 eu yk \u00ac pi \u00b3j } ud e h u ( g( hf 6 h) ( gf 5( g0 ) 5( g2 q e ( g2 eu yk \u00ac pi \u00b3j } ud e } | ( g( hf 6 h) 2 b1 `( g( ( 3 e e e eu yk \u00ac pi \u00b3j } ud ( } | ( g( hf f hf 3 gf 5( g) 6 e ( e e eu yk \u00ac pi \u00b3j } ud ) } | ( g( hf q hq 6 g( 5( gf f e ) e e c @d t x fe ug w @h @i eu yk u h f } e h u 0 ge he ( h6 g6 0 b1 `6 ge ( 5( g) p( gq e q1 r( j \u00f0} xd u h f } e h u 0 ge he ( he g3 e ) a( h) s1 re e a0 h) ) ge eu yk \u00ac pi \u00b3j } ud e h u 0 ge he ) h) g( 1 rq 56 g3 f 52 gq e q ) ge eu yk \u00ac pi \u00b3j } ud e } | 0 ge he ) h) g( ( g3 t1 51 r( 5( h3 e e e e eu yk \u00ac pi \u00b3j } ud ( } | 0 ge he ) h0 g3 ( g6 h2 53 g( e e e e e eu yk \u00ac pi \u00b3j } ud ) } | 0 ge he ) hf g3 ( gq hq 5f b1 ) ( e e e $ a h h % \u00ed \u00a1 x\u00a2 h \u00a1 \u00a3 8\u00a4 2\u00ef p\u00a5 6\u00a5 \u00a2 %\u00a5 5\u00a6 s\u00a2 %\u00a5 \u00a5 \u00a3 8 \u00a7 y\u00a1 \u00a2 g\u00a9 g\u00aa \u00a1 \u00a3 \u00eb \u00e8 u e9 q d a \u00ec \u00b2 u i 8 6 % 7 !f y 8!f y\" a 9 3f y r@ b % sf hi %r 9 %c h& s' x\" of yi u\u00a2 c v gf h9 if h\" $ %& \u00fb %r 9 %c \u00a2 w ! 8d u \u00ab 3f y9 %d \u00e2 ) !f y 8!f h & c 87 {\" $8 %& \" $& xf y 8!e \u00fbt f yi r7 !f h 8!f y\" a d 69 if h r@ c v d of y\" $ d a ) 8 6 6& i' )9 & \u00a6i \" $r ed gf \u00a6 e ih uj e \u00a6k ml n c o p qh r ts j vu 3 c tj v uk w ix ex eu x zy {u x vx e uy {j u h m| e} x| ej v u $ u x ey {u h y {s x vx e h uj ef u ' y 9d x eu x d e| d l y u x ex e \u00a6y j v| h u qx e | e| e i| | es y \u00a2 q| x eu h w tx q f u yy y {s x vx e h gy i| h j v t | e ih y { u 3 g i xd f y j k \u00a6y f tx tj u h | nu 3 d x vu x d d x eu d ix ej d i| d j vx eu h % eu yk h 3 qj } xd g h % th gk 5y u h | ej vx d h uj v g t| e \u00a6k th g f } x| d | w tx v zj es x eh h j vu d gf v} 2 s h k e ih uj d f 'x eu 'f | c h 5k i s 3 h @y {u h gy s x ex e ih uj f u 3 y d x eu x d e| c q| uf f q| t h w | ej t gf | e h ej e ny u h | d | ej e ih y {} 0u ' 'y u ' s h y i tj u h cd x eu j eu yy u 'f | t qh k k qj d 0j } xd i| d u yk \u00a6 tj } ud w th g f } x| d | u 3 u yk \u00a6k (f tj \u00a1 n\u00a2 a\u00a3 | zy {u h | ej ex h uj | d tj | d \u00a4 y j u h %d x eu gf \u00a6 j v th u} \u00a5| d ad f m eu yk \u00a6 tj } ud my u h | ej vx d h uj v| do n qh k y i th \u00a6 | eu 'f \u00a6k i \u00a7 y ih uj df } r \u00a2 @d x eu d u | e uk | d ed f 5 th gk i \u00a7 y i ih uj j e \u00a6y h s y o ( ' h \u00a9 h u h ~ \u00a6f f eu yk \u00a6k qj } xd uk d x eu x d o \u00a8k t h u | e | cj v \u00aa x v u q| eu h | \u00ac\u00ab u 3 ( h gy u h | d | ej e ih y {} w u} z h gk h \u00ae h f h gy u h | d | ej e ih uj f| es | e j v| fu 3 eu yk \u00a6 tj } ud y {u h | ej ex d h uj e| d h y { \u00a6 y y u h | ej vx d h uj i d | j ex y u 3 j v e| e} y e u 3f \u00a4u yy iy s x vx e ih y h 5j e zd x eu x d o f h f \u00a4| es | e ij f | eu \u00a2j e \u00a6f f | d u | e| d f | eu s x dy { | u ' 3d x eu x d x ex vu x e| d l n @x v u f \u00b0i | ts j eu ' tj v \u00a6k \u00a9y {u x ex v uy {j d u h \u00b1 u} \u00a6x e d gf y h \u00a5| e} y u 3f u yy y {s x vx e ih y { | tx vu s h gk nj e ad u | e| d f f| eu s x dy { | th gk x e \u00a6y f y {s f qj d h z eu yk \u00ac | e th gk j } ud i| u 3 gj v x e x d j ej v h d x eu x e| | e} x| ej v u qj d y f f } \u00b2 f| f u h 2 t| n s | tx v h u qx e | e| e | do gl n d x eu d u | e | c x d qj e x t| d f f h us g t ix fu 3 \u00a4 f j v x vh qj d | fj e g tj w h \u1ef9 if s gk \u00a2 th \u00b3 h uj v h gk uk d x eu x d u qx dy m| ed y \u00a2 | w d j w| d f f \u00b4 uy i ts | \n t\u00ba ae \u00f8 \u00e4 \u00fd \u00fd u\u00e8 v\u00fd \u00fd \u00e9 \u00ea x\u00ba \u00eb \u00ec \u00ed w\u00ed 0\u00ee c\u00ef \u00f0 \u00f1 t\u00f2 \u00f4\u00f3 \u00b4\u00f5 x\u00f5 \u00f5 h f | es | e j \u00a8y u h h | (d u | e| d f | eu s x dy { i| \u00e0u 3 \u00ac x ex vu x e| h w k th y { u \u00f6 ( | \u00a4d td ix td x e | e ih uj e| tj e g t| d y 0 f u x j v \u00f7 qh k c qx d u s | tu d j \u00b0\u00a6 tj u h j v uy h s | ed f \u00a6 e h uj v uk 5 h \u00f8l n o qh k \u00aej v ih \u00a9k | dy {s | e| e i| j e| c i\u00f9 \u00a6y j ih i| e| c q| e uk \u00aeu h s th uj j d qj d i xd x a h uj v| d \u00fa \u00fb f\u00fc \u00fd \u00fe (\u00ff \u00a1 \u00a3\u00a2 \u00a3\u00a4 \u00a8\u00fd \u00a6\u00a5 q\u00ff 2\u00fc \n 8d a 7 d9 if ad a 89 & xf d u' 5 %r d8 %& f h 9 %\" $\u1e27f 4 9 %7 \u00a3 89 i \u00a18 & xf h 9 %\" $\u1e27f a\" $& r\" ac h & 87 8 8 xf h9 \" $\u00a1& e #c vq # %d s e88 6 88 8& 5\" a\u00a19 p8d a9 & s x& 8 )f yi ac h e7 \" ar 6 d $ 8& r\" $h s\" ar t \u00eb u 6t u e g # 8 %& xf y 69 \" a\u00fff h& 89 q & c 87 \" a\u00e4f hi & 9 c a ' )9 ce f h d a e89 if h f \u00a9e g # 8 6 \n xf y 69 \" a\u00fff h& (f hi 9 if 59 6 58 %& \" $7 8 6 87 d' x 6 r hc a9 ce \u00a1q 8 6 8!f y 87 q he \u00bf 6 8 d $9 %8\" $r pf hi v& xe gc vq d e88 6 88 8& f yi 9 3f \u00a3\" $c a # %& c 87 {f yi %& c v8 & xf h 9 %\" $\u1e27f y& q he 3f yi 8 & xe gc vq d a& 4 % \u00bf ' 5i 8df hi & & c 8!f y 87 & xe gc vq d a& 9 6 q9 % \" a9 q d a 8& 4 q he \u00a1c a9 0 e\" ar rf hi 8c \u2022i 9 c w rc h % e88 6 88 8& 8d $& !' xi 8 6 s x8@ bt \u00b1 d a s 5e p du \u00a6 @ \u00abh i\" $r %t \u00eb u t qi 8\u00a8& c a & xe gc vq d u 88 6 88 \u00a3i 9 & q # 8 8\u00e0 !' 5 \" of f h 8f h 9 % if hi 8 & xe gc vq # %d rq he c h\" a& xf y9 %0 % 4 f hi 8 p ! g\" a& xf y& 9 & xe gc vq d s' 5\" ff hi \u00e7d a 8& & e88 6 88 8& f hi 9 \" a\u00fff h 87 87 \u00e79 %7 9 & xe gc vq \n \u00a9e g d8 %& xf y 69 \" a\u00fff h& ct hk u ' ) ! w 8 4 ' 5i 8\u00a38 & \" $7 8 6\" $r d 8 d a9 8 8c a 8\u00fff aq he 9 d8 %& xf y9 %\u00fff & xe gc vq # %d 4 y \" $c a9 c v & xf )7 !f y 8 c a\" $ u\" ff h& \u00ab 9 d a 8t \u00a7 f )\" $& 7 \" $ ah d of )@ b ef hi u8 6 8\u1e27f 8 & \" a @ wy \" $c a9 f y u7 !f y 8 c a\" $ \u00abf yi e q9 %d $ q 9 %& 87 a %dc h e7 8& i9 7 )f \u00a9e g 8& s d oe yt \u00a6g w gf h9 if h\" $ & i @ @ b !f y\" a d& e #c vq # %d $& s if hi 8 #f yi 9 %\u00e48 & xf y9 %\u00fff & xe gc vq d a& cu (89 %d9 d a& q # d a e89 if h 87 aq gf sf hi 8\" $ 8 6 8!f h\" $ %d\" a& \u00a67 \" $ a8 d ff rq # 889 % & c u& 89 6i d& 9 8 ' x\" ad $d g ! g 9 %7 xf y e c v i t g \u00a3 gf h9 if h\" $ %& @ e 87 \" $89 3f y & xe gc vq # %d $& 89 if 5q # 8 6 8!f h 87 pq he f hi 8 6 8\u00fff x@ b 69 c a !' ) 60 et \n hi 9 df yi hr \" o 8{ \" a 6\" ff \u00a9e ae t f h 8 & 5 6 8d $9 3f y 87 f y r 6 \" ar e8 8& & xs 8!f ht t \u00ec u 9 6 5 c a\" ff 6f y 87 t \u00a7 \u00favr 8 8 69 if h !b c9 7 gb f y 8& xf d& 89 6i 4 f hi f h 8& f q ye 0\u00e2 ) !f y 8!f h\" $ %\u1e85\u00b1 d a h& u\" a& ui 89 8 pf hi 9 c h e7 d9 %7 wf \u00a9e g # d9 9 %d fe g& 8& 4 q 889 & 4 ' xi 8 9 f y\" a8 d $9 % s x& & # 8!f h 87 u d8d a9 & 8& a9 % !' 5 \" of f h 8\u00a84 f yi 8d a9 & 8& if hi 9 if 59 % r if 6 !' x 6\" ff 6f y 87 a if 5i 9 c f y dq # )i 80 % h7 d' 5 \n %i 8 ef hi 9 vf hi 9 if @ b % 9 d& \" $r %d $ ) 8 6 6tu i d7 !f y 8!f h\" $ %\u00a8 9 3f y x' x\" of yi \u00e8\u00e2 ) !f y 8!f h\" $ %\u00a8\u00b1 d a h& \u00eb 9 7 \u00ec ' )9 %& d9 q c dn \u00b8 \" $ ! 8 xe 89 & 8t u i \" a 7 4 ' ) a ! g d a 6 87 f hi a\u00eb c vq 8 @ 9j \u00fa d a9 & \" $q d a \u00a1k %r 69 c a& ct \u00fb pd $9 % & \" $q d a a 3b r 69 c a& u9 6 v %r 69 c a& f yi 9 3f di 9 c f yi x& c9 %c h v % i \" $r %i 8 \" a 6\" ff \u00a9e f hi 9 f hi v % \" ar \" a9 d 9 c a r f yi x %r 9 %c h& p' 5\" ff hi \u00a2 c v gf y9 3f y\" a & 9 % \" a9 q d a v e88 6 88 8& \" $\u1e27f yi x& c9 %c h 8d $9 % & @ s9 8 8 xf h9 \" $g\u00a2 ut u i \u00a6 8& d ff \" a& (& i c' x\u00e4\" $\u00e4u e9 q d a t e 8 & \" a7 8 87 )f yi c v gb \u00eb \u00b6 \u00ed w\u00ed 0\u00ee c\u00ef \u00f0 \u00f1 t\u00f2 \u00f4\u00f3 \u00b4\u00f5 x\u00f5 \u00f5 u e9 q d a v \u00b2 |u i ps c vq # 8 @ ) d $9 % & \" $q d a v 6 r % 9 %c h& 9 %c h %r f yi p %r 69 c a& ' x\" of yi \u2022\u00a2 c v gf y9 3f y\" a y\" a & f h vf yi e 9 6\" $9 %q d a \u00ab' xi %& 9 c a \u00a6q 8r 9 %\u00fc' x\" of yi 0j r k t p \u00a7 \u00faf yi \u00a68 %d $ c a0j \u00fa\u00fbpd a9 & \" aq d $ %r 69 c a& sk 4 6 r % 9 %c h& (f hi 9 if ' ) 8 6 \u00eb t 5 8t e \" o e9 d a 8\u00fff x af h a 89 c a\" $r a @ 9 6\" $9 %q d a 8& 9 7 \u00ec t 5 8t e \" o e9 d a 8\u00fff \u00a6 f y & x' x\" of yi \" $r @ q9 % r % c h 8\u1e27f y& \u00ab @ 89 d ad $& f y 8 c ac v gf y9 3f y\" o vq \" ad ff 6b c\" $ 6 87 \" $89 3f y 8& & i 9 & \" $ 89 3f y\" a ' ) 8 6 58 \u1e27f y 87 9 & 6 r % 9 %c ht h w %c u e9 q d a \u00a3' ) {& 8 f hi 9 if f yi \u00eb c vq 8 @ v d a9 & \" $q d a 6 r % 9 %c h& 7 \" $7 if \" $8 6 89 & ! g d a & \n \u00bc \u00fc \u00bd vae \u00e1 \u00e3 d fe ge f h gi fj k i l me fi u& 9 v ! #9 c a d a 4 ' ) x8 %& \" $7 8 (f hi xr % 8 8 9 3f y % %@ i9 hh s\" aq # %9 %88\" & 8t e 88 ' 5\" ff hi w % 8 6 6\u00b2 \u00eb \u00b2 on x \u00b2 u wv hx qp tr | hs qt r t u v wt xu y z y{ yp \u00a8r |u v ~} r | s \u2022u u w hz x y \u00ec \u00b2 on \u00b2 u wv hx qp tr | hs qt tu w yt xu rv qt tu w hz w{ yp sr u rv y r | hs {u \u00b2 u y 7 u v u \u00a8u y r u p 5 u y ru v u yv x wp xr | s wt xu rv qt tu wt xu y r { s \u00e9f hi \" $ 89 if h\" $ %\" a\u00e4f hi d $\" a a& i d a7 pq # |u w hz u v u \u00a8u y u u i 9 %d $r % 6\" ff hi c & ci c' 5\" a\u00a8 8!f yt \u00a6 8 c a gf y 8& uf hi 8 \" a7 8 # 87 8 !f c h\" a\" $c h9 %d \" $8 %& c\" a& xf y 8\u1e27f & c q & !f h& e f \u00a9' ) \u00a8c a e7 8& 9 7 f \u00a9e g 8& t \u00b0k u 8 6 4 ' ) {7 3f \n 8r if hi e \u00f9 \u00f2 \u00fb\u00d7 y\u00e1 \u00f8 g\u00ef \u00f1\u00f4 !\u00d7 8\u00f5 { (\u00f4 \u00fa\u00ef \u00f1\u00f0 b \u00ee \u00a1\u00e4 \u00e2 d\u00df \u00d7 g\u00a2 ' # \u00eb d\u00ec \u00ed w\u00ed 0\u00ee c\u00ef \u00f0 \u00f1 t\u00f2 \u00f4\u00f3 \u00b4\u00f5 x\u00f5 \u00f5 \" $8 \u00a3& i 9 % \" a9 q d a \u00a1 e88 6 88 8& 9 & d\" a\u00e0k u 8 \" a& xf y\" a\u00a3\u00b1 d $ 8& \u00eb t \u00eb i4 \u00ae\u00eb t \u00ec 9 %7 \u00eb t $ \" $c a # %& 5c a e7 r8 & xf y 69 \" a\u00fff h& 8 \u00a8@ % a dc fe \u00ecs 8!f ht \u00ec u sf yi 9 3f x9 % & xf y 6 r % h if yi 9 %p\u00f4 b\u00f5 9 7 \u00d7 8\u00f8 \u00ef 4 ' ) x8 % d $7 p 8 d a9 8 k u 8 \" a& xf y\" a5\u00b1 d a 8& \u00eb t \u00eb b \u00eb t $ hq he {9 \" a 87 p 6 d $ 5 p8 & xf y 69 \" a\u00fff & xf y 6 \n\t\t\t & xf h 9 %\" $\u1e27f y& i %q gf y9 %\" $ 87 x@ b 6 c f hi v 8 6 % 8 & i& xe gc vq # %d s e88 6 88 8& i9 6 v\" $8 %c h 9 3f y\" aq d $ ' x\" of yi \u00a1f hi if hi h d8 & xf y 69 \" a\u00fff h& t pi 9 c p % # %& 87 9 8 h8\"$ 8\u1e27f v9 %d $r % 6\" ff hi c f hi 9 if 7 & v9 c a\" $\" ac h9 %d \" $8 %& \" $& xf y 8\u1e27f )& c q & !f ) %@ c h e7 8 & xf h 9 \" a\u1e27f y& @ b 6 c 9 %}\" $8 %& \" $& xf y 8\u1e27f s xc x d of y\" au & !f r @ 8 & xf h 9 %\" $\u1e27f y& 1 f 2 t \" a8 ) 89 i d8 %& xf y 69 \" a\u00fff 0 % 8 8 & if h 9 %0 h @ qf yi u& xe gc vq # %d \u00b9 \u00e9 \u00ac\u00e4 \u00a6\u00e2 \u00e0 \u00a4\u00bd \u00be \u2022 \u00d7 x\u00e2 9\u00ed \u00ee \u00e9 \u00bc \u00eb \u00ee \u00ed \u00e9 \u00ec \u00be \u00e0 \u00ed \u00b8\u00e2 \u00e7 u\u00e2 \u00e0 \u00ea \u2022 n\u00be \u00d7 \u00a6\u00e8 \u00e9 \u00be \u00e4 \u00e0 \u00e2 \u2022 \u00e0 \u00e2 \u00acae t\u00d7 \u00bc \u00ed \u00ea \u2022 \u00ed \u00ee \u00ea \u00e0 \u00e7 \u00be \u00e7 x\u00e2 \u00e8 \u00e5 \u00e2 w\u00e8 \u00e2 \u00e0 \u00e2 \u00e8 \u00e2 9\u00ed \u00ee \u00e2 \u00ed \u00e2 \u00e8 \u00f6 \u00ed \u00e2 \u00ac\u00e7 x\u00e2 \u00e0 e\u00ed \u00e9 a\u00f6 e\u00e2 \u00be \u2022 c\u00e0 \u00e2 \u00ed \u00e0 \u00e9 \u00ec \u00e7 x\u00e9 \u00e0 \u00e0 \u00ea \u00f1\u00d7 \u00f2 \u00e2 ( \u00be \u00f2 \u00f1\u00bc \u00e2 \u00e0 t\u00ba \n\t\t\t & xf h 9 %\" $\u1e27f y& p\" ac h & 87 q ye 9 8d $9 % & 0h bp \u00a8r 6t u `w 9 6 {& c hc a9 6\" dc 8 87 \" $h s\" ar t \u00eb t ud ad d a 8& i 8 x 8c vq e7 ge f yi 59 & & c h gf h\" $ %\u1e27f hi 9 if x ! 8 xe { \" a 88 x %@ i8 c ac v \" $89 3f y\" a p\" $& 8 e 8 9 3f y\" o w 8t \u00a3\u00b1 d a \u00a3s fe \u00a6\u00ac uu 5\u00eb c vq 8 & x \" $ 89 3f y\" a q # e7 ge r % 9 %d $& xq # 889 % & 5f hi hc h e7 \n\t\t\t & \" a7 8 x\u00e2 ) !f y 8!f h\" $ %d\u00b1 d $ \u00ec s \u00e9f hi r i \" of 89 %d7 !f y 8!f \u00abf yi i 9 % \" a9 q d a wu y z a\" $\u00fcf hi \u00a68d a9 & i 89 7 %@ \u00a3n 9 & 9 8 6 u 6t",
        "prob": 0.9468794326241137
    }, {
        "ID": 777,
        "phrase": " we have that, for all of u , t |u [t ai (a, i) , b] = z |u [a, z ib (i, b)]",
        "prob": 0.22000000000000003
    }, {
        "ID": 1184,
        "phrase": " i kj al &j em j an o j ap pq d fe hg 6i kj l am i n go wp rq s t wp u wv hx #p 6y t zy w{ y s w| y } ws w| ~s ~ p r q rx k hp t | w s p 6t s y v w p h ~s y | u hp 6 z} rp ht yt wp ht s zy s rx ky u x \u00a8 w x \u00a8p u u 8v hp 6x s rx g yy | ~s w as { 6p hu hx s u \u00a8p 7 w u wp q fy 8v wv hx y g o wp hu bs 2 o p ry wx kp y u r w p r| p r p 6y ho s r 2y y t u # p 6x \u00a8 wp #v hx kp hu \u00a8p h y ~s w an o wp rt s u x s ~} g s r 2 ~ av hx p hu ku hs r yy | ~| u a| p 6t \u00a6 | ~s up ht s y zu x kp hy w u bs u hq us o s o wp rx kp hy | ~ av v u ku hs } gs | s gn go s u wv y \u00a8v p 6x v hx kp hu \u00a8p 6 u hy hv x w w w v p u } w o z z t wp | y y wt zx y g s up rp h w{ s x w up h uy 2 s p rt s x #p p ht up ht s y zu u p 6 x kp hy ~s 2y y ys wt 2 ~ v hx kp hu kp 6 g y s wy | g x s } y w s zy u x #p yu ky g} w| p up t s y 2 } \u00a1 p r v wp u k n go yp v | 8s rx kp 6p rx r s up bu u p 6 s u v} y u p t 2 r zy zt y g y } y yu p ry y wt zy | ~| w q u y rx y | p \u00a2 gs w} | p bu 8v yv v rx w u y ~s up 6t s y 2 v hp hu hy yu q p r| w| y u 6 rx p hy u p \u00a2 p u hs u v} \u00a8 2u x \u00a8p 6y w 7s p 6t s y zu p 6x \u00a8{ 6p 6x \u00a8u k n o wp av x w w w v hp s v v| p 6 up y ~s r s g | yt wp u hy v hx kp r| ~s s yy wx { 6p 6x \u00a8u s r 2 w \u00a3 7p } v\u00a4 b o g rx s v v| y rx k u \u00a5 \u00a7\u00a6 \u00a9 0\u00aa \u00ac\u00ab h\u00ae h\u00b0\u00b1 r\u00b2 \u00ac\u00b3 g\u00b5 6 \u00b6 a\u00b2 \u2022 w\u00b9 \u00ba \u00bb \u00bc\u00b9 g\u00ba \u00ac\u2022 \u00be\u00bd w\u00bf \u00a4\u00bb s\u00e0 \u00e1 \u00e3\u00e2 \u00be\u2022 \u00be\u00e4 g\u00b9 g\u00ba \u2022 \u00be\u00bd \u00bb \u00bc \u00b6 a\u00ba \u00ac\u00b9 \u00e1 \u00be\u00e1 \u00e3\u2022 \u00be\u00b2 w\u00e5 \u00ac\u00bf \u00b0\u00e2 \u00be\u00b5 6\u00b9 g\u00bd \u00e4 ae\u2022 \u00be\u00b2 y\u00e5 \u00a7\u00bb \u00b9 \u00ba a\u2022 \u00be\u00bd y\u00bf 2\u00e7 &\u00b9 g\u00e8 \u00e9 \u00e0 a\u00e2 \u00be \u00b6 a\u00b5 6\u2022 \u00be\u00b2 y\u00e5 \u00ea \u00eb g\u00ec 7\u00ed 6\u00ee a\u00ef b\u00f0 \u00a6\u00f1 7\u00f2 \u00a4\u00ed 6\u00f3 #\u00ef b\u00ec \n \u00ed m\u00ee o\u00ef \u00f0 \u00f1 \u00a3\u00f2 6\u00f3 g\u00f4 \u00f5 \u00f6 \u00a1\u00d7 7\u00f8 \u00f2 \u00a3\u00f9 \u00fa \u00f1 \u00a3\u00fb \u00a3\u00fc \u00ee \u00f8 \"\u00f2 \u00fb \u00a3\u00f8 \u00f0 \u00f1 \u00a3\u00f2 \u00fd r\u00fe '\u00df \u00e0 x\u00e1 \u00e2 \u00e4\u00e3 \u00b1\u00e5 2ae \u00bf\u00e7 \u00a2\u00e8 \u00e9 \u00ea \n \u00eb r\u00ec \"\u00ed \u00ee p\u00ef \u00f0 p\u00f1 \u00f3\u00f2 6\u00f4 '\u00f5 \u00f6 r\u00f7 \u00a5\u00f8 \u00f9 \u00fa \n s ut %v xw \u00a8y \u00a1a pb c dw \u00a8e !f \u00a8g xy \u00a1t ih \u00a5v qp rqs pt it vu wy #g xx ye !f \u00a5 # \n \n \n \n\t\t\t k ml on p q \u00a3r rs ut \u00a1v wr x ul oy #z { | 7r \u00a3} l or q \u00a3y q \u00a5} \u00a3 u \n\t\t\t \" 2 9 x p ' ' \n\t\t\t \u00fb m\u00fc o\u00fd \u00fe \u00a7\u00ff \u00a1 \u00a3\u00a2 \u00a5\u00a4 \u00a5\u00a6 \u00bf\u00fe \u00a8 \u00a7 \u00a9 \u00a5\u00ff \u00ff ! #\" \u00a5\u00a9 \u00a9\u00fc %$ &\" '\u00a9",
        "prob": 0.5952702702702704
    }, {
        "ID": 2053,
        "phrase": " we include both si and ai in the hash (as opposed to only the proof si) to ensure that it is hard for the vote constructor to precompute hi values for all possible sis",
        "prob": 0.1823529411764706
    }, {
        "ID": 2401,
        "phrase": " key: be = backbone, bld = blood, by = body, ce = carnivore, cg = covering, ct = cat, dn = description, fd = food, fg = flesh eating, fr = fur, hd = head, ls = legs, ml = mammal, ne = name, os = other features, ps = purrs, ts = tibs, ve = vertebrate",
        "prob": 0.738235294117647
    }, {
        "ID": 2402,
        "phrase": " key: be = backbone, bld = blood, by = body, ce = carnivore, cg = covering, ct = cat, dn = description, fd = food, fg = flesh eating, fr = fur, hd = head, ls = legs, ml = mammal, ne = name, os = other features, ps = purrs, ts = tibs, ve = vertebrate",
        "prob": 0.7676470588235292
    }, {
        "ID": 2744,
        "phrase": " , ai k } represents {pi 1 , ",
        "prob": 0.18333333333333335
    }, {
        "ID": 2744,
        "phrase": " , ai k } represents {pi 1 , ",
        "prob": 0.18333333333333335
    }, {
        "ID": 2744,
        "phrase": " , ai k } represents {pi 1 , ",
        "prob": 0.18333333333333335
    }, {
        "ID": 3402,
        "phrase": " , x k \u2192 a k ] for the substitution \u03c3 such that \u03c3(xi) = ai for 1 \u2264 i \u2264 k",
        "prob": 0.18333333333333335
    }, {
        "ID": 3949,
        "phrase": ", x(i) = 1 if and only if i \u2208 b), then vc(b) = a0 + i\u2208n ai \u2022 x(i) + i,j\u2208n aij \u2022 x(i) \u2022 x(j) + i,j,k\u2208n a ijk \u2022 x(i) \u2022 x(j) \u2022 x(j), (7) where a0, ai, aij, and a ijk (for i, j, k \u2208 n ) denote the constant, linear, quadratic, and cubic coefficients of the polynomial, respectively",
        "prob": 0.38846153846153847
    }, {
        "ID": 4263,
        "phrase": " the dynamics of the collected signal samples {si} are given by si+1 = aisi + ui, (3) ai = e \u2212a\u2206 i , where \u2206i \u2206 = |xi+1 \u2212 xi| and ui \u223c n (0, \u03c00(1 \u2212 a 2 i ))",
        "prob": 0.2928571428571428
    }, {
        "ID": 4389,
        "phrase": " , ai : xi, ",
        "prob": 0.22000000000000003
    }, {
        "ID": 4390,
        "phrase": " , ai : xi, ",
        "prob": 0.22000000000000003
    }, {
        "ID": 4454,
        "phrase": " the acwd of \u03b3 r (a/b) is given by \n 1 and \u00b5 2 by \u00b5 1 \u25b3= i\u2208i1 |s ai |, \u00b5 2 \u25b3= 12 i\u2208i2 |s ai |",
        "prob": 0.15714285714285717
    }, {
        "ID": 4503,
        "phrase": " assuming the snr value s ht \u00a8( \u00a8w ey is large enough for (1) to tightly approximate 2 43 , we have 2 3 pi q sr ut 8 wv q \u00a3 ba 6 \u00a3 cb \u00a8d yx r 0 1 % $r gs t ( xw y # \u00a3 c \u00a7 v e \u00a3 8 @ c g 4 i q sr ut 8 q \u00a3 6 a \u00a7 \u00a3 4\u00a3 ! a 8 6 d d e \u00a3 8 @ c g 4 1 (2) with d \u00a6# e& gf ih kj ml sf n f o # h @j 1l f p \u00a6# ",
        "prob": 0.38846153846153847
    }, {
        "ID": 5194,
        "phrase": " action ai is executed just before the completion of the transition",
        "prob": 0.1375
    }, {
        "ID": 5805,
        "phrase": " the quantity p(t + 1 < b, t \u2212 1 \u2264 t + 1 + b l(t + 1 )\u22121 ) can be expanded as (14) p(t + 1 < b, t \u2212 1 \u2264 t + 1 + b l(t + 1 )\u22121 ) = \u03b5 2 \u00b5 e \uf8eb \uf8ed h i=1 ni j=1 ai 0 p + (x(u))p \u2212 (x(d i j )) du \uf8f6 \uf8f8 + o(\u03b5 2 ), where h is geometric distributed with parameter \u03bb/(\u00b5+\u03bb), (n i , d i 1 , ",
        "prob": 0.2733333333333333
    }, {
        "ID": 5805,
        "phrase": " the coefficient of \u03b5 2 in the expansion of e((b \u2212 b \u03b5 )\u00bd a+ ) with respect to \u03b5 > 0 is given by (15) a + = \u2212 1 \u00b5 e b 0 (b \u2212 v) e \u03bd p + (x(0))p + (x(v)) dv \u2212 1 \u00b5 2 (1 \u2212 \u03c1) e \uf8eb \uf8ed h i=1 ni j=1 ai 0 p + (x(u))p \u2212 (x(d j )) du \uf8f6 \uf8f8 ",
        "prob": 0.43571428571428567
    }, {
        "ID": 5974,
        "phrase": " , ai : xi, ",
        "prob": 0.22000000000000003
    }, {
        "ID": 6130,
        "phrase": "ht ml or http://www",
        "prob": 0.15714285714285714
    }, {
        "ID": 6533,
        "phrase": " a solution for a given set of demanded rates {r c } is an assignment of values to variables {\u03bd cv ab , \u03bd cvi ab , \u03c0 {c,c \u2032 }j ib , \u03c0 cc \u2032 j ib , \u03c1 cc \u2032 j ab , \u03b3 {cv,c \u2032 v \u2032 } i , \u03c3 {c,c \u2032 } i , \u03b7 cc \u2032 j i } satisfying: b \u03bd cv ib + \u03bd cvi ib + c \u2032 =c,v \u2032 \u03b3 {cv,c \u2032 v \u2032 } i = a \u03bd cv ai + v \u2032 \u03bd cv \u2032 v vi + c \u2032 \u03b7 cc \u2032 v i + r c i = v = s c 0 v = s c , d c , i = d c b \u03c0 {c,c \u2032 }j ib + \u03c3 {c,c \u2032 }j i = a \u03c0 {c,c \u2032 }j ai + v,v \u2032 \u03b3 {cv,c \u2032 v \u2032 } i b \u03c0 cc \u2032 j ib + \u03b7 cc \u2032 j i = a \u03c0 cc \u2032 j ai + \u03c3 {c,c \u2032 }j i b \u03c1 cc \u2032 j ib + \u03b7 cc \u2032 j i = a \u03c1 cc \u2032 j ai + v \u03b3 {cv,c \u2032 i} j c,v (\u03bd cv ab + \u03bd cva ab ) + c,c \u2032 ,j \u03c1 cc \u2032 j ab + \u03c0 cc \u2032 j ab + {c,c \u2032 },j \u03c0 {c,c \u2032 }j ab \u2264 c ab we show how to find a solution for the problem with rates {r c } if there exists a solution for the problem with slightly higher rates {(1 + 2\u01eb)r c } for any \u01eb > 0",
        "prob": 0.7118421052631579
    }, {
        "ID": 6881,
        "phrase": " let ai = xi, qi, q 0 i , fi, \u2206i be an automaton of li, for any 1 \u2264 i \u2264 r",
        "prob": 0.2625
    }, {
        "ID": 7176,
        "phrase": " , (x im , y im , a im , b im ) independently of (x, y) according to p xi 1 yi 1 ai 1 bi 1 \u2022\u2022\u2022 xi m yi m ai m bi m ",
        "prob": 0.41000000000000003
    }, {
        "ID": 7177,
        "phrase": " , (x im , y im , a im , b im ) independently of (x, y) according to p xi 1 yi 1 ai 1 bi 1 \u2022\u2022\u2022 xi m yi m ai m bi m ",
        "prob": 0.41000000000000003
    }, {
        "ID": 7178,
        "phrase": " , (x im , y im , a im , b im ) independently of (x, y) according to p e xi 1 e yi 1 e ai 1 e bi 1 \u2022\u2022\u2022 e xi m e yi m e ai m e bi m ",
        "prob": 0.41000000000000003
    }, {
        "ID": 7408,
        "phrase": " if s = s 1 s 2 , there are two cases: if t = t 1 t 2 with s k \u2192 = ai t k then we conclude by (ih) and (cc)",
        "prob": 0.23333333333333334
    }, {
        "ID": 7408,
        "phrase": "r\u03b8b with l\u03c3\u2704 ai r\u03b8 and d\u03c3 \u2193 ai\u22121 c\u03c3",
        "prob": 0.22000000000000003
    }, {
        "ID": 7409,
        "phrase": " if s = s 1 s 2 , there are two cases: if t = t 1 t 2 with s k \u2192 = ai t k then we conclude by (ih) and (cc)",
        "prob": 0.23333333333333334
    }, {
        "ID": 7409,
        "phrase": "r\u03b8b with l\u03c3\u2704 ai r\u03b8 and d\u03c3 \u2193 ai\u22121 c\u03c3",
        "prob": 0.22000000000000003
    }, {
        "ID": 7516,
        "phrase": " in this case, (59) is equal to \uf8f1 \uf8f2 \uf8f3 e \uf8eb \uf8ed a1 \u03b1=1 c (p1,\u03b1) w c (q1,\u03b1) w b1 \u03b3=1 c (r1,\u03b3 ) w c (s1,\u03b3 ) w \uf8f6 \uf8f8 \u2212 e a1 \u03b1=1 c (p1,\u03b1) w c (q1,\u03b1) w e \uf8eb \uf8ed b1 \u03b3=1 c (r1,\u03b3 ) w c (s1,\u03b3 ) w \uf8f6 \uf8f8 \uf8fc \uf8fd \uf8fe \u00d7 j i=2 e ai \u03b1=1 c (pi,\u03b1) ui c (qi,\u03b1) ui \u2022 l i=2 e \uf8eb \uf8ed bi \u03b3=1 c (ri,\u03b3 ) vi c (si,\u03b3 ) vi \uf8f6 \uf8f8 \u00d7 product of \u03b4 functions, ( 60 ) where the summation is over all p i,\u03b1(i) , q i,\u03b1(i ) , i = 1, \u2022 \u2022 \u2022 , j, \u03b1(i) = 1, \u2022 \u2022 \u2022 , a i and r i,\u03b3(i) , s i,\u03b3(i) , i = 1, \u2022 \u2022 \u2022 , l, \u03b3(i) = 1, \u2022 \u2022 \u2022 , b i ",
        "prob": 0.3642857142857143
    }, {
        "ID": 7516,
        "phrase": " in this case, (59) is equal to \uf8f1 \uf8f2 \uf8f3 t i=1 e \uf8eb \uf8ed ai \u03b1=1 c (pi,\u03b1) wi c (qi,\u03b1) wi bi \u03b3=1 c (ri,\u03b3 ) wi c (si,\u03b3 ) wi \uf8f6 \uf8f8 \u2212 t i=1 e ai \u03b1=1 c (pi,\u03b1) wi c (qi,\u03b1) wi e \uf8eb \uf8ed bi \u03b3=1 c (ri,\u03b3 ) wi c (si,\u03b3 ) wi \uf8f6 \uf8f8 \uf8fc \uf8fd \uf8fe \u00d7 j i=t+1 e ai \u03b1=1 c (pi,\u03b1) ui c (qi,\u03b1) ui \u2022 l i=t+1 e \uf8eb \uf8ed bi \u03b3=1 c (ri,\u03b3 ) vi c (si,\u03b3 ) vi \uf8f6 \uf8f8 \u00d7 product of \u03b4 functions",
        "prob": 0.48518518518518516
    }, {
        "ID": 7705,
        "phrase": " , x n ]\u00b8\u00fb \u00d7 \u00fe \u00f6\u00f3\u00b9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 a / \u2208 h d \u00ba \u00e1\u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f3\u00fa \u00f3\u00f2 \u00f5\u00f9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 \u00f3 v \u00f4\u00f6\u00f3\u00fa \u00d7 \u00f8 \u00f8 \u00f8 \u00f6 \u00fc \u00d7\u00f8\u00d7 \u00f6 \u00d7 \u00b9\u00f0\u00f3\u00d7 \u00d7\u00f9 \u00d7 \u00f8 a gl n (c) \u00d7\u00f9 \u00f8 \u00f8 a \u2208 gl n (q) \\ ai a 0 \u2229 q[x 1 , ",
        "prob": 0.3
    }, {
        "ID": 7706,
        "phrase": " , x n ]\u00b8\u00fb \u00d7 \u00fe \u00f6\u00f3\u00b9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 a / \u2208 h d \u00ba \u00e1\u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f3\u00fa \u00f3\u00f2 \u00f5\u00f9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 \u00f3 v \u00f4\u00f6\u00f3\u00fa \u00d7 \u00f8 \u00f8 \u00f8 \u00f6 \u00fc \u00d7\u00f8\u00d7 \u00f6 \u00d7 \u00b9\u00f0\u00f3\u00d7 \u00d7\u00f9 \u00d7 \u00f8 a gl n (c) \u00d7\u00f9 \u00f8 \u00f8 a \u2208 gl n (q) \\ ai a 0 \u2229 q[x 1 , ",
        "prob": 0.4428571428571429
    }, {
        "ID": 7757,
        "phrase": "   simulation check(a 1 , a 2 ) /* ai = \u03c3, xi, g, li, ii, hi, ei, \u01ebi, \u03c4i, \u03c0i , 1 \u2264 i \u2264 2 */ { let q := h 1 \u2227 h 2 ; q \u2032 : (q = q \u2032 ), do { q \u2032 := q; for each e 1 \u2208 e 1 , q := q \u2227 \u00acf a (e 1 , q); if (i 1 = fm elm(i 1 \u2227 i 2 \u2227 q, l 2 \u222a x 2 \n ",
        "prob": 0.2818181818181818
    }, {
        "ID": 8391,
        "phrase": " , g m\u22121 (x)} by computing g i (x) = (f (x)) ai mod e(x)",
        "prob": 0.18333333333333335
    }, {
        "ID": 8465,
        "phrase": " 1i \u2212 ix 4q x 2i + ix 3i x 4i + ix 1q \u2212x 3q + ix 2q \u2212x 2i + ix 3i x 1i + ix 4q \u2212x 3q \u2212 ix 2q \u2212x 4i + ix 1q \u2212x 4i \u2212 ix 1q x 3q \u2212 ix 2q x 1i \u2212 ix 4q x 2i + ix 3i x 3q + ix 2q x 4i \u2212 ix 1q \u2212x 2i + ix 3i x 1i + ix 4q 0 0 x 5i \u2212 ix 8q x 6i + ix 7i x 8i + ix 5q \u2212x 7q + ix 6q \u2212x 6i + ix 7i x 5i + ix 8q \u2212x 7q \u2212 ix 6q \u2212x 8i + ix 5q \u2212x 8i \u2212 ix 5q x 7q \u2212 ix 6q x 5i \u2212 ix 8q x 6i + ix 7i x 7q + ix 6q x 8i \u2212 ix 5q \u2212x 6i + ix 7i x 5i + ix 8q 6 6 6 6 6 6 6 6 4 x 3 7 7 7 7 7 7 5 7 7 (6) \n\t\t\t for example, joint precoding of all the real variables will make the code 1-group ml decodable",
        "prob": 0.6978260869565217
    }, {
        "ID": 8754,
        "phrase": " likewise proportion of ci's edges in the whole graph is given by ai: eij = x v\u2208c i ,w\u2208c j avw/2m ai = x v\u2208c i kv/2m",
        "prob": 0.3
    }, {
        "ID": 8766,
        "phrase": " moreover, \u03c8(r 0 \u03c8 + \u03c6 1 , \u03c6 2 ) = ai and det(r 0 \u03c8 + \u03c6 1 ) = r 2 0 det \u03c8 + det \u03c6 1 \u2212 r 0 \u03c8(\u03c8, \u03c6 1 ) = 0",
        "prob": 0.18333333333333332
    }, {
        "ID": 9005,
        "phrase": ", in machine learning, the minimum description length (mdl) principle can be regarded as a downscaled practical version of ac",
        "prob": 0.13125
    }, {
        "ID": 9143,
        "phrase": " we first note that for the more complicated ones are: z a z b \u2208 z 2 \u2297z 2 with a \u227b b, there is an \u03b1 a,b \u2208 p 2 , such that \u03b1 a,b = z a z b + i a i z ai z bi with a i \u227b b i ",
        "prob": 0.21000000000000002
    }, {
        "ID": 9243,
        "phrase": " an alcnr-knowledge base is a pair = ht ; ai where t is a tbox and a is an abox",
        "prob": 0.19090909090909092
    }, {
        "ID": 9380,
        "phrase": " xc \u2032 i = ai * (x2i\u22121 + x2ij) + (re(bi) + im(bi)j) = (ai * x2i\u22121 + re(bi)) + (ai * x2i + im(bi))j for i = 1, \u2022 \u2022 \u2022 , k",
        "prob": 0.7000000000000001
    }, {
        "ID": 9380,
        "phrase": " if we map the resulting vector to a point x \u2032 in srect, we get x \u2032 2i\u22121 = ai * x2i\u22121 + re(bi) and x \u2032 2i = ai * x2i + im(bi) for i = 1, \u2022 \u2022 \u2022 , k",
        "prob": 0.3642857142857143
    }, {
        "ID": 9381,
        "phrase": " xc \u2032 i = ai * (x2i\u22121 + x2ij) + (re(bi) + im(bi)j) = (ai * x2i\u22121 + re(bi)) + (ai * x2i + im(bi))j for i = 1, \u2022 \u2022 \u2022 , k",
        "prob": 0.7000000000000001
    }, {
        "ID": 9381,
        "phrase": " if we map the resulting vector to a point x \u2032 in srect, we get x \u2032 2i\u22121 = ai * x2i\u22121 + re(bi) and x \u2032 2i = ai * x2i + im(bi) for i = 1, \u2022 \u2022 \u2022 , k",
        "prob": 0.3642857142857143
    }, {
        "ID": 9448,
        "phrase": " t he ac t i ve s t at i ons i nc l ude t hos e t hat have f r ame s t o t r a n s m i t a n d a r e w ai t i ng f or th ea c c e ssrig h t, that is, for ausable tokentoarrive alongw i t h t h e c u r r e n t l y t r a n s m i t t i n g s t a t i o n , i f a n y ",
        "prob": 0.29285714285714287
    }, {
        "ID": 9448,
        "phrase": "t h us , t he ke y me t r i c i s not t he t hr oughput unde r l ow loadbut the m axim umobt ai nabl e t hr oughput unde r hi gh l oad",
        "prob": 0.6529411764705882
    }, {
        "ID": 9450,
        "phrase": " more r e s e a r c hi n t h i sa r e ai sr e q u i r e db e f o r et h i sp r o p o s a lc a n be i mpl emen t e di n t on e t w orks",
        "prob": 0.25833333333333336
    }, {
        "ID": 9517,
        "phrase": "+an, ai = (li) \u22121 \u2022mi \u2208 q(x, y, dx) if we define the corresponding dy-differentiation for the coefficients: l \u22121 \u2022 m = m \u2022 l \u22121 , l, m, l, m \u2208 r ([ \u2202 (li) \u22121 \u2022mi /\u2202y = (li) \u22121 \u2022\u2202(mi)/\u2202y\u2212(li) \u22121 \u2022l \u2032 i \u2022(li) \u22121 with \u2202(mi)/\u2202y = \u2202 m0(x, y)d k x + ",
        "prob": 0.2733333333333334
    }]
}, {
    "topic_id": 10,
    "top_words": ["artificial", "intelligence", "systems", "agent", "distributed", "agents", "knowledge", "information", "work", "multi", "based", "software", "model", "area", "system"],
    "phrases": [{
        "ID": 6,
        "phrase": " in fact, the distributed artificial intelligence literature is full of systems that try to make the agents' decisions as loosely-coupled as possible (??)",
        "prob": 0.44999999999999996
    }, {
        "ID": 7,
        "phrase": " in fact, the distributed artificial intelligence literature is full of systems that try to make the agents' decisions as loosely-coupled as possible  (lesser and corkill [1981] ,  liu and sycara [1995] )",
        "prob": 0.5499999999999999
    }, {
        "ID": 8,
        "phrase": " in fact, the distributed artificial intelligence literature is full of systems that try to make the agents' decisions as loosely-coupled as possible  [19, 21] ",
        "prob": 0.33888888888888885
    }, {
        "ID": 50,
        "phrase": "  glover and mcmillan [4]  rely on integration of techniques from management sciences and artificial intelligence to solve general shift scheduling problems",
        "prob": 0.2833333333333334
    }, {
        "ID": 51,
        "phrase": "  glover and mcmillan [4]  rely on integration of techniques from management sciences and artificial intelligence to solve general shift scheduling problems",
        "prob": 0.2833333333333334
    }, {
        "ID": 141,
        "phrase": " \n the ai\u00b5 model in functional form the cybernetic or agent model: a good way to start thinking about intelligent systems is to consider more generally cybernetic systems, in ai usually called agents",
        "prob": 0.6565217391304348
    }, {
        "ID": 423,
        "phrase": " actual causation is also important in artificial intelligence applications",
        "prob": 0.31
    }, {
        "ID": 449,
        "phrase": " levy and weld  [82]  wrote a survey in the special issue of artificial intelligence on intelligent internet systems that we think describes a broader domain than web mining",
        "prob": 0.19523809523809527
    }, {
        "ID": 473,
        "phrase": " \n related work analysis of malfunctioning systems based on their intended logical specification has been studied in the field of artificial intelligence  [5]  and known as model-based diagnosis, which has some similarities with our work",
        "prob": 0.3521739130434783
    }, {
        "ID": 631,
        "phrase": ",  [10, 15, 43, 55] ), but the term \"grid\" has also been conflated, at least in popular perception, to embrace everything from advanced networking to artificial intelligence",
        "prob": 0.38125000000000003
    }, {
        "ID": 641,
        "phrase": " also, function optimization can be viewed as search, so theories developed for it may be relevant to other applications of search, for instance artificial intelligence  [21]  and evolutionary biology  [30] ",
        "prob": 0.2157894736842105
    }, {
        "ID": 708,
        "phrase": " in breuker, leenes & winkels (eds) legal knowledge and information systems, jurix 2000: the 13th annual conference, frontiers in artificial intelligence and applications series, ios press, pp",
        "prob": 0.7958333333333332
    }, {
        "ID": 708,
        "phrase": " in breuker, leenes & winkels (eds) legal knowledge and information systems, jurix 2000: the 13th annual conference, frontiers in artificial intelligence and applications series, ios press, pp",
        "prob": 0.8374999999999998
    }, {
        "ID": 708,
        "phrase": " in breuker, leenes & winkels (eds) legal knowledge and information systems, jurix 2000: the 13th annual conference, frontiers in artificial intelligence and applications series, ios press, pp",
        "prob": 0.8374999999999998
    }, {
        "ID": 708,
        "phrase": " in breuker, leenes & winkels (eds) legal knowledge and information systems, jurix 2000: the 13th annual conference, frontiers in artificial intelligence and applications series, ios press, pp",
        "prob": 0.8374999999999998
    }, {
        "ID": 708,
        "phrase": " in breuker, leenes & winkels (eds) legal knowledge and information systems, jurix 2000: the 13th annual conference, frontiers in artificial intelligence and applications series, ios press, pp",
        "prob": 0.8374999999999998
    }, {
        "ID": 708,
        "phrase": " in breuker, leenes & winkels (eds) legal knowledge and information systems, jurix 2000: the 13th annual conference, frontiers in artificial intelligence and applications series, ios press, pp",
        "prob": 0.8374999999999998
    }, {
        "ID": 708,
        "phrase": " in breuker, leenes & winkels (eds) legal knowledge and information systems, jurix 2000: the 13th annual conference, frontiers in artificial intelligence and applications series, ios press, pp",
        "prob": 0.8374999999999998
    }, {
        "ID": 725,
        "phrase": " the autonomous nature of the information sources, where we may only be able to represent partial information and where information from different sources may be overlapping or even inconsistent, increases the possibilities to apply techniques from the areas of artificial intelligence and computational logic",
        "prob": 0.21034482758620693
    }, {
        "ID": 757,
        "phrase": " \n how it is related to distributed artificial intelligence nowadays the most popular approach to distributed artificial intelligence (dai) is the concept of intelligent agents, particularly mobile agents -the complete atomic intelligent systems which are set to accomplish a specific task by means of their internal intelligence",
        "prob": 0.5656249999999999
    }, {
        "ID": 757,
        "phrase": " some more complicated search engines use ai techniques for finding related pages, but at any rate everything is based on plain-text representation of the initial information",
        "prob": 0.355
    }, {
        "ID": 895,
        "phrase": ", expert systems and artificial intelligence, 229",
        "prob": 0.3875
    }, {
        "ID": 1034,
        "phrase": " the ml approach is more convenient than the ke approach also in this latter case",
        "prob": 0.31
    }, {
        "ID": 1241,
        "phrase": " such an idea fits very well with ideas popular in the distributed artificial intelligence community concerning the role of intelligent agents",
        "prob": 0.4764705882352941
    }, {
        "ID": 1271,
        "phrase": " * this work was partially supported by the jean and helene alfassa fund for research in artificial intelligence reading",
        "prob": 0.6066666666666667
    }, {
        "ID": 1280,
        "phrase": " in the limit case, where all agents have access to information regarding the state sensed by all their peers, each agent could be seen as a classical machine learning (ml) system with distributed sensors if we consider other agents' actions as part of the environment",
        "prob": 0.21785714285714283
    }, {
        "ID": 1282,
        "phrase": " now, this may be the future of computing but software agents originated from the field of artificial intelligence, back in the 1950's",
        "prob": 0.22142857142857145
    }, {
        "ID": 1291,
        "phrase": " the contribution of this work to ai is in the area of knowledge representation",
        "prob": 0.5666666666666668
    }, {
        "ID": 1291,
        "phrase": " the second sub-system is a two-agent model based on distributed artificial intelligence  [bg88] ",
        "prob": 0.4733333333333334
    }, {
        "ID": 1291,
        "phrase": " first, we present background information regarding ai methodologies applied to music, and software agents and dai",
        "prob": 0.43571428571428567
    }, {
        "ID": 1291,
        "phrase": " \n artificial intelligence and music in this section we describe some representative research that applies artificial intelligence (ai) methodologies (i",
        "prob": 0.4733333333333334
    }, {
        "ID": 1291,
        "phrase": " a detailed overview of music systems that use ai tools can be found in  [cam93] ",
        "prob": 0.19090909090909092
    }, {
        "ID": 1291,
        "phrase": " distributed artificial intelligence (dai) is the area in ai that investigates the behavior of societies of agents",
        "prob": 0.5083333333333334
    }, {
        "ID": 1291,
        "phrase": " research in distributed artificial intelligence (dai)  [bg88]  can also contribute to developing new methods for computer music",
        "prob": 0.4066666666666666
    }, {
        "ID": 1291,
        "phrase": " this research focuses on the question of whether there is any advantage in integrating a neural network together with a distributed artificial intelligence approach within the music domain",
        "prob": 0.255
    }, {
        "ID": 1334,
        "phrase": "  [26, 42, 43] ), artificial intelligence (e",
        "prob": 0.35000000000000003
    }, {
        "ID": 1368,
        "phrase": " examples of modules are classes in object-oriented systems, modules in languages of the modula and ml families, packages in the ada lineage, etc",
        "prob": 0.22777777777777775
    }, {
        "ID": 1398,
        "phrase": ", and instead seek a purely operational approach to artificial intelligence",
        "prob": 0.4636363636363637
    }, {
        "ID": 1398,
        "phrase": " the idea that logic should be the foundation for ai has fallen out of favor; indeed, much of the work of artificial intelligence today is done with non-discrete systems such as neural nets, which would not count as part of proof theory",
        "prob": 0.2730769230769231
    }, {
        "ID": 1398,
        "phrase": " i also think that some of the currently expressed fears about the dangers of artificial intelligence are way overblown",
        "prob": 0.23846153846153847
    }, {
        "ID": 1525,
        "phrase": "introduction in the field of artificial intelligence, knowledge-based systems (kbs) and behaviour-based systems (bbs) have modelled and simulated exhibitions of intelligence of different types, which we could call \"cognitive\" intelligence and \"adaptive\" intelligence, respectively",
        "prob": 0.4862068965517241
    }, {
        "ID": 1525,
        "phrase": " in section 4 we note limits of bbks, which are related to the limits of epigenetic robotics and artificial intelligence",
        "prob": 0.22142857142857145
    }, {
        "ID": 1564,
        "phrase": " for example, since the early 40s there is a distinction between classical decision theory and artificial intelligence based on utility aspiration levels and goal based planning (as pioneered by simon  [12] )",
        "prob": 0.18636363636363634
    }, {
        "ID": 1682,
        "phrase": " the brain has better pattern recognition capabilities than most of the ai software",
        "prob": 0.31
    }, {
        "ID": 1698,
        "phrase": " objective caml is a popular object-oriented dialect of ml that takes this approach  (chailloux et al",
        "prob": 0.29285714285714287
    }, {
        "ID": 1839,
        "phrase": " our future work is directed to evolving the bvl with feedback of researchers in the areas of ethology, artificial intelligence, life sciences, and complex systems",
        "prob": 0.37368421052631584
    }, {
        "ID": 1840,
        "phrase": " within computer sciences, the artificial intelligence area has constituted one of the main scenarios to model biological systems",
        "prob": 0.5687500000000001
    }, {
        "ID": 1840,
        "phrase": " between the main techniques of artificial intelligence and computer sciences commonly used to model cellular signalling networks are artificial neural networks  [1 and 18] , boolean networks  [4 ] , petri nets  [7] , rule-based systems  [3] , cellular automata  [4] , and multi-agent systems  [5, 17 and 19] ",
        "prob": 0.5193548387096774
    }, {
        "ID": 1840,
        "phrase": " \n blackboard architecture the blackboard architecture concept was conceived by artificial intelligence researchers in the 1970's",
        "prob": 0.7000000000000001
    }, {
        "ID": 1840,
        "phrase": " (1) was obtained when considering the adaptive autonomous agents as functional components of the model, and using different techniques of artificial intelligence to support the cognitive capabilities mentioned in section 5",
        "prob": 0.3681818181818182
    }, {
        "ID": 1841,
        "phrase": " among the main techniques of artificial intelligence and computer sciences commonly used to model cellular signalling networks are artificial neural networks  (bray and lay, 1994; pritchard and dufton, 2000) , boolean networks  (edwards, 1995) , petri nets  (fuss, 1987) , rule-based systems  (c\u00e1rdenas-garc\u00eda, 2001) , cellular automata  (edwards, 1995; wurthner, mukhopadhyay and peimann, 2000) , and multi-agent systems  (fisher, paton and matsuno, 1999; paton, staniford and kendall, 1995; schwab and pienta, 1997) ",
        "prob": 0.5980769230769231
    }, {
        "ID": 1841,
        "phrase": " \n conclusion we have constructed an agent-based system where cognitive capabilities are coded using behaviour-based paradigms and the blackboard architecture, combined with other artificial intelligence techniques",
        "prob": 0.5045454545454546
    }, {
        "ID": 1850,
        "phrase": "introduction by the middle 1980's, researchers in the areas of artificial intelligence (ai), computer sciences, cognitive sciences and psychology realized that the idea of computers as intelligent machines was inappropriate",
        "prob": 0.33809523809523806
    }, {
        "ID": 1871,
        "phrase": " those who champion the situated robotics approach to artificial intelligence (e",
        "prob": 0.6100000000000001
    }, {
        "ID": 1871,
        "phrase": " \n conclusion the focus of this paper has been limited to addressing french's claim, but there may be more general lessons here about the nature of human cognition and the philosophical foundations of research in situated robotics and embodied artificial intelligence",
        "prob": 0.284
    }, {
        "ID": 1928,
        "phrase": " usually, skepticism and credulism represent two major semantic intuitions for knowledge representation in artificial intelligence",
        "prob": 0.44375000000000003
    }, {
        "ID": 1929,
        "phrase": " usually, skepticism and credulism represent two major semantic intuitions for knowledge representation in artificial intelligence",
        "prob": 0.44375000000000003
    }, {
        "ID": 1937,
        "phrase": ", 1996][sutton and barto, 1998 ], well studied in the control systems and ai literature (and was one of the main influences in bringing controltheoretic techniques to realize adaptivity in scientific software; e",
        "prob": 0.255
    }, {
        "ID": 2025,
        "phrase": " in classical cognitive science and artificial intelligence (e",
        "prob": 0.4555555555555556
    }, {
        "ID": 2025,
        "phrase": " cybernetics  (wiener, 1948) , and more recently certain branches of artificial intelligence and artificial life (e",
        "prob": 0.39230769230769236
    }, {
        "ID": 2333,
        "phrase": " universally optimal ai systems",
        "prob": 0.15714285714285717
    }, {
        "ID": 2333,
        "phrase": " \n the ai\u00b5 model in functional form \n the cybernetic agent model a good way to start thinking about intelligent systems is to consider more generally cybernetic systems, in ai usually called agents",
        "prob": 0.6565217391304348
    }, {
        "ID": 2333,
        "phrase": " \n y \n artificial intelligence | control theory agent = controller environment = system policy = control=policy transition matrix = transition matrix? observation=input=perception = output action=output = input (instantaneous) reward = immediate or one-period cost cumulative reward=value = expected (total) cost(-to-go) model learning = system identification exploitation =? (optimal?) stochastic control? reactive agent = closed loop control prewired agent? = open loop control markov decision process = controlled markov chain belief state = information state bellman equationbellman equations = bellman equation (ricatti eq",
        "prob": 0.17285714285714285
    }, {
        "ID": 2474,
        "phrase": " 8  this definition of knowledge has proved useful in many applications in distributed systems and ai (see  [fhmv95]  and the references therein)",
        "prob": 0.25625000000000003
    }, {
        "ID": 2559,
        "phrase": " what is most interesting about these results is that these pairs denote the original contributions that were offered by the dissertation! indeed, the dissertation was about using ideas and methodologies from complex adaptive systems, evolutionary systems, and artificial life and apply them to artificial intelligence and cognitive science",
        "prob": 0.41724137931034483
    }, {
        "ID": 2732,
        "phrase": " some related research on automatically accumulating and categorizing is carried out in ai and semantic network area",
        "prob": 0.3153846153846154
    }, {
        "ID": 2749,
        "phrase": " \u2022 to review the artificial intelligence capabilities of the sp model and its relationship with other artificial intelligence systems",
        "prob": 0.5785714285714286
    }, {
        "ID": 2749,
        "phrase": " the main points of difference between the sp system and other artificial intelligence systems are also reviewed",
        "prob": 0.23846153846153847
    }, {
        "ID": 2749,
        "phrase": " the artificial intelligence capabilities of the sp model are reviewed and its relationship with other artificial intelligence systems is described",
        "prob": 0.54
    }, {
        "ID": 2797,
        "phrase": " we suggest to abandon the term configuration, bound to a very specific application area (even if it is broadly distributed in the economy), in favor of a more general purpose and ai related denomination : object oriented constraint programs (oocp for short)",
        "prob": 0.37407407407407406
    }, {
        "ID": 2797,
        "phrase": " oocp has many potential ai applications, ranging from context free language parsing (we use this example), to image recognition, or distributed agent intelligence and planning",
        "prob": 0.2904761904761905
    }, {
        "ID": 2797,
        "phrase": " section 5 presents the specification of an artificial intelligence application of object oriented constraint programs to context free grammars parsing",
        "prob": 0.33888888888888885
    }, {
        "ID": 2839,
        "phrase": " the developed formalism can be implemented in any applications that use hierarchically structured information, such as \u2022 taxonomical and content management systems; \u2022 expert, artificial intelligence, and machine learning systems; \u2022 intelligent control systems and robots; \u2022 data and knowledge bases; \u2022 internet search engines, online documentation, and help subsystems; \u2022 application-specific lists, catalogues, and directories; \u2022 compilers for object-and aspect-oriented languages with multiple inheritance; \u2022 generative and intentional programming environments; \u2022 components of operating systems (file and folder catalogues, registry, etc",
        "prob": 0.31311475409836065
    }, {
        "ID": 2844,
        "phrase": " (artificial intelligence) in them",
        "prob": 0.35000000000000003
    }, {
        "ID": 2845,
        "phrase": " (artificial intelligence) in them",
        "prob": 0.35000000000000003
    }, {
        "ID": 3010,
        "phrase": "introduction distributed systems composed of large numbers of relatively simple autonomous agents are receiving increasing amount of attention in the artificial intelligence (ai), robotics and networking communities",
        "prob": 0.3521739130434782
    }, {
        "ID": 3010,
        "phrase": " it has been applied to ecology  [25] , epidemiology  [18] , social dynamics  [27] , artificial intelligence  [30] , and behavior of markets  [29] , to name just a few disciplines",
        "prob": 0.5071428571428572
    }, {
        "ID": 3129,
        "phrase": " the classical ai approach known as the interpreted symbolic structures approach, where knowledge is based on information stored in data structures of the agent  [rosenschein 1985 ], can be seen as an instance of explicit knowledge",
        "prob": 0.5695652173913044
    }, {
        "ID": 3130,
        "phrase": " the classical ai approach known as the interpreted symbolic structures approach, where knowledge is based on information stored in data structures of the agent, can be seen as an instance of explicit knowledge",
        "prob": 0.55
    }, {
        "ID": 3131,
        "phrase": " the classical ai approach known as the interpreted symbolic structures approach, where knowledge is based on information stored in data structures of the agent, can be seen as an instance of explicit knowledge",
        "prob": 0.5045454545454545
    }, {
        "ID": 3332,
        "phrase": " fipa), support for the mobility of the agents from host to host, ability to support ai oriented languages (e",
        "prob": 0.29285714285714287
    }, {
        "ID": 3708,
        "phrase": " many lessons important for this domain can be learned from the multi-agent systems field of artificial intelligence (ai) concerning relevant topics for cooperative robotics, such as distributed continual planning  (desjardins, m",
        "prob": 0.46249999999999997
    }, {
        "ID": 3713,
        "phrase": " in the field of artificial intelligence, agent is regarded as an autonomous object with lifecycle in certain circumstances, and a system consisting of multiple agents that interact with and interrelate to each other is called a multi-agent system or mas",
        "prob": 0.7124999999999998
    }, {
        "ID": 3713,
        "phrase": "the study of the collaboration, coordination and negotiation among different agents in a multi-agent system (mas) has always been the most challenging yet popular in the research of distributed artificial intelligence",
        "prob": 0.41363636363636364
    }, {
        "ID": 3871,
        "phrase": "introduction over the last few years, a number of studies were reported concerning a machine learning, and how it has been applied to help mobile robots to improve their operational capabilities",
        "prob": 0.20500000000000002
    }, {
        "ID": 3871,
        "phrase": " the ability to acquire these faculties to treat and transmit knowledge constitutes the key of a certain kind of artificial intelligence",
        "prob": 0.19375
    }, {
        "ID": 3874,
        "phrase": " \u2022 the artificial intelligence category attempts to validate psychology hypothesis, mainly learning, by simulating intelligent mobile robot behaviors",
        "prob": 0.2833333333333333
    }, {
        "ID": 3892,
        "phrase": " in contrast, welldefined problem solving tasks have been a primary area of research for artificial intelligence work on multi-agent algorithms  [13] ",
        "prob": 0.33888888888888885
    }, {
        "ID": 3959,
        "phrase": "9, 10 artificial intelligence ",
        "prob": 0.18333333333333332
    }, {
        "ID": 4071,
        "phrase": " \n related work a variety of approaches to state estimation and fault diagnosis have been proposed in the control systems, artificial intelligence, and robotics literature",
        "prob": 0.4789473684210526
    }, {
        "ID": 4248,
        "phrase": " thus, we introduce a new approach to universal artificial intelligence, which is in a sense dual to the aixi model based on bayesian learning  [hut04] ",
        "prob": 0.2157894736842105
    }, {
        "ID": 4264,
        "phrase": " they give operational tools for modelling agent behaviour for various simulations in the domain of distributed artificial intelligence  [2] ",
        "prob": 0.38125000000000003
    }, {
        "ID": 4269,
        "phrase": " distribution of vowel inventories sizes in emergent and upsid human vowel systems \n \n \n\t\t\t this does not mean that nowadays honey bees have not a precise innate hard \n\t\t\t the term 'agent' is used in artificial intelligence as an abbreviation of 'artificial software agent', and denotes a software entity which is functionally equivalent to a robot (this is like a virtual robot in the virtual environment of the computer) \n\t\t\t (v i,t ",
        "prob": 0.36829268292682926
    }, {
        "ID": 4409,
        "phrase": " software elements draw from numerous domains, including the natural sciences, artificial intelligence, sensor networks, and embedded systems",
        "prob": 0.2833333333333334
    }, {
        "ID": 4415,
        "phrase": " introduction a traditional approach to artificial intelligence (ai) is known as connectionism, and its represented by the field of artificial neural network (ann)",
        "prob": 0.3
    }, {
        "ID": 4552,
        "phrase": " \n introduction the robocup soccer server  [13]  is a useful simulation tool for developing and evaluating different approaches in the field of artificial intelligence, robotics and multi-agent systems",
        "prob": 0.23181818181818184
    }, {
        "ID": 5488,
        "phrase": " \n artificial intelligence intelligence knowledge based expert systems, knowledge based expert systems or simply, expert systems are a product of artificial intelligence [a",
        "prob": 0.6714285714285714
    }, {
        "ID": 5520,
        "phrase": " we assume that the reader has a basic familiarity with artificial neural networks and symbolic artificial intelligence, as conveyed by any introductory courses or textbooks on the topic, e",
        "prob": 0.26842105263157895
    }, {
        "ID": 5859,
        "phrase": " further developments in this area exploit the use of artificial intelligence (ai) technique to estimate the inertia matrix automatically and continuously using neural network  (mailah, 2001) , iterative learning  (loo et al",
        "prob": 0.26521739130434785
    }, {
        "ID": 6146,
        "phrase": " recent developments of artificial intelligence oriented to integrating knowledge from multiple sources include the use of knowledge systems, cognitive dictionaries, datasets, data dictionaries",
        "prob": 0.45909090909090905
    }, {
        "ID": 6356,
        "phrase": " adaptive control theory  [kv86]  considers very simple (from an ai perspective) or special systems (e",
        "prob": 0.23846153846153847
    }, {
        "ID": 6398,
        "phrase": " however, \"learning\" is understood differently in different sections of the artificial intelligence",
        "prob": 0.2583333333333333
    }, {
        "ID": 6398,
        "phrase": " from the analysis of the literature on the artificial intelligence it is possible to distinguish two types of learning depending on whether an intelligent system or an organism has or has not aprioristic information about an object",
        "prob": 0.33809523809523806
    }, {
        "ID": 6398,
        "phrase": " all modern systems of the artificial intelligence are capable of learning only after the second type, i",
        "prob": 0.3416666666666667
    }, {
        "ID": 6398,
        "phrase": " it includes all living organisms (including the man), the artificial intelligence and adaptive systems",
        "prob": 0.3416666666666667
    }, {
        "ID": 6590,
        "phrase": " in artificial intelligence, this framework is used in the area of reinforcement learning  [sb98] ",
        "prob": 0.25833333333333336
    }, {
        "ID": 6590,
        "phrase": " of course in artificial intelligence the agent will be a machine and so \u03c0 will be a computable function",
        "prob": 0.2818181818181818
    }, {
        "ID": 6658,
        "phrase": "  1  we neglect issues of convergence of the em algorithm and assume that the ml estimation is performed perfectly",
        "prob": 0.23846153846153847
    }, {
        "ID": 6721,
        "phrase": " (from a more traditional for ai perspective -in terms of product model and considering the past that is, obviously, a particular case of the first law of creative semiosis, the creative process can be defined as a mapping f n [\u00b5 n (f n-1 [\u00b5 n-1 (f n-2 [\u2026\u00b5 1 (f 0 [\u03be 0 ])\u2026])])] \u2192 \u03c9 = \u2329\u03c6, \u03bb\u232a -17- representing a progressive transition from a state described in \u03be 0 as an initial specification, to \u03c9 a model of the creative product -a solution that comprises a requirement specification \u03c6, that is a formal theory, and its realization \u03bb, that is a model of the theory",
        "prob": 0.19285714285714284
    }, {
        "ID": 6785,
        "phrase": " it is reasonable to state that a strong artificial intelligence system competitive to the creative human brain should exhibit a certain level of complexity",
        "prob": 0.33888888888888885
    }, {
        "ID": 7000,
        "phrase": " \n artificial intelligence isn't the way to smarter software what exactly is artificial intelligence (ai)? even ai wizards have trouble answering this question",
        "prob": 0.5055555555555556
    }, {
        "ID": 7000,
        "phrase": " for present purposes ai is about \"smarter\" software in general",
        "prob": 0.23333333333333334
    }, {
        "ID": 7000,
        "phrase": " thus hard ai can never be the ultimate answer to smarter software",
        "prob": 0.2818181818181818
    }, {
        "ID": 7000,
        "phrase": " it is not in any sense artificial intelligence software",
        "prob": 0.3875
    }, {
        "ID": 7566,
        "phrase": " indeed, in both the artificial intelligence and the systems communities a surprisingly broad array of issues have been proposed as appropriate to approach via voting systems",
        "prob": 0.3736842105263158
    }, {
        "ID": 7805,
        "phrase": " as these bonds are widened, one may expect progress in artificial intelligence and other disciplines",
        "prob": 0.42500000000000004
    }, {
        "ID": 7806,
        "phrase": " as these bonds are widened, one may expect progress in artificial intelligence and other disciplines",
        "prob": 0.3416666666666667
    }, {
        "ID": 7807,
        "phrase": " as these bonds are widened, one may expect progress in artificial intelligence and other disciplines",
        "prob": 0.3416666666666667
    }, {
        "ID": 7915,
        "phrase": " but it is also worth considering car racing from an evolutionary robotics (er) / embodied artificial intelligence perspective",
        "prob": 0.3642857142857143
    }, {
        "ID": 8108,
        "phrase": " the kernel is designed by the ml expert and it governs the efficiency of the svm approach",
        "prob": 0.25833333333333336
    }, {
        "ID": 8147,
        "phrase": " in distributed ai applied in requirement engineering for complex software design, the use of viewpoints is to organise multi-perspective software development and to manage inconsistency (see for example  13  )",
        "prob": 0.41363636363636364
    }, {
        "ID": 8148,
        "phrase": " in distributed ai applied in requirement engineering for complex software design, the use of viewpoints is to organise multi-perspective software development and to manage inconsistency (see for example  13  )",
        "prob": 0.41363636363636364
    }, {
        "ID": 8172,
        "phrase": "  falzon and visser (1989)  have identified this problem as a general one in knowledge acquisition, especially when the traditional -and in ai preferred-interview methods are used: designers may present their knowledge (structures and processes) in terms adapted to the knowledge engineers",
        "prob": 0.325
    }, {
        "ID": 8172,
        "phrase": " the \"collaboration\" between a human information system and an ai system is generally based on pragmatic reasons: autonomous, automatic systems do not manage alone in complex tasks, and this problem is handled in a pragmatic, empirical way -even if this stand is never made explicit",
        "prob": 0.47
    }, {
        "ID": 8196,
        "phrase": " on the basis of the work performed in different disciplines -artificial intelligence  (wenger, 1987) , cognitive ergonomics  (rasmussen, 1979; darses, 1997) , ethnomethodology  (bucciarelli, 1998) , computer-supported-cooperative work  (schmidt, 1994) , an initial general definition of the notion of \"viewpoint\" would be : \" for a person, a particular, personal, representation of an object to be designed\"",
        "prob": 0.7742857142857141
    }, {
        "ID": 8197,
        "phrase": " on the basis of the work performed in different disciplines -artificial intelligence  (wenger, 1987) , cognitive ergonomics  (rasmussen, 1979; darses, 1997) , ethnomethodology  (bucciarelli, 1998) , computer-supported-cooperative work  (schmidt, 1994) , an initial general definition of the notion of \"viewpoint\" would be : \" for a person, a particular, personal, representation of an object to be designed\"",
        "prob": 0.7742857142857141
    }, {
        "ID": 8205,
        "phrase": " on the basis of the work performed in different disciplines -artificial intelligence  (wenger, 1987) , cognitive ergonomics  (rasmussen, 1979; darses, 1997) , ethnomethodology  (bucciarelli, 1998) , computer-supported-cooperative work  (schmidt, 1994) , an initial general definition of the notion of \"viewpoint\" would be : \" for a person, a particular, personal, representation of an object to be designed\"",
        "prob": 0.7457142857142856
    }, {
        "ID": 8266,
        "phrase": " this requires a shared workspace accessible to all contributors (similar to what in ai is called a \"blackboard system\")",
        "prob": 0.39230769230769236
    }, {
        "ID": 8497,
        "phrase": " \n multi-agent systems mass originate in distributed artificial intelligence (dai) and in artificial life",
        "prob": 0.65
    }, {
        "ID": 8498,
        "phrase": " \n multi-agent systems mass originate in distributed artificial intelligence (dai) and in artificial life",
        "prob": 0.7214285714285715
    }, {
        "ID": 8555,
        "phrase": " \n the cybernetic agent model a good way to start thinking about intelligent systems is to consider more generally cybernetic systems, in ai usually called agents",
        "prob": 0.755
    }, {
        "ID": 8555,
        "phrase": " if \u00b5 ai is the true prior probability, the question now is, what is the behavior \u1e8fai k of the ai\u00b5 agent",
        "prob": 0.11000000000000001
    }, {
        "ID": 8634,
        "phrase": " nouns artint artificial intelligence 1624 405 231 artlife artificial life 2095 448 275 artnn artificial neural network 4698 1262 389 captcha captcha 1479 318 169 complin computational linguistics 648 168 80 compvis computer vision 2396 737 311 evolcom evolutionary computation 156 58 43 fuzzlog fuzzy logic 1663 399 204 genalg genetic algorithms 2775 715 306 matrans machine translation 1643 411 172 magent multi-agent system 493 104 67 semnet semantic network 475 96 74 turing turing test 2432 459 225 virtw virtual world 583 144 79 all files 5724 1165",
        "prob": 0.3081632653061224
    }, {
        "ID": 8673,
        "phrase": " frontiers in artificial intelligence and application(serie)",
        "prob": 0.26249999999999996
    }, {
        "ID": 8941,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.8142857142857141
    }, {
        "ID": 8942,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.8142857142857141
    }, {
        "ID": 8943,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.8142857142857141
    }, {
        "ID": 8944,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.8142857142857141
    }, {
        "ID": 8945,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.7666666666666665
    }, {
        "ID": 8946,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.8142857142857141
    }, {
        "ID": 8947,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.7666666666666665
    }, {
        "ID": 8948,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.8142857142857141
    }, {
        "ID": 8949,
        "phrase": " this area comprises classical systems and 'discrete' automata theories endorsed by system-theoretical  (r\u00f6ssler, 1971) , artificial intelligence (ai) and artificial life (alife) approaches such as evolutionary computation  (fogel et al",
        "prob": 0.7958333333333332
    }, {
        "ID": 8949,
        "phrase": ", 2006) , machine learning  (mitchel, 1997) , synthetic neural networks  (dyer, 1995; smith, 2006)  or adaptive autonomous agents  (maes, 1995)  for transducing knowledge from biology and related life science disciplines into computer science and engineering",
        "prob": 0.35000000000000003
    }, {
        "ID": 9183,
        "phrase": " \n conclusion in our closing remarks, we would like to emphasize several aspects of our parsing model which make it interesting from the perspective of cognitive science and brain-inspired artificial intelligence",
        "prob": 0.2652173913043478
    }, {
        "ID": 9244,
        "phrase": " prominent among the alternative approaches are the so-called behavior-based, situated, and animat methods  (brooks, 1986; maes, 1989; kaelbling & rosenschein, 1990; wilson, 1991) , which convert sensory inputs into actions in a much more direct fashion than do ai systems based on representation and reasoning",
        "prob": 0.3903225806451613
    }, {
        "ID": 9255,
        "phrase": " this gives succinct and useful representations, as the ones discussed in discrete event systems (des)  (ramadge & wonham, 1989)  and in work in ai that incorporates uncertainty to control-theoretic models  (moses & tennenholtz, 1991) ",
        "prob": 0.2652173913043478
    }, {
        "ID": 9255,
        "phrase": " the part of our work which discusses multi-agent plans is related to issues in distributed ai  (bond & gasser, 1988)  and to the complexity of multi-agent planning  (tennenholtz & moses, 1989) ; we investigate the computational di culty that arises due to uncertainty concerning the activities of an additional agent(s)",
        "prob": 0.29354838709677417
    }, {
        "ID": 9255,
        "phrase": " hence, the most appropriate similar model of knowledge representation in ai is the situated automata  (rosenschein, 1985) ",
        "prob": 0.39230769230769236
    }, {
        "ID": 9266,
        "phrase": ",  malone, 1987) , and in distributed ai (e",
        "prob": 0.22000000000000003
    }, {
        "ID": 9266,
        "phrase": " our work applies recent work on reinforcement learning in ai where the information the agent gets is purely local",
        "prob": 0.3400000000000001
    }, {
        "ID": 9267,
        "phrase": "  doyle (1983)  has proposed that ai itself be de ned as the computational study of rational behaviour|e ectively equating rational behaviour with intelligence",
        "prob": 0.14
    }, {
        "ID": 9275,
        "phrase": " our current research in this direction is based on the old ai idea of using a multi-scale representation",
        "prob": 0.2928571428571428
    }, {
        "ID": 9278,
        "phrase": " thus, past machine learning systems have responded to incomplete explanations either in only a single way, or in multiple ways, but that are tried in a xed sequence",
        "prob": 0.205
    }, {
        "ID": 9305,
        "phrase": " one particular area both of these elds have been concerned with is multi-agent environments; examples include work in distributed ai  (bond & gasser, 1988) , and work on decentralized supervisory control  (lin & wonham, 1988) ",
        "prob": 0.5260869565217392
    }, {
        "ID": 9305,
        "phrase": " in di erence to most ai work on multi-agent systems, work on decentralized discrete event systems distinguishes between controllable and uncontrollable events",
        "prob": 0.5611111111111111
    }, {
        "ID": 9305,
        "phrase": " what distinguishes partially controlled multi-agent systems in the ai context from similar models in des are the structural assumptions we make about the uncontrolled agents involved",
        "prob": 0.26842105263157895
    }, {
        "ID": 9305,
        "phrase": " hence, typical multi-agent systems studied in ai include agents that exhibit one or both of these properties",
        "prob": 0.2928571428571428
    }, {
        "ID": 9321,
        "phrase": " \n the concept of the environment intuitively, the notion of \\the environment\" in ai and robotics refers to the relatively enduring and stable set of circumstances that surround some given individual",
        "prob": 0.2157894736842105
    }, {
        "ID": 9348,
        "phrase": " the problems involved belong in the specific area of artificial intelligence",
        "prob": 0.2818181818181818
    }, {
        "ID": 9378,
        "phrase": " \n a multi-agents system \u2026 in the field of distributed artificial intelligence (genesereth & ketchpel 94) have shown in detail how interoperability of heterogeneous software components can be tackled with multi-agents techniques",
        "prob": 0.4826086956521739
    }, {
        "ID": 9504,
        "phrase": " 1 interface comparison: traditional ai planning systems vs",
        "prob": 0.10999999999999999
    }, {
        "ID": 9564,
        "phrase": " \n related work we will consider work related to the theme of this paper in three main areas, distributed artificial intelligence (dai), evolutionary neural networks, and behavior based reinforcement learning",
        "prob": 0.37916666666666665
    }, {
        "ID": 9565,
        "phrase": " in these methodologies, techniques in artificial intelligence, natural language processing, machine learning, and adaptive behavior seem to overshadow the agent's architecture, in many cases undermining the main purpose of the agent  [7]   [13] ",
        "prob": 0.444
    }, {
        "ID": 9566,
        "phrase": " in these methodologies, techniques in artificial intelligence, natural language processing, machine learning, and adaptive behavior seem to overshadow the agent's architecture, in many cases undermining the main purpose of the agent  [16][17] ",
        "prob": 0.36400000000000005
    }, {
        "ID": 9566,
        "phrase": " the combination of machine learning and multi-agent systems can have benefits for both",
        "prob": 0.37272727272727274
    }, {
        "ID": 9604,
        "phrase": " details context 2 \n : support vector machines: training and applications massachusetts institute of technology artificial intelligence laboratory center for biological and computational learning department of brain and cognitive sciences a",
        "prob": 0.28400000000000003
    }, {
        "ID": 9616,
        "phrase": " i assume that fact is clear to everyone: whatever maybe the case in robotics or fast arithmetic, in the nl parts of ai there is no point modelling or training for skills that humans do not have! 3",
        "prob": 0.14761904761904762
    }, {
        "ID": 9662,
        "phrase": " nonetheless, this problem is related to previous work in many fields: distributed artificial intelligence, multi-agent systems, computational ecologies, adaptive control, game theory  [6] , computational markets  [2] , markov decision theory, and ant-based optimization",
        "prob": 0.4548387096774194
    }, {
        "ID": 9679,
        "phrase": " it also provides background knowledge concerning two main pillars on which this thesis rests: the data oriented parsing (dop) model and machine learning paradigms",
        "prob": 0.480952380952381
    }, {
        "ID": 9680,
        "phrase": " it also provides background knowledge concerning two main pillars on which this thesis rests: the data oriented parsing (dop) model and machine learning paradigms",
        "prob": 0.4333333333333334
    }, {
        "ID": 9779,
        "phrase": " this is the branch of machine learning that is concerned with an agent who periodically receives \"reward\" signals from the environment that partially reflect the value of that agent's private utility function",
        "prob": 0.1952380952380952
    }]
}, {
    "topic_id": 11,
    "top_words": ["ml", "estimator", "noise", "estimation", "code", "channel", "model", "estimate", "prequential", "based", "receiver", "mean", "proposed", "gaussian", "method"],
    "phrases": [{
        "ID": 424,
        "phrase": " we present the argument for ml 1 = 1 here",
        "prob": 0.15714285714285717
    }, {
        "ID": 661,
        "phrase": " in each case, the ratio is close to 1, indicating that the machine learning model achieves performance close to that of the annotator whose data it was trained on",
        "prob": 0.39444444444444443
    }, {
        "ID": 713,
        "phrase": "gogichaishwili re-directed their collaborators in tbilisi, georgia, towards more close usage of the ai principles and approaches",
        "prob": 0.2733333333333333
    }, {
        "ID": 1374,
        "phrase": " intuition: the functions h x (\u03b1) + \u03b1 (the ml code length plus the model complexity) and \u03bb x (\u03b1) (the mdl code length) are essentially the same function",
        "prob": 0.5941176470588235
    }, {
        "ID": 1374,
        "phrase": " intuition: a model achieving the mdl code length \u03bb x (\u03b1), or the ml code length h x (\u03b1), essentially achieves the best possible fit \u03b2 x (\u03b1)",
        "prob": 0.6166666666666667
    }, {
        "ID": 1374,
        "phrase": " intuition: although models of best fit (witnessing \u03b2 x (\u03b1)) do not necessarily achieve the mdl code length \u03bb x (\u03b1) or the ml code length h x (\u03b1), they do so at the model complexities where the mdl code length decreases, and, equivalently, the ml code length decreases at a slope of more than \u22121",
        "prob": 0.7033333333333333
    }, {
        "ID": 1464,
        "phrase": " for p(m i ) we use the ml estimate, i",
        "prob": 0.2625
    }, {
        "ID": 1464,
        "phrase": " as before, for p(m i ) we use the ml estimate, i",
        "prob": 0.1375
    }, {
        "ID": 1464,
        "phrase": " ml ling",
        "prob": 0.35000000000000003
    }, {
        "ID": 1538,
        "phrase": " first the algorithm is used to obtain the ml segmentation of order k =2; the difference of the means of the two segments is tested for statistical significance by the scheffe criterion (for details see  [16]  and  [33] )",
        "prob": 0.23181818181818184
    }, {
        "ID": 1881,
        "phrase": " though ml estimation is intuitively very appealing and natural, ml estimators are not in general unbiased",
        "prob": 0.29285714285714287
    }, {
        "ID": 1881,
        "phrase": "  2  for example if we estimate a set of data with a normal distribution, the ml estimation of the variance is the variance of the sample, while as every schoolboy knows, the unbiased estimator is the sample variance which divides by n 1 rather than n",
        "prob": 0.5458333333333333
    }, {
        "ID": 1881,
        "phrase": " \n the expectation-maximisation theorem the expectation-maximisation (em) algorithm is a general algorithm for ml estimation",
        "prob": 0.29285714285714287
    }, {
        "ID": 1881,
        "phrase": " we want to perform ml estimation of the parameters of the model \u03b8",
        "prob": 0.4555555555555556
    }, {
        "ID": 1881,
        "phrase": " here, i use it to refer to a range of techniques that trade off model complexity against the fit of the model against the data, in an attempt to reduce some of the problems of overtraining associated with ml estimation",
        "prob": 0.33809523809523806
    }, {
        "ID": 1881,
        "phrase": " estimating the kld between two distributions by calculating the kld between the empirical distributions (the ml estimator) is rather misguided -an error that is repeated at greater length in  lee (1999) ",
        "prob": 0.5045454545454545
    }, {
        "ID": 1881,
        "phrase": " \n compression based this line of work rather than using the ml criterion, uses an mdl criterion or some equivalent",
        "prob": 0.4437500000000001
    }, {
        "ID": 2257,
        "phrase": " \n maximum likelihood count estimation in ml count estimation, we simply interpret the normalized counts nij as probability estimates of wi given corpus j and the \u03bbj as mixture coefficients for a linear interpolation",
        "prob": 0.204
    }, {
        "ID": 2257,
        "phrase": " the trend of the curves in this graph, which continues up to a vocabulary size of around 40,000 words, clearly shows that the ml method outperforms all the other three methods by over 1% absolute",
        "prob": 0.355
    }, {
        "ID": 2375,
        "phrase": " 7 \u03c0 was defined in  [hut02]  as the mean e[\u03c0] whereas \u03c0 has been defined in this work as the ml estimate",
        "prob": 0.25833333333333336
    }, {
        "ID": 2942,
        "phrase": " this process can be done by using ml techniques such as neural networks [gl01a, gl01b, hon97, kkl + 00] or bayesian classifiers  [bp97, pb97] ",
        "prob": 0.22777777777777775
    }, {
        "ID": 3601,
        "phrase": " we call the minimum noise level for this to be the case, the ml threshold",
        "prob": 0.2818181818181818
    }, {
        "ID": 3602,
        "phrase": " we call the minimum noise level for this to be the case, the ml threshold",
        "prob": 0.2818181818181818
    }, {
        "ID": 4020,
        "phrase": " conveniently, the ml estimator \u03bc for both distributions is the average of the data (the proof is immediate if we set the derivative to zero)",
        "prob": 0.34
    }, {
        "ID": 4020,
        "phrase": " the two-part code is slightly redundant, since code words are assigned to data sequences of which the ml estimator lies outside the range that was encoded in the first part -such data sequences cannot occur, since for such a sequence we would have encoded a different range",
        "prob": 0.30606060606060603
    }, {
        "ID": 4020,
        "phrase": " the idea here is, rather than explicitly encoding a parameter range in which we know the ml estimator to lie, to treat the range (0, \u00b5 * ) as a hyper-parameter",
        "prob": 0.33888888888888885
    }, {
        "ID": 4020,
        "phrase": " \n plug-in predictive code the plug-in predictive code, or prequential ml code, is an attractive universal code because it is usually a lot easier to implement than either nml or a bayesian code",
        "prob": 0.5423076923076923
    }, {
        "ID": 4020,
        "phrase": " here the outcomes are coded sequentially using the probability distribution indexed by the ml estimator for the previous outcomes  [8, 16] ; for a general introduction see  [11] ",
        "prob": 0.22777777777777775
    }, {
        "ID": 4020,
        "phrase": " l pipc (x n ) = n i=1 l x i | \u03bc(x i\u22121 ) where l x i | \u03bc(x i\u22121 ) = \u2212 ln p x i | \u03bc(x i\u22121 ) is the number of nats needed to encode outcome x i using the code based on the ml estimator on x i\u22121 ",
        "prob": 0.31875
    }, {
        "ID": 4020,
        "phrase": " while we have to be careful to avoid overinterpreting our results, we find that the ml criterion consistently displays the largest bias in favour of the poisson model",
        "prob": 0.44999999999999996
    }, {
        "ID": 4020,
        "phrase": " figure  3  shows how the ml criterion misclassifies a sequence as poisson about four times more often than the other way around when the mean is 4; when the mean is raised to 16 bias has increased even further, to a ratio of twenty to one",
        "prob": 0.46249999999999997
    }, {
        "ID": 4020,
        "phrase": ") comparing the two graphs in figure  3 , we find that as the mean of the generating distribution is increased, the prediction errors for all criteria except ml move closer together, showing that for higher means it becomes even more worthwhile to try and compensate for the favouritism of ml/bic",
        "prob": 0.22903225806451613
    }, {
        "ID": 4020,
        "phrase": " clearly the ml and plug-in criteria, which were observed to be the most biased in section 5",
        "prob": 0.25833333333333336
    }, {
        "ID": 4020,
        "phrase": " when the probability that the data is poisson distributed is assessed by the ml criterion to be around 0",
        "prob": 0.3416666666666667
    }, {
        "ID": 4020,
        "phrase": " bayes anml 2part anml max=10 bayesian ml        figure 1 : 1 figure 1: the poisson and geometric distributions for \u00b5 = 5",
        "prob": 0.38125000000000003
    }, {
        "ID": 4047,
        "phrase": " for ml optimal mud, the performance is determined by the sum of many exponential terms, which is difficult to tackle with matrices",
        "prob": 0.19375
    }, {
        "ID": 4047,
        "phrase": " \u2022 ml channel estimation",
        "prob": 0.4428571428571429
    }, {
        "ID": 4047,
        "phrase": " for ml channel estimation, \u03b4h k is uncorrelated with h k , thus resulting in e h k \u0125k = 1 and e \u0125k \u0125k = 1 + \u2206 2 h ",
        "prob": 0.31
    }, {
        "ID": 4047,
        "phrase": " for ml channel estimation, we have \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 v 0 = u 1 \u2212 m 2 (1+\u2206 2 h )q \u2212 t m \u221a (1+\u2206 2 h )q , v a = 1 + \u2206 2 h z a \u221a 1 \u2212 q \u2212 t \u221a q , a = 1, ",
        "prob": 0.4428571428571429
    }, {
        "ID": 4047,
        "phrase": " ( 22 ) the corresponding output signal-to-interference-plus-noise-ratios (sinrs) of the ml and mmse channel estimation are given by the following expressions, respectively",
        "prob": 0.4333333333333334
    }, {
        "ID": 4047,
        "phrase": " \u2022 the imperfect channel estimation also increases the variance of the residual mai, which equals \u03b2(1 \u2212 2m + (1 + \u2206 2 h )q) for ml channel estimation based systems and \u03b2(1 \u2212 (1 \u2212 \u2206 2 h )(2m \u2212 q)) for mmse channel estimation based systems",
        "prob": 0.5761904761904763
    }, {
        "ID": 4047,
        "phrase": " 1) ml channel estimation: when deriving the expressions of c-io mud, we consider a fixed chip period and drop the index of the chip period for simplicity",
        "prob": 0.45499999999999996
    }, {
        "ID": 4047,
        "phrase": " ( 35 ) applying the same procedure as ml channel estimation, we can obtain the lr of io mud, which is given by p (b k = 1|r) p (b k = \u22121|r) = {b|bk=1} exp \u2212 1 2\u03c3 2 r \u2212 1 \u221a n \u0125b 2 {b|bk=\u22121} exp \u2212 1 2\u03c3 2 r \u2212 1 \u221a n \u0125b 2 , (36) where the control parameter, or equivalent noise power, \u03c3 2 = \u03c3 2 n + \u03b2\u2206 2 h ",
        "prob": 0.4136363636363637
    }, {
        "ID": 4047,
        "phrase": " ( 39 ) the intuition behind (38) is similar to that of ml channel estimation",
        "prob": 0.31
    }, {
        "ID": 4047,
        "phrase": " on comparing (34) and (  39 ), an immediate conclusion is that the c-io mud is more susceptible to the error incurred by mmse channel estimation than that incurred by ml channel estimation, when \u2206 2 h is identical for both estimators",
        "prob": 0.6238095238095238
    }, {
        "ID": 4047,
        "phrase": " this figure also shows that d-io mud is more susceptible to the error of mmse channel estimation than that of ml estimation",
        "prob": 0.6733333333333333
    }, {
        "ID": 4047,
        "phrase": " the following conclusions are of particular interest: \u2022 the performance of mud is more susceptible to mmse channel estimation errors than ml ones",
        "prob": 0.5941176470588235
    }, {
        "ID": 4047,
        "phrase": " \u2022 the mud schemes that consider the distribution of channel estimation errors can improve the system performance, considerably for ml channel estimation errors and marginally for mmse channel estimation errors",
        "prob": 0.7541666666666665
    }, {
        "ID": 4048,
        "phrase": " in particular, ml based multiuser detection and mmse multiuser detection are both well known  [24] ",
        "prob": 0.43571428571428567
    }, {
        "ID": 4061,
        "phrase": " analysis similar to that in  [11]  demonstrates that if a consistent estimator is used instead of the ml estimator in the mdl estimator, then the asymptotic probability of detection remains the same",
        "prob": 0.4263157894736842
    }, {
        "ID": 4115,
        "phrase": " the prequential ml code u works by sequentially predicting z i+1 using a (slightly modified) ml or bayesian map estimator \u03b8i = \u03b8(z i ) based on the past data, that is, the first i outcomes z i = z 1 , ",
        "prob": 0.5045454545454545
    }, {
        "ID": 4115,
        "phrase": " in our main theorem, we show that if l u denotes the prequential ml code length, and m is a regular one-parameter exponential family (k = 1), then r u (n) = 1 2 var p x var m \u03b8 * x ln n + o(1), ( 5 ) where x is the sufficient statistic of the family",
        "prob": 0.33809523809523806
    }, {
        "ID": 4115,
        "phrase": " then the ml estimator \u03bci is the empirical mean of z 1 , ",
        "prob": 0.3875
    }, {
        "ID": 4115,
        "phrase": " related work there are a plethora of results concerning the redundancy and/or the regret for the prequential ml code, for a large variety of models including multivariate exponential families, arma processes, regression models and so on",
        "prob": 0.31153846153846154
    }, {
        "ID": 4115,
        "phrase": " in other cases  [9, 21] , regret of a prequential ml-type code is evaluated on an individual sequence basis, and it is found that the regret grows as k 2 ln n+o(1) for all sequences whose ml estimator remains bounded away from the boundary of the space",
        "prob": 0.37407407407407406
    }, {
        "ID": 4115,
        "phrase": " we are now ready to define the prequential ml model",
        "prob": 0.23333333333333334
    }, {
        "ID": 4115,
        "phrase": " definition 2 (prequential ml model) let \u03b8 \u00b5 be the mean value parameter domain of an exponential family m = {m \u00b5 | \u00b5 \u2208 \u03b8 \u00b5 }",
        "prob": 0.4733333333333334
    }, {
        "ID": 4115,
        "phrase": " given m and constants x 0 \u2208 \u03b8 \u00b5 and n 0 > 0, we define the prequential ml model u by setting, for all n, all z n+1 \u2208 z n+1 : u (z n+1 | z n ) = m \u03bc(z n ) (z n+1 ), where u (z n+1 | z n ) is the density/mass function of z n+1 conditional on z n = z n , \u03bc(z n ) := x 0 \u2022 n 0 + n i=1 x i n + n 0 , and m \u03bc(z n ) (\u2022) is the density of the distribution in m with mean \u03bc(z n )",
        "prob": 0.3588235294117647
    }, {
        "ID": 4115,
        "phrase": " we usually refer to the prequential ml model in terms of the corresponding codelength function l u (z n ) = n\u22121 i=0 l u (z i+1 | z i ) = n\u22121 i=0 \u2212 ln m \u03bci (z i+1 )",
        "prob": 0.5071428571428572
    }, {
        "ID": 4115,
        "phrase": " here we define our prequential model in terms of a slightly modified maximum likelihood estimator that introduces a 'fake initial outcome' x 0 with multiplicity n 0 in order to avoid infinite code lengths (see the quote by rissanen on \"inherent singularity\" in section 6) and to ensure that the prequential ml code length of the first outcome is well-defined",
        "prob": 0.2657894736842105
    }, {
        "ID": 4115,
        "phrase": " this definition can be reconciled with settings in which the startup problem is resolved by ignoring the first few outcomes, by setting x 0 to the ml estimator for the ignored outcomes and n 0 to their number",
        "prob": 0.32105263157894737
    }, {
        "ID": 4115,
        "phrase": " consider first the case n 0 = 0, so that for n \u2265 1, \u03bcn is just the standard ml estimator",
        "prob": 0.41000000000000003
    }, {
        "ID": 4115,
        "phrase": " the second follows because for exponential families, the ml estimator \u03bci is just the empirical average i \u22121 x i , so that e p (\u03bc i \u2212 m \u00b5 * (x) d 4 d\u00b5 4 d(m \u00b5 * m \u00b5 ) bernoulli (\u00b5 * ) x (1 \u2212 \u00b5 * ) (1\u2212x) 6\u00b5 * \u00b5 4 + 6(1 \u2212 \u00b5 * ) (1 \u2212 \u00b5) 4 poisson e \u00b5 * \u00b5 * x x! 6\u00b5 * \u00b5 4 geometric \u03b8 x (1 \u2212 \u03b8) = (\u00b5 * ) x (\u00b5 * + 1) x+1 6\u00b5 * \u00b5 4 \u2212 6(\u00b5 * + 1) (\u00b5 + 1) 4 exponential 1 \u00b5 * e \u2212x/\u00b5 * \u2212 6 \u00b5 4 + 24\u00b5 * \u00b5 5 normal (fixed mean = 0) 1 \u221a 2\u03c0\u00b5 * x e \u2212 x 2\u00b5 * \u2212 3 \u00b5 4 + 12\u00b5 * \u00b5 5 normal (fixed variance = 1) 1 \u221a 2\u03c0 e \u2212 1 2 (x\u2212\u00b5 * ) 2 0 pareto ab a x a+1 for b = a \u2212 1 a \u00b5 * 6a \u00b5 4 figure 1: d 4 d\u00b5 4 d(m \u00b5 * m \u00b5 ) for a number of exponential families",
        "prob": 0.4033333333333334
    }, {
        "ID": 4115,
        "phrase": " to make this work, we (1) slightly modify the ml estimator by introducing the initial fake outcome x 0 ",
        "prob": 0.4357142857142857
    }, {
        "ID": 4115,
        "phrase": " in any case, our result is sufficient to show that in some cases (namely, if x is finite), we have r u (n) = 1 2 var p x var m \u00b5 * x ln n + o(1), so that, up to o(1)-terms, the redundancy and the regret of the prequential ml code behave in the same way",
        "prob": 0.40499999999999997
    }, {
        "ID": 4115,
        "phrase": " \n variations of prequential coding \n justifying our modification of the ml estimator if the prequential code is based on the ordinary ml estimator (n 0 = 0 in definition 2) then, apart from being undefined for the first outcome, it may achieve infinite codelengths on the observed data",
        "prob": 0.5392857142857143
    }, {
        "ID": 4115,
        "phrase": " if we first observe z 1 = 0 and then z 2 = 1, the codelength of z 2 according to the ordinary ml estimator of z 2 given z 1 would be \u2212 ln m \u03bc(z 1 )(z 2 ) = \u2212 ln 0 = \u221e",
        "prob": 0.54
    }, {
        "ID": 4115,
        "phrase": ",  [7] ) is to use the ordinary ml estimator, but only start using after having observed m examples, where m is the smallest number such that \u2212 ln m \u03bc(z m ) (z m+1 ) is guaranteed to be finite, no matter what value z m+1 is realized",
        "prob": 0.305
    }, {
        "ID": 4115,
        "phrase": " after that, one uses the prequential code with the standard ml estimator",
        "prob": 0.41000000000000003
    }, {
        "ID": 4115,
        "phrase": " the advantage of our solution is that, as we now show, it allows us to interpret our modified ml estimator also as a bayesian map and bayesian mean estimator, thereby showing that the same behavior can be expected for such estimators",
        "prob": 0.39565217391304347
    }, {
        "ID": 4115,
        "phrase": " \n prequential models with other estimators the bayesian map estimator if a conjugate prior is used, the bayesian maximum aposteriori estimator can always be interpreted as an ml estimator based on the sample and some additional 'fake data' (  [3] ; see also the notion of ess (equivalent sample size) priors discussed in, for example,  [15] )",
        "prob": 0.46
    }, {
        "ID": 4115,
        "phrase": " therefore, the prequential ml model as defined above can also be interpreted as a prequential map model for that class of priors, and the whole analysis carries over to that setting",
        "prob": 0.37368421052631584
    }, {
        "ID": 4115,
        "phrase": " the bayesian mean estimator it follows by the work of hartigan  [12, chapter 7]  on the socalled 'maximum likelihood prior', that by slightly modifying conjugate priors, we can construct priors such that the bayesian mean rather than map estimator is of the form of our modified ml estimator",
        "prob": 0.5033333333333334
    }, {
        "ID": 4115,
        "phrase": " \n rissanen's predictive mdl approach the mdl model selection criterion that is based on comparing the prequential ml codelengths for the models under consideration is called the predictive mdl (pmdl) criterion by rissanen  [22] ",
        "prob": 0.524
    }, {
        "ID": 4115,
        "phrase": " the prequential ml codelength then becomes redundant: the same data can be coded in any order, yielding different code words",
        "prob": 0.25625000000000003
    }, {
        "ID": 4115,
        "phrase": "); however example 1 illustrates that circumstances in which the prequential ml codelength and the nml codelength behave very differently remain, under any regime that amounts to reordering the sample, including the one suggested by rissanen",
        "prob": 0.39565217391304347
    }, {
        "ID": 4115,
        "phrase": " \n practical significance for model selection there exist a plethora of results showing that in various contexts, if p \u2208 m, then the prequential ml code achieves optimal redundancy (see section 2, related work)",
        "prob": 0.5458333333333333
    }, {
        "ID": 4115,
        "phrase": "\" our result however shows that the prequential ml code may behave quite differently from the nml and bayes codes, thereby strengthening the conclusion that it should not be taken as a definition of stochastic complexity",
        "prob": 0.1708333333333333
    }, {
        "ID": 4115,
        "phrase": " now suppose we use the prequential ml codelengths rather than the nml codelengths",
        "prob": 0.3416666666666667
    }, {
        "ID": 4115,
        "phrase": " we have found experimentally  [8]  that the error rate for model selection based on the prequential ml code decreases more slowly than when other universal codes are used",
        "prob": 0.3736842105263158
    }, {
        "ID": 4115,
        "phrase": " even though in some cases the redundancy grows more slowly than  1  2 ln n, so that the prequential ml code is in a sense more efficient than the nml code, model selection based on the prequential ml codes behaves worse than bayesian and nml-based model selection",
        "prob": 0.6161290322580644
    }, {
        "ID": 4115,
        "phrase": " the practical relevance of this phenomenon stems from the fact that the prequential ml codelengths are often a lot easier to compute than the bayes or nml codes, so that they are often used in applications  [18, 16] ",
        "prob": 0.23181818181818184
    }, {
        "ID": 4115,
        "phrase": " theoretical significance the result is also of theoretical-statistical interest: our theorem can be re-interpreted as establishing bounds on the asymptotic kullback-leibler risk of density estimation using ml and bayes estimators under misspecification (p \u2208 m)",
        "prob": 0.38846153846153847
    }, {
        "ID": 4115,
        "phrase": " in case u is the prequential ml model, pn = m \u03b8n is simply our modified ml estimator",
        "prob": 0.5461538461538462
    }, {
        "ID": 4115,
        "phrase": " we will call standard estimators like the ml estimator, which are required to lie in m, in-model estimators",
        "prob": 0.4066666666666667
    }, {
        "ID": 4115,
        "phrase": " we recognize r u (n), the redundancy of the prequential ml model, as the accumulated expected kl risk of our modified ml estimator (see proposition 10 and lemma 9)",
        "prob": 0.4789473684210526
    }, {
        "ID": 4115,
        "phrase": " in exactly the same way as for the prequential ml code, the redundancy of the bayesian code can be re-interpreted as the accumulated kl risk of the bayesian predictive distribution",
        "prob": 0.655
    }, {
        "ID": 4115,
        "phrase": " with this interpretation, our theorem 1 expresses that under misspecification, the cumulative kl risk of the ml estimator differs from the cumulative kl risk of the bayes estimator by a term of o(ln n)",
        "prob": 0.4333333333333333
    }, {
        "ID": 4115,
        "phrase": " this suggests that each term in the sum of (  18 ) should be almost equal to the variance of the ml estimator, which is varx/i",
        "prob": 0.4692307692307693
    }, {
        "ID": 4115,
        "phrase": "2 lemma 9: redundancy for exponential families lemma 9 let u be a prequential ml model and m be an exponential family as in theorem 1",
        "prob": 0.3812500000000001
    }, {
        "ID": 4115,
        "phrase": " proof we omit irrelevant constants and the term for the first outcome, which is well-defined because of our modification of the ml estimator",
        "prob": 0.38125
    }, {
        "ID": 4115,
        "phrase": " within this section, \u03bc(x n ) is defined as the ordinary ml estimator",
        "prob": 0.31
    }, {
        "ID": 4115,
        "phrase": " note that, if x n is such that its ml estimate is defined, then f (x n ) = \u2212 ln m \u00b5 * (x n ) + ln m \u03bc(x n ) (x n )",
        "prob": 0.41000000000000003
    }, {
        "ID": 4115,
        "phrase": " since the first derivative of \u00b5 at the ml estimate \u03bc is 0, the first-order term is 0",
        "prob": 0.25833333333333336
    }, {
        "ID": 4115,
        "phrase": " a particular type of universal code, the prequential ml code or ml plug-in code, exhibits behavior that we found unexpected",
        "prob": 0.4263157894736842
    }, {
        "ID": 4115,
        "phrase": " while other important universal codes such as the nml/shtarkov and bayesian codes, achieve a regret of 1 2 ln n, where n is the sample size, the prequential ml code achieves a relative redundancy of 1 2 var p x varm \u00b5 * x ln n",
        "prob": 0.4826086956521739
    }, {
        "ID": 4115,
        "phrase": " the first result is robust with respect to slight variations in the definition of the prequential ml code: in our framework the so-called \"start-up problem\" (the unavailability of an ml estimate for the first few outcomes) is resolved by introducing fake initial outcomes",
        "prob": 0.5366666666666666
    }, {
        "ID": 4208,
        "phrase": " both of the (93, 47) and (105, 53) codes achieve ml performance with the modified bp decoder",
        "prob": 0.37272727272727274
    }, {
        "ID": 4252,
        "phrase": " such ml channel estimation algorithms  [3]  are suitable for training-symbol-based systems, in which a fraction of the transmitted symbols is known to both the transmitter and receiver",
        "prob": 0.2157894736842105
    }, {
        "ID": 4457,
        "phrase": " gaussian noise, will be close to the optimal ml performance",
        "prob": 0.51
    }, {
        "ID": 4458,
        "phrase": " gaussian noise, will be close to the optimal ml performance",
        "prob": 0.51
    }, {
        "ID": 4459,
        "phrase": " gaussian noise, will be close to the optimal ml performance",
        "prob": 0.41000000000000003
    }, {
        "ID": 4459,
        "phrase": " examples in this section we present three different examples of tanner graphs which give rise to different types of pseudocodewords and examine their performance on the binary input additive white gaussian noise channel (biawgnc), with signal to noise ratio e b /n o , with ms, sp, and ml decoding",
        "prob": 0.23823529411764705
    }, {
        "ID": 4548,
        "phrase": "001 parameter mu of ml algorithm net",
        "prob": 0.1375
    }, {
        "ID": 4659,
        "phrase": " this means that we have c (s n+1 ) = {d } and t (s n+1 ) = {l ai }",
        "prob": 0.22000000000000003
    }, {
        "ID": 4855,
        "phrase": " first, the rs code itself is a good code, which can perform close to capacity under ml decoding",
        "prob": 0.4357142857142857
    }, {
        "ID": 5054,
        "phrase": " the second alternative presents significant advantages with respect to (i) reliability-complexity tradeoff in ml decoding, and (ii) the cutoff-rate criterion",
        "prob": 0.2833333333333334
    }, {
        "ID": 5118,
        "phrase": " in mimo fading channels ml detection is desirable to achieve high-performance, as this is the optimal detection technique in presence of additive gaussian noise",
        "prob": 0.5842105263157894
    }, {
        "ID": 5119,
        "phrase": " in mimo fading channels ml detection is desirable to achieve high-performance, as this is the optimal detection technique in presence of additive gaussian noise",
        "prob": 0.5842105263157894
    }, {
        "ID": 5120,
        "phrase": " in mimo fading channels ml detection is desirable to achieve high-performance, as this is the optimal detection technique in presence of additive gaussian noise",
        "prob": 0.4789473684210527
    }, {
        "ID": 5210,
        "phrase": " this nda ml estimator was found iteratively, but unfortunately requiring processing of all observables for each iteration, making it computationally complex",
        "prob": 0.3
    }, {
        "ID": 5210,
        "phrase": " this performance is achieved with significantly lower computational complexity than the ml estimator",
        "prob": 0.25833333333333336
    }, {
        "ID": 5210,
        "phrase": " for large \u03b3 the cm estimator approaches the ml estimator, which was shown analytically in  [15] ",
        "prob": 0.5916666666666667
    }, {
        "ID": 5210,
        "phrase": " finally, the suggested am estimator has almost identical performance (both in nmse and nb) as the ml estimator for all \u03b3, even though it has a computationally complexity that is less than the first ml iteration",
        "prob": 0.5045454545454545
    }, {
        "ID": 5210,
        "phrase": " the ml estimator after 10 iterations and the am estimator have a small positive nb (around 1%) for large n ",
        "prob": 0.4692307692307693
    }, {
        "ID": 5210,
        "phrase": " the ml estimator and the mm estimator are the only two estimators that are unbiased for large n , but only the ml estimator approaches the ncrlb in fig",
        "prob": 0.4764705882352941
    }, {
        "ID": 5210,
        "phrase": " the second best estimator, after the ml estimator, over the whole range of n is the suggested am estimator",
        "prob": 0.5461538461538462
    }, {
        "ID": 5210,
        "phrase": " a novel snr estimator with low computationally complexity was introduced and shown to be surpassed in performance only by the iterative ml estimator among previously suggested estimators",
        "prob": 0.24285714285714283
    }, {
        "ID": 5210,
        "phrase": " the proposed estimator performs close to the performance of the iterative ml estimator at significantly lower computationally complexity",
        "prob": 0.44375000000000003
    }, {
        "ID": 5210,
        "phrase": " the results show that the proposed estimator performs close to the iterative ml estimator at significantly lower computational complexity",
        "prob": 0.24117647058823527
    }, {
        "ID": 5233,
        "phrase": " (20) the ml receiver performs linear processing on y to yield the following equivalent parallel channel model \u1ef9i = \u03c1 m h 2 x i + wi , for i = 1, \u2022 \u2022 \u2022 , k",
        "prob": 0.44375
    }, {
        "ID": 5250,
        "phrase": " proposed system initialization: let for n i \u2264 \u2200 \u2264 1 , i a has a private key ai n a a 1 be n original signcrypters",
        "prob": 0.25833333333333336
    }, {
        "ID": 5343,
        "phrase": " therefore e(x|r) which is also the mmse estimate is the output of the ml detector",
        "prob": 0.37272727272727274
    }, {
        "ID": 5369,
        "phrase": " it is also observed that the steady-state transmit powers for the decorrelator and the mmse detector are close to those of the ml detector (in this case, the difference is less than 22%)",
        "prob": 0.44999999999999996
    }, {
        "ID": 5379,
        "phrase": " however, for the special case of a mimo system with two antennas (with real coefficients), it has been shown that by using the lll approximation and considering two points per dimension we achieve the ml decoding performance  [44] ",
        "prob": 0.42083333333333334
    }, {
        "ID": 5379,
        "phrase": " moreover, the performance of the proposed method is comparable with that in the ml one",
        "prob": 0.41000000000000003
    }, {
        "ID": 5379,
        "phrase": " by increasing the dimension, the resulting gap between the relaxation model (  32 ) and the ml decoding increases",
        "prob": 0.39230769230769236
    }, {
        "ID": 5379,
        "phrase": " in a system with 64-qam and 256-qam, the performance of the relaxation model (  34 ) is close to the ml performance with k = 8 and k = 16, respectively",
        "prob": 0.5785714285714286
    }, {
        "ID": 5379,
        "phrase": " comparison of the relaxation model proposed in  [29]  and that in our method in a mimo system with 4 transmit and receive antennas, employing 8-psk modulation /n 0 ser method proposed in  [27]  method proposed in  [30]  model (32) \u2212 algorithm i model (34) \u2212 rounding ml decoding fig",
        "prob": 0.4678571428571429
    }, {
        "ID": 5380,
        "phrase": " moreover, the performance of the proposed method is comparable with that in the ml one",
        "prob": 0.51
    }, {
        "ID": 5380,
        "phrase": "  1  demonstrates that the proposed quasi-ml method using model  (32)  and the randomization procedure achieves near ml performance in an un-coded 2 \u00d7 2 mimo system with qpsk constellation",
        "prob": 0.3681818181818182
    }, {
        "ID": 5380,
        "phrase": " by increasing the dimension, the resulting gap between the relaxation model (  32 ) and the ml decoding increases",
        "prob": 0.4692307692307693
    }, {
        "ID": 5380,
        "phrase": " in a system with 64-qam and 256-qam, the performance of the relaxation model (  34 ) is close to the ml performance with k = 8 and k = 16, respectively",
        "prob": 0.5071428571428572
    }, {
        "ID": 5380,
        "phrase": " the performance of the proposed sdp relaxation model  (34) , model iv, is close to the ml performance",
        "prob": 0.4357142857142857
    }, {
        "ID": 5393,
        "phrase": " 3 (from abramson [3]  plus the dashed rectangle s) presents a set theoretic model of a simple information channel consisting of a transmitter of alphabet a with individual elements ai and total elements t and a receiver of alphabet b with individual elements bi and total elements r",
        "prob": 0.28928571428571426
    }, {
        "ID": 5501,
        "phrase": " channel decoupling property of ostbcs with perfect channel knowledge, the receiver performs ml decoding on the ostbc g g g",
        "prob": 0.5062500000000001
    }, {
        "ID": 5502,
        "phrase": " channel decoupling property of ostbcs with perfect channel knowledge, the receiver performs ml decoding on the ostbc g g g",
        "prob": 0.6312500000000001
    }, {
        "ID": 5727,
        "phrase": " in  [25] , we apply the generalized ds2 bound to study the robustness of a mismatched decoding that is based on ml decoding with respect to the faulty channel measurements",
        "prob": 0.3210526315789474
    }, {
        "ID": 5738,
        "phrase": " ( 69 ) the integration region y in the case of a gaussian likelihood f was chosen through the ml parameter estimators to be the least possible hyperspheres containing the data x \u22a5 and x ",
        "prob": 0.2833333333333334
    }, {
        "ID": 5738,
        "phrase": " while the ml esimator \u03c4 * (x \u22a5 ) for the noise naturally imposes a spherical geometry on the part of the data space containing the noise, the same cannot be said of the ml estimator \u03b2 * for the parameters \u03b2, which is simply: \u03b2 * (z ) = z ",
        "prob": 0.29047619047619044
    }, {
        "ID": 5738,
        "phrase": " the result follows by recognizing that \u2206 (1) in the case we will be concentrating on: \u03c0 \u03bb is a ggd and \u03bb * is the ml estimator the criterion c(\u2022) in (104) becomes d = z x, m (\u03c0) d , \u03b3 d , d ",
        "prob": 0.3642857142857143
    }, {
        "ID": 5843,
        "phrase": " the data type for stream in the ml language is shown in figure  9 ",
        "prob": 0.2818181818181818
    }, {
        "ID": 6109,
        "phrase": " assuming that perfect channel state information (csi) is available at the receiver, the decision rule for ml decoding is to minimize the metric l\u22121 t=0 m\u22121 j=0 v jt \u2212 n \u22121 i=0 h ijt s it 2 (3) over all codewords",
        "prob": 0.1952380952380952
    }, {
        "ID": 6109,
        "phrase": " the ml decision rule for such a situation, derived in a general setting is: consider the received signal r, given by r = c 1 s i + jc 2 s q + n (91) where c 1 , c 2 are real constants and s i , s q are in-phase and quadrature-phase components of transmitted signal s",
        "prob": 0.324
    }, {
        "ID": 6109,
        "phrase": " the ml decision rule when the in-phase, n i , and quadraturephase component, n q , of the gaussian noise, n have different variances c 1 \u03c3 2 and c 2 \u03c3 2 is derived by considering the pdf of n, given by p n (n) = 1 2\u03c0\u03c3 2 \u221a c 1 c 2 e \u2212 n 2 i 2c 1 \u03c3 2 e \u2212 n 2 q 2c 2 \u03c3 2 ",
        "prob": 0.4263157894736842
    }, {
        "ID": 6175,
        "phrase": " the simulation result shows that the mmse-bp algorithm with one surviving label and two surviving labels have the same performance as that of the ml algorithm",
        "prob": 0.44999999999999996
    }, {
        "ID": 6175,
        "phrase": " as snr increases, the mmse-bp with simplified initialization approaches the ml performance asymptotically",
        "prob": 0.3642857142857143
    }, {
        "ID": 6175,
        "phrase": " ml and bp with one and two surviving labels are identical",
        "prob": 0.51
    }, {
        "ID": 6176,
        "phrase": " e b /n 0 for both ml and mmse-bp algorithm when coordinate interleaving is absent (\u03c0 ci is the identical permutation)",
        "prob": 0.4692307692307693
    }, {
        "ID": 6176,
        "phrase": " the mmse-bp algorithm achieves ml performance, regardless of the number of surviving labels",
        "prob": 0.5071428571428572
    }, {
        "ID": 6176,
        "phrase": " lsd  [24] , shown for performance comparison, essentially tracks mmse-bp; a slight difference from  [24]  is that the sphere was centered on x (see  (25) ) instead of the unconstrained ml estimate \u015d of [24, eq",
        "prob": 0.3227272727272727
    }, {
        "ID": 6176,
        "phrase": " ml and bp with one and two surviving labels are identical",
        "prob": 0.6100000000000001
    }, {
        "ID": 6177,
        "phrase": " e b /n0 for both ml and mmse-bp algorithm when coordinate interleaving is absent (\u03c0ci is the identical permutation)",
        "prob": 0.46923076923076923
    }, {
        "ID": 6177,
        "phrase": " the mmse-bp algorithm achieves ml performance, regardless of the number of surviving labels",
        "prob": 0.5785714285714286
    }, {
        "ID": 6177,
        "phrase": " lsd  [24] , shown for performance comparison, essentially tracks mmse-bp; a slight difference from  [24]  is that the sphere was centered on x (see (  25 )) instead of the unconstrained ml estimate \u015d of [24, eq",
        "prob": 0.45909090909090905
    }, {
        "ID": 6177,
        "phrase": " ml and bp with one and two surviving labels are identical",
        "prob": 0.51
    }, {
        "ID": 6193,
        "phrase": " using the relation \u03c4 ( \u03b8) = \u00b5(\u03b8 * ) guaranteed by the definition of the ml estimator and surrogate estimator, we have \u03c4 ( \u03b8 + \u03b3) \u2212 \u00b5(\u03b8 * + \u03b3) 2 = \u03c4 ( \u03b8 + \u03b3) \u2212 \u03c4 ( \u03b8) + [\u00b5(\u03b8 * ) \u2212 \u00b5(\u03b8 * + \u03b3)] 2 = \u2207 2 b( \u03b8 + s\u03b3) \u2212 \u2207 2 a(\u03b8 * + t\u03b3) \u03b3 2 , for some s, t \u2208 [0, 1], where we have used the mean value theorem",
        "prob": 0.25625
    }, {
        "ID": 6308,
        "phrase": " \u03b8 will denote the ml estimator of \u03b8",
        "prob": 0.15714285714285717
    }, {
        "ID": 6308,
        "phrase": " case, because the ml is taken over the pattern probability and not over the i",
        "prob": 0.23333333333333334
    }, {
        "ID": 6308,
        "phrase": " ml probability (not the pattern ml probability) but the summation is only on all possible patterns, results in modified individual redundancy of rn q, \u03c8 (x n ) = 1",
        "prob": 0.24117647058823527
    }, {
        "ID": 6308,
        "phrase": " the redundancy of this code consists of the cost of relaying the quantized ml estimators and the cost caused by the quantization of the ml parameters",
        "prob": 0.3
    }, {
        "ID": 6308,
        "phrase": " if we observe the sequence x n and obtain the ml estimator \u03b8 of \u03b8 in the i",
        "prob": 0.34444444444444444
    }, {
        "ID": 6308,
        "phrase": ", the event in which the ml estimate of component \u03b8 i is outside an interval of length \u2206 (\u03c4 b i ) centered at \u03b8 i ",
        "prob": 0.5083333333333334
    }, {
        "ID": 6308,
        "phrase": " therefore, if the ml i",
        "prob": 0.18333333333333335
    }, {
        "ID": 6308,
        "phrase": " then, the probability that the ml estimator of \u03b8 from the observed x n is outside the sphere of radius 1/ \u221a n 1\u2212\u03b5 centered in \u03b8 vanishes with n, lim n\u2192\u221e p \u03b8 \u03b8 \u2212 \u03b8 > 1 \u221a n 1\u2212\u03b5 = 0, ( 62 ) for every alphabet size k",
        "prob": 0.4176470588235295
    }, {
        "ID": 6308,
        "phrase": " ml estimator \u03b8",
        "prob": 0.18333333333333335
    }, {
        "ID": 6308,
        "phrase": " ml estimator of \u03b8 from x n ",
        "prob": 0.35000000000000003
    }, {
        "ID": 6308,
        "phrase": " ( 73 ) now, to bound the cost of quantizing the pattern ml estimator reflected in the second term of (71), we consider the logarithm of the ratio between p \u03c8(\u03b8) [\u03c8 (x n )] and p \u03d5 [\u03c8 (x n )]",
        "prob": 0.25625000000000003
    }, {
        "ID": 6502,
        "phrase": " if the input is sent through a noise-less cdma channel characterized by the spreading matrix s , then the signal ai is modulated onto a n-bit signal m as 1/ 2 n \u2212 = m s ai",
        "prob": 0.22777777777777775
    }, {
        "ID": 6658,
        "phrase": " we will show that from the consistency result about the ml parameter estimation for the mismatched model  [8] , these estimated parameters will give an accurate estimation of the conditional distribution of x t given z t , as the observation length increases and the hmp class gets richer",
        "prob": 0.44814814814814813
    }, {
        "ID": 6658,
        "phrase": "  1  we denote the ml estimator in \u03b8 \u03b4 k based on z n by qk,\u03b4 [z n ] = arg max q\u2208\u03b8 \u03b4 k q(z n )",
        "prob": 0.17500000000000002
    }, {
        "ID": 6658,
        "phrase": "3 consistency of ml estimator when p z \u2208 \u03b8 \u03b4 k , an ml estimator qk,\u03b4 [z n ] is said to be strongly consistent if lim n\u2192\u221e qk,\u03b4 [z n ] = p z a",
        "prob": 0.4066666666666666
    }, {
        "ID": 6658,
        "phrase": " the strong consistency of the ml estimator qk,\u03b4 [z n ] of the parameter of a finite-alphabet stationary ergodic hmp was proved in  [1] ",
        "prob": 0.5687500000000001
    }, {
        "ID": 6658,
        "phrase": "1], we have the consistency in the sense that if the observed noisy signal is not necessarily a hmp, and we still perform the ml estimation in \u03b8 \u03b4 k , then we get lim n\u2192\u221e qk,\u03b4 [z n ] \u2208 n a",
        "prob": 0.44999999999999996
    }, {
        "ID": 6658,
        "phrase": "1, we only need to estimate the state transition probabilities of the underlying markov chain to obtain this ml estimator, and this can be efficiently done by the expectation-maximization (em) algorithm",
        "prob": 0.255
    }, {
        "ID": 6658,
        "phrase": " from (1), we know that as the observation length n increases, this ml estimator will converge to the parameter that minimizes the relative entropy rate between the true output probability law p z ",
        "prob": 0.35500000000000004
    }, {
        "ID": 6658,
        "phrase": " proof: recall that qk,\u03b4 k [z n ] is an ml estimator in \u03b8 \u03b4 k k based on the observation z n ",
        "prob": 0.37272727272727274
    }, {
        "ID": 6658,
        "phrase": " once establishing this inequality, we show that lim k\u2192\u221e lim sup t\u2192\u221e \n then, we can model {z t } in \u03b8 \u03b3 k k , or equivalently, model (x t , s t ) as k-th order markov chain, and obtain q t k , the ml estimator in \u03b8 \u03b3 k k based on z m i(t) ",
        "prob": 0.29047619047619044
    }, {
        "ID": 6718,
        "phrase": " on one hand, as long as perfect channel estimation is guaranteed at the receiver, ml decoding is the optimal solution to minimize ber",
        "prob": 0.35882352941176476
    }, {
        "ID": 6779,
        "phrase": " as shown in figure  1 , we consider a receiver that feeds back decisions from channel decoders to both an ml channel estimator and a pic multiuser detector",
        "prob": 0.7277777777777777
    }, {
        "ID": 6779,
        "phrase": " the performance analyses of ml channel estimation and pic multiuser detection are given in section iii and section iv, respectively",
        "prob": 0.1823529411764706
    }, {
        "ID": 6779,
        "phrase": " then, both the training symbols and fed back decisions are considered as training symbols and used for ml channel estimation",
        "prob": 0.31875000000000003
    }, {
        "ID": 6779,
        "phrase": " first, we explain the training symbol based ml channel estimation algorithm that is used in the first iteration",
        "prob": 0.44375
    }, {
        "ID": 6779,
        "phrase": " training symbol based ml channel estimation first we assume that there are m training symbols, channel symbols known to the receiver, within a single coherence period",
        "prob": 0.3681818181818182
    }, {
        "ID": 6779,
        "phrase": " computational aspect the main computational cost of the iterative channel estimation and multiuser detection includes: \u2022 solving the linear equation r\u00e2 = y for ml channel estimation",
        "prob": 0.3857142857142857
    }, {
        "ID": 6785,
        "phrase": " we believe that simulation of imagination is a first step for building a powerful ai system",
        "prob": 0.25833333333333336
    }, {
        "ID": 6876,
        "phrase": " the ml detector, or receiver, selects the message, \u015d, which minimizes the distance between the received signals and the hypothesized noise-free message, h\u015d",
        "prob": 0.24117647058823527
    }, {
        "ID": 6990,
        "phrase": " it seems that the ml estimator is overfitting the data",
        "prob": 0.34444444444444444
    }, {
        "ID": 6990,
        "phrase": " in collaboration with turing, good  [5]  proposed an estimator for the probabilities of rare symbols that differs considerably from the ml estimator",
        "prob": 0.38125000000000003
    }, {
        "ID": 6990,
        "phrase": " it is known that the good-turing estimator performs poorly for high-probability symbols  [3] , but this is not a problem since the ml estimator can be employed to estimate the probabilities of symbols that appear frequently in the observed string",
        "prob": 0.24400000000000002
    }, {
        "ID": 7067,
        "phrase": " a little algebra then shows that the bp estimate for the expectation of e a (x \u2202a ) is e a (x \u2202a ) bp = x \u2202a e a (x \u2202a ) exp{\u2212\u03b2e a (x \u2202a ) + h i\u2192a \u03c3 ai (x i )} x \u2202a exp{\u2212\u03b2e a (x \u2202a ) + h i\u2192a \u03c3 ai (x i )} , (12) where \u03c3 ai (x) = +1 if setting x i = x satisfies clause a, and = \u22121 otherwise",
        "prob": 0.3588235294117647
    }, {
        "ID": 7073,
        "phrase": " if the boundary effects are ignored, the minimum distance of ml detection is obviously d ml = \u03bb(\u03bb), where \u03bb(\u03bb) denotes the length of the shortest vector in \u03bb",
        "prob": 0.24117647058823527
    }, {
        "ID": 7144,
        "phrase": " let us first compare the map and ml estimators, to later better explain our preference for the map",
        "prob": 0.3812500000000001
    }, {
        "ID": 7144,
        "phrase": " both the map and ml converge in probability to the true value, so that the corresponding estimators of z t also converge in probability to the true value",
        "prob": 0.4437500000000001
    }, {
        "ID": 7209,
        "phrase": " information theory ( ) the main results are: 3 2 2 3 2 2 2 2 1 2 1 2 1 2 3 3 3 3 1 3 (1 ) 3 (1 ) 2 2 \u00a1 \u00a2 \u00a3 \u00a4 \u00a5 \u00a6 \u00a7 \u00a6 \u00a2 \u00a2 \u00a2 \u00a2 \u03b5 \u03b5 \u03b5 \u03b5 \u03b5 \u03b5 \u03c3 \u03c3 \u03c3 \u03c3 \u03c3 \u03c3 \uf8eb \uf8f6 \uf8eb \uf8f6 \uf8eb \uf8f6 \uf8eb \uf8f6 \uf8ec \uf8f7 \uf8ec \uf8f7 = \u2212 + \u2212 + \u2212 + \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 \uf8ec \uf8f7 + + \uf8ed \uf8f8 \uf8ed \uf8f8 \uf8ed \uf8f8 \uf8ed \uf8f8 ,( -as it was predicted the mlbr and ml for known state noise source are very close, it means that mlbr as powerful as most imaginable powerful rule; -the mlbr receiver much better than mls receiver ; -in spite of mlbr detector ignores some information about probability of transmitted signal, the mlbr receiver better than ml receiver for unknown state noise source, it means that it is possible to expect from robust algorithms based on this rule much better results than mls; -the ml and mlbr decisions in impulsive noise provide better error rate than mls in gaussian noise, it shows that it worthwhile to investigate this issue of design decoding algorithms based on taking to account non-gaussianity of noise, since the achievable performance can be better than in gaussian noise ",
        "prob": 0.5505494505494506
    }, {
        "ID": 7210,
        "phrase": " theory  the main results are: -the mlbnr and ml are very close for known state noise source, which means that the mlbnr is as powerful as the most powerful rule for the gaussian \u03b5-tail, so, hopefully the mlbnr will be efficient for other tails, as efficient as it is for the investigated laplas tail; -despite the fact the mlbnr detector ignores some information about the probability of the transmitted signal, the mlbnr receiver is better than the ml receiver for unknown state noise source, which means that it is possible to expect much better results from robust algorithms based on this rule than from the mls detector; the mlbnr receiver is much better than the mls receiver ; -sometimes, the ml and mlbnr decisions in impulsive noise provide a better error rate than mls in gaussian noise",
        "prob": 0.6215189873417721
    }, {
        "ID": 7210,
        "phrase": " 1 example of quantitative analysis of performance relations: the ml decoder when it is unknown if the noise sample was generated by background or impulse noise; for the ml decoder when it is known if the noise sample was generated by background or impulse noise; for the mls decoder in impulsive noise and for the mls decoder in only background noise",
        "prob": 0.45999999999999996
    }, {
        "ID": 7337,
        "phrase": " \n figure 9 9 figure 9 upper bounds on the mean squared distortion of the proposed analog code constructed using the binary golay code [23, 12, 7] as the component code and hard decision ml decoders for the component codes at the receiver",
        "prob": 0.325
    }, {
        "ID": 7337,
        "phrase": " \n figure 10 10 figure10upper bounds on the mean squared distortion of the proposed analog code constructed using the binary code[72, 36, 16]  as the component code and hard decision ml decoders for the component codes at the receiver",
        "prob": 0.4269230769230769
    }, {
        "ID": 7409,
        "phrase": " using commutation of \u2704 ai and \u2192 h , we obtain a term t \u2032 such that s \u2032 \u2704 ai t \u2032 ",
        "prob": 0.2625
    }, {
        "ID": 7614,
        "phrase": " however, in the low noise regime bp decoding clearly fails to approximate ml in practical (finite size) ldpc codes, thus causing the error-invited talk at 44-th annual allerton conference on communications, control and computing,  sep 27-sep 29, 2006",
        "prob": 0.18484848484848485
    }, {
        "ID": 8229,
        "phrase": " (11) 3 reaching global ml estimate through self-synchronization the basic idea of this paper is that, when the whole network observes a common phenomenon, the self-synchronization process forms the basic mechanism for reaching the globally optimal ml estimate through local exchange of the state functions, without sending the observations to any fusion center",
        "prob": 0.3447368421052632
    }, {
        "ID": 8229,
        "phrase": " (13) this value coincides with the globally optimal ml estimate  [33] ",
        "prob": 0.51
    }, {
        "ID": 8229,
        "phrase": " in this case, setting, in  (5) ,  (11)  becomes q i = a h i c \u22121 i a i and \u03c9 i = a h i c \u22121 i a i \u22121 a h i c \u22121 i x i , the synchronized state \u03c9 \u22c6 l = \u03beml = n i=1 a h i c \u22121 i a i \u22121 n i=1 a h i c \u22121 i x i , (15) which coincides with the globally optimal ml estimate  [33] ",
        "prob": 0.4066666666666666
    }, {
        "ID": 8229,
        "phrase": " conversely, following the proposed approach, if the network converges, each node tends to the optimal ml estimate without sending all these data to any sink node, but simply exchanging the state vectors \u03b8 i (t) with nearby nodes",
        "prob": 0.23461538461538461
    }, {
        "ID": 8229,
        "phrase": " the proposed system has indeed a broader applicability than just global ml estimation for a linear observation model",
        "prob": 0.4066666666666667
    }, {
        "ID": 8229,
        "phrase": " nevertheless, the class of functions in  (16)  contains not only the linear ml case, but it comprises many cases of practical interest (like, for example, computation of the sufficient statistics in detection of gaussian processes in gaussian noise, computation of maximum, minimum, histograms, geometric mean of the observed values, etc",
        "prob": 0.28857142857142853
    }, {
        "ID": 8229,
        "phrase": " \n ml estimation in the presence of noise different sources of noise affect the system: the observation noise, represented by the vector of random variables w i in (  14 ), and the system or coupling noise, represented by the stochastic process v i (t) in  (1)  (or (  4 ))",
        "prob": 0.484
    }, {
        "ID": 8229,
        "phrase": " \n observation noise in section 3, we showed how to choose the network parameters to guarantee the convergence of each node to the globally optimum ml estimate",
        "prob": 0.39444444444444443
    }, {
        "ID": 8229,
        "phrase": " as an example of vector ml estimation, in fig",
        "prob": 0.34444444444444444
    }, {
        "ID": 8229,
        "phrase": " the dashed line and the circles represent the global ml estimates achievable with an ideal control node that receives the observations and all mixing matrices a i with no errors",
        "prob": 0.255
    }, {
        "ID": 8229,
        "phrase": " the three sets of marks, in each curve, represent the variances obtained with the decentralized ml estimator, whereas the solid lines refer to the centralized ml estimator",
        "prob": 0.4809523809523809
    }, {
        "ID": 8229,
        "phrase": " it is interesting to observe that: 1) even though sin(x) is not monotonic, and thus it does not satisfy assumption a2 of theorem 1, the corresponding system behaves as the system with the monotonically increasing function tanh(x); 2) the decentralized method has practically the same performance as the centralized one; 3) even though the coupling is only local and it does not change with n , the variance decays as 1/n , as the optimal ml estimator -this confirms the scalability of the proposed approach",
        "prob": 0.3833333333333333
    }, {
        "ID": 8229,
        "phrase": " we can see that, also in this case, the state derivatives of all the nodes converge to values centered around the globally optimum ml estimates",
        "prob": 0.41764705882352937
    }, {
        "ID": 8229,
        "phrase": "  4    \n conclusion in this work we have shown that, if a sensor network observes a common event, a network of nonlinearly coupled first-order dynamical systems can be used to achieve a globally optimum ml estimate, without the need to send any data to any fusion center",
        "prob": 0.39032258064516134
    }, {
        "ID": 8229,
        "phrase": " we have shown that the conditions guaranteeing the global asymptotic stability of the ml estimate, seen as the self-synchronization state of the whole system, depend on the coupling strength k and on the network topology through the algebraic connectivity \u03bb 2 ",
        "prob": 0.484
    }, {
        "ID": 8229,
        "phrase": " (86) figure 2 : 2 evolution of the pulsation \u03b8i (t) as a function of time (solid line); optimal centralized ml estimate (dashed lines plus circles): a) observation noise only; b) observation plus coupling noise",
        "prob": 0.6439999999999999
    }, {
        "ID": 8229,
        "phrase": " we derive the conditions on the coupling mechanism guaranteeing that, if the network observes one common phenomenon, each node converges to the globally optimal ml estimate",
        "prob": 0.26842105263157895
    }, {
        "ID": 8464,
        "phrase": "  1  that the newly proposed code performs slightly better compared to the 4-group ml decodable ciod  [2] ",
        "prob": 0.47333333333333344
    }, {
        "ID": 8756,
        "phrase": " bp all cog, 15 rows, agda ml estimation cog 31,16,a , 15 rows, st",
        "prob": 0.6230769230769231
    }, {
        "ID": 8756,
        "phrase": " bp all cog, 15 rows, agda ml estimation ber \u2192 \u2190 er 10 0 10 \u22121 fer \u2192 10 \u22122 10 \u22123 0",
        "prob": 0.5083333333333334
    }, {
        "ID": 8757,
        "phrase": " bp all cog, 15 rows, agda ml estimation cog 31,16,a , 15 rows, st",
        "prob": 0.6230769230769231
    }, {
        "ID": 8757,
        "phrase": " bp all cog, 15 rows, agda ml estimation ber \u2192 \u2190 er 10 0 10 \u22121 fer \u2192 10 \u22122 10 \u22123 0",
        "prob": 0.5083333333333334
    }, {
        "ID": 8781,
        "phrase": ", the computation of hypothesis testing problem, the linear ml estimation  [6, 12] , the sufficient statistic in detection of gaussian processes in gaussian noise  [13] , the maximum, the minimum, the histograms, the geometric mean of the sensors' measurements, and so on  [6, 12] ",
        "prob": 0.484
    }, {
        "ID": 8781,
        "phrase": " the estimate is performed through the interaction system (3), with functions gi(yi) = yi/ai and coefficients ci = a 2 i /\u03c3 2 i , chosen in order to achieve the globally optimal ml estimate",
        "prob": 0.6368421052631579
    }, {
        "ID": 8781,
        "phrase": " the results refer to following cases of interest: a) ml estimate achieved with a centralized system, with no communication errors between nodes and fusion center (dotted lines); b) estimate achieved with the proposed method, with no propagation delays, as a benchmark term (dashed and dotted lines plus \u00d7 marks for the average value); c) estimate achieved with the proposed method, with propagation delays (dashed lines plus stars for the average value); d) estimate achieved with the two-step estimation method leading to (10) (solid lines plus circles for the average value)",
        "prob": 0.90327868852459
    }, {
        "ID": 8781,
        "phrase": " algorithm based on (3) behaves, asymptotically, as the (centralized) globally optimal ml estimator",
        "prob": 0.6230769230769231
    }, {
        "ID": 8781,
        "phrase": " in the presence of delays, we observe a clear bias (dashed lines), due to the large delay values, but still with a final estimation variance close to the ml estimator's",
        "prob": 0.5045454545454545
    }, {
        "ID": 8781,
        "phrase": " interestingly, if the two-step procedure leading to  (10)  provides results very close to the optimal ml estimator, with no apparent bias, in spite of the large delays and the random channel fading coefficients",
        "prob": 0.7958333333333332
    }, {
        "ID": 8782,
        "phrase": ", the computation of hypothesis testing problem, the linear ml estimation  [8, 13] , the sufficient statistic in detection of gaussian processes in gaussian noise, the maximum, the minimum, the histograms, the geometric mean of the sensors' measurements, and so on  [8, 13] ",
        "prob": 0.444
    }, {
        "ID": 8782,
        "phrase": " the estimate is performed through the interaction system (3), with functions gi(yi) = yi/ai and coefficients ci = a 2 i /\u03c3 2 i , chosen in order to achieve the globally optimal ml estimate",
        "prob": 0.6368421052631579
    }, {
        "ID": 8782,
        "phrase": " the results refer to following cases of interest: a) ml estimate achieved with a centralized system, with no communication errors between nodes and fusion center (dotted lines); b) estimate achieved with the proposed method, with no propagation delays, as a benchmark term (dashed and dotted lines plus \u00d7 marks for the average value); c) estimate achieved with the proposed method, with propagation delays (dashed lines plus stars for the average value); d) estimate achieved with the two-step estimation method leading to (10) (solid lines plus circles for the average value)",
        "prob": 0.8868852459016393
    }, {
        "ID": 8782,
        "phrase": " from figure  2  we can see that, in the absence of delays, the (decentralized) iterative algorithm based on (3) behaves, asymptotically, as the (centralized) globally optimal ml estimator",
        "prob": 0.4789473684210526
    }, {
        "ID": 8782,
        "phrase": " in the presence of delays, we observe a clear bias (dashed lines), due to the large delay values, but still with a final estimation variance close to the ml estimator's",
        "prob": 0.5499999999999999
    }, {
        "ID": 8782,
        "phrase": " interestingly, if the two-step procedure leading to  (10)  provides results very close to the optimal ml estimator, with no apparent bias, in spite of the large delays and the random channel fading coefficients",
        "prob": 0.7958333333333332
    }, {
        "ID": 8835,
        "phrase": " in some cases, bp over loopy factor graphs of channel codes has been shown to have near ml performance",
        "prob": 0.2733333333333333
    }, {
        "ID": 8907,
        "phrase": " to quote from  [5] : \"although we have, by now, accumulated a considerable amount of results on the hardness of ml decoding, the broad worst-case nature of these results is still somewhat unsatisfactory",
        "prob": 0.29047619047619044
    }, {
        "ID": 8907,
        "phrase": " by this we mean that, in some cases, the decoder can certify that the solution is the ml solution; thus, we either get an exact ml codeword or declare an error",
        "prob": 0.268421052631579
    }, {
        "ID": 9163,
        "phrase": " the curves show that, as the snr increases, proposed method outperforms the lp and the spa, and significantly closes the gap to the ml decoder performance",
        "prob": 0.3210526315789474
    }, {
        "ID": 9221,
        "phrase": " ml provides a simple form of exception handling",
        "prob": 0.20999999999999994
    }]
}, {
    "topic_id": 12,
    "top_words": ["ml", "decoding", "complexity", "codes", "single", "symbol", "diversity", "decodable", "transmit", "symbols", "group", "antennas", "full", "order", "rate"],
    "phrases": [{
        "ID": 658,
        "phrase": " first, it conveys simply that the ai class involves a given set of assignments",
        "prob": 0.17500000000000002
    }, {
        "ID": 2333,
        "phrase": " more precisely, the presented definition does not lead to an enumeration procedure for \u03be ai alt ",
        "prob": 0.20999999999999996
    }, {
        "ID": 3220,
        "phrase": " these ml bits will serve as input to the privacy amplification protocol",
        "prob": 0.2818181818181818
    }, {
        "ID": 3602,
        "phrase": " 1 1 \u01eb it \u01eb ml exit(\u01eb) 0 1 1 \u01eb it \u01eb ml exit(\u01eb) in fig",
        "prob": 0.23333333333333334
    }, {
        "ID": 3630,
        "phrase": " in the case of the uncoded multi-antenna systems, the computational complexity of the naive maximumlikelihood (ml) decoding algorithm grows exponentially with the number of transmit antennas, so we need an efficient algorithm to implement ml decoding",
        "prob": 0.3370370370370371
    }, {
        "ID": 3630,
        "phrase": " to implement ml decoding on the channel described by eq",
        "prob": 0.20999999999999996
    }, {
        "ID": 3630,
        "phrase": " by these reductions of the complexity, the proposed methods enable us to implement ml decoding for the multi-antenna system with a lager number of transmit antennas",
        "prob": 0.505
    }, {
        "ID": 3630,
        "phrase": "we propose use of qr factorization with sort and dijkstra's algorithm for decreasing the computational complexity of the sphere decoder that is used for ml detection of signals on the multi-antenna fading channel",
        "prob": 0.37916666666666665
    }, {
        "ID": 4089,
        "phrase": " the multiuser app computation is o(q k ), an improvement over joint ml decoding, but still prohibitive",
        "prob": 0.29285714285714287
    }, {
        "ID": 4115,
        "phrase": " in this paper, we show for the first time that (3) does not hold for the prequential ml code",
        "prob": 0.175
    }, {
        "ID": 4464,
        "phrase": " , (i k , j k ), (i k , j 1 ) in h such that p ai 1 \u2022j1 (p ai 1 \u2022j2 ) \u22121 p ai 2 \u2022j2 (p ai 2 \u2022j3 ) \u22121 \u2022 \u2022 \u2022 p ai k \u2022j k (p ai k \u2022j1 ) \u22121 evaluates to the identity matrix i",
        "prob": 0.15714285714285714
    }, {
        "ID": 4694,
        "phrase": " on the other hand, if two variables defined as two different representations of one single event are not completely correlated, then it is highly probable that a ml process will be able to extract different unshared information from both of them, improving classification rates",
        "prob": 0.15185185185185185
    }, {
        "ID": 4786,
        "phrase": "  6  compares the performance of this decoder with the ml performance for a 4 \u00d7 4, 4\u2212qam v-blast system",
        "prob": 0.3416666666666667
    }, {
        "ID": 4786,
        "phrase": " as observed in  [16] , one obtains a sizable performance gain when using rate-3 tast constellation under ml decoding",
        "prob": 0.54
    }, {
        "ID": 4786,
        "phrase": " it has been shown that the complexity of ml decoding of this class of codes grows exponentially with the number of transmit antennas and data rates",
        "prob": 0.3588235294117647
    }, {
        "ID": 4786,
        "phrase": " thus, the stack algorithm too achieves the same diversity as the ml decoder for a v-blast system, for any finite value of b",
        "prob": 0.34
    }, {
        "ID": 4786,
        "phrase": " \n decoding of algebraic stc with golay(12,24) code, m=2, t=12, n=1, decoding of hammons\u2212elgamal stacking construction stc, m=t=3, n=1, r=1 bpcu ml decoding mmse\u2212lattice decoding \n figure 8 : 8 figure 8: performance of mmse-dfe lattice decoding and ml decoding for algebraic space-time codes \n figure 9 : 9 figure 9: frame and bit error rate curves for the fano and psp algorithms for convolutional codes over an isi channel \n table 1 : 1 complexity ratio of the proposed algorithm for rate-3 tast constellation over rate-1 tast constellation in a 3 \u00d7 1 mimo system snr (db) 22 24 26 28 30 \u03b3 41 31 23 16 12 \n\t\t\t we use the superscript c to denote complex variables",
        "prob": 0.4630769230769231
    }, {
        "ID": 5037,
        "phrase": " for x \u2208 c, let d ml x \u03bb \u2208 r n x \u2032 \u2022 \u03bb t \u2265 2 exceptions to this observation include for example the class of convolutional codes with not too many states",
        "prob": 0.2733333333333333
    }, {
        "ID": 5054,
        "phrase": " the ml decoding complexity \u03c7 is proportional to the number of codewords, \u03c7 \u223c = 2 n r ",
        "prob": 0.41000000000000003
    }, {
        "ID": 5054,
        "phrase": " can any dmc be split in some way to achieve coding gains as measured by improvements in the ml reliability-complexity tradeoff or in the cutoff rate? and, if so, what are the limits of such gains? we address these questions in the framework of coding systems that consist of three elements: (i) channel combining, (ii) input relabeling, and (iii) channel splitting",
        "prob": 0.23142857142857143
    }, {
        "ID": 5075,
        "phrase": " by way of comparison, consider ml decoding",
        "prob": 0.1222222222222222
    }, {
        "ID": 5118,
        "phrase": " such schemes are sub-optimal, since they yield a low spatial diversity order: for a mimo system with l t transmit and l r receive antennas this is equal to l r \u2212 l t + 1, as opposed to l r for ml  [2] ",
        "prob": 0.505
    }, {
        "ID": 5118,
        "phrase": " it should be noted if the matrix inversion in the zf detector requires o ((2l t ) 2 ) operations then the order of magnitude complexity of the zf detector is the same as the ml detector",
        "prob": 0.7277777777777777
    }, {
        "ID": 5118,
        "phrase": " the ml performance is compared to the well understood zero forcing (zf) detector",
        "prob": 0.5461538461538462
    }, {
        "ID": 5118,
        "phrase": " the advantage of ml detection versus linear detection in terms of diversity is obvious from these plots",
        "prob": 0.4357142857142857
    }, {
        "ID": 5119,
        "phrase": " such schemes are sub-optimal, since they yield a low spatial diversity order: for a mimo system with l t transmit and l r receive antennas this is equal to l r \u2212 l t + 1, as opposed to l r for ml  [2] ",
        "prob": 0.5549999999999999
    }, {
        "ID": 5119,
        "phrase": " it should be noted if the matrix inversion in the zf detector requires o ((2l t ) 2 ) operations then the order of magnitude complexity of the zf detector is the same as the ml detector",
        "prob": 0.7277777777777777
    }, {
        "ID": 5119,
        "phrase": " the ml performance is compared to the well understood zero forcing (zf) detector",
        "prob": 0.3153846153846154
    }, {
        "ID": 5119,
        "phrase": " the advantage of ml detection versus linear detection in terms of diversity is obvious from these plots",
        "prob": 0.5071428571428572
    }, {
        "ID": 5120,
        "phrase": " such schemes yield a low spatial diversity order: for a mimo system with l t transmit and l r receive antennas this is equal to l r \u2212 l t + 1, as opposed to l r for ml  [2] ",
        "prob": 0.6529411764705882
    }, {
        "ID": 5120,
        "phrase": " the ml performance is compared to the well understood zero forcing (zf) detector",
        "prob": 0.5461538461538461
    }, {
        "ID": 5120,
        "phrase": " the advantage of ml detection versus linear detection in terms of diversity is obvious from these plots",
        "prob": 0.5071428571428571
    }, {
        "ID": 5233,
        "phrase": "  12  depicts the outage curves corresponding to r = 8 and 12 bpcu for a 2 \u00d7 2 v-blast scheme with ml decoding",
        "prob": 0.3153846153846154
    }, {
        "ID": 5233,
        "phrase": "  13 , on the other hand, compares the outage behavior of 2 \u00d7 2 mimo and ml v-blast schemes for r = 4, 16 and 32 bpcu",
        "prob": 0.42500000000000004
    }, {
        "ID": 5233,
        "phrase": " (74) this follows immediately from (72) and the fact that pr{e s * } upper-bounds the ml error probability of a mimo channel with |s * | transmit antennas, m receive antennas and rate |s * | m r",
        "prob": 0.32105263157894737
    }, {
        "ID": 5344,
        "phrase": " comparing those results against computer simulations, it is shown that orthogonally decoded gabba stbcs achieve nearly the same performance of achievable with the ml decoder (which is prohibitively complex for large codes and higher-order constellations), especially in systems with a relatively large number of antennas at the receiver",
        "prob": 0.33636363636363636
    }, {
        "ID": 5344,
        "phrase": " therefore, we shall take the approach of deriving analytical expressions (bounds) corresponding to the ml decoder (whose complexity is prohibitive for large systems and high-order constellations), and compare the curves with simulation results obtained using the proposed gabba orthogonal decoder",
        "prob": 0.284375
    }, {
        "ID": 5344,
        "phrase": " finally, it is clearly shown that the diversity order attained by the gabba stbc with its orthogonal decoder is the same as the one theoretically achievable with the ml decoder",
        "prob": 0.33888888888888885
    }, {
        "ID": 5344,
        "phrase": " this is because at nt = 2 the gabba code reduces to the alamouti scheme, which admits a linear orthogonal decoder identical to the ml decoder",
        "prob": 0.30000000000000004
    }, {
        "ID": 5369,
        "phrase": " this means that in terms of energy efficiency 3 , the decorrelator and the mmse detector are almost as good as the ml detector",
        "prob": 0.34
    }, {
        "ID": 5379,
        "phrase": " another quasi-maximum likelihood decoding method is introduced in  [29]  for larger psk constellations with near ml performance and low complexity",
        "prob": 0.32105263157894737
    }, {
        "ID": 5379,
        "phrase": "  3  demonstrates that the proposed quasi-ml method using model  (32)  and the randomization procedure achieves near ml performance in an un-coded 2 \u00d7 2 mimo system with qpsk constellation",
        "prob": 0.45909090909090916
    }, {
        "ID": 5379,
        "phrase": " the performance of the proposed sdp relaxation model (  34 ) is close to the ml performance, while the order of the worst-case complexity is lower as compared to sd (polynomial vs",
        "prob": 0.1952380952380952
    }, {
        "ID": 5379,
        "phrase": " the method in  [27]  can handle qam constellations; however, it achieves near ml performance only in the case of bpsk and qpsk constellations",
        "prob": 0.5352941176470588
    }, {
        "ID": 5380,
        "phrase": " another quasi-maximum likelihood decoding method is introduced in  [29]  for larger psk constellations with near ml performance and low complexity",
        "prob": 0.3736842105263158
    }, {
        "ID": 5380,
        "phrase": " however, for the special case of a mimo system with two antennas (with real coefficients), it has been shown that by using the lll approximation and considering two points per dimension we achieve the ml decoding performance  [42] ",
        "prob": 0.3375
    }, {
        "ID": 5380,
        "phrase": " the method in  [27]  can handle qam constellations; however, it achieves near ml performance only in the case of bpsk and qpsk constellations",
        "prob": 0.5941176470588235
    }, {
        "ID": 5380,
        "phrase": " in  [26] , it is shown that generally, there is an exponential lower bound on comparison of the relaxation model proposed in  [29]  and that in our method in a mimo system with 4 transmit and receive antennas, employing 8-psk modulation /n 0 ser method proposed in  [27]  method proposed in  [30]  model (32) \u2212 algorithm i model (34) \u2212 rounding ml decoding fig",
        "prob": 0.396969696969697
    }, {
        "ID": 5501,
        "phrase": " due to the orthogonality of columns of g g g, space-time block decoding (signal combining) makes the ml decision metric decompose into n parts, each only a function of one and only one of  6  in general, a correlation matrix is positive semidefinite with all diagonal entries 1",
        "prob": 0.48518518518518516
    }, {
        "ID": 5502,
        "phrase": " due to the orthogonality of columns of g g g, space-time block decoding (signal combining) makes the ml decision metric decompose into n parts, each only a function of one and only one of  6  in general, a correlation matrix is positive semidefinite with all diagonal entries 1",
        "prob": 0.5222222222222221
    }, {
        "ID": 5645,
        "phrase": " \n v-blast with ml decoding diversity gain: d(r) spatial multiplexing gain: r = r/ log(sn r) (1, (n \u2212 1) 2 ) (n, 0) (r, (n \u2212 r) 2 ) (n \u2212 1, 1) (0, n 2 ) figure  7 : the i",
        "prob": 0.4733333333333334
    }, {
        "ID": 5645,
        "phrase": " our main result is a precise characterization of the diversity performance under joint ml decoding of the streams; the proof is available in appendix h",
        "prob": 0.41764705882352937
    }, {
        "ID": 5645,
        "phrase": " \n d-blast and ml decoding in this section, we discuss the ml decoding of the two data streams in the d-blast architecture in some detail",
        "prob": 0.5352941176470588
    }, {
        "ID": 5645,
        "phrase": " however, due to the specific structure of the zeros in the d-blast architecture, the joint ml decoder can be broken down algorithmically into three separate steps: 1",
        "prob": 0.26842105263157895
    }, {
        "ID": 5645,
        "phrase": " thus, the ml decoding of the two streams of the d-blast architecture reduces to that of a decoding uncoded qam transmission over the v-blast architecture",
        "prob": 0.6722222222222222
    }, {
        "ID": 5645,
        "phrase": " the diversity gain of joint ml decoding the data streams of the time-space code in (69) at a total multiplexing rate of r bits/symbol over the (n t + 1) \u00d7 n r i",
        "prob": 0.7277777777777777
    }, {
        "ID": 5645,
        "phrase": " the diversity gain of joint ml decoding the data streams of the time-space code in (69) at a total multiplexing rate of r bits/symbol over any isotropic n t+1 \u00d7 2 mimo channel achieves the second segment of its tradeoff curve, provided  k 2 \u2212 k 1 \u2265 2, \n a converse for approximate universality we want to show that if a coding scheme does not satisfy the universal code design criterion, then there exists a fading distribution such that the coding scheme is not tradeoff optimal",
        "prob": 0.6386363636363636
    }, {
        "ID": 5646,
        "phrase": " \n v-blast with ml decoding diversity gain: d(r) spatial multiplexing gain: r = r/ log(sn r) (1, (n \u2212 1) 2 ) (n, 0) (r, (n \u2212 r) 2 ) (n \u2212 1, 1) (0, n 2 ) figure  7 : the i",
        "prob": 0.54
    }, {
        "ID": 5646,
        "phrase": " our main result is a precise characterization of the diversity performance under joint ml decoding of the streams; the proof is available in appendix f",
        "prob": 0.41764705882352937
    }, {
        "ID": 5646,
        "phrase": " \n d-blast and ml decoding in this section, we discuss the ml decoding of the two data streams in the d-blast architecture in some detail",
        "prob": 0.4764705882352942
    }, {
        "ID": 5646,
        "phrase": " however, due to the specific structure of the zeros in the d-blast architecture, the joint ml decoder can be broken down algorithmically into three separate steps: 1",
        "prob": 0.3736842105263158
    }, {
        "ID": 5646,
        "phrase": " thus, the ml decoding of the two streams of the d-blast architecture reduces to that of a decoding uncoded qam transmission over the v-blast architecture",
        "prob": 0.6722222222222222
    }, {
        "ID": 5646,
        "phrase": " the diversity gain of joint ml decoding the data streams of the time-space code in (54) at a total multiplexing rate of r bits/symbol over the (n t + 1) \u00d7 n r i",
        "prob": 0.6722222222222222
    }, {
        "ID": 5646,
        "phrase": " the diversity gain of joint ml decoding the data streams of the time-space code in (54) at a total multiplexing rate of r bits/symbol over any isotropic n t+1 \u00d7 2 mimo channel achieves the second segment of its tradeoff curve, provided k 2 \u2212 k 1 \u2265 2, k 1 \u2264 0",
        "prob": 0.6576923076923076
    }, {
        "ID": 5817,
        "phrase": "  [13]  propose a trellis based ml soft-decision decoder for convolutional codes which uses a stack and a metric that ensures ml decoding",
        "prob": 0.42631578947368426
    }, {
        "ID": 5818,
        "phrase": " propose the use of the a * algorithm for ml decoding of block codes on their conventional trellises and report significant experimental gains in decoding complexity for signal to noise ratios ranging from 5 db to 8 db",
        "prob": 0.204
    }, {
        "ID": 5818,
        "phrase": "  [13]  propose a trellis based ml soft-decision decoder for convolutional codes which uses a stack and a metric that ensures ml decoding",
        "prob": 0.4263157894736842
    }, {
        "ID": 5899,
        "phrase": " by using the union bound, we can show that the exact ml decoding achieves the diversity order of m, the number of antennas",
        "prob": 0.5687500000000001
    }, {
        "ID": 5899,
        "phrase": " also, it is shown that by using the naive lattice decoding, instead of ml decoding, we do not loose the diversity order",
        "prob": 0.4733333333333334
    }, {
        "ID": 5900,
        "phrase": " by using the union bound, we can show that the exact ml decoding achieves the diversity order of n, the number of receive antennas",
        "prob": 0.4764705882352941
    }, {
        "ID": 5900,
        "phrase": " also, it is shown that by using the naive lattice decoding, instead of ml decoding, we do not loose the receive diversity order",
        "prob": 0.5687500000000001
    }, {
        "ID": 5969,
        "phrase": " thus, m does not implement l ai \u2264 p lni-t a i ",
        "prob": 0.15714285714285717
    }, {
        "ID": 6109,
        "phrase": " formally definition 2 (single-symbol decodable (sd) stbc): a single-symbol decodable (sd) stbc of rate k/l in k complex indeterminates x k = x ki + jx kq , k = 0, \u2022 \u2022 \u2022 , k \u2212 1 is a linear stbc such that the ml decoding metric can be written as a square of several terms each depending on at most one indeterminate",
        "prob": 0.6999999999999998
    }, {
        "ID": 6109,
        "phrase": " in this paper, we first characterize all linear stbcs that admit single-symbol ml decoding, (not necessarily full-rank) over quasi-static fading channels, the class of single-symbol decodable designs (sdd)",
        "prob": 0.7814814814814813
    }, {
        "ID": 6109,
        "phrase": " therefore, we characterize all linear stbcs that allow single-symbol ml decoding when used in rapid-fading channels",
        "prob": 0.5941176470588235
    }, {
        "ID": 6109,
        "phrase": " single-symbol decodable designs in the first part of this section we characterize all stbcs that allow single-symbol ml decoding in quasi-static fading channel and using this characterization define single-symbol decodable designs (sdd) in terms of the weight matrices and discuss several examples of such designs",
        "prob": 0.6513513513513512
    }, {
        "ID": 6109,
        "phrase": " characterization of sd stbcs consider the matrix channel model for quasi-static fading channel given in  (5)  and the corresponding ml decoding metric  (6) ",
        "prob": 0.45500000000000007
    }, {
        "ID": 6109,
        "phrase": " for a linear stbc with k variables, we are concerned about those stbcs for which the ml metric (  6 ) can be written as sum of several terms with each term involving at-most one variable only and hence sd",
        "prob": 0.3227272727272727
    }, {
        "ID": 6109,
        "phrase": " when the number of receive antennas m = 1, observe that the diversity gain in the alamouti code is due to the fact that each symbol sees two different channels h 0 and h 1 and the low ml decoding complexity is due to the use of the orthogonality of columns of signal transmission matrix, by the receiver, over two symbol periods to form an estimate of each symbol",
        "prob": 0.7324324324324323
    }, {
        "ID": 6109,
        "phrase": " ( 84 ) remark 26: note that forming the ml metric for each variable in (84), implicitly involves co-ordinate de-interleaving, in the same way as the coding involves co-ordinate interleaving",
        "prob": 0.41363636363636364
    }, {
        "ID": 6109,
        "phrase": " but, the main factor in favor of ciod as compared to stbc-cr (as also any stbc other than stbc-od) is that ciod allows linear complexity ml decoding while stbc-cr has exponential ml decoding complexity",
        "prob": 0.696153846153846
    }, {
        "ID": 6109,
        "phrase": " we first characterize all linear stbcs that allow singlesymbol ml decoding when used in rapid-fading channels",
        "prob": 0.5687500000000001
    }, {
        "ID": 6109,
        "phrase": "space-time block codes (stbc) from orthogonal designs (od) and co-ordinate interleaved orthogonal designs (ciod) have been attracting wider attention due to their amenability for fast (single-symbol) ml decoding, and full-rate with full-rank over quasi-static fading channels",
        "prob": 0.7457142857142856
    }, {
        "ID": 6109,
        "phrase": " however, these codes are instances of single-symbol decodable codes and it is natural to ask, if there exist codes other than stbcs form ods and ciods that allow single-symbol decoding? in this paper, the above question is answered in the affirmative by characterizing all linear stbcs, that allow single-symbol ml decoding (not necessarily full-diversity) over quasi-static fading channels-calling them single-symbol decodable designs (sdd)",
        "prob": 0.6895833333333332
    }, {
        "ID": 6149,
        "phrase": " the ml decoding fer for cooperative coding scheme averaged over all possible reliable sets can be bounded as follows fer (m ) = all possible f p(f) pw \u03b3 | f \u2264 all possible f p(f) \u2022 g(m, f, snr) (30) where the superscript (m ) represents the number of (potential) transmitting nodes",
        "prob": 0.27
    }, {
        "ID": 6165,
        "phrase": " the near ml decoding curve is obtained using improved turbo decoding with a large number for l max ",
        "prob": 0.3812500000000001
    }, {
        "ID": 6296,
        "phrase": " in this paper, we focus on a new class of qo-stbc whose ml decoding only requires the joint detection of two real symbols",
        "prob": 0.6894736842105263
    }, {
        "ID": 6296,
        "phrase": " orthogonal stbc orthogonal stbc (o-stbc) has the simplest decoding complexity, as its ml decoding can be achieved by linear detection",
        "prob": 0.5941176470588235
    }, {
        "ID": 6296,
        "phrase": " it can be shown that its ml decoding metric can be calculated as the sum f 1 + f 2 + f 3 + f 4 , where the terms f 1 to f 4 are given in  (8) ",
        "prob": 0.17500000000000002
    }, {
        "ID": 6296,
        "phrase": " joint detection of two real symbols), and is independent of x k for i \u2260 k, the minimization of the ml metric is equivalent to minimizing the four f i terms independently",
        "prob": 0.5611111111111111
    }, {
        "ID": 6296,
        "phrase": " the number of real symbols required for joint ml detection) of mdc-qostbc versus the o-stbc, qo-stbc and ciod/aciod with constellation rotation",
        "prob": 0.755
    }, {
        "ID": 6296,
        "phrase": " of real symbols for ml joint detection minimum determinant p o qo-stbc [3] [6] 45 0 4 16 0 ciod [7] 31",
        "prob": 0.5785714285714286
    }, {
        "ID": 6340,
        "phrase": " if a properly optimized layer ordering technique is utilized, numerical results reported in  [10] ,  [11]  demonstrate that the ld detector is able to achieve full receive diversity and a degradation from ml performance of fractions of a db",
        "prob": 0.27307692307692305
    }, {
        "ID": 6340,
        "phrase": " its preprocessing is less complex -o(l to conclude this section, it should be mentioned that no efficient soft-output ml decoding strategy has been proposed so far for full diversity full data rate algebraic space-time codes (stcs) like the golden codes (gc)  [28] ",
        "prob": 0.36666666666666664
    }, {
        "ID": 6340,
        "phrase": " the performance comparison of layered bicm systems and uncoded gc provided in section v shows that soft-output ml detection and eccs are essential in order to exploit the high-data rate and high link robustness promised by mimo for next generation wireless applications (like wireless local area networks (wlans), undergoing standardization as ieee 802",
        "prob": 0.28809523809523807
    }, {
        "ID": 6340,
        "phrase": " in a subset of cases, also the performance of exhaustive-search ml detection was verified, including l t = 3 and 16qam corresponding to 4096 operations per complex symbol",
        "prob": 0.33888888888888896
    }, {
        "ID": 6340,
        "phrase": " it should be noted that the algorithm achieves optimal hard-output ml performance in case of two transmit antennas",
        "prob": 0.38125000000000003
    }, {
        "ID": 6373,
        "phrase": ", achieving the dmt) under ml decoding",
        "prob": 0.3875
    }, {
        "ID": 6374,
        "phrase": ", achieving the dmt) under ml decoding",
        "prob": 0.3875
    }, {
        "ID": 6435,
        "phrase": " on the other hand, it follows from lemma 3 (see appendix) that in the special case of uniform fading, if k e ml = 2 for m \u2265 1 and l large, the mutual information on the noncoherent channel for a unit energy orthogonal constellation with e m l e x 2 2 2 { } = s satisfies i ml ml l m ml m me m l m l \u02c6; l n , ",
        "prob": 0.15185185185185185
    }, {
        "ID": 6502,
        "phrase": " m\u00fcller, senior member, ieee i an input i for which the constraint (4) holds satisfies the following condition for / k n \u03b2 = [1]: ( ) { } ( ) 1 1 1 1 , d 1 k k k \u03b2 \u03bb \u03b4 \u03b2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221e \u2212 \u2212 = \u222b + s s a ai \u03bbi , (5) where the k variables of integration are the k eigenvalues of the diagonal matrix \u03bb ",
        "prob": 0.2157894736842105
    }, {
        "ID": 6676,
        "phrase": " although ml decoding is not practically viable, the low-density nature of our construction means that they have low degree, and with high probability (w",
        "prob": 0.33888888888888885
    }, {
        "ID": 6718,
        "phrase": " we find that our approach has similar diversity performance to bd with an ml receiver and much better performance than bd with a zf receiver",
        "prob": 0.22777777777777775
    }, {
        "ID": 6718,
        "phrase": " from the viewpoint of diversity gain, the proposed scheme has the same diversity order with the ml type receiver as mentioned earlier",
        "prob": 0.5062500000000001
    }, {
        "ID": 6718,
        "phrase": " we observe that the proposed scheme has the same slope as the ml-rx mu mimo scheme with the ml receiver and provides better diversity gain than the zf mu sm-mimo and zf-rx mu mimo schemes with linear precoding and decoding, respectively",
        "prob": 0.5222222222222223
    }, {
        "ID": 6718,
        "phrase": " the complexity of o(n m +\u03b1 ) is greater than o(n m ) referred to as the complexity of ml decoding scheme with l k transmit data streams",
        "prob": 0.5071428571428572
    }, {
        "ID": 6718,
        "phrase": " the zf-rx mu mimo and the ml-rx mu mimo schemes has no special encoding techniques at the transmitter, however, they use the zf and the ml decoding algorithms at the receiver, respectively",
        "prob": 0.4333333333333333
    }, {
        "ID": 6785,
        "phrase": " the ai needs a system for categorizing sequential events in time and for forming concepts",
        "prob": 0.25833333333333336
    }, {
        "ID": 6876,
        "phrase": " however, for a general channel matrix, h, and vector of received signals, y, the ml detection problem in  (2)  has been shown to be np-hard  [3]  and the full search solution has a complexity of o(2 m ) where m is the number of symbols jointly detected",
        "prob": 0.244
    }, {
        "ID": 6876,
        "phrase": " however, the numerical results also indicate that the loss in diversity (with respect to the ml detector) remains small",
        "prob": 0.20666666666666664
    }, {
        "ID": 6876,
        "phrase": " loosely speaking, although suboptimal, the sdr detector will have an error probability which vanishes at the same rate as the ml detector in the high snr limit and the loss due to suboptimality will be a shift in snr and not a loss of diversity",
        "prob": 0.31153846153846154
    }, {
        "ID": 6876,
        "phrase": " note also that there is a one-to-one correspondence between the rank one matrices and all possible messages (not equal to the transmitted message), \u015d \u2208 b m \\e, that are searched over by the ml detector",
        "prob": 0.26842105263157895
    }, {
        "ID": 6876,
        "phrase": " thus, (in a very loose sense) the reason for the high diversity of the sdr detector is that the elements added in the relaxation (the ones in y fr ) are less likely to cause errors than the elements already present in the feasible set of the ml detection problem (the ones in y r1 )",
        "prob": 0.2033333333333333
    }, {
        "ID": 6876,
        "phrase": " it is however also unreasonable to expect the bound to be very loose in the sense that the sdr detector would maintain the same diversity as the ml detector in the general case where n < m",
        "prob": 0.4263157894736842
    }, {
        "ID": 6876,
        "phrase": " therefore, the typical error events of the sdr detector no longer coincide with the error events of the ml detector and the sdr detector can experience a loss in diversity",
        "prob": 0.2904761904761905
    }, {
        "ID": 6892,
        "phrase": " in the above (in)equalities, x ai , 1 \u2264 i \u2264 s, represents the number of occurrences of a i in w \u2032 ",
        "prob": 0.1375
    }, {
        "ID": 6970,
        "phrase": " although maximum-likelihood (ml) decoding is in general prohibitively complex for long codes, the derivation of bounds on the ml decoding error probability is of interest, providing an ultimate indication of the system performance",
        "prob": 0.23461538461538461
    }, {
        "ID": 7486,
        "phrase": " due to its single-symbol ml decodability and full diversity order, the repetition-based cooperative strategy was used and studied in many literatures  [4] ,  [6] -  [10] ",
        "prob": 0.45500000000000007
    }, {
        "ID": 7486,
        "phrase": " however, none of those codes were single-symbol ml decodable",
        "prob": 0.4636363636363637
    }, {
        "ID": 7486,
        "phrase": " it is well-known that the generalized orthogonal designs can achieve  1  a code or a scheme is said to be single-symbol ml decodable, if its ml decoding metric can be written as a sum of several terms, each of which depends on at most one transmitted symbol  [5] ",
        "prob": 0.6333333333333332
    }, {
        "ID": 7486,
        "phrase": " however, when the generalized orthogonal designs were directly used in cooperative networks, the orthogonality of the codes was lost, and hence, the codes were not single-symbol ml decodable any more  [19] ",
        "prob": 0.6714285714285714
    }, {
        "ID": 7486,
        "phrase": " but, the codes proposed in  [22]  were not single-symbol ml decodable in general",
        "prob": 0.5545454545454546
    }, {
        "ID": 7486,
        "phrase": " to the best of our knowledge, high data-rate distributed space-time codes which achieve both the single-symbol ml decodability and the full diversity order have never been designed",
        "prob": 0.5695652173913043
    }, {
        "ID": 7486,
        "phrase": " the proposed dostbcs achieve the single-symbol ml decodability and full diversity order",
        "prob": 0.7214285714285715
    }, {
        "ID": 7486,
        "phrase": " 7 substituting (10) into  (9) , it is easy to show that the dostbcs are single-symbol ml decodable",
        "prob": 0.5083333333333334
    }, {
        "ID": 7486,
        "phrase": " obviously, the row-monomial dostbcs are single-symbol ml decodable because they are in a subset of the dostbcs",
        "prob": 0.65
    }, {
        "ID": 7486,
        "phrase": " since the schemes proposed in  [14] -  [18] ,  [22]  are not single-symbol ml decodable, their performance is not compared in this paper",
        "prob": 0.65
    }, {
        "ID": 7486,
        "phrase": " conclusion this paper focuses on designing high data-rate distributed space-time codes with singlesymbol ml decodability and full diversity order",
        "prob": 0.6714285714285714
    }, {
        "ID": 7486,
        "phrase": "17 \n\t\t\t if the transmitted symbols are real-valued, it is easy to show that the rate-one generalized real orthogonal design proposed in [21]  can be used in cooperative networks without any changes, while achieving the single-symbol ml decodability and full diversity order",
        "prob": 0.7033333333333333
    }, {
        "ID": 7487,
        "phrase": " due to its single-symbol ml decodability and full diversity order, the repetition-based cooperative strategy was used and studied in many literatures  [4] ,  [6] -  [10] ",
        "prob": 0.45500000000000007
    }, {
        "ID": 7487,
        "phrase": " however, none of those codes were single-symbol ml decodable",
        "prob": 0.6454545454545455
    }, {
        "ID": 7487,
        "phrase": " it is well-known that the generalized orthogonal designs can achieve  1  a code or a scheme is said to be single-symbol ml decodable, if its ml decoding metric can be written as a sum of several terms, each of which depends on at most one transmitted symbol  [5] ",
        "prob": 0.6333333333333332
    }, {
        "ID": 7487,
        "phrase": " however, when the generalized orthogonal designs were directly used in cooperative networks, the orthogonality of the codes was lost, and hence, the codes were not single-symbol ml decodable any more  [19] ",
        "prob": 0.5761904761904761
    }, {
        "ID": 7487,
        "phrase": " but, the codes proposed in  [22]  were not single-symbol ml decodable in general",
        "prob": 0.5545454545454546
    }, {
        "ID": 7487,
        "phrase": " to the best of our knowledge, high data-rate distributed space-time codes which achieve both the single-symbol ml decodability and the full diversity order have never been designed",
        "prob": 0.5260869565217391
    }, {
        "ID": 7487,
        "phrase": " the proposed dostbcs achieve the single-symbol ml decodability and full diversity order",
        "prob": 0.65
    }, {
        "ID": 7487,
        "phrase": " 7 substituting (10) into  (9) , it is easy to show that the dostbcs are single-symbol ml decodable",
        "prob": 0.5083333333333334
    }, {
        "ID": 7487,
        "phrase": " obviously, the row-monomial dostbcs are single-symbol ml decodable because they are in a subset of the dostbcs",
        "prob": 0.65
    }, {
        "ID": 7487,
        "phrase": " since the schemes proposed in  [14] -  [18] ,  [22]  are not single-symbol ml decodable, their performance is not compared in this paper",
        "prob": 0.5785714285714286
    }, {
        "ID": 7487,
        "phrase": " conclusion this paper focuses on designing high data-rate distributed space-time codes with singlesymbol ml decodability and full diversity order",
        "prob": 0.6714285714285714
    }, {
        "ID": 7487,
        "phrase": "17 \n\t\t\t if the transmitted symbols are real-valued, it is easy to show that the rate-one generalized real orthogonal design proposed in [21]  can be used in cooperative networks without any changes, while achieving the single-symbol ml decodability and full diversity order",
        "prob": 0.7366666666666666
    }, {
        "ID": 7752,
        "phrase": " we only consider immutable variables (as in the ml programming language) for simplicity",
        "prob": 0.2818181818181818
    }, {
        "ID": 7753,
        "phrase": " we only consider immutable variables (as in the ml programming language) for simplicity",
        "prob": 0.37272727272727274
    }, {
        "ID": 7870,
        "phrase": " in this case, ml decoding consists of finding the waveform with the highest z i ",
        "prob": 0.19090909090909092
    }, {
        "ID": 7889,
        "phrase": " in all the previous works  [2] -  [7] , the important aspect of ml decoding complexity at the destination was not considered",
        "prob": 0.23846153846153847
    }, {
        "ID": 7889,
        "phrase": " an initiative in this direction was first taken in  [8] , wherein dstcs with reduced ml decoding complexity were constructed for certain number of relays",
        "prob": 0.33888888888888885
    }, {
        "ID": 7889,
        "phrase": " the contributions of this paper are as follows \u2022 construction of a new family of dstcs based on co-ordinate interleaved orthogonal designs (ciod)  [10]  which have reduced ml decoding complexity compared to the existing ones  [5] ,  [8]  in the literature",
        "prob": 0.42692307692307696
    }, {
        "ID": 7889,
        "phrase": " code construction for the distributed space-time coded protocols in part-i  [1] , it was shown that the simplicity of ml decoding offered by orthogonal designs in colocated mimo systems was lost when they were used as dstcs on the relay channel",
        "prob": 0.4653846153846154
    }, {
        "ID": 7889,
        "phrase": " towards identifying dstcs with reduced ml decoding complexity, we define the class of conjugate linear row-orthogonal dstcs (clro-dstcs) as those satisfying the following two conditions: \u2022 condition 1: any column of the design should contain only the symbols or only the conjugates of the symbols",
        "prob": 0.5193548387096774
    }, {
        "ID": 7889,
        "phrase": " low ml decoding complexity clro-dstcs before proceeding to the code construction, we shall briefly overview the notion of g\u2212group ml decodable codes  [11] ",
        "prob": 0.5761904761904761
    }, {
        "ID": 7889,
        "phrase": " (3) such linear dispersion stbcs are said to be g-group ml decodable",
        "prob": 0.6454545454545455
    }, {
        "ID": 7889,
        "phrase": " \u1ef9 = \u03c9 \u2212 1 2 y = \u03c0 3 \u03c0 1 p 2 \u03c0 1 p + 1 \u03c9 \u2212 1 2 sh + \u03c9 \u2212 1 2 w thus the 4 group ml decodability requirement demands that the weight matrices of \u03c9 \u2212 1 2 s satisfy (2) for g = 4",
        "prob": 0.29285714285714287
    }, {
        "ID": 7889,
        "phrase": " it can be shown that a sufficient condition for \u03c9 \u2212 1 2 s to be 4-group ml decodable is that the weight ma- trices of \u03b3 \u2212 1 2 a 1 s ",
        "prob": 0.3153846153846154
    }, {
        "ID": 7889,
        "phrase": " hence by construction, the code c p is a rate one, full diversity, 4-group ml decodable code",
        "prob": 0.5785714285714286
    }, {
        "ID": 7889,
        "phrase": " because of the block diagonal nature of c p and due to the structure of the corresponding relay matrices, the low ml decoding complexity feature is retained even after applying the whitening filter",
        "prob": 0.5499999999999999
    }, {
        "ID": 7889,
        "phrase": " note that all the codes constructed in  [4] ,  [5] ,  [7]  are 1-group ml decodable codes",
        "prob": 0.5545454545454546
    }, {
        "ID": 7889,
        "phrase": " the codes reported in  [8]  are 2-group ml decodable clro-dstcs for even number of relays",
        "prob": 0.65
    }, {
        "ID": 7889,
        "phrase": " however, in this paper a class of 4group ml decodable dstcs have been provided for any number of relays",
        "prob": 0.5785714285714286
    }, {
        "ID": 7889,
        "phrase": " theorem 1: the toeplitz stbc when applied as a dstc in gnaf-iii protocol or jing-hassibi protocol  [2]  employing a square qam or a psk signaling scheme of cardinality k and a linear zf/mmse receiver or ml receiver at the destination provides full diversity for the system",
        "prob": 0.5968749999999999
    }, {
        "ID": 7890,
        "phrase": " moreover, since the performance of a ml receiver is invariant to permutations of the received vector, it follows that the optimal dm-g tradeoff of the gnaf-i protocol is at least as good as the naf protocol  [5] ",
        "prob": 0.2652173913043478
    }, {
        "ID": 7891,
        "phrase": " it is easily that the ml decoding of a g-group decodable code requires only g k=1 |a k | computations which in general is much smaller than |a | = g k=1 a k ",
        "prob": 0.34
    }, {
        "ID": 7967,
        "phrase": " (t : w ) in ml notation)",
        "prob": 0.18333333333333335
    }, {
        "ID": 8006,
        "phrase": " using these virtual mimo channels, each source is able to transmit ml bits in t t = t (phase 1) + t (phase 2) + t (phase 3) = 18l k \u2032 1 m 2\u2212b + cn + 18cq k \u2032 1 m 2\u2212b total channel uses where l/c \u2265 \u03ba for some \u03ba > 0 and independent of m (or n)",
        "prob": 0.8227272727272725
    }, {
        "ID": 8007,
        "phrase": " using these virtual mimo channels, each source is able to transmit ml bits in t t = t (phase 1) + t (phase 2) + t (phase 3) = 18l k \u2032 1 m 2\u2212b + cn + 18cq k \u2032 1 m 2\u2212b total channel uses where l/c \u2265 \u03ba for some \u03ba > 0 and independent of m (or n)",
        "prob": 0.7318181818181817
    }, {
        "ID": 8008,
        "phrase": " using these virtual mimo channels, each source is able to transmit ml bits in t t = t (phase 1) + t (phase 2) + t (phase 3) = 18l k 1 m 2\u2212b + 2cn + 18cq k 1 m 2\u2212b total channel uses where l/c \u2265 \u03ba for some \u03ba > 0 independent of m (or n)",
        "prob": 0.8227272727272725
    }, {
        "ID": 8009,
        "phrase": " using these virtual mimo channels, each source is able to transmit ml bits in t t = t (phase 1) + t (phase 2) + t (phase 3) = 18l k 1 m 2\u2212b + 2cn + 18cq k 1 m 2\u2212b total channel uses where l/c \u2265 \u03ba for some \u03ba > 0 independent of m (or n)",
        "prob": 0.8227272727272725
    }, {
        "ID": 8042,
        "phrase": " however, for low rate codes, p ml must be computed to evaluate p asd (see  [29]  for details)",
        "prob": 0.20666666666666667
    }, {
        "ID": 8464,
        "phrase": " the ml decoding of a stbc in k complex variables x 1 , x 2 , \u2022 \u2022 \u2022 , x k is, in general, joint decoding of all the k variables",
        "prob": 0.5461538461538462
    }, {
        "ID": 8464,
        "phrase": " however, for the alamouti code k = 2 and the variables x 1 and x 2 can be decoded independently for ml decoding",
        "prob": 0.3416666666666667
    }, {
        "ID": 8464,
        "phrase": " in general, if k = g\u03bb and the variables can be partitioned into g subsets each containing \u03bb number of variables and the ml decoding can be done for the variables of a subset independently of the variables of other subsets the code is said to be g-group ml decodable or \u03bb-symbol decodable  [9] ,  [10] ",
        "prob": 0.5807692307692307
    }, {
        "ID": 8464,
        "phrase": " the alamouti code is single-symbol decodable or two-group ml decodable",
        "prob": 0.7000000000000001
    }, {
        "ID": 8464,
        "phrase": " however, most of these code constructions did not consider the important aspect of ml decoding complexity at the destination",
        "prob": 0.5071428571428572
    }, {
        "ID": 8464,
        "phrase": " an initiative in this direction was first taken in  [11]  wherein two-group ml decodable dstcs were proposed using a construction procedure called 'doubling construction'",
        "prob": 0.4809523809523809
    }, {
        "ID": 8464,
        "phrase": " later in  [3] , a class of rate one, full diversity, four-group ml decodable dstcs called precoded ciods(coordinate interleaved orthogonal designs) were proposed for arbitrary number of relays",
        "prob": 0.6708333333333332
    }, {
        "ID": 8464,
        "phrase": " in  [10] , a class of four-group ml decodable stcs were proposed for the colocated mimo systems",
        "prob": 0.4692307692307693
    }, {
        "ID": 8464,
        "phrase": " hence it is important to address the problem of constructing a new class of four-group ml decodable dstcs which have low papr and uniform distribution of power among the relays",
        "prob": 0.39565217391304347
    }, {
        "ID": 8464,
        "phrase": " \u2022 source can transmit  1  2 complex symbols per channel use \u2022 full diversity \u2022 four group ml decodable \u2022 unitary relay matrices",
        "prob": 0.7947368421052632
    }, {
        "ID": 8464,
        "phrase": " the paper is organized as follows: we briefly describe the notion of four-group ml decodable codes and also state the dstc design constraints which are due to the protocol in section ii",
        "prob": 0.3681818181818182
    }, {
        "ID": 8464,
        "phrase": " four group ml decodable dstc design \n problem in this section, we briefly describe the two phase based cooperative diversity protocol of  [1] ,  [2]  and introduce the problem statement",
        "prob": 0.5260869565217392
    }, {
        "ID": 8464,
        "phrase": " (4) then, it can be easily shown  [9] ,  [10]  that s(x) is g-group ml decodable",
        "prob": 0.41000000000000003
    }, {
        "ID": 8464,
        "phrase": " combining all the given requirements, the 4-group ml decodable dstc design problem is thus to find space-time block codes satisfying the following three constraints",
        "prob": 0.39565217391304347
    }, {
        "ID": 8464,
        "phrase": " code construction procedure having described the problem statement, in this section we explicitly construct a new class of rate one, full diversity fourgroup ml decodable dstcs",
        "prob": 0.5954545454545455
    }, {
        "ID": 8464,
        "phrase": " (8) this ensures that the code s is two-group ml decodable, one group involving variables in a and the other group involving the variables in b",
        "prob": 0.5687500000000001
    }, {
        "ID": 8464,
        "phrase": " this fact was exploited in  [11]  to construct two-group ml decodable dstcs",
        "prob": 0.5083333333333334
    }, {
        "ID": 8464,
        "phrase": " however, note that in addition if a and b are individually two-group ml decodable, then it can be easily shown that the code s will be four-group ml decodable",
        "prob": 0.4789473684210527
    }, {
        "ID": 8464,
        "phrase": " hence we require two-group ml decodable codes whose codewords commute among themselves",
        "prob": 0.4066666666666667
    }, {
        "ID": 8464,
        "phrase": " c 1 = s 1 s 2 \u2212s 2 s 1 and c 2 = s 1 s 2 s 2 s 1 we can show that both c 1 and c 2 are two-group ml decodable codes",
        "prob": 0.51
    }, {
        "ID": 8464,
        "phrase": " s = \uf8ee \uf8ef \uf8ef \uf8f0 s 1 s 2 \u2212s * 3 \u2212s * 4 s 2 s 1 \u2212s * 4 \u2212s * 3 s 3 s 4 s * 1 s * 2 s 4 s 3 s * 2 s * 1 \uf8f9 \uf8fa \uf8fa \uf8fb (9) it can be easily verified that s is indeed 4-group ml decodable",
        "prob": 0.31
    }, {
        "ID": 8464,
        "phrase": " it is easy to check that if the design w or x is ggroup ml decodable, then the design d obtained using abba construction is also g-group ml decodable",
        "prob": 0.5611111111111111
    }, {
        "ID": 8464,
        "phrase": " the design c will be two-group ml decodable and it will also  have commuting codewords",
        "prob": 0.5545454545454546
    }, {
        "ID": 8464,
        "phrase": " thus we obtain a r \u00d7 r design which will be four-group ml decodable",
        "prob": 0.37272727272727274
    }, {
        "ID": 8464,
        "phrase": " the salient feature of the proposed dstcs is that they satisfy the extra constraints imposed by the protocols and are also four-group ml decodable which leads to significant reduction in ml decoding complexity compared to all existing dstc constructions",
        "prob": 0.48518518518518516
    }, {
        "ID": 8465,
        "phrase": " \u2022 exploiting the relaxed constraints we propose a class of four group ml decodable codes using the recently constructed clifford unitary weight single symbol decodable (cuw-ssd) codes  [19] ",
        "prob": 0.696153846153846
    }, {
        "ID": 8465,
        "phrase": " , r and if \u2206s = s i \u2212 s j has full rank for all pairs of distinct codewords s i and s j , then full diversity of order r + 1 will be achieved when a ml receiver is employed at the destination",
        "prob": 0.5941176470588235
    }, {
        "ID": 8465,
        "phrase": " low ml decoding complexity dstcs for partial csi relay channel in this subsection, we explicitly construct a class of 4-group ml decodable dstcs for the partial csi relay channel",
        "prob": 0.6439999999999999
    }, {
        "ID": 8465,
        "phrase": " the ml decoding of a dstc in k real variables x 1 , ",
        "prob": 0.5666666666666668
    }, {
        "ID": 8465,
        "phrase": " however if k = g\u03bb and if the variables can be partitioned into g subsets each containing \u03bb number of variables such that the ml decoding can be done for a subset independently of the variables of other subsets, then the code is said to be g-group ml decodable",
        "prob": 0.6130434782608696
    }, {
        "ID": 8465,
        "phrase": " we need to premultiply y by \u03c9 \u2212 1 2 in order to make the covariance matrix of w to be identity matrix (this process is called whitening) during the process of ml decoding",
        "prob": 0.33888888888888885
    }, {
        "ID": 8465,
        "phrase": " this may in general disturb the low ml decodability property of dstcs",
        "prob": 0.42500000000000004
    }, {
        "ID": 8465,
        "phrase": " because of the block diagonal structure of this code, 4-group ml decodability is retained even after the process of whitening",
        "prob": 0.4733333333333334
    }, {
        "ID": 8465,
        "phrase": " for other even number of relays, we can put a combination of pciod and the 4\u00d74 code in the above example on the blocks along the diagonal and precode appropriately to get full diversity and still retaining 4-group ml decodability",
        "prob": 0.364
    }, {
        "ID": 8465,
        "phrase": " exploiting the relaxed code design constraints, we propose dstcs obtained from clifford algebras which have low ml decoding complexity",
        "prob": 0.5611111111111111
    }, {
        "ID": 8477,
        "phrase": "s)] and we use the ml notation fn x \u21d2 ",
        "prob": 0.1375
    }, {
        "ID": 8556,
        "phrase": " , l\u22121, and that of the ml decoder at round l, using the union bhattacharyya bound  [40]  on a random coded modulation scheme over q concatenated with linear dispersion space-time modulation",
        "prob": 0.4333333333333334
    }, {
        "ID": 8556,
        "phrase": " we may, however, choose a modulator that spreads symbols over m blocks where m < b in order to reduce the complexity of the ml decoder",
        "prob": 0.19375
    }, {
        "ID": 8556,
        "phrase": " in particular, \u03b2 should be chosen such that bt n r \u03b2 \u2265 d \u22c6 (r 1 ) in order to achieve the optimal ml exponent d \u22c6 (r 1 )",
        "prob": 0.17500000000000002
    }, {
        "ID": 8561,
        "phrase": " in this paper, we construct that a new class of space-time codes that are inspired from the codes in  [14]  that have a useful property that the ml decoding is controllable and have maximum rate of one",
        "prob": 0.405
    }, {
        "ID": 8561,
        "phrase": " on one extreme, one can design codes that have single symbol ml decoding and on the other, the ml decoding requires decoding of m/2 symbols together, where m are the number of transmit antennas",
        "prob": 0.8049999999999998
    }, {
        "ID": 8561,
        "phrase": " it is, however, shown for the constructed codes that for rate one codes with single symbol ml decoding, full-diversity is impossible and for codes that require more than one symbols to be decoded together for ml symbols decoding, it is indeed possible to have full-diversity",
        "prob": 0.7620689655172412
    }, {
        "ID": 8561,
        "phrase": " designing codes with higher ml decoding complexity can be done to achieve higher coding gain",
        "prob": 0.6066666666666667
    }, {
        "ID": 8561,
        "phrase": " the main difference between these codes and those in  [14]  is the choice of r that will allow us to vary the ml decoding complexity and construct full-diversity codes with decoding of a pair of symbols",
        "prob": 0.5761904761904761
    }, {
        "ID": 8561,
        "phrase": " receiver processing we give a practical decoding algorithm to have a low complexity ml decoding done over a single partition",
        "prob": 0.5352941176470588
    }, {
        "ID": 8561,
        "phrase": " this property is quite useful in constructing codes with controllable ml decoding complexity",
        "prob": 0.3153846153846154
    }, {
        "ID": 8561,
        "phrase": " (  17 ) that it is w m,i that dictates the ml decoding complexity",
        "prob": 0.3875
    }, {
        "ID": 8561,
        "phrase": " (  17 ), this code will admit single symbol ml decoding",
        "prob": 0.41000000000000003
    }, {
        "ID": 8561,
        "phrase": " by using this block diagonal structure, we can construct codes with ml decoding of different symbols together and hence the ml decoding complexity can be controlled",
        "prob": 0.655
    }, {
        "ID": 8561,
        "phrase": " it is shown that it is impossible to attain full-diversity with single symbol ml decoding but it can indeed be attained if allow more than one symbols to interfere with each other with constellation rotation (ml decoding of symbols in pairs for example)",
        "prob": 0.6039999999999999
    }, {
        "ID": 8561,
        "phrase": " conclusions we have constructed a class of linear space-time codes that have controllable ml decoding complexity for any number of transmit antennas",
        "prob": 0.7277777777777777
    }, {
        "ID": 8561,
        "phrase": " for the codes with single symbol ml decoding, it is impossible to have full-diversity",
        "prob": 0.5916666666666667
    }, {
        "ID": 8561,
        "phrase": " for codes with ml decoding involving more than one symbol, one can construct codes that offer full-diversity by using constellation rotation for example",
        "prob": 0.6166666666666667
    }, {
        "ID": 8561,
        "phrase": " one can thus construct codes that offer full-diversity whose ml decoding involve the decoding of symbols in pairs",
        "prob": 0.5352941176470588
    }, {
        "ID": 8561,
        "phrase": " f ( 48 ) 48 since the elements of c and e are drawn from the same constellation, hencemin c,e det {g m [a m,1 (w m,1 (c \u2212 e))]} = 0(49)hence one cannot achieve full-diversity with single symbol ml decoding",
        "prob": 0.5941176470588235
    }, {
        "ID": 8561,
        "phrase": "we construct a class of linear space-time block codes for any number of transmit antennas that have controllable ml decoding complexity with a maximum rate of 1 symbol per channel use",
        "prob": 0.7869565217391302
    }, {
        "ID": 8561,
        "phrase": " the decoding complexity for m transmit antennas can be varied from ml decoding of m/2 symbols together to single symbol ml decoding",
        "prob": 0.7705882352941176
    }, {
        "ID": 8561,
        "phrase": " a significant result is obtained that one can construct rate-1, full-diversity space-time codes whose ml decoding involves decoding symbols in pairs for any number of transmit antennas",
        "prob": 0.5875
    }, {
        "ID": 8562,
        "phrase": " while orthogonal designs offer full diversity with single symbol ml decoding, they don't have rate 1 for more than 2 transmit antennas",
        "prob": 0.5941176470588235
    }, {
        "ID": 8562,
        "phrase": " in this paper, we construct that a new class of spacetime codes with a maximum code rate of 1, that are inspired from the codes in  [12] , that have a useful property that the ml decoding is controllable",
        "prob": 0.30500000000000005
    }, {
        "ID": 8562,
        "phrase": " on one extreme, one can design rate 1 codes that have single symbol ml decoding offering diversity of 2, and on the other, one can have codes offering full diversity with ml decoding of m/2 symbols together",
        "prob": 0.8227272727272725
    }, {
        "ID": 8562,
        "phrase": " it is, however, shown for the constructed codes that for rate one codes with single symbol ml decoding, full-diversity is impossible and for codes that require more than one symbols to be decoded together for ml symbols decoding, it is indeed possible to have full-diversity",
        "prob": 0.7965517241379308
    }, {
        "ID": 8562,
        "phrase": " iterative construction of space-time codes the main difference between these codes and those in  [12]  is the choice of r that will allow us to vary the ml decoding complexity and construct full-diversity codes with decoding of a pair of symbols",
        "prob": 0.5423076923076923
    }, {
        "ID": 8562,
        "phrase": " receiver processing we give a practical decoding algorithm to have a low complexity ml decoding done over a single partition",
        "prob": 0.5352941176470588
    }, {
        "ID": 8562,
        "phrase": " this property is quite useful in constructing codes with controllable ml decoding complexity",
        "prob": 0.39230769230769236
    }, {
        "ID": 8562,
        "phrase": " we note here from (17) that it is w m,i that dictates the ml decoding complexity",
        "prob": 0.4555555555555556
    }, {
        "ID": 8562,
        "phrase": " for example, we could precode the information-carrying symbol vector c in  (1)   such that v m,i (c) = w m,i v m,i (s) (45) according to (17), this code will admit single symbol ml decoding",
        "prob": 0.5055555555555555
    }, {
        "ID": 8562,
        "phrase": " in general, ml decoding of m/2 n , n = 1, 2, \u2022 \u2022 \u2022 , log 2 m , symbols together would mean having the precoding matrix as a block diagonal matrix with each block as w m/2 n\u22121 ,1 (scaled appropriately) with constellation rotation to ensure that the rank of g m [a m,1 (c \u2212 e)] is m/2 n\u22121 ",
        "prob": 0.5458333333333333
    }, {
        "ID": 8562,
        "phrase": " by using this block diagonal structure, we can construct codes with ml decoding of different symbols together and hence the ml decoding complexity can be controlled",
        "prob": 0.705
    }, {
        "ID": 8562,
        "phrase": " the code design for such m is done by consturcting a code for 2 \u2308log 2 m\u2309 transmit antennas that admits ml decoding complexity of 2 \u2308log 2 m\u2309\u2212n (n = 1, 2, \u2022 \u2022 \u2022) and has rank of each partition as 2 \u2308log 2 m\u2309\u2212n+1 and then deleting columns suitably chosen to retain the same rank and to have the code matrix of the size 2 \u2308log 2 m\u2309 \u00d7 m ",
        "prob": 0.471875
    }, {
        "ID": 8562,
        "phrase": " conclusions we have constructed a class of linear space-time codes that have controllable ml decoding complexity for any number of transmit antennas",
        "prob": 0.7277777777777777
    }, {
        "ID": 8562,
        "phrase": "we construct a class of linear space-time block codes for any number of transmit antennas that have controllable ml decoding complexity with a maximum rate of 1 symbol per channel use",
        "prob": 0.7869565217391302
    }, {
        "ID": 8562,
        "phrase": " the decoding complexity for m transmit antennas can be varied from ml decoding of 2 \u2308log 2 m \u2309\u22121 symbols together to single symbol ml decoding",
        "prob": 0.7277777777777777
    }, {
        "ID": 8562,
        "phrase": " for ml decoding of 2 \u2308log 2 m \u2309\u2212n (n = 1, 2, \u2022 \u2022 \u2022) symbols together, a diversity of min(m, 2 \u2308log 2 m \u2309\u2212n+1 ) can be achieved",
        "prob": 0.39230769230769236
    }, {
        "ID": 8658,
        "phrase": " ; cn where for all i, ai \u2264 ci \u2264 bi",
        "prob": 0.22000000000000003
    }, {
        "ID": 8675,
        "phrase": " but the ml decoding complexity of stbcs become prohibitively large for large number of transmit and receive antennas",
        "prob": 0.5062500000000001
    }, {
        "ID": 8675,
        "phrase": " in  [2, 3, 4] , orthogonal designs, single and double symbol ml decodable stbcs have been proposed to solve this problem",
        "prob": 0.6066666666666667
    }, {
        "ID": 8675,
        "phrase": " \u2022 by restricting to cyclic division algebras, we obtain stbcs which are simultaneously mmse optimal as well as fully diverse for ml reception",
        "prob": 0.5611111111111111
    }, {
        "ID": 8675,
        "phrase": " finally, we discuss the decoding procedure for the codes in this paper and also highlight its simplicity as compared to ml decoding",
        "prob": 0.4066666666666667
    }, {
        "ID": 8675,
        "phrase": " fully diverse when a ml receiver is employed since they arise from matrix representation of division algebras  [13] ",
        "prob": 0.54
    }, {
        "ID": 8675,
        "phrase": " note that the decoding complexity is linear in the size of the signal set as compared to exponential in the case of ml reception",
        "prob": 0.31875
    }, {
        "ID": 8675,
        "phrase": " however the ml decoding complexity of stbcs become prohibitive large as the number of transmit and receive antennas increase",
        "prob": 0.5941176470588235
    }, {
        "ID": 8675,
        "phrase": " to solve this problem, orthogonal designs, single symbol ml decodable and double symbol ml decodable stbcs have been proposed in the literature",
        "prob": 0.6368421052631579
    }, {
        "ID": 8675,
        "phrase": " hence these stbcs achieve least ser when mmse reception is employed and are fully diverse when ml reception is employed",
        "prob": 0.711764705882353
    }, {
        "ID": 8676,
        "phrase": " in  [1] ,  [2] ,  [3] , orthogonal designs, single and double symbol ml decodable stbcs have been proposed to solve this problem",
        "prob": 0.6733333333333333
    }, {
        "ID": 8676,
        "phrase": " \u2022 by restricting to a certain class of cyclic division algebras  [13] , stbcs which are simultaneously mmse optimal as well as fully diverse for ml reception are identified",
        "prob": 0.5549999999999999
    }, {
        "ID": 8676,
        "phrase": " finally, the decoding procedure for the codes in this paper is discussed and its simplicity as compared to ml decoding is highlighted",
        "prob": 0.4066666666666667
    }, {
        "ID": 8676,
        "phrase": " a concrete example of such a code is the best known 2 transmit antenna stbc for ml reception, i",
        "prob": 0.5071428571428572
    }, {
        "ID": 8676,
        "phrase": " decoding procedure in this subsection, the decoding procedure for the codes in this paper is briefly explained and its receiver simplicity compared to ml reception is highlighted",
        "prob": 0.4789473684210527
    }, {
        "ID": 8676,
        "phrase": " on the other hand, it is well known that under ml decoding a diversity order of mn is possible if the stbc is fully diverse",
        "prob": 0.31875
    }, {
        "ID": 8676,
        "phrase": " however, the ml decoding complexity of stbcs becomes prohibitive large as the number of transmit and receive antennas increase",
        "prob": 0.5941176470588235
    }, {
        "ID": 8676,
        "phrase": " hence, these stbcs achieve least ser when mmse reception is employed and are fully diverse when ml reception is employed",
        "prob": 0.711764705882353
    }, {
        "ID": 8766,
        "phrase": ", y + z = ai for some number a",
        "prob": 0.22000000000000003
    }, {
        "ID": 8837,
        "phrase": " since we used the channel ml times to communicate (w s 1 ) m , we see that we can keep the total number of channel uses, n, smaller than mn(1 + \u03b7 8 ) for arbitrarily small \u03b7 8 by making n sufficiently large",
        "prob": 0.2652173913043478
    }, {
        "ID": 8907,
        "phrase": " since the publication of  [1] , the computational complexity of ml decoding of general linear codes has been extensively studied",
        "prob": 0.34
    }, {
        "ID": 8907,
        "phrase": " since each step of the new ml certificate algorithm is of order o(n 2 ), the total complexity is of order o(n 2 )",
        "prob": 0.2928571428571429
    }, {
        "ID": 9197,
        "phrase": "p-stc pragmatic space-time codes bfc block fading channels cc convolutional codes pep pairwise error probability qpsk quaternary phase shift keying m-qam m-ary quadrature amplitude modulation gtf generalized transfer function st-gtf space-time generalized transfer function fer frame error rate ml maximum likelihood mimomultiple input multiple output rbfc reference block fading channel",
        "prob": 0.3701754385964912
    }, {
        "ID": 9315,
        "phrase": " when designing a data entry system one might be tempted to implement just adaptive menus given their algorithmic simplicity, especially compared to sophisticated methods in machine learning that have been proposed for predictive fillin",
        "prob": 0.204
    }, {
        "ID": 9672,
        "phrase": "\" unfortunately, these methods require time polynomial in the number of states in the state space, which makes them prohibitively expensive for most ai problems",
        "prob": 0.24117647058823527
    }]
}, {
    "topic_id": 13,
    "top_words": ["learning", "machine", "results", "used", "models", "data", "experimental", "literature", "using", "classi", "work", "experiments", "algorithms", "cation", "algorithm"],
    "phrases": [{
        "ID": 6,
        "phrase": " we validate the framework by comparing its predictions with our own experimental results and with experimental results gathered from the ai literature",
        "prob": 0.7214285714285715
    }, {
        "ID": 6,
        "phrase": " different machine learning algorithms will achieve this match with different degrees of success",
        "prob": 0.6230769230769231
    }, {
        "ID": 6,
        "phrase": " we validate the framework with experimental results using reinforcement learning agents in a market system, as well as with other experimental results gathered from the ai literature",
        "prob": 0.6894736842105263
    }, {
        "ID": 7,
        "phrase": " we validate the framework by comparing its predictions with our own experimental results and with experimental results gathered from the ai literature",
        "prob": 0.7214285714285715
    }, {
        "ID": 7,
        "phrase": " different machine learning algorithms will achieve this match with different degrees of success",
        "prob": 0.6230769230769231
    }, {
        "ID": 7,
        "phrase": " we validate the framework with experimental results using reinforcement learning agents in a market system, as well as with other experimental results gathered from the ai literature",
        "prob": 0.6368421052631579
    }, {
        "ID": 8,
        "phrase": " we validate the framework by comparing its predictions with our own experimental results and with experimental results gathered from the ai literature",
        "prob": 0.7214285714285715
    }, {
        "ID": 8,
        "phrase": " different machine learning algorithms will achieve this match with different degrees of success",
        "prob": 0.5461538461538462
    }, {
        "ID": 8,
        "phrase": " we validate the framework with experimental results using reinforcement learning agents in a market system, as well as with other experimental results gathered from the ai literature",
        "prob": 0.6894736842105263
    }, {
        "ID": 132,
        "phrase": " typical examples are: programs for machine learning that construct a model of the knowledge using decision trees and production rules (see, e",
        "prob": 0.2833333333333333
    }, {
        "ID": 145,
        "phrase": " in a series of conferences held at purdue  [40, 41, 42] , the use of ai approaches for such tasks as algorithm selection, automatic programming, and process management were explored",
        "prob": 0.3944444444444445
    }, {
        "ID": 164,
        "phrase": " the line data was studied again by  (mooney, 1996) , where seven different machine learning methodologies are compared",
        "prob": 0.29285714285714287
    }, {
        "ID": 209,
        "phrase": " to the best of our knowledge, however, only one attempt has ever been made to apply a machine learning algorithm to anti-spam filtering  (sahami et al",
        "prob": 0.5611111111111111
    }, {
        "ID": 219,
        "phrase": " we also touch briefly on alternative machine learning models for prosodic features",
        "prob": 0.42500000000000004
    }, {
        "ID": 220,
        "phrase": " we also touch briefly on alternative machine learning models for prosodic features",
        "prob": 0.5083333333333334
    }, {
        "ID": 237,
        "phrase": " that is, we created parallel prosodic databases for both corpora, and used the same machine learning approach for prosodic modeling in all cases",
        "prob": 0.31875000000000003
    }, {
        "ID": 310,
        "phrase": " we will apply seven machine learning algorithms to the same basenp task",
        "prob": 0.6454545454545455
    }, {
        "ID": 310,
        "phrase": " after this we will describe the data representations we used and the machine learning algorithms that we will apply to the task",
        "prob": 0.5461538461538462
    }, {
        "ID": 310,
        "phrase": " \n machine learning algorithms this section contains a brief description of the seven machine learning algorithms that we will apply to the basenp identification task: al-lis, c5",
        "prob": 0.480952380952381
    }, {
        "ID": 310,
        "phrase": " \n concluding remarks in this paper we have examined two methods for combining the results of machine learning algorithms for identifying base noun phrases",
        "prob": 0.4263157894736842
    }, {
        "ID": 310,
        "phrase": "we use seven machine learning algorithms for one task: identifying base noun phrases",
        "prob": 0.65
    }, {
        "ID": 317,
        "phrase": "'s experiments constitute the only previous attempt to apply machine learning to antispam filtering",
        "prob": 0.7000000000000001
    }, {
        "ID": 317,
        "phrase": " we plan to implement alternative anti-spam filters, based on other machine learning algorithms, and evaluate them on publicly available benchmark corpora",
        "prob": 0.42631578947368426
    }, {
        "ID": 343,
        "phrase": "to appear in machine learning journal \n introduction traditionally, classification systems have been built by experimenting with many different classifiers, comparing their performance and choosing the best",
        "prob": 0.33809523809523806
    }, {
        "ID": 343,
        "phrase": " more general comparisons can be made with receiver operating characteristic (roc) analysis, a classic methodology from signal detection theory that is common in medical diagnosis and has recently begun to be used more generally in ai classifier work  (beck & schultz, 1986; egan, 1975; swets, 1988; friedman & wyatt, 1997) ",
        "prob": 0.190625
    }, {
        "ID": 343,
        "phrase": " multi-criteria optimization was used previously in machine learning by tcheng, lambert, lu and rendell  (tcheng et al",
        "prob": 0.38125000000000003
    }, {
        "ID": 345,
        "phrase": " we address the issue of anti-spam filtering with the aid of machine learning",
        "prob": 0.42500000000000004
    }, {
        "ID": 345,
        "phrase": " to our knowledge, this is the only previous attempt to apply machine learning to anti-spam filtering",
        "prob": 0.7000000000000001
    }, {
        "ID": 345,
        "phrase": "we investigate the performance of two machine learning algorithms in the context of antispam filtering",
        "prob": 0.5461538461538462
    }, {
        "ID": 360,
        "phrase": " in this direction, this work compares five different ml algorithms and explores their portability and tuning ability by training and testing them on different corpora",
        "prob": 0.4789473684210526
    }, {
        "ID": 425,
        "phrase": ") there has also been work in the ai literature on causality",
        "prob": 0.3
    }, {
        "ID": 461,
        "phrase": " \n related work our work is closely related to efforts in the propositional learning field to increase the capability of machine learning systems to handle large databases",
        "prob": 0.4333333333333333
    }, {
        "ID": 660,
        "phrase": " it has been amply demonstrated that a wide assortment of machine learning algorithms are quite effective at extracting linguistic information from manually annotated corpora",
        "prob": 0.3210526315789474
    }, {
        "ID": 660,
        "phrase": " much previous work has been done on this problem and many different methods have been used:  church's parts (1988)  program uses a markov model;  bourigault (1992)  uses heuristics along with a grammar;  voutilainen's nptool (1993)  uses a lexicon combined with a constraint grammar;  juteson and katz (1995)    \n learning base noun phrases by machine we used the base noun phrase system of ramshaw and marcus (r&m) as the machine learning system with which to compare the hu-man learners",
        "prob": 0.3226415094339622
    }, {
        "ID": 660,
        "phrase": " it is difficult to compare different machine learning approaches to base np annotation, since different definitions of base np are used in many of the papers, but the r&m system is the best of those that have been tested on the penn treebank",
        "prob": 0.262962962962963
    }, {
        "ID": 660,
        "phrase": " this challenges the claim that machine learning offers portability advantages over manual rule writing, seeing that relatively unmotivated people can near-match the best machine performance on this task in so little time at a labor cost of approximately us$40",
        "prob": 0.4033333333333333
    }, {
        "ID": 661,
        "phrase": " although learning curves showing performance relative to amount of training data are common in the machine learning literature, these are inadequate for comparing systems with different sources of training data or supervision",
        "prob": 0.6439999999999999
    }, {
        "ID": 661,
        "phrase": " \n learning by rules in previous work,  brill & ngai (1999)  showed that under certain circumstances, it is possible for humans writing rules to perform as well as a stateof-the-art machine learning system for base noun phrase chunking",
        "prob": 0.24482758620689657
    }, {
        "ID": 661,
        "phrase": "  \n cost models for cross-modal learning comparison traditionally, evaluation models in the machine learning literature measure performance relative to variable quantities of training data",
        "prob": 0.743478260869565
    }, {
        "ID": 661,
        "phrase": " several novel variations on active learning are investigated, and underlying cost models for cross-modal machine learning comparison are presented and explored",
        "prob": 0.30500000000000005
    }, {
        "ID": 698,
        "phrase": " an early study by  litman and passonneau (1995)  used hand-labeled prosodic boundaries and lexical information, but applied machine learning to a training corpus and tested on unseen data",
        "prob": 0.3521739130434783
    }, {
        "ID": 740,
        "phrase": "  1  the success of machine learning techniques in text categorization  (sebastiani, 2001)  has recently led to alternative, learning-based approaches  (sahami, et al",
        "prob": 0.2277777777777778
    }, {
        "ID": 817,
        "phrase": " such a thinking component can be realized in many ways, by using one of the numerous approaches that have been developed in the agent and ai literature",
        "prob": 0.20666666666666667
    }, {
        "ID": 869,
        "phrase": " during testing, a machine learning algorithm is used to compare the features extracted from the training data to the actual features in the occurrence to be disambiguated",
        "prob": 0.6166666666666667
    }, {
        "ID": 1018,
        "phrase": "introduction cross-validation is a generally applicable and very useful technique for many tasks often encountered in machine learning, such as accuracy estimation, feature selection or parameter tuning",
        "prob": 0.4826086956521739
    }, {
        "ID": 1034,
        "phrase": " measures alternative to \u03c0 and \u03c1 and commonly used in the ml literature, such as accuracy (estimated as \u00e2 = t p +t n t p +t n +f p +f n ) and error (estimated as \u00ea = f p +f n t p +t n +f p +f n = 1 \u2212 \u00e2), are not widely used in tc",
        "prob": 0.24117647058823527
    }, {
        "ID": 1158,
        "phrase": " \n planning under incomplete knowledge planning under incomplete knowledge has been widely investigated in the ai literature",
        "prob": 0.16153846153846155
    }, {
        "ID": 1209,
        "phrase": " 2 to the best of our knowledge, the ai literature while describing dynamic processes closely related to the ones we study here do not prove convergence results of this type",
        "prob": 0.33888888888888885
    }, {
        "ID": 1282,
        "phrase": " such agent systems were all grounded in the real world, using proven ai techniques to achieve concrete results (applying the maxim \"a little ai goes a long way\")",
        "prob": 0.14761904761904762
    }, {
        "ID": 1282,
        "phrase": " the analysis in this paper will focus on classifying the agent, identifying techniques used such as specific machine learning techniques or user modelling types, and where applicable results published by the original author",
        "prob": 0.21250000000000002
    }, {
        "ID": 1466,
        "phrase": " the most common representations use matrices or graphs to represent connections among individuals as well as several models from the ir, database, and machine learning fields for more complex types of information",
        "prob": 0.25416666666666665
    }, {
        "ID": 1483,
        "phrase": " but we stress that the machine learning methods and features we use are not specific to movie reviews, and should be easily applicable to other domains as long as sufficient training data exists",
        "prob": 0.4809523809523809
    }, {
        "ID": 1483,
        "phrase": " to implement these machine learning algorithms on our document data, we used the following standard bag-of-features framework",
        "prob": 0.41764705882352937
    }, {
        "ID": 1483,
        "phrase": "com/reviews/ \n\t\t\t later experiments using these words as features for machine learning methods did not yield better results",
        "prob": 0.31875000000000003
    }, {
        "ID": 1483,
        "phrase": " using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines",
        "prob": 0.39444444444444443
    }, {
        "ID": 1688,
        "phrase": " although, we do not claim that all of ai literature has been searched",
        "prob": 0.2625
    }, {
        "ID": 1803,
        "phrase": " \n dataset \n roc analysis although accuracy estimation values such as those in table  1  are very widely used in the machine learning community for comparison of classifiers, provost et al",
        "prob": 0.255
    }, {
        "ID": 1805,
        "phrase": " these experiments are relevant, as they compare the systems in the important domain of ai planning on benchmark instances which are really \u2022 49 used to compare planning systems",
        "prob": 0.2833333333333333
    }, {
        "ID": 1869,
        "phrase": " neither of these commercial algorithms use machine learning techniques, so the experiments lend some support to the claim that machine learning is a valuable approach to automatic keyphrase extraction",
        "prob": 0.3681818181818182
    }, {
        "ID": 1877,
        "phrase": " given a set of phrases with a shared single-word stem (for example, the set of phrases {\"learning\", \"machine learning\", \"learnability\"} shares the single-word stem \"learn\"), genex tends to choose the best member of the set, rather than choosing the whole set",
        "prob": 0.396969696969697
    }, {
        "ID": 1881,
        "phrase": " though in the field of machine learning, much work is done on small controlled data sets, which clearly facilitate the empirical evaluation of different learning algorithms, in the context of the purpose of this thesis, i feel this would be misguided",
        "prob": 0.325
    }, {
        "ID": 1881,
        "phrase": " in particular if we have a large set of models, which include an infinite sequence of models with increasing complexity, the ml estimate will often select the model that exactly memorises the data",
        "prob": 0.18636363636363634
    }, {
        "ID": 1881,
        "phrase": " there are a number of alternative machine learning techniques that might be applicable here",
        "prob": 0.19090909090909092
    }, {
        "ID": 1891,
        "phrase": " the majority of the machine learning literature ignores all types of cost (unless accuracy is interpreted as a type of cost measure)",
        "prob": 0.41764705882352937
    }, {
        "ID": 1894,
        "phrase": " we then show how the work of several machine learning researchers fits into this framework",
        "prob": 0.25833333333333336
    }, {
        "ID": 1896,
        "phrase": " bernhard pfahringer of the austrian research institute for artificial intelligence used a clever exhaustive search algorithm to win the first and third competitions",
        "prob": 0.205
    }, {
        "ID": 2100,
        "phrase": " and so, the effect of chomsky's claim, together with some negative results for machine learning and a general lack of computing power at the time, was to cause researchers to turn away from empirical approaches and toward knowledge-based approaches where human experts encoded relevant information in computer-usable form",
        "prob": 0.20285714285714285
    }, {
        "ID": 2288,
        "phrase": " they have used the data for developing a named-entity recognition system that includes a machine learning component",
        "prob": 0.2733333333333333
    }, {
        "ID": 2301,
        "phrase": " we discuss our methodology and how it was instantiated using two different machine learning algorithms",
        "prob": 0.4692307692307693
    }, {
        "ID": 2333,
        "phrase": " unfortunately v * \u03be cannot be used directly since this measure is itself only semi-computable and the approximation quality by using computable versions of \u03be ai given a time of order c\u2022 t is crude  [lv97] ",
        "prob": 0.24285714285714283
    }, {
        "ID": 2333,
        "phrase": " \n supervised learning from examples (ex) the developed ai models provide a frame for reinforcement learning",
        "prob": 0.29285714285714287
    }, {
        "ID": 2333,
        "phrase": " to be more specific, in the following i suggest a framework for machine learning research",
        "prob": 0.1909090909090909
    }, {
        "ID": 2333,
        "phrase": " real-world machine learning tasks will with overwhelming majority be solved by developing algorithms which approximate kolmogorov complexity / solomonoff's prior (e",
        "prob": 0.3736842105263158
    }, {
        "ID": 2480,
        "phrase": " as such, it might appear unrelated to the performance measures otherwise used in machine learning",
        "prob": 0.23846153846153847
    }, {
        "ID": 2521,
        "phrase": " the goal of machine learning research is the development of algorithms that increase the ability of an agent to match a set of inputs to their corresponding outputs  [7] ",
        "prob": 0.2833333333333333
    }, {
        "ID": 2760,
        "phrase": "  [7, 14, 18, 33] ) and multiplicative updates have become widespread in machine learning algorithms",
        "prob": 0.2818181818181818
    }, {
        "ID": 3095,
        "phrase": " many data mining and machine learning researchers have worked on spam detection and filtering, commonly treating it as a basic text classification problem",
        "prob": 0.25500000000000006
    }, {
        "ID": 3193,
        "phrase": " for industrial problems, for which we have hundreds of sample, we can afford to use separate sets for training and evaluation, but the results confirm that the differences between a proper machine learning setting (different sets) and a \"data mining\" setting (same set) are not significant",
        "prob": 0.3964285714285714
    }, {
        "ID": 3305,
        "phrase": " a well-known principle of machine learning is that, everything else being equal, models with fewer parameters are more likely to make accurate predictions on previously unseen data",
        "prob": 0.2318181818181818
    }, {
        "ID": 3306,
        "phrase": " a well-known principle of machine learning is that, everything else being equal, models with fewer parameters are more likely to make accurate predictions on previously unseen data",
        "prob": 0.2772727272727273
    }, {
        "ID": 3443,
        "phrase": " naive bayes was a reasonable choice to quickly bootstrap the jndm into existence and is a good benchmark to beat, but there are, of course, many other machine learning techniques that could (and probably should) be used instead",
        "prob": 0.21250000000000002
    }, {
        "ID": 3443,
        "phrase": " in an attempt for even further automation, a machine learning algorithm called the privileged reviewer will also be introduced",
        "prob": 0.2928571428571428
    }, {
        "ID": 3600,
        "phrase": " we tested this idea by developing a machine learning system that can perform engagement detection in everyday dialogue and achieved reasonably good results",
        "prob": 0.37368421052631584
    }, {
        "ID": 4115,
        "phrase": " under the heading \"related work\" in section 2 we list a substantial amount of literature in which the regret for the prequential ml code is proven to grow with 1 2 ln n",
        "prob": 0.3210526315789474
    }, {
        "ID": 4552,
        "phrase": " but it is very difficult when users use ml classifiers because understanding their compiled knowledge is very difficult and their knowledge is so strongly coupled with the knowledge of training data sets that it is not easily changed without deliberate changing them",
        "prob": 0.20400000000000001
    }, {
        "ID": 4552,
        "phrase": " there has also been work done in the area of combining machine learning techniques with rdr to reduce the amount of knowledge acquisition needed from an expert  [3] ",
        "prob": 0.33888888888888885
    }, {
        "ID": 4693,
        "phrase": " therefore, as we are able to process this kind of data together efficiently using machine learning algorithms, we can be sure to obtain better results than any of the three sources alone",
        "prob": 0.3227272727272727
    }, {
        "ID": 4783,
        "phrase": " , s m , we use a total of at most n i=1 # ai (s) log m # ai (s) + 1 < (h 0 (s) + 2)m comparisons",
        "prob": 0.26249999999999996
    }, {
        "ID": 4826,
        "phrase": "introduction for data compression, machine learning and cryptanalysis, we often want to know the kolmogorov complexity k(s)  [21, 12, 4]  of a string s, that is, the minimum space needed to store s",
        "prob": 0.355
    }, {
        "ID": 4827,
        "phrase": "introduction for data compression, machine learning and cryptanalysis, we often want to know the kolmogorov complexity k(s)  [23, 13, 4, 15]  of a string s, that is, the minimum space needed to store s",
        "prob": 0.305
    }, {
        "ID": 5196,
        "phrase": " we must be careful not to sacrifice one for the other, which might happen in practice, since mv and ml can often be anti-correlated depending upon hardware choice and detection strategy",
        "prob": 0.2318181818181818
    }, {
        "ID": 5327,
        "phrase": " to address this problem of portability, a recent research effort focused on using machine learning throughout the ie process  (muslea, 1999) ",
        "prob": 0.17222222222222222
    }, {
        "ID": 5520,
        "phrase": " this is the case in particular for learning tasks which traditionally fall into the realm of symbolic artificial intelligence, and which are characterized by complex and often recursive interdependencies between symbolically represented pieces of knowledge",
        "prob": 0.22173913043478263
    }, {
        "ID": 5568,
        "phrase": " as a third point of ai relevance, from spg probabilistic domain models it is possible to derive algorithms for simulation (as in section 3",
        "prob": 0.19375
    }, {
        "ID": 5714,
        "phrase": " at about the same time as forrest was undertaking her work, researchers in the uk started to investigate the nature of learning in the immune system and how that might by used to create machine learning algorithms  [24] ",
        "prob": 0.41363636363636364
    }, {
        "ID": 5845,
        "phrase": " in the ml community, it is recognized that such methodology is flawed, given that the learning algorithm can overfit the data used during the training and perform poorly on unseen data of the same application domain  [2, 3] ",
        "prob": 0.41363636363636364
    }, {
        "ID": 5845,
        "phrase": " even though this methodology has been widely accepted and applied in the ml and pr communities for a long time, the ec community still lags behind by publishing papers that are reporting results on data sets that were used during the evolution (training) phase",
        "prob": 0.26999999999999996
    }, {
        "ID": 5854,
        "phrase": " animal intelligence experiments suggest that one can speak of different styles of solving ai problems",
        "prob": 0.23846153846153845
    }, {
        "ID": 5894,
        "phrase": " nonparametric methods studied within machine learning have demonstrated widespread empirical success in many centralized (i",
        "prob": 0.31875000000000003
    }, {
        "ID": 6190,
        "phrase": " using the canonical embedding of the set {0, 1} into r and of the set c into r n , ml decoding can then be cast as x arg min x\u2208c x, \u03bb ",
        "prob": 0.22142857142857145
    }, {
        "ID": 6308,
        "phrase": " the occurrence of \u0101 implies event b, which means that the ml estimates in this case will remain in the original ordering, i",
        "prob": 0.22142857142857145
    }, {
        "ID": 6340,
        "phrase": " to our knowledge, the class of ml approaching algorithms is quite limited",
        "prob": 0.2818181818181818
    }, {
        "ID": 6408,
        "phrase": " in table  2    \n validation to validate our results, we employ the standard machine learning methodology called cross-validation",
        "prob": 0.5062500000000001
    }, {
        "ID": 6572,
        "phrase": " naturally, machine learning has (re)discovered and exploited quite different principles for choosing priors, appropriate for this situation",
        "prob": 0.31875000000000003
    }, {
        "ID": 6590,
        "phrase": " however, while these tests work well for humans, if we wish to measure the intelligence of other things, perhaps of a monkey or a new machine learning algorithm, they are clearly inappropriate",
        "prob": 0.24285714285714288
    }, {
        "ID": 6692,
        "phrase": " \n related work except for pednault who mixed linear and quadratic segments  [36] , we know of no other attempt to segment time series using polynomials of variable degrees in the data mining and knowledge discovery literature though there is related work in the spline and statistical literature  [18, 31, 33]  and machine learning literature  [2, 4, 7] ",
        "prob": 0.8599999999999999
    }, {
        "ID": 6694,
        "phrase": " except for pednault who mixed linear and quadratic segments  [14] , we know of no other attempt to segment time series using polynomials of variable degrees in the data mining and knowledge discovery literature though there is related work in the spline and statistical literature  [15, 16, 17]  and machine learning literature  [18, 19, 20] ",
        "prob": 0.8515151515151513
    }, {
        "ID": 6695,
        "phrase": " terzi and tsaparas  [42]  achieved a except for pednault who mixed linear and quadratic segments  [40] , we know of no other attempt to segment time series using polynomials of variable degrees in the data mining and knowledge discovery literature though there is related work in the spline and statistical literature  [19, 35, 37]  and machine learning literature  [3, 5, 8] ",
        "prob": 0.8916666666666665
    }, {
        "ID": 6696,
        "phrase": " terzi and tsaparas  [42]  achieved a except for pednault who mixed linear and quadratic segments  [40] , we know of no other attempt to segment time series using polynomials of variable degrees in the data mining and knowledge discovery literature though there is related work in the spline and statistical literature  [19, 35, 37]  and machine learning literature  [3, 5, 8] ",
        "prob": 0.8916666666666665
    }, {
        "ID": 6697,
        "phrase": " terzi and tsaparas  [42]  achieved a except for pednault who mixed linear and quadratic segments  [40] , we know of no other attempt to segment time series using polynomials of variable degrees in the data mining and knowledge discovery literature though there is related work in the spline and statistical literature  [19, 35, 37]  and machine learning literature  [3, 5, 8] ",
        "prob": 0.8916666666666665
    }, {
        "ID": 6724,
        "phrase": " many frameworks, adaptations to real-life problems, intertwining of base algorithms were, and continue to be, proposed in the literature; ranging from statistical approaches to state of the art machine learning algorithms, parametric to non parametric procedures, a plethora of methods is available to users",
        "prob": 0.1645161290322581
    }, {
        "ID": 6899,
        "phrase": " we believe the monge-kantorovich kernels might be useful in machine learning tasks, although we expect their computational cost to be problematic at the moment",
        "prob": 0.4263157894736842
    }, {
        "ID": 7087,
        "phrase": " n \uf0b3\uf0200 and m \uf0b3\uf0200 where c, ai and b j are literals",
        "prob": 0.22000000000000003
    }, {
        "ID": 7476,
        "phrase": " for example, in the experimental machine learning, n is often a constant (the size of the given data set) and it is the norm f f of the contemplated prediction rule f that varies",
        "prob": 0.3736842105263158
    }, {
        "ID": 7592,
        "phrase": " \n experiments and results \n corpora our first experiments are based on four different french corpora (table  1 ): 2 handbooks in artificial intelligence (ai) and linguistics (li) and 2 collections of scientific papers dealing with knowledge engineering (in the following: ke01 and ke04)",
        "prob": 0.27307692307692305
    }, {
        "ID": 7593,
        "phrase": " ml techniques appear therefore very appealing to automate the process of rule acquisition  (freitag, 1998; califf et al",
        "prob": 0.20666666666666667
    }, {
        "ID": 7601,
        "phrase": " the third one is often interpreted as a learning process and corresponds to what most machine learning researchers study",
        "prob": 0.29285714285714287
    }, {
        "ID": 8074,
        "phrase": " this argument applies directly also in the machine learning content",
        "prob": 0.41000000000000003
    }, {
        "ID": 8075,
        "phrase": " this argument applies directly also in the machine learning content",
        "prob": 0.41000000000000003
    }, {
        "ID": 8108,
        "phrase": " first, the linear supervised machine learning task is set as a well-posed (quadratic) optimization problem",
        "prob": 0.31875000000000003
    }, {
        "ID": 8108,
        "phrase": " empirical validation on standard ml benchmark demonstrates that ekm is competitive using state-of-the-art svms with tuned hyper-parameters",
        "prob": 0.24285714285714283
    }, {
        "ID": 8247,
        "phrase": " for our design, we reuse turing's idea of the punishments and rewards mechanism, which he posited as useful in child machine learning",
        "prob": 0.25625000000000003
    }, {
        "ID": 8555,
        "phrase": "14 we anticipate notationally the later identification of the moves of player 1/2 with the actions/observations in the ai models",
        "prob": 0.17500000000000002
    }, {
        "ID": 8557,
        "phrase": " we envisage the invariants to be used as inputs to an existing machine learning algorithm, for example as features to build kernels from",
        "prob": 0.6937500000000001
    }, {
        "ID": 8558,
        "phrase": " we envisage the invariants to be used as inputs to an existing machine learning algorithm, for example as features to build kernels from",
        "prob": 0.6312500000000001
    }, {
        "ID": 8559,
        "phrase": " we envisage the invariants to be used as inputs to an existing machine learning algorithm, for example as features to build kernels from",
        "prob": 0.5062500000000001
    }, {
        "ID": 9228,
        "phrase": " its ml definition is let taut_forall_fconv = (rewrite_fconv forall_truth) orelsefc (rewrite_fconv forall_falsity);;the family of conversions is modular",
        "prob": 0.31875000000000003
    }, {
        "ID": 9249,
        "phrase": " in our previous experiments, we used a methodology that is typical in empirical evaluations of machine learning systems: the training data and the test data are disjoint",
        "prob": 0.5842105263157894
    }, {
        "ID": 9251,
        "phrase": " (1992)  suggest that some traditional ai problems can be formulated as model-nding tasks; e",
        "prob": 0.19090909090909092
    }, {
        "ID": 9256,
        "phrase": " \n decision trees for discourse analysis a key to making machine learning work for a complex task such as discourse processing is to break the problem into a number of small decisions and build a separate classi er for each",
        "prob": 0.36400000000000005
    }, {
        "ID": 9256,
        "phrase": " knowledge of this sort could be manually engineered rather than acquired from machine learning, but the hundreds of rules needed might take weeks or months of e ort to create and test",
        "prob": 0.2318181818181818
    }, {
        "ID": 9256,
        "phrase": " finding a mechanism for choosing appropriate features is more critical than which machine learning algorithm is applied",
        "prob": 0.29285714285714287
    }, {
        "ID": 9263,
        "phrase": " the absence of comparison with machine learning systems that can handle classification error costs has no impact on most of the experiments reported here",
        "prob": 0.25625000000000003
    }, {
        "ID": 9278,
        "phrase": " \n empirical evaluation most empirical evaluations of machine learning systems take one of four forms, each appropriate for addressing di erent evaluation questions: a",
        "prob": 0.44999999999999996
    }, {
        "ID": 9281,
        "phrase": " the use of admissible search is of potential value in machine learning as it enables better experimental evaluation of alternative learning biases",
        "prob": 0.22777777777777775
    }, {
        "ID": 9281,
        "phrase": " experimental evidence that this is indeed the case for some machine learning tasks is presented below in section 6",
        "prob": 0.23846153846153847
    }, {
        "ID": 9285,
        "phrase": " characteristic models were studied in ai  (dechter & pearl, 1992; kavvadias et al",
        "prob": 0.20999999999999996
    }, {
        "ID": 9287,
        "phrase": " many of these methods developed within the machine learning community, such as id3 decision tree induction  (quinlan, 1986) , have been applied exclusively to classi cation tasks",
        "prob": 0.3857142857142858
    }, {
        "ID": 9287,
        "phrase": " experimental results on real-world data demonstrate that the new techniques are competitive with existing machine learning and statistical methods and can sometimes yield superior regression performance",
        "prob": 0.43913043478260866
    }, {
        "ID": 9294,
        "phrase": "introduction the goal of machine learning is to create systems that can improve their performance at some task as they acquire experience or data",
        "prob": 0.38125000000000003
    }, {
        "ID": 9294,
        "phrase": "for many types of machine learning algorithms, one can compute the statistically \\optimal\" way to select training data",
        "prob": 0.19375
    }, {
        "ID": 9297,
        "phrase": " \n final comments on external validation criteria our proposal of external validation criteria for clustering such as error rate and classi cation cost stem from a larger, often implicit, but long-standing bias of some in ai that learning systems should serve the ends of some arti cial autonomous agent",
        "prob": 0.3558823529411765
    }, {
        "ID": 9297,
        "phrase": " if external validation criteria of error rate and cost are well correlated with traditional criteria of cohesion and coupling, then why use the former criteria at all? in part, this stems from an ai and machine learning bias that systems should be designed and evaluated with a speci c performance task in mind",
        "prob": 0.35806451612903223
    }, {
        "ID": 9298,
        "phrase": " the majority of machine learning researchers would not be in the slightest disconcerted if their systems failed to perform well when trained on such data",
        "prob": 0.3
    }, {
        "ID": 9298,
        "phrase": " a nal argument that might be considered to support the occam thesis is that the majority of machine learning systems employ some form of occam's razor and they appear to perform well in practice",
        "prob": 0.2652173913043478
    }, {
        "ID": 9301,
        "phrase": " this inherent difficulty in recognizing the worth (or lack of worth) of control knowledge has been termed the utility problem  (minton, 1988)  and has been studied extensively in the machine learning community  (gratch & dejong, 1992 , greiner & jurisca, 1992 , holder, 1992 , subramanian & hunter, 1992 ",
        "prob": 0.28928571428571426
    }, {
        "ID": 9302,
        "phrase": " there have been many successful speedup learning systems described in the experimental machine learning literature, prodigy  (minton, 1990)  and soar  (laird, rosenbloom, & newell, 1986)  being two of the most prominent ones",
        "prob": 0.43913043478260866
    }, {
        "ID": 9302,
        "phrase": " \n future work to apply our work to ai planning domains such as the blocks world, we need to extend our results to richer hypothesis spaces that include rst order relational predicates",
        "prob": 0.2652173913043478
    }, {
        "ID": 9302,
        "phrase": " this work integrates many strands of experimental and theoretical work in machine learning, including empirical learning of control rules, macro-operator learning, explanation-based learning (ebl), and probably approximately correct (pac) learning",
        "prob": 0.23666666666666672
    }, {
        "ID": 9310,
        "phrase": " this paper examines the utility of machine learning for automating the construction of models for classifying cue phrases from such empirical data",
        "prob": 0.5352941176470588
    }, {
        "ID": 9310,
        "phrase": " a set of experiments are described that use two machine learning programs, cgrendel  (cohen, 1992 (cohen, , 1993 ) and c4",
        "prob": 0.4733333333333334
    }, {
        "ID": 9310,
        "phrase": " the features, classes and training examples used in the studies of  hirschberg and litman (1993) , as well as additional features, classes and training examples, are given as input to the machine learning programs",
        "prob": 0.3956521739130435
    }, {
        "ID": 9310,
        "phrase": " the experimental results show that machine learning is indeed an e ective technique, not only for automating the generation of classi cation models, but also for improving upon previous results",
        "prob": 0.719047619047619
    }, {
        "ID": 9310,
        "phrase": " section 3 then describes the machine learning approach to cue phrase classi cation that is taken in this paper",
        "prob": 0.40666666666666673
    }, {
        "ID": 9310,
        "phrase": " in particular, the section describes four sets of experiments that use machine learning to automatically induce cue phrase classi cation models",
        "prob": 0.505
    }, {
        "ID": 9310,
        "phrase": " the types of inputs and outputs of the machine learning programs are presented, as are the methodologies that are used to evaluate the results",
        "prob": 0.47333333333333333
    }, {
        "ID": 9310,
        "phrase": " hirschberg's and litman's data (cue phrases taken from corpora of recorded and transcribed speech, classi ed as discourse or sentential, and coded using both speech-based and text-based features) will be used to create the input for the machine learning experiments",
        "prob": 0.5366666666666666
    }, {
        "ID": 9310,
        "phrase": " hirschberg's and litman's results (performance gures for manually developed cue phrase classi cation models) will be used as a benchmark for evaluating the performance of the classi cation models produced by machine learning",
        "prob": 0.8499999999999999
    }, {
        "ID": 9310,
        "phrase": " \n experiments using machine learning this section describes experiments that use the machine learning programs c4",
        "prob": 0.54
    }, {
        "ID": 9310,
        "phrase": " the rst group of machine learning experiments replicate the training and testing conditions used by  hirschberg and litman (1993)  (reviewed in the previous section), to support a direct comparison of the manual and machine learning approaches",
        "prob": 0.5423076923076923
    }, {
        "ID": 9310,
        "phrase": " the third set of experiments allow the machine learning algorithms to distinguish among the 34 cue phrases, to evaluate the utility of developing classi cation models specialized for particular cue phrases",
        "prob": 0.6439999999999999
    }, {
        "ID": 9310,
        "phrase": " \n the machine learning inputs this section describes the inputs to both of the machine learning programs, namely, the names of the classi cations to be learned, the names and possible values of a xed set of for some of the machine learning experiments, a third cue phrase classi cation will also be considered",
        "prob": 0.5343749999999999
    }, {
        "ID": 9310,
        "phrase": " \n the machine learning outputs the output of both machine learning programs are classi cation models",
        "prob": 0.43571428571428567
    }, {
        "ID": 9310,
        "phrase": "5 and cgrendel is to increase the reliability of any comparisons between the machine learning and manual results",
        "prob": 0.5916666666666667
    }, {
        "ID": 9310,
        "phrase": " \n evaluation the output of each machine learning experiment is a classi cation model that has been learned from the training data",
        "prob": 0.6066666666666667
    }, {
        "ID": 9310,
        "phrase": "  10   \n the experimental conditions this section describes the conditions used in each set of machine learning experiments",
        "prob": 0.5071428571428572
    }, {
        "ID": 9310,
        "phrase": " this allows a direct comparison of the manual and machine learning approaches",
        "prob": 0.37272727272727274
    }, {
        "ID": 9310,
        "phrase": " as will be seen, the results suggest that machine learning is useful for automating the generation of linguistically viable classi cation classi cation models, for generating classi cation models that perform with lower error rates than manually developed hypotheses, and for adding to the body of linguistic knowledge regarding cue phrases",
        "prob": 0.7054054054054053
    }, {
        "ID": 9310,
        "phrase": " \n experiment set 1: replicating hirschberg and litman the rst group of experiments replicate the training, testing, and evaluation conditions used by  hirschberg and litman (1993) , in order to investigate how well machine learning performs in comparison to the manual development of cue phrase classi cation models",
        "prob": 0.7970588235294116
    }, {
        "ID": 9310,
        "phrase": " figure  4  shows the best performing prosodic classi cation models learned by the two machine learning programs; the top of the gure replicates the manually derived prosodic model from figure  1  for ease of comparison",
        "prob": 0.5592592592592592
    }, {
        "ID": 9310,
        "phrase": " comparison of the error rates of the learned and manually developed models suggests that machine learning is an e ective technique for automating the development of cue phrase classi cation models",
        "prob": 0.8304347826086954
    }, {
        "ID": 9310,
        "phrase": " thus, machine learning supports the automatic construction of a variety of cue phrase classi cation models that achieve similar performance as the manually constructed models",
        "prob": 0.5954545454545455
    }, {
        "ID": 9310,
        "phrase": " the results from p-p and from intonational in the classi able cue phrase test set are shown in italics, as they suggest that machine learning may also be useful for improving performance",
        "prob": 0.5761904761904761
    }, {
        "ID": 9310,
        "phrase": " the ease of inducing classi cation models from many di erent sets of features using machine learning supports the generation and evaluation of a wide variety of hypotheses (e",
        "prob": 0.5499999999999999
    }, {
        "ID": 9310,
        "phrase": " in particular, the duplication of the results suggests that the ability to match and perhaps even to improve upon manual performance by using machine learning is not due to the speci cs of either learning program",
        "prob": 0.444
    }, {
        "ID": 9310,
        "phrase": " as in experiment set 1, comparison of the error rates of the learned and manually developed models suggests that machine learning is an e ective technique for not only automating the development of cue phrase classi cation models, but also for improving performance",
        "prob": 0.7814814814814813
    }, {
        "ID": 9310,
        "phrase": " when tested on the classi able non-conjuncts (where the error rate of the manually derived model decreases), machine learning is useful for automating but not for improving performance",
        "prob": 0.6238095238095238
    }, {
        "ID": 9310,
        "phrase": " however, the results suggest that machine learning is still an e ective technique for automating the development of cue phrase classi cation models",
        "prob": 0.6894736842105263
    }, {
        "ID": 9310,
        "phrase": " \n discussion the experimental results suggest that machine learning is a useful tool for both automating the generation of classi cation models and improving upon manually derived results",
        "prob": 0.7318181818181817
    }, {
        "ID": 9310,
        "phrase": " 18 \n utility the results of the machine learning experiments are quite promising, in that when compared to manually derived classi cation models already in the literature, the learned classi cation models often perform with comparable if not higher accuracy",
        "prob": 0.6464285714285714
    }, {
        "ID": 9310,
        "phrase": " thus, machine learning appears to be an e ective technique for automating the generation of classi cation models",
        "prob": 0.6066666666666667
    }, {
        "ID": 9310,
        "phrase": " \n related work this paper has both compared the results obtained using machine learning to previously existing manually-obtained results, and has also used machine learning as a tool for developing theories given new linguistic data (as in the models resulting from experiment set 3, where the new feature token was considered)",
        "prob": 0.3638888888888889
    }, {
        "ID": 9310,
        "phrase": "  siegel (1994)  similarly uses machine learning (in particular, a genetic learning algorithm) to classify cue phrases from a previously unstudied set of textual features: a feature corresponding to token, as well as textual features containing the lexical or orthographic item immediately to the left of and in the 4 positions to the right of the example",
        "prob": 0.25277777777777777
    }, {
        "ID": 9310,
        "phrase": " machine learning often results in algorithms that outperform manually derived alternatives  (litman & passonneau, 1995; passonneau & litman, in press; aone & bennett, 1995; mccarthy & lehnert, 1995) , although statistical inference is not always used to evaluate the signi cance of the performance di erences",
        "prob": 0.5968749999999999
    }, {
        "ID": 9310,
        "phrase": " \n conclusion this paper has demonstrated the utility of machine learning techniques for cue phrase classi cation",
        "prob": 0.4066666666666666
    }, {
        "ID": 9310,
        "phrase": " machine learning supports the automatic generation of linguistically viable classi cation models",
        "prob": 0.7214285714285715
    }, {
        "ID": 9310,
        "phrase": " a rst set of experiments were presented that used the machine learning programs cgrendel  (cohen, 1992 (cohen, , 1993  and c4",
        "prob": 0.6733333333333333
    }, {
        "ID": 9310,
        "phrase": " in contrast, machine learning in conjunction with cross-validation (experiment set 2) supported the building of classi cation models using a much larger amount of the data for training",
        "prob": 0.43913043478260866
    }, {
        "ID": 9310,
        "phrase": " a nal advantage of the machine learning approach is that the ease of inducing classi cation models from many di erent sets of features supports an exploration of the comparative utility of di erent knowledge sources",
        "prob": 0.524
    }, {
        "ID": 9310,
        "phrase": " in sum, the results of this paper suggest that machine learning is a useful tool for cue phrase classi cation, when the amount of data precludes e ective human analysis, when the exibility a orded by easy retraining is needed (e",
        "prob": 0.5222222222222223
    }, {
        "ID": 9310,
        "phrase": " machine learning should continue to be a useful tool for helping to address these issues",
        "prob": 0.25833333333333336
    }, {
        "ID": 9310,
        "phrase": " this paper explores the use of machine learning for classifying cue phrases as discourse or sentential",
        "prob": 0.65
    }, {
        "ID": 9310,
        "phrase": " two machine learning programs (cgrendel and c4",
        "prob": 0.23333333333333334
    }, {
        "ID": 9310,
        "phrase": " machine learning is shown to be an e ective technique for not only automating the generation of classi cation models, but also for improving upon previous results",
        "prob": 0.7277777777777777
    }, {
        "ID": 9311,
        "phrase": " our use of the term joint plan di ers from other uses in the ai literature  cohen & levesque, 1991) ",
        "prob": 0.3153846153846154
    }, {
        "ID": 9321,
        "phrase": " early ai did not treat internal state (memory) and external state (functionally signi cant mutable states of the world) as importantly di erent, and it is often analytically convenient to treat them in a uniform fashion",
        "prob": 0.20400000000000004
    }, {
        "ID": 9323,
        "phrase": " for this reason, the machine learning and statistics communities devote considerable research e ort to inductive-learning algorithms",
        "prob": 0.25625000000000003
    }, {
        "ID": 9323,
        "phrase": "9% from a ten-fold cross validation on the full splice junction dataset of 3190 examples commonly used by machine learning researchers",
        "prob": 0.22777777777777775
    }, {
        "ID": 9331,
        "phrase": " we should emphasize here that the primary goal of our described research is the construction of e ective structure recognition systems, rather than the comparison of alternative methods of machine learning and classi cation per se",
        "prob": 0.2772727272727273
    }, {
        "ID": 9342,
        "phrase": " not surprisingly, a signi cant amount of work in ai planning has been aimed at improving the performance of domain independent planners by dynamically customizing them to a given domain",
        "prob": 0.355
    }, {
        "ID": 9347,
        "phrase": " best-rst search has several meanings in the ai literature",
        "prob": 0.31
    }, {
        "ID": 9347,
        "phrase": " most of the machine learning community is concerned with improving the classi cation accuracy of classi ers based on classi ed examples",
        "prob": 0.4176470588235295
    }, {
        "ID": 9567,
        "phrase": ", human expert models, cooperative knowledge base tuning), machine learning (e",
        "prob": 0.39230769230769236
    }, {
        "ID": 9571,
        "phrase": " having introduced the machine learning methods and data sets that we focus on in this paper, and the experimental method we used, the next section describes empirical results from a first set of experiments aimed at getting more insight into the effect of editing exceptional instances in memory-based learning",
        "prob": 0.2454545454545455
    }, {
        "ID": 9679,
        "phrase": " past experience in machine learning cast doubt on the feasibility of improving performance by using ebl (?)",
        "prob": 0.5399999999999999
    }, {
        "ID": 9680,
        "phrase": " past experience in machine learning cast doubt on the feasibility of improving performance by using ebl  (minton, 1990) ",
        "prob": 0.50625
    }, {
        "ID": 9691,
        "phrase": "introduction although machine learning approaches have achieved success in many areas of natural language processing, researchers have only recently begun to investigate applying machine learning methods to discourse-level problems  (litman 1994 , andernach 1996 , reithinger & klesen 1997 , wiebe et al",
        "prob": 0.25312500000000004
    }, {
        "ID": 9691,
        "phrase": " although this set is likely to include all of the useful phrases, it also includes many extraneous phrases, and we hypothesize that these irrelevant phrases can overwhelm a machine learning algorithm",
        "prob": 0.4809523809523809
    }, {
        "ID": 9714,
        "phrase": " a widely used strategy in statistics and artificial intelligence is to reduce the original graph with loops to an equivalent graph without loops (this can be achieved by clustering variables in a judicious manner) and then applying pearl's algorithm to the new graph",
        "prob": 0.25357142857142856
    }, {
        "ID": 9718,
        "phrase": " \n methods and experiments in this section we present and explain the data representation formats and the machine learning algorithm that we have used",
        "prob": 0.5062500000000001
    }, {
        "ID": 9718,
        "phrase": " \n memory-based learning we have build a basenp recognizer by training a machine learning algorithm with correct tagged data and testing it with unseen data",
        "prob": 0.505
    }, {
        "ID": 9778,
        "phrase": " so world utility is g(\u03b6), and when \u03b7 is an ml algorithm \"striving to increase\" its private utility, we write that utility as \u03b3 \u03b7 (\u03b6)",
        "prob": 0.5785714285714286
    }, {
        "ID": 9778,
        "phrase": " \n experiments we modified arthur's original problem to be more general, and since we are not interested here in directly comparing our results to those in [1, 2, 4, 8], we use a more conventional ml algorithm than the ones investigated in  [1, 2, 4, 8, 13] , an algorithm that approximately minimizes free energy",
        "prob": 0.27307692307692305
    }, {
        "ID": 9779,
        "phrase": " an alternative and more challenging approach is to use distributed computing, where not only are the individual reasoning, planning and scheduling ai tasks parallelized, but there are different modules with different such tasks, concurrently working toward a common goal  [137, 138, 166] ",
        "prob": 0.284
    }, {
        "ID": 9869,
        "phrase": ") when \u03b7 is an agent that uses a machine learning (ml) algorithm to \"try to increase\" its private utility, we write that private utility as g \u03b7 (\u03b6), or more generally, to allow that utility to vary in time, g \u03b7,\u03c4 (\u03b6)",
        "prob": 0.55
    }]
}, {
    "topic_id": 14,
    "top_words": ["section", "paper", "approach", "see", "two", "defined", "constraints", "described", "literature", "use", "introduce", "next", "easy", "describes", "describe"],
    "phrases": [{
        "ID": 6,
        "phrase": " \n application of our theory to experiments in the literature in this section we show how we can apply our theory to experimental results found in the ai and mas literature",
        "prob": 0.4437500000000001
    }, {
        "ID": 7,
        "phrase": " \n application of our theory to experiments in the literature in this section we show how we can apply our theory to experimental results found in the ai and mas literature",
        "prob": 0.5062500000000001
    }, {
        "ID": 8,
        "phrase": "   \n application of our theory to experiments in the literature in this section we show how we can apply our theory to experimental results found in the ai and mas literature",
        "prob": 0.5687500000000001
    }, {
        "ID": 99,
        "phrase": " as we shall see in the following section, these counts are all we need to implement an interesting number of ai applications",
        "prob": 0.22142857142857145
    }, {
        "ID": 141,
        "phrase": " in the next section we develop an alternative but equivalent formulation of the ai model given above",
        "prob": 0.17499999999999996
    }, {
        "ID": 141,
        "phrase": " in this and the next two subsections we show that \u03be ai defined in (  24 ) is universal and converges to \u00b5 ai analog to the sp case  (19)  and  (20) ",
        "prob": 0.29285714285714287
    }, {
        "ID": 141,
        "phrase": " \u2022 there are two possible objections to ai in general and, therefore, also against ai\u03be in particular we want to comment on briefly",
        "prob": 0.25833333333333336
    }, {
        "ID": 186,
        "phrase": " while it is possible to transfer much of the present proposal to the transducer-based setting that is often preferred nowadays, the monostratal approach still offers an attractive alternative due to its easy blend with monostratal grammars such as hpsg and the good prospects for machine learning of its surfacetrue constraints  (ellison (1992) ,  belz (1998) )",
        "prob": 0.31714285714285717
    }, {
        "ID": 279,
        "phrase": " we have also displayed an \"easy-hard-easy\" pattern similar to the ones observed experimentally in the ai literature",
        "prob": 0.3642857142857143
    }, {
        "ID": 287,
        "phrase": " ai constraints",
        "prob": 0.22000000000000003
    }, {
        "ID": 287,
        "phrase": " ia constraints: are symmetrical to ai constraints",
        "prob": 0.3
    }, {
        "ID": 321,
        "phrase": " we also note that large-scale semantic sort hierarchies are already in use in artificial intelligence and natural language generation projects (for example, cyc  (lenat, 1995 ) and kpml's upper model (bateman, 1997)), and that the techniques that we discuss in this paper are in principle compatible with these hierarchies",
        "prob": 0.19677419354838713
    }, {
        "ID": 368,
        "phrase": " currently the generated interpreters are programs in caml  [cam]  which is a dialect in the ml family",
        "prob": 0.17500000000000002
    }, {
        "ID": 377,
        "phrase": " in this paper, we describe an approach to the integration of rule-based programming in standard ml (sml)  [9] , with a strong focus on overlapping rules to achieve the effects described above",
        "prob": 0.24285714285714283
    }, {
        "ID": 425,
        "phrase": " although ml 1 = 1 is a cause of fb = 1 in both the disjunctive and conjunctive scenarios, the models m 1 and m 2 differ in regard to explanation, as we shall see in part ii of this paper",
        "prob": 0.3736842105263158
    }, {
        "ID": 658,
        "phrase": "'s example is (52); the sentence adopts an informal and concise style to describe an ai class for an academic help domain",
        "prob": 0.2733333333333334
    }, {
        "ID": 663,
        "phrase": " ia constraints: are symmetrical to ai constraints",
        "prob": 0.4428571428571429
    }, {
        "ID": 1018,
        "phrase": " in section 5 we briefly discuss to what extent the results generalize to other machine learning techniques, and mention the limitations of our approach",
        "prob": 0.25625000000000003
    }, {
        "ID": 1034,
        "phrase": " section 4 describes the main ideas underlying the ml approach to classification",
        "prob": 0.3416666666666667
    }, {
        "ID": 1034,
        "phrase": " [1998]  have found that a rocchio classifier can achieve an effectiveness comparable to that of a stateof-the-art ml method such as \"boosting\" (see section 6",
        "prob": 0.22777777777777775
    }, {
        "ID": 1034,
        "phrase": " concerning issue (i), it is known from the ml literature that, in order to guarantee good effectiveness, the classifiers forming the committee should be as independent as possible  [tumer and ghosh 1996] ",
        "prob": 0.305
    }, {
        "ID": 1704,
        "phrase": " in contrast to g\u00e4rdenfors' definition, the dominant approach to explanation in the ai literature, the maximum a posteriori (map) approach (see, for example,  [henrion and druzdzel 1991; pearl 1988; shimony 1991] ), focuses on the probability of the explanation, that is, what we have denoted pr( x = x)",
        "prob": 0.7346153846153844
    }, {
        "ID": 1705,
        "phrase": " in contrast to g\u00e4rdenfors' definition, the dominant approach to explanation in the ai literature, the maximum a posteriori (map) approach (see, for example,  [henrion and druzdzel 1990; pearl 1988; shimony 1991] ), focuses on the probability of the explanation, that is, what we have denoted pr( x = x)",
        "prob": 0.7346153846153844
    }, {
        "ID": 1706,
        "phrase": ") in contrast to g\u00e4rdenfors' definition, the dominant approach to explanation in the ai literature, the maximum a posteriori (map) approach (see, for example,  [henrion and druzdzel 1990; pearl 1988; shimony 1991] ), focuses on the probability of the explanation, that is, what we have denoted pr( x = x)",
        "prob": 0.696153846153846
    }, {
        "ID": 1792,
        "phrase": " part of this paper was presented at the 25th german conference on artificial intelligence, ki2002, aachen, germany, september 2002  [hw02] ",
        "prob": 0.25625000000000003
    }, {
        "ID": 1793,
        "phrase": " part of this paper was presented at the 25th german conference on artificial intelligence, ki2002, aachen, germany, september 2002  (hitzler and wendt 2002) ",
        "prob": 0.4176470588235295
    }, {
        "ID": 1883,
        "phrase": " then q is \u2206-more general than q \u2032 for \u03b7 if: n = m and \u2200i \u2208 [1, n], ai is \u2206-more general than bi for \u03b7 ",
        "prob": 0.2625
    }, {
        "ID": 1887,
        "phrase": " this section has presented a general theory and the remainder of the paper will demonstrate that the theory can be fruitfully applied to a real, concrete machine learning algorithm",
        "prob": 0.32105263157894737
    }, {
        "ID": 2070,
        "phrase": " these implications form the basis for our current machine learning algorithm, which is described in the next section",
        "prob": 0.22142857142857142
    }, {
        "ID": 2301,
        "phrase": " this paper presents a machine learning (ml) approach to the subtask of discourse planning that attempts to find the most natural ordering of facts in each generated document",
        "prob": 0.35500000000000004
    }, {
        "ID": 2301,
        "phrase": " \n conclusions and future work this paper has presented a machine learning approach to the fact-ordering subtask of discourse planning",
        "prob": 0.30000000000000004
    }, {
        "ID": 2301,
        "phrase": "this paper presents a machine learning approach to discourse planning in natural language generation",
        "prob": 0.3642857142857143
    }, {
        "ID": 2333,
        "phrase": " in this and the next subsection we show that \u03be ai defined in (5",
        "prob": 0.3875
    }, {
        "ID": 2333,
        "phrase": " \n convergence of \u03be ai to \u00b5 ai in section 3",
        "prob": 0.18333333333333335
    }, {
        "ID": 2333,
        "phrase": " but not all ai problems are of this 'easy' type",
        "prob": 0.15714285714285717
    }, {
        "ID": 2349,
        "phrase": " another approach, which goes back to at least  robinson [1973]  and has been explored in the economics literature  [hammond 1994 ], the ai literature  [lehmann and magidor 1992; wilson 1995] , and the philosophy literature (see  [mcgee 1994 ] and the references therein) is to consider nonstandard probability spaces (nps's), where there are infinitesimals that can be used to model events that, intuitively, have infinitesimally small probability yet may still be learned or observed",
        "prob": 0.6214285714285713
    }, {
        "ID": 2350,
        "phrase": " it also arises in the analysis of conditional statements by philosophers (see  [adams 1966; mcgee 1994] ), and in dealing with nonmonotonicity in artificial intelligence (see, for example,  [lehmann and magidor 1992] )",
        "prob": 0.40499999999999997
    }, {
        "ID": 2350,
        "phrase": " a second approach, which goes back to at least  robinson [1973]  and has been explored in the economics literature  [hammond 1994; hammond 1999 ], the ai literature  [lehmann and magidor 1992; wilson 1995] , and the philosophy literature (see  [mcgee 1994 ] and the references therein) is to consider nonstandard probability spaces (nps's), where there are infinitesimals that can be used to model events that, intuitively, have infinitesimally small probability yet may still be learned or observed",
        "prob": 0.5837209302325581
    }, {
        "ID": 2480,
        "phrase": " \n interactions in common machine learning procedures in this section we will attempt to show that interactions, as they have been defined, are relevant to a number of supervised and unsupervised learning procedures",
        "prob": 0.355
    }, {
        "ID": 2480,
        "phrase": " a recent survey of interactions in machine learning  [15]  noted that interactions are interesting for an observer, that interactions make learning harder, and that interactions can be resolved via feature construction",
        "prob": 0.4136363636363637
    }, {
        "ID": 2481,
        "phrase": " a machine learning method that disregards interactions may get caught in two traps: myopia is caused by learning algorithms assuming independence in spite of interactions, whereas fragmentation arises from assuming an interaction in spite of independence",
        "prob": 0.5896551724137931
    }, {
        "ID": 2482,
        "phrase": " a machine learning method that disregards interactions may get caught in two traps: myopia is caused by learning algorithms assuming independence in spite of interactions, whereas fragmentation arises from assuming an interaction in spite of independence",
        "prob": 0.5896551724137931
    }, {
        "ID": 2795,
        "phrase": " the machine learning approach can be phrased as a supervised learning problem",
        "prob": 0.19090909090909092
    }, {
        "ID": 2850,
        "phrase": " as a rough generalisation, conventional computing systems use absolute constraints whereas artificial intelligence applications use heuristic constraints",
        "prob": 0.32105263157894737
    }, {
        "ID": 2876,
        "phrase": " a conjunction of m such constraints is conveniently described by c : ai \u2264 b where a is an m \u00d7 n real-valued coefficient matrix, i = x 1 ",
        "prob": 0.5916666666666667
    }, {
        "ID": 3180,
        "phrase": " this paper is structured as follows: after reviewing the structure of win32 programs, we describe concurrent ml and give an outline of the framework, focusing on the important points of window management",
        "prob": 0.18636363636363634
    }, {
        "ID": 3443,
        "phrase": " note that, this paper therefore presents no new machine learning algorithms, just a novel application of known techniques",
        "prob": 0.25625000000000003
    }, {
        "ID": 3443,
        "phrase": " the use of machine learning techniques as described in this paper, and (hopefully) to be described in forthcoming articles in the jndm, could therefore have a profound effect on society at large",
        "prob": 0.24285714285714288
    }, {
        "ID": 3443,
        "phrase": "this paper describes a new breed of academic journals that use statistical machine learning techniques to make them more democratic",
        "prob": 0.3588235294117647
    }, {
        "ID": 3500,
        "phrase": " specifically, given that diagnosis cames in different forms in the literature, two of the main approaches pursued in the ai community (cf",
        "prob": 0.1823529411764706
    }, {
        "ID": 3550,
        "phrase": " 5) presentation [ ] yes [ ] somewhat [x] no 4b) are technical limitations/difficulties adequately discussed? [ ] yes [ ] somewhat [ ] no 4c) is the approach adequately evaluated? 5a) are the title and abstract appropriate? [ ] yes [x] somewhat [ ] no 5b) is the paper well-organized? [ ] yes [ ] somewhat [x] no 5c) is the paper easy to read and understand? review two [ ] yes [ ] somewhat [x] no 5d) are figures/tables/illustrations sufficient? --ecai 2004 review sheet for authors --paper nr: c0693 [ ] yes [ ] somewhat [x] no for papers focusing on applications: 4d) is the application domain adequately described? [ ] yes [ ] somewhat [ ] no 4e) is the choice of a particular methodology discussed? [ ] yes [ ] somewhat [ ] no for papers describing a methodology: 4f) \n\t\t\t european conference on artificial intelligence",
        "prob": 0.6227272727272728
    }, {
        "ID": 3630,
        "phrase": " if we apply searching part in section 2 to q r, then we get more efficiently the ml estimate p",
        "prob": 0.25833333333333336
    }, {
        "ID": 3708,
        "phrase": "this paper describes an approach to the design of a population of cooperative robots based on concepts borrowed from systems theory and artificial intelligence",
        "prob": 0.22777777777777775
    }, {
        "ID": 3870,
        "phrase": " , a l ), consider the quantity \u03d5(c) = l i=1 ai j=1 j",
        "prob": 0.18333333333333332
    }, {
        "ID": 4047,
        "phrase": " for simplicity, we discuss only ml channel estimation based systems in this section",
        "prob": 0.17500000000000002
    }, {
        "ID": 4208,
        "phrase": " section iii introduces the idea of a more-likely codeword and its relationship to ml and iterative decoders",
        "prob": 0.4066666666666667
    }, {
        "ID": 4422,
        "phrase": " therefore, if y j \u2212 x j < # ai (s)/m, then the first j bits of b(a i ) suffice to distinguish it",
        "prob": 0.21000000000000002
    }, {
        "ID": 4490,
        "phrase": " one of the main approaches pursued by researchers in artificial intelligence and computational complexity to tackle this problem has been the identification of tractable cases obtained by imposing restrictions in the constraints (see  [4, 6, 9, 10, 12, 13, 21, 22, 23, 30, 31, 37, 38] )",
        "prob": 0.41363636363636364
    }, {
        "ID": 4493,
        "phrase": " one of the main approaches pursued by researchers in artificial intelligence and computational complexity to tackle this problem has been the identification of tractable cases obtained by imposing restrictions in the constraints (see  [4, 6, 9, 10, 12, 13, 21, 22, 23, 30, 31, 37, 38] )",
        "prob": 0.36818181818181817
    }, {
        "ID": 4856,
        "phrase": " the details for obtaining the ml lower bound is described in  [20]  and the ml upper bound will be discussed in detail in the following subsection",
        "prob": 0.3
    }, {
        "ID": 5118,
        "phrase": " \n ml demodulation in this section we describe how the system equations defined in section 4 lead to a simplified yet optimal ml demodulation",
        "prob": 0.39444444444444443
    }, {
        "ID": 5119,
        "phrase": " \n ml demodulation in this section we describe how the system equations defined in section 4 lead to a simplified yet optimal ml demodulation",
        "prob": 0.39444444444444443
    }, {
        "ID": 5120,
        "phrase": " when the order of transmit antennas is reversed the model becomes \u1ef9s = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 \u1ef9s1 \u1ef9s2 \u1ef9s3 \u1ef9s4 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 v 3 v 4 \u03c3 2 2 v 1 \u2212 s 1 v 3 \u2212 s 2 v 4 \u03c3 2 2 v 2 + s 2 v 3 \u2212 s 1 v 4 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb rs = \uf8ee \uf8ef \uf8ef \uf8ef \uf8f0 \u03c3 2 2 0 s 1 \u2212s 2 0 \u03c3 2 2 s 2 s 1 0 0 \u03c3 2 1 \u03c3 2 2 \u2212 s 2 1 \u2212 s 2 2 0 0 0 0 \u03c3 2 1 \u03c3 2 2 \u2212 s 2 1 \u2212 s 2 2 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fb (26) \n ml demodulation in this section we describe how the system equations defined in section 4 lead to a simplified yet optimal ml demodulation",
        "prob": 0.284
    }, {
        "ID": 5646,
        "phrase": " we study the joint ml decoder in some detail in the next section",
        "prob": 0.2818181818181818
    }, {
        "ID": 5697,
        "phrase": " there are two main approaches to adding values to the model:  (1)  to introduce references as in the ml language, and (2) to assume that signals carry values and that the last emission \"covers\" in a sense the previous ones (if any)",
        "prob": 0.2125
    }, {
        "ID": 5908,
        "phrase": " the effectiveness of this method depends on how closely the new relaxation approximates the ml decoding problem, and how efficiently we can search for those constraints that introduce cuts",
        "prob": 0.32105263157894737
    }, {
        "ID": 5957,
        "phrase": " various versions of the cornerclassification family of itnns, which have found applications in artificial intelligence (ai), are described",
        "prob": 0.22142857142857142
    }, {
        "ID": 5969,
        "phrase": " by the definition of l ai , 0 4 k \u2208 l ai if and only if m a \u2032 (0 4 k ) rejects",
        "prob": 0.35000000000000003
    }, {
        "ID": 5969,
        "phrase": " 0 4k+3 \u2208 l ai , yet m ai (0 4k+3 ) rejects",
        "prob": 0.18333333333333335
    }, {
        "ID": 5969,
        "phrase": " 0 4k \u2208 l 2 ai , yet m ai (0 4k ) rejects",
        "prob": 0.35000000000000003
    }, {
        "ID": 6122,
        "phrase": " in this example, we note (r i ai \u2192 ",
        "prob": 0.18333333333333335
    }, {
        "ID": 6408,
        "phrase": " in this work, we introduce a radically new approach based on machine learning to construct a representative as taxonomy",
        "prob": 0.40666666666666673
    }, {
        "ID": 6408,
        "phrase": " in this paper, we introduce a radically new approach based on machine learning techniques to map all the ases in the internet into a natural as taxonomy",
        "prob": 0.45000000000000007
    }, {
        "ID": 6658,
        "phrase": " a detailed explanation of this approach and the property of the ml parameter estimation can be found in  [2] [3]  [12]   [8] ",
        "prob": 0.3416666666666666
    }, {
        "ID": 6875,
        "phrase": " in  (lehmann 1995)  and  (friedman & halpern 1996) , it is argued that this modelling is not sufficient in many ai applications",
        "prob": 0.25833333333333336
    }, {
        "ID": 7082,
        "phrase": " norms are a topic often discussed in the framework of ai and law, and in multi-agent interactions  (boman 1999 , dignum et al",
        "prob": 0.2733333333333333
    }, {
        "ID": 7144,
        "phrase": " the map and ml differ in that the map estimator of q (t, \u00b1, n) is biased towards  1  2 , and that of z t is biased towards 1",
        "prob": 0.3153846153846154
    }, {
        "ID": 7365,
        "phrase": " another review with a focus on the artificial intelligence literature is given in  [43] ",
        "prob": 0.2818181818181818
    }, {
        "ID": 7408,
        "phrase": " 8 248 for all i \u2265 0, \u2704 ai commutes with \u2192 h ",
        "prob": 0.22000000000000003
    }, {
        "ID": 7409,
        "phrase": " therefore, because l\u03c3 \u2704 ai r\u03b8, we have b = \u2205 and t = \u03bbx",
        "prob": 0.22000000000000003
    }, {
        "ID": 7409,
        "phrase": " 8 248 for all i \u2265 0, \u2704 ai commutes with \u2192 h ",
        "prob": 0.22000000000000003
    }, {
        "ID": 7870,
        "phrase": " if the ml detector in the natural form is used, then (6) continues to apply as appropriately interpreted",
        "prob": 0.16153846153846155
    }, {
        "ID": 7939,
        "phrase": " the application of the decomposition theory to linear programming, and in particular to ml decoding, is the subject of section 6",
        "prob": 0.29285714285714287
    }, {
        "ID": 7940,
        "phrase": " the application of the decomposition theory to linear programming, and in particular to ml decoding, is the subject of section 6",
        "prob": 0.2928571428571428
    }, {
        "ID": 8041,
        "phrase": " usually, p list \u226b p ml and, therefore, we will approximate p asd \u2248 p list throughout the rest of this paper",
        "prob": 0.29285714285714287
    }, {
        "ID": 8111,
        "phrase": " more generally, the presented approach can be discussed with respect to the generative versus discriminative dilemma in machine learning",
        "prob": 0.34
    }, {
        "ID": 8229,
        "phrase": " we can see that, in spite of the low snr, all the nodes converge to the ml estimate, as predicted",
        "prob": 0.23846153846153847
    }, {
        "ID": 8247,
        "phrase": " \n armchair ai we rush through the basics; professionals can perhaps skip this section and start directly with the next section, which discusses consciousness and then work back if necessary",
        "prob": 0.40499999999999997
    }, {
        "ID": 8555,
        "phrase": " the science of artificial intelligence (ai) may be defined as the construction of intelligent systems and their analysis",
        "prob": 0.3153846153846154
    }, {
        "ID": 8555,
        "phrase": " in other words: the ai problem has not yet been well defined",
        "prob": 0.23333333333333334
    }, {
        "ID": 8555,
        "phrase": " but not all ai problems are of this 'easy' type",
        "prob": 0.15714285714285714
    }, {
        "ID": 8556,
        "phrase": " we now characterize the behavior of p ml e (\u03c1|h l ) for a particular code construction  7  , namely, random codes constructed  7  we could simply conclude the proof by following the same arguments of the proof in [18, appendix i], namely, using p ml e (\u03c1|hl) < \u03b4 + 1 1{hl \u2208 ol} to argue that pe(\u03c1) \u2264\u03c1 d \u22c6 d (r 1 ) (see  [18,  appendix i] for details)",
        "prob": 0.190625
    }, {
        "ID": 8907,
        "phrase": " therefore in the remainder of the paper the main effort is to determine ml certificate decoders and to compute (or bound) p e (n)",
        "prob": 0.34
    }, {
        "ID": 9163,
        "phrase": " the effectiveness of this method depends on how closely the new relaxation approximates the ml decoding problem, and how efficiently we can search for those constraints that introduce cuts",
        "prob": 0.3210526315789474
    }, {
        "ID": 9224,
        "phrase": " an ml function is defined by equations on its patterns of input",
        "prob": 0.21000000000000002
    }, {
        "ID": 9224,
        "phrase": " i started with ml and the lcf architecture, as described in the next section",
        "prob": 0.37272727272727274
    }, {
        "ID": 9228,
        "phrase": " \n reference summary of ml this section describes just enough of ml to enable you to follow the rest of the paper",
        "prob": 0.20666666666666667
    }, {
        "ID": 9287,
        "phrase": "we describe a machine learning method for predicting the value of a real-valued function, given the values of multiple input variables",
        "prob": 0.2833333333333333
    }, {
        "ID": 9298,
        "phrase": " a knowledgeable user would not apply machine learning to such data, at least not in the expectation of obtaining a useful classi er therefrom",
        "prob": 0.3
    }, {
        "ID": 9310,
        "phrase": " section 4 presents and discusses the experimental results, and highlights the many bene ts of the machine learning approach",
        "prob": 0.25625000000000003
    }, {
        "ID": 9310,
        "phrase": " finally, section 6 discusses the use of machine learning in other studies of discourse, while section 7 concludes",
        "prob": 0.3642857142857143
    }, {
        "ID": 9439,
        "phrase": " laf and ai are both initialized to zero as discussed in section 2",
        "prob": 0.23333333333333334
    }, {
        "ID": 9615,
        "phrase": "introduction fodor and lepore (fl from here on) have saddled up recently and ridden again at the windmills of artificial intelligence (ai): this time against pustejovsky's generative lexicon  (pustejovsky, 1995 : fl call the work tgl), so as to make an example for the rest of us",
        "prob": 0.22592592592592592
    }, {
        "ID": 9679,
        "phrase": " \n elements of machine learning this section describes, in short, both bayesian learning and explanation-based learning (ebl) (also called analytical learning)",
        "prob": 0.21578947368421056
    }, {
        "ID": 9679,
        "phrase": " in order to introduce the necessary terminology, this section starts with a brief informal description of the general setting for machine learning (for a good introduction on the subject, we refer the reader to (?))",
        "prob": 0.6409090909090909
    }, {
        "ID": 9679,
        "phrase": " throughout this chapter, we employ the machine learning terminology defined in section 2",
        "prob": 0.42500000000000004
    }, {
        "ID": 9680,
        "phrase": " \n elements of machine learning this section describes, in short, both bayesian learning and explanation-based learning (ebl) (also called analytical learning)",
        "prob": 0.2157894736842105
    }, {
        "ID": 9680,
        "phrase": " in order to introduce the necessary terminology, this section starts with a brief informal description of the general setting for machine learning (for a good introduction on the subject, we refer the reader to  (mitchell, 1997) )",
        "prob": 0.5695652173913044
    }, {
        "ID": 9680,
        "phrase": " throughout this chapter, we employ the machine learning terminology defined in section 2",
        "prob": 0.42500000000000004
    }, {
        "ID": 9851,
        "phrase": " it thus inherits two key advantages of the former model, namely easy integrability into monostratal frameworks of grammar such as hpsg  (pollard & sag 1994)  and simplified machine learning of surface-only generalizations  (ellison 1992) ",
        "prob": 0.337037037037037
    }]
}, {
    "topic_id": 15,
    "top_words": ["pr", "ae", "log", "ml", "yx", "standard", "dx", "new", "apply", "power", "example", "ds", "jersey", "tcr", "represent"],
    "phrases": [{
        "ID": 141,
        "phrase": " convergence of \u03be ai to \u00b5 ai : in  [14]  the following inequality is proved 2 |x| i=1 y i (y i \u2212z i ) 2 \u2264 |x| i=1 y i ln y i z i with |x| i=1 y i = 1, |x| i=1 z i \u2264 1 ( 34 ) if we identify i = x k and y i = \u00b5(yx <k yx k ) and z i = \u03be(yx <k yx k ), multiply both sides with \u00b5(yx <k ), take the sum over x <k , then the sum over k and use bayes' rule \u00b5(yx <k )\u2022\u00b5(yx <k yx k ) = \u00b5(yx 1:k ) we get 2 n k=1 x 1:k \u00b5(yx 1:k ) \u00b5(yx <k x k ) \u2212 \u03be(yx <k x k ) 2 \u2264 n k=1 x 1:k \u00b5(yx 1:k ) ln \u00b5(yx <k x k ) \u03be(yx <k x k ) = ",
        "prob": 0.5029411764705882
    }, {
        "ID": 141,
        "phrase": " \u1e8f\u2032 k x \u2032 k ) which is 1 for x \u2032 k = \u1e8b\u2032 k as defined in ( clearly, the ai system receives no feedback, i",
        "prob": 0.23333333333333334
    }, {
        "ID": 141,
        "phrase": "yx sn ) = s\u22121 r=0 \u00b5 ai 1 (yx rn+1 ",
        "prob": 0.2625
    }, {
        "ID": 377,
        "phrase": "    \n implementation the framework we have described has been implemented for the standard ml of new jersey compiler  [1]  using the reactive library described in  [11] ",
        "prob": 0.4764705882352941
    }, {
        "ID": 460,
        "phrase": " \u00eb k \u2265 2 \u00f0\u00f3\u00f6\u00d7 {u 1 } k\u22121 \u00d7\u00f8 \u00ebae \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f2\u00f8 \u00f2 (n \u2212 1) \u00f8 \u00f4 \u00d7\u00ba \u00eb k = 1 \u00f0\u00f3\u00f6\u00d7 \u00f0 \u00d7 \u00f9\u00f0 \u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00d7\u00f8 {t 1 } = {{u 1 }} \u2212\u2192 f lat {u 1 } \u2212\u2192 \u03c1 {u \u2032 1 } \u00ba \u00ba \u00e4 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f6\u00f8 \u00f9 \u03c1 \u2205 \u00b9 \u00f0\u00f9\u00f0 \u00bd \u00bf \u00fa u 1 \u2212\u2192 \u03c1 u \u2032 1 \u00f8 u \u2032 1 \u00ebae \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f2\u00f8 \u00f2 (n \u2212 1) \u00f8 \u00f4 \u00d7\u00ba \u00e8 \u00f6 \u00f2 \u00f9\u00f8 \u00f3\u00f2\u00b8{{u \u2032 1 } k } \u00f8 {{u 1 } k\u22121 } \u00d7\u00f3\u00f2\u00f8 \u00ebae \u00f8 \u00f4 \u00f6 \u00f3\u00f2\u00d7 \u00f5\u00f9 \u00f2\u00f8\u00b8{{u 1 } k } \u00d7\u00f8 \u00ebae\u00ba p \u00e4 \u00f1\u00f1 \u00ba \u00f8 \u00f2\u00f8 \u00f3\u00f2\u00f2 \u00d7 \u00f9\u00f2 \u00f3\u00f2\u00f8 \u00fc\u00f8 e \u00f8 \u00f9\u00f2 \u00f2\u00d7 \u00f1 \u00f0 \u00f8 \u00f6\u00f1 \u00d7 u i \u00f8 \u00f0\u00d7 \u00f5\u00f9 e \u22a2 u i : ai = 1, ",
        "prob": 0.5666666666666668
    }, {
        "ID": 477,
        "phrase": " convergence of \u03be ai to \u00b5 ai : from (12) one can show n k=1 x 1:k \u00b5(yx <k ) \u00b5(yx <k yx k ) \u2212 \u03be(yx <k yx k ) 2 < ln 2\u2022k(\u00b5) + o(1) (13) for computable chronological measures \u00b5",
        "prob": 0.34
    }, {
        "ID": 529,
        "phrase": " , a k with the sum equal to s, k i=1 log ai \u2264 \u2113 log 2s \u2113 , where k \u2264 \u2113 \u2264 s",
        "prob": 0.2625
    }, {
        "ID": 530,
        "phrase": " , a k with the sum equal to s, k i=1 log ai \u2264 \u2113 log 2s \u2113 , where k \u2264 \u2113 \u2264 s",
        "prob": 0.2625
    }, {
        "ID": 762,
        "phrase": " g n p 0 a 0 c 0 a n c n p n \u00f9\u00f6 \u00ec \u00f0 \u00f2 \u00f2 \u00f8\u00f6 \u00d7 \u00f3 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f9\u00f6 \u00f2 \u00f6\u00f3\u00f9\u00f2 n\u00ba ai \u00f8\u00f6 \u00d7 \u00f3\u00f2\u00f8 \u00f2 \u00f6\u00f3\u00f9\u00f2 \u00f2 \u00fa \u00f0\u00f9 \u00d7\u00ba ci \u00f8\u00f6 \u00d7 \u00f3\u00f2\u00f8 \u00f2 \u00f2\u00f8 \u00f8\u00fd \u00f6\u00f8 \u00f8 \u00d7\u00ba pi \u00f2\u00f3 \u00d7 \u00f3\u00f1 \u00f2 \u00f8 \u00f6\u00f3\u00f9\u00f2 \u00f2 \u00fa \u00f0\u00f9 \u00f8\u00f6 \u00f2 \u00f8 \u00f6\u00f8 \u00f8 \u00f8\u00f6 \u00f3\u00f6 \u00f6\u00f3\u00f9\u00f2 i\u00b8 \u00f2 \u00f4 \u00f6\u00f8 \u00f4 \u00f8 \u00f2 \u00f8 \u00f8 \u00f1 \u00f8\u00f6 \u00b8\u00fb \u00f3\u00d7 \u00f6\u00f3\u00f3\u00f8 \u00f8 \u00f6\u00f3\u00f9\u00f2 i \u00d7 gi\u00ba \u00ec\u00eb\u00eb \u00f2 \u00f1 \u00f2 \u00f8 \u00f2 \u00fd \u00f8 \u00f1 \u00ba \u00eb\u00f9 \u00f8\u00f6 \u00d7 \u00f6 \u00f2\u00f3\u00f8 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3\u00f6 \u00f0 \u00f2 \u00b8\u00d7 \u00f2 \u00f8 \u00f6 \u00f2\u00f3 \u00d7 \u00f6 \u00f3\u00f2\u00f0\u00fd \u00f1 \u00f2 \u00f2 \u00f9\u00f0 \u00fb \u00f8 \u00f2 \u00f3\u00f2 \u00d7\u00f9 a i \u00f8\u00f6 \u00ba c i \u00f8\u00f6 \u00d7 \u00f6 \u00f6\u00f8 \u00f8 \u00f6 \u00fa \u00f0 \u00f8\u00f6 \u00d7\u00b8 \u00f2 \u00f8 \u00f2 \u00f8 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00f6\u00f8 \u00f8 \u00f6 \u00fa \u00f3\u00f6 \u00f6\u00f3\u00f9\u00f2 i\u00ba c i \u00f8\u00f6 \u00d7 \u00f6 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00b4\u00d7\u00f3 \u00f6 \u00f2\u00f8 c i \u00f8\u00f6 \u00d7 \u00f1 \u00f8 \u00d7 \u00f6 \u00f3\u00f1\u00f1\u00f3\u00f2 \u00f2\u00f3 \u00d7\u00b5\u00b8 \u00f0 \u00f2 \u00b8 \u00f2 \u00f8 \u00f6 \u00f2\u00f3 \u00d7 \u00f6 \u00d7\u00f3\u00f6\u00f8 \u00fd \u00f2\u00f8 \u00f8\u00fd \u00f2 \u00f1 \u00ba \u00f9\u00f6 \u00f2 \u00f6\u00f3\u00f9\u00f2 i\u00b8\u00f8 \u00f6\u00f3\u00f3\u00f8 \u00d7 \u00d7 \u00f3 \u00f8\u00f6 \u00d7 a i \u00f2 c i \u00f6 \u00f3\u00f1 \u00f2 \u00fb \u00f8 \u00f3\u00f2 \u00b9\u00fb \u00fd \u00f3\u00f0\u00f0 \u00d7 \u00f3\u00f2\u00b9\u00f6 \u00d7 \u00d7\u00f8 \u00f2\u00f8 \u00d7 \u00f9\u00f2\u00b9 \u00f8 \u00f3\u00f2 \u00f2 \u00f6 \u00f9\u00d7 \u00f8\u00f3 \u00f0 \u00f0 \u00f8 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f6\u00f3\u00f3\u00f8 \u00d7 p i \u00f3\u00f6 \u00f6\u00f3\u00f9\u00f2 i\u00ba \u00ec \u00d7 \u00fa \u00f0\u00f9 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f9\u00f6 \u00f2 \u00f6\u00f3\u00f9\u00f2 i\u00ba p i \u00f2\u00f3 \u00d7 \u00f6 \u00d7\u00f8\u00f3\u00f6 \u00f2 \u00f0 \u00f2 \u00f9\u00f8 \u00f2\u00f3\u00f8 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f8 \u00f1 \u00f8\u00f6 \u00ba \u00ec \u00f6\u00f3\u00f3\u00f8 \u00d7 g i \u00f3 \u00f8 \u00f8 \u00f1 \u00f8\u00f6 \u00f8 \u00f6\u00f3\u00f9\u00f2 i \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f4 \u00d7\u00f8 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00fd \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7\u00ba g i \u00d7 \u00d7 \u00f2 \u00fd \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f2\u00f3 \u00d7 \u00f2 \u00d7\u00b9 \u00f8\u00f6 \u00f9\u00f8 \u00f6\u00f3\u00f9\u00f2 \u00f8 \u00fb\u00f3\u00f6\u00f0 \u00b8\u00d7 \u00f2 \u00f8 \u00f4\u00f0 \u00fd\u00d7 \u00f8 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f6\u00f3\u00f0 \u00f3 \u00d7 \u00f0 \u00b9\u00d7 \u00f2 \u00f6\u00f3\u00f3\u00f8 \u00f6\u00f8 \u00f8 \u00f3\u00f6 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00f9\u00f8 \u00f3\u00f6 \u00f8\u00fd\u00ba \u00f0\u00f0 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4\u00d7 \u00f2 \u00f6 \u00fa \u00f2\u00f8 \u00f8\u00fd \u00f6\u00b9 \u00f8 \u00f8 \u00d7 \u00f2 \u00fa \u00f6 \u00f8 \u00f6\u00f3\u00f9 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00fc \u00d7\u00f8 \u00f2 \u00f4\u00f6\u00f3\u00f3 \u00d7 \u00f6\u00f3\u00f3\u00f8 \u00f8 g i \u00f9\u00f6 \u00f2 \u00f6\u00f3\u00f9\u00f2 i\u00ba \u00e1\u00f2 \u00f8 \u00f9\u00f6 \u00b8\u00fb \u00f2 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f2 \u00d7 \u00f2\u00f8\u00f3 \u00f6\u00f3\u00f9\u00f2 n + 1\u00b8 \u00f2 \u00fb \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00f6\u00f8 \u00f8 \u00f8\u00f6 c n+1 \u00fb \u00f0\u00f0 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00d7 \u00f4 \u00f6 \u00eb \u00b9 \u00f8 \u00f3\u00f2 \u00ba \u00ba\u00be\u00b8\u00f8 \u00f2 \u00f2 \u00fb \u00f0 \u00f2 \u00f2 \u00f8\u00f6 a n+1 \u00fb \u00f0\u00f0 \u00f3\u00f1\u00b9 \u00f4\u00f9\u00f8 \u00b8 \u00d7 \u00f4 \u00f6 \u00eb \u00f8 \u00f3\u00f2 \u00ba \u00ba\u00bf\u00ba \u00ec\u00f6 \u00d7 c n+1 \u00f2 a n+1 \u00fb \u00f0\u00f0 \u00f3\u00f1 \u00f2 \u00f2\u00f8\u00f3 \u00f8 \u00f2 \u00fb \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00fa \u00f0\u00f9 p n+1 \u00b8\u00fb \u00fb \u00f0\u00f0 \u00f2\u00d7 \u00f6\u00f8 \u00f2\u00f8\u00f3 \u00f8 \u00f8 \u00f1 \u00f8\u00f6 \u00b8\u00fd \u00f0 \u00f2 \u00f2 \u00fb \u00f6\u00f3\u00f3\u00f8 \u00d7 g n+1 \u00b8\u00fb \u00fb \u00f0\u00f0 \u00d7 \u00f2 \u00fd \u00f8 \u00f2 \u00fb \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f2\u00f3 \u00f1 \u00f1 \u00f6\u00d7 \u00f4\u00b8 \u00f2 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f6\u00f3\u00f9\u00f2 \u00f8 \u00fb\u00f3\u00f6\u00f0 \u00f8\u00f3 \u00f6 \u00f4\u00f0 g n \u00ba g n \u00f2 \u00d7 \u00f6 \u00f2 \u00d7 \u00f3\u00f9\u00f0 \u00f3\u00f2\u00d7 \u00b9 \u00f6 \u00f9\u00d7 \u00f0 \u00d7\u00d7 \u00f8 \u00f6 g n+1 \u00d7 \u00f2 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00ba \u00ec ae \u00f6\u00d7 \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00ec \u00f3 \u00f0 \u00f2 \u00f8 ae \u00f6\u00d7 \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00d7 \u00f8\u00f3 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f0 \u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f2\u00f3 \u00d7 \u00f3\u00fa \u00f6 \u00fa \u00f6\u00fd \u00f0\u00f3\u00f2 \u00f4 \u00f6 \u00f3 \u00d7 \u00f3 \u00f8 \u00f1 \u00b4\u00f3\u00f2 \u00f8 \u00d7 \u00f0 \u00f3 \u00f1\u00f3\u00f2\u00f8 \u00d7\u00b5 \u00f2 \u00fb \u00f8 \u00f0\u00fd \u00fa \u00f6 \u00f0 \u00f3\u00fb \u00d7 \u00fe \u00d7\u00ba \u00ef \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f1\u00f1\u00f9\u00f2 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f3\u00fb \u00f0 \u00fa \u00f0\u00b8\u00d7 \u00f2 \u00f8 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f1\u00f4\u00f0 \u00fc \u00f8\u00fd \u00f3 \u00f4 \u00f8\u00b9\u00f0 \u00fa \u00f0 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6\u00d7 \u00b4\u00d7\u00f9 \u00d7 \u00f2\u00d7 \u00ee \u2104\u00b5 \u00d7 \u00f8\u00f3\u00f3 \u00f3\u00f6 \u00f3\u00f9\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00f3 \u00f6\u00f9\u00f2 \u00f2 \u00f6 \u00d7\u00f3\u00f2 \u00f0 \u00f8 \u00f1 \u00ba \u00ef \u00fb \u00f2\u00f8 \u00d7 \u00f9\u00f0 \u00f6 \u00f8 \u00f8 \u00f3\u00f9\u00f0 \u00f4\u00b9 \u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f8 \u00f9\u00f6 \u00fd \u00f3 \u00f4 \u00f8\u00b9 \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6\u00d7 \u00fb \u00f8 \u00b9 \u00f3\u00f9\u00f8 \u00f8 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f8 \u00f1 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f3\u00f2\u00d7 \u00f6 \u00fa \u00f2\u00f8\u00d7 \u00f3\u00f2 \u00f4 \u00f8 \u00f0 \u00fa \u00f0\u00ba \u00ec\u00f3 \u00f8 \u00d7 \u00f2 \u00b8\u00fb \u00fa \u00f8\u00f8 \u00f1\u00f4\u00f8 \u00f8\u00f3 \u00f9 \u00f0 \u00d7\u00f6 \u00f8 \u00fa \u00f2\u00f8\u00b8 \u00f3\u00fb\u00b9 \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00f8 \u00f8 \u00f0 \u00d7 \u00f2 \u00b9 \u00fa \u00f9 \u00f0 \u00f4 \u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f9\u00f8 \u00d7\u00f8 \u00f0\u00f0 \u00f6 \u00f8\u00d7 \u00f8 \u00f1\u00f4 \u00f8 \u00f3 \u00f8\u00f6 \u00f2\u00f8 \u00f6 \u00f4 \u00f2 \u00f2 \u00d7\u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 \u00f3\u00f1\u00f4\u00f6\u00f3\u00f1 \u00d7 \u00b9 \u00f8\u00fb \u00f2 \u00d7\u00f4 \u00f2 \u00f9\u00f6 \u00fd\u00b8 \u00f9\u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8\u00f0\u00fd \u00f6\u00f6\u00d7 \u00f3\u00f2 \u00f8 \u00d7 \u00f3 \u00f4 \u00d7\u00d7 \u00f1 \u00d7\u00f1 \u00b4\u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f6 \u00f4\u00f3\u00f6\u00f8 \u00f3\u00fb \u00f8\u00f6 \u00f2\u00d7 \u00f6 \u00f8 \u00f1 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00f3\u00f6 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00fb \u00f8 \u00fb\u00f3\u00f9\u00f0 \u00f3\u00f2\u00d7\u00f9\u00f1 \u00f2 \u00f4\u00f6 \u00f8 \u00ba\u00b5 \u00bd \u00f9\u00d7 \u00fb \u00f1 \u00f8 \u00d7\u00d7\u00f9\u00f1\u00f4\u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f0\u00f0 \u00f2\u00f3 \u00d7 \u00f4 \u00f6\u00f8 \u00b9 \u00f4 \u00f8 \u00f2 \u00f2 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00f6 \u00fb \u00f0\u00f0\u00b9\u00f3\u00f2\u00f2 \u00f8 \u00fb \u00f2 \u00f6 \u00f9 \u00f8 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f1\u00f4\u00f0 \u00fc \u00f8\u00fd \u00f3 \u00f8 \u00d7 \u00f1\u00b9 \u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00fd \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00f8 \u00f3\u00f2\u00f0\u00fd \u00f8 \u00f0 \u00f2 \u00d7 \u00f3\u00f2 \u00fb \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00f2 \u00d7\u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f2\u00f3 \u00d7 \u00f6 \u00f8\u00f8 \u00f1 \u00fd \u00f0 \u00f1 \u00f8 \u00f8 \u00f2 \u00fb \u00f8 \u00f3 \u00f3\u00fb\u00ba \u00e1\u00f2 \u00f3\u00f8 \u00f6 \u00fb\u00f3\u00f6 \u00d7\u00b8\u00f2\u00f3 \u00f2\u00f8 \u00f6\u00f1 \u00f8 \u00f0 \u00f2 \u00d7 \u00f3\u00f2 \u00f4 \u00f8 \u00f6\u00f3\u00f1 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00f8\u00f3 \u00f8 \u00d7\u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f3\u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00f2 \u00f0 \u00d7\u00f8 \u00f3\u00f4 \u00f6 \u00f3\u00f8\u00f8\u00f0 \u00f2 \u00f0 \u00f2 \u00d7\u00ba \u00ec \u00d7 \u00f0\u00b9 \u00f0\u00f3\u00fb\u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f3\u00f9\u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8\u00f3\u00f4\u00f3\u00f0\u00f3 \u00fd \u00d7 \u00d7\u00f8 \u00f6 \u00fb \u00f6 \u00fa \u00f6\u00fd \u00f2\u00f3 \u00f2 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f3\u00f2\u00f2 \u00f8 \u00fb \u00f8 \u00f2\u00f8\u00f6 \u00f0 \u00f9 \u00f2\u00f3 \u00f8 \u00f8 \u00d7 \u00f6 \u00f8 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00fa \u00f6\u00fd \u00f2\u00f3 \u00ba \u00f2\u00f3 \u00d7 \u00d7\u00d7 \u00f2 \u00f2 \u00fb \u00f8 \u00f8 \u00f8 \u00f3\u00f6\u00b9 \u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f2 \u00f3\u00d7\u00f8\u00b3\u00d7 \u00f6\u00d7\u00f8\u00b9\u00f0 \u00f2 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8\u00ba \u00ec \u00f9\u00d7 ae \u00f6\u00d7 \u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f1\u00f3 \u00f0 \u00ec\u00eb\u00eb \u00f3\u00f2\u00f2 \u00f8 \u00f8\u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00ec\u00b9\u00bd \u00f0 \u00d7 \u00f0 \u00f2 \u00fd \u00d7\u00d7 \u00f2 \u00f2 \u00f8 \u00f8 \u00f2\u00f3 \u00f2 \u00fb \u00f8 \u00f3 \u00bd\u00ba \u00e5 \u00f4\u00d7\u00ba ae \u00f6\u00d7 \u00d7 \u00f1\u00f3 \u00f0\u00d7 \u00f2 \u00b9\u00f8\u00f3\u00b9 \u00f2 \u00f0 \u00f8 \u00f2\u00fd \u00fd \u00d7\u00d7 \u00f2 \u00f2 \u00fa \u00f6 \u00f0 \u00f8 \u00f2 \u00d7 \u00f8\u00f3 \u00f2 \u00f3\u00d7\u00f8\u00ba \u00ec \u00d7 \u00fa \u00f6 \u00f0 \u00f8 \u00f2 \u00d7 \u00f2 \u00f8 \u00f3\u00f9 \u00f8 \u00f3 \u00d7 \u00f8 \u00fa \u00f6 \u00f3\u00f2 \u00fb \u00fd \u00f0 \u00f8 \u00f2\u00fd \u00f6\u00f3\u00f1 \u00f8 \u00f2 \u00f3\u00d7\u00f8 \u00f8\u00f3 \u00f2\u00f8\u00f6 \u00f0 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00ef \u00f2 \u00f8\u00fb\u00f3 \u00f2 \u00f3\u00d7\u00f8\u00d7 \u00f3\u00f1\u00f1\u00f9\u00f2 \u00f8 \u00b8\u00f8 \u00f2 \u00b9\u00f8\u00f3\u00b9 \u00f2 \u00f0 \u00f8 \u00f2\u00fd \u00d7 \u00f0\u00f9\u00f0 \u00f8 \u00fd \u00f2 \u00f8 \u00f8\u00fb\u00f3 \u00f3\u00d7\u00f8\u00d7\u00b3 \u00f0 \u00f8 \u00f2 \u00d7 \u00f8\u00f3 \u00f8 \u00f6\u00ba \u00ec \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00d7 \u00f1\u00f3 \u00f0 \u00f8 \u00f6 \u00f8 \u00f8\u00f6 \u00f8 \u00f3\u00f2 \u00f0 \u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00f8 \u00b8 \u00f9\u00f8 \u00fb \u00f0\u00f9\u00f1\u00f4 \u00f8 \u00f4 \u00fd\u00d7 \u00f0\u00b8\u00f0 \u00f2 \u00b8\u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00f8\u00f6 \u00f2\u00d7\u00f4\u00f3\u00f6\u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f2\u00f8\u00f3 \u00f3\u00f2 \u00f0 \u00fd \u00f6\u00ba \u00ec \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00fa \u00f3\u00f6 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00d7 \u00f0 \u00fd \u00f6\u00d7 \u00f8 \u00f2 \u00f2 \u00f9\u00f2 \u00d7\u00f3\u00f2 \u00d7 \u00f1\u00f3 \u00f0 \u00f9\u00d7 \u00f2 \u00f2 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00fb \u00f0\u00f0 \u00f6 \u00f3\u00fb \u00d7 \u00f9\u00f0 \u00f2 \u00b8\u00fb \u00f6 \u00fb \u00f2 \u00f3\u00fb \u00f8\u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00fd\u00f8 \u00d7 \u00f3 \u00f1 \u00d7\u00d7 \u00f4 \u00d7\u00d7 \u00f6\u00f3\u00f1 \u00f6 \u00f0 \u00fd \u00f6 \u00f8\u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f4\u00f3\u00f6\u00f8 \u00f0 \u00fd \u00f6\u00ba \u00f6 \u00f3\u00fb \u00d7 \u00f9\u00f0 \u00f2 \u00f0\u00f0\u00f3 \u00f8 \u00d7 \u00f2 \u00fb \u00f8 \u00f8\u00f3 \u00f3\u00fb\u00d7 \u00f3\u00f2\u00f0\u00fd \u00f9\u00f4 \u00f8\u00f3 \u00f8 \u00f6 \u00f6 \u00d7 \u00f6 \u00b8 \u00fa \u00f2 \u00f8 \u00f3\u00fb \u00f3\u00f9\u00f0 \u00f9\u00d7 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f8\u00d7 \u00f6 \u00d7 \u00f6 \u00ba \u00ec \u00f6 \u00d7 \u00f6 \u00f2 \u00fb \u00f8 \u00d7 \u00f8 \u00f2 \u00fb \u00f8 \u00f3 \u00f2\u00f3 \u00fa \u00fd \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3\u00fb\u00d7 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00f6 \u00fa \u00fd \u00f8 \u00f8 \u00f2\u00f3 \u00ba \u00ef \u00f6 \u00f3\u00fb \u00f1\u00f3\u00fa \u00d7 \u00f8\u00fb \u00f2 \u00f8\u00fb\u00f3 \u00f2\u00f3 \u00d7 \u00f3 \u00f6 \u00f2\u00f8 \u00f2 \u00fb \u00f8 \u00b8\u00f8 \u00f2 \u00b9 \u00fb \u00f8 \u00f3 \u00f8 \u00f3\u00fb \u00d7 \u00f8 \u00f6\u00f1 \u00f2 \u00fd \u00f8 \u00f2 \u00f8 \u00f1 \u00f2 \u00b9 \u00f1\u00f9\u00f1 \u00f3 \u00f8 \u00f6 \u00d7 \u00f6 \u00f2 \u00fb \u00f8 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00f2 \u00d7\u00b9 \u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f3\u00fb\u00ba \u00f3\u00f6 \u00fc \u00f1\u00f4\u00f0 \u00b8 10mbps \u00f2\u00f3 \u00fb \u00f8 \u00f3\u00f9\u00f6 \u00f9\u00f6\u00f6 \u00f2\u00f8 \u00f3\u00fb\u00d7 \u00f2 \u00f8 \u00f8 \u00d7 \u00f3\u00fb \u00f8\u00f3 100mbps \u00f2\u00f3 \u00fb \u00f8 \u00f8 \u00f6 \u00f9\u00f6\u00f6 \u00f2\u00f8 \u00f3\u00fb\u00d7\u00b8\u00f8 \u00f0\u00f0\u00f3 \u00f8 \u00f2 \u00fb \u00f8 \u00d7 min{100/(3 + 1), 10/(4 + 1)} = 2mbps\u00ba \u00fa \u00f2 \u00f8 \u00f3\u00f9 \u00f8 100mbps \u00f2\u00f3 \u00f3\u00f9\u00f0 \u00fa\u00f3\u00f8 25mbps \u00f8\u00f3 \u00f8 \u00d7 \u00f3\u00fb\u00b8\u00f8 \u00f3\u00fb \u00f3\u00f2\u00f0\u00fd \u00f8 \u00d7 \u00f9\u00f4 2mbps\u00ba \u00e1\u00f2 \u00f4\u00f6 \u00f8 \u00f8 \u00d7 \u00f1 \u00f2\u00d7 \u00f8 \u00f8 \u00d7\u00f3\u00f1 \u00f3 \u00f8 \u00f3\u00f8 \u00f6 \u00f3\u00fb\u00d7 \u00f3\u00f2 \u00f8 100mbps \u00f2\u00f3 \u00f3\u00f9\u00f0 \u00f9\u00f8 \u00f0 \u00fe \u00f1\u00f3\u00f6 \u00f8 \u00f2 1/4 \u00f3 \u00f8 \u00f2 \u00fb \u00f8 \u00b8 \u00f9\u00f8 \u00f2 \u00f3\u00f9\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00fb \u00f4 \u00d7\u00d7 \u00f1 \u00d7\u00f8 \u00f0\u00f0\u00fd \u00f0 \u00fa \u00f8 \u00f1 \u00fb \u00f8 \u00f8 \u00f6 \u00f6 \u00d7 \u00f6 \u00b4 \u00f2 \u00b9 \u00fb \u00f8 \u00fa \u00fd \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3\u00fb\u00d7\u00b5\u00ba \u00d7 \u00f3\u00fb\u00d7 \u00f6 \u00f2 \u00f8 \u00f8 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00b8 \u00f6 \u00f3\u00fb \u00d7 \u00f9\u00f0 \u00f2 \u00fd\u00f2 \u00f1 \u00f0\u00f0\u00fd \u00f9\u00f4 \u00f8 \u00d7 \u00f8 \u00f1\u00f3\u00f9\u00f2\u00f8 \u00f3 \u00f2 \u00fb \u00f8 \u00f0\u00f0\u00f3 \u00f8 \u00f8\u00f3 \u00fa \u00f6\u00fd \u00f8 \u00fa \u00f3\u00fb \u00f2 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00ef \u00f2 \u00f2\u00f3\u00f9 \u00f8 \u00f1 \u00f4 \u00d7\u00d7 \u00d7 \u00f3\u00f6 \u00f0\u00f0 \u00f3 \u00f8 \u00f8\u00d7 \u00f3 \u00f3\u00fb \u00f8\u00f3 \u00f8\u00f6 \u00f2\u00d7 \u00f6\u00f6 \u00b8ae \u00f6\u00d7 \u00d7 \u00f0 \u00fa \u00f6\u00d7 \u00f8 \u00f3\u00fb \u00f8\u00f3 \u00f8 \u00d7\u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f2\u00f3 \u00ba \u00d7\u00d7 \u00f2\u00f8 \u00f0\u00f0\u00fd\u00b8ae \u00f6\u00d7 \u00d7 \u00f0\u00f9\u00f0 \u00f8 \u00d7 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f8\u00f6 \u00f2\u00d7 \u00f6 \u00f8 \u00f1 \u00f3\u00f6 \u00f3\u00fb\u00ba \u00e1\u00f2 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f2 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f6 \u00f8 \u00f1 \u00d7 \u00f3 \u00f3\u00fb\u00d7ae \u00f6\u00d7 \u00d7 \u00f0\u00d7\u00f3 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00d7 \u00f0\u00f3 \u00f0 \u00f0\u00f3 \u00f3\u00f6 \u00f2\u00f3 \u00f2 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00ba \u00f3 \u00f2 \u00f8 \u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f0\u00f3 \u00f6 \u00f8 \u00fc\u00b9 \u00f4 \u00f6 \u00f2 \u00fd \u00f6 \u00f0 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00d7\u00ba \u00f2\u00f3 \u00b3\u00d7 \u00f0\u00f3 \u00f2 \u00f3\u00f2 \u00f9\u00f6 \u00f8\u00f3 \u00f6 \u00f8 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd\u00b8\u00f8 \u00f9\u00d7 \u00f0\u00f3\u00d7 \u00f0\u00fd \u00f4\u00b9 \u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3 \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00f0\u00f3 \u00d7\u00ba \u00e1\u00f2 \u00f4 \u00f6\u00b9 \u00f8 \u00f9\u00f0 \u00f6\u00b8\u00fb \u00f9\u00d7 \u00f8 \u00d7 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00fd \u00f8\u00f3 \u00fa \u00f6 \u00fd \u00f8 \u00f4 \u00f6\u00f8\u00d7 \u00f3 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f8 \u00f8 \u00f1\u00f9\u00d7\u00f8 \u00f3\u00f9\u00f2\u00f8 \u00f3\u00f6 \u00f0\u00f3 \u00f6 \u00f8\u00b8\u00d7\u00f9 \u00d7 \u00f8 \u00d7\u00fd\u00f2 \u00f6\u00f3\u00f2 \u00fe \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00ba \u00ba\u00bd\u00ba \u00ec \u00f0\u00f3 \u00f0 \u00f2\u00f3 \u00f0\u00f3 \u00d7 \u00f2 ae \u00f6\u00d7 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f6 \u00f2 \u00f3\u00f1 \u00f0 \u00f2 \u00f6 \u00f6 \u00f8 \u00f4 \u00f8\u00f8 \u00f6\u00f2\u00ba \u00fa \u00f2 \u00f8 \u00f1 \u00fc \u00f1\u00f9\u00f1 \u00f3 \u00d7 \u00f8 \u00f8\u00fb \u00f2 \u00f8 \u00f0\u00f3 \u00f0 \u00f0\u00f3 \u00f2 \u00f6 \u00f0 \u00f8 \u00f1 \u00b8 \u00f2\u00f3 \u00f4 \u00d7 \u00f6 \u00f8 \u00f3 \u00f3 \u00d7 \u00f8 \u00f2 \u00b8 \u00f2 \u00f2 \u00fb \u00f3 \u00d7 \u00f8\u00ba \u00e1\u00f8 \u00f8 \u00f2 \u00f0 \u00f2 \u00f6\u00f0\u00fd \u00f2 \u00d7 \u00f8\u00d7 \u00b9 \u00f6 \u00f2 \u00f6\u00f3\u00f1 \u00f8 \u00f6 \u00f0 \u00f8 \u00f1 \u00f9\u00f2\u00f8 \u00f0 \u00f8 \u00f2 \u00fb \u00f3 \u00d7 \u00f8 \u00d7 \u00f6 \u00ba \u00ef \u00f2 \u00f8 \u00f2 \u00fb \u00f3 \u00d7 \u00f8 \u00d7 \u00f6 \u00b8\u00f8 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f6 \u00f4 \u00f8 \u00ba \u00f0\u00f3\u00f2 \u00fb \u00f8 \u00f0\u00f3 \u00f0 \u00f0\u00f3 \u00b8ae \u00f6\u00d7 \u00d7 \u00f0\u00d7\u00f3 \u00f3 \u00f6\u00d7 \u00f2 \u00f2\u00f8 \u00f6 \u00f8\u00f3 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8 \u00f8 \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00f0\u00fd \u00f0 \u00f6 \u00f1\u00f3\u00f9\u00f2\u00f8\u00d7 \u00f3 \u00e8\u00ed \u00f8 \u00f1 \u00ba \u00ef \u00f9\u00d7 \u00f8 \u00d7 \u00f8\u00f9\u00f6 \u00f3 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f8 \u00f0 \u00fd \u00f2\u00f9\u00f6\u00f6 \u00fd \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00fc\u00f4 \u00f2\u00d7 \u00fa \u00f6\u00fd\u00f4\u00b9 \u00f8\u00f3 \u00f6 \u00f4 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2\u00d7\u00b8\u00d7\u00f9 \u00d7 \u00f2 \u00f6 \u00f8 \u00f2 \u00d7 \u00f2 \u00f8\u00f9\u00f6 \u00d7\u00ba \u00ec \u00f9\u00d7 ae \u00f6\u00d7 \u00d7 \u00f3 \u00f6\u00d7 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00d7 \u00f2 \u00f6\u00d7 \u00f3 \u00f8\u00fb \u00f2 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00d7\u00fd\u00d7\u00f8 \u00f1 \u00b4\u00fb \u00d7 \u00f8 \u00f2 \u00d7\u00f8 \u00f6 \u00f8\u00f3 \u00f4\u00f3\u00f6\u00f8 \u00f8\u00f3 \u00f4\u00f0\u00f3\u00fd \u00f0 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00b5 \u00f3\u00f6 \u00f4\u00f4\u00f6\u00f3\u00fc\u00b9 \u00f1 \u00f8 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00fc \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00fd\u00b8\u00fb \u00d7 \u00d7 \u00f6 \u00f8\u00f3 \u00f3 \u00f2 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00f3 \u00f6\u00f9\u00f2 \u00d7\u00f8 \u00f6\u00ba \u00e7\u00f9\u00f6 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00b9 \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00d7 \u00f2 \u00f8\u00f3 \u00f2\u00f3 \u00f9\u00f6 \u00f8 \u00f3\u00f2 \u00f3 \u00d7 \u00f6\u00fd\u00f4\u00f8\u00f3 \u00f6 \u00f4 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2 \u00b4 \u00f1\u00f3 \u00f9\u00f0 \u00f6 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f8 \u00f3\u00f2\u00b5\u00ba \u00f0\u00f0 \u00f3\u00f8 \u00f6 \u00f6\u00fd\u00f4\u00f8\u00f3 \u00f6 \u00f4 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f6 \u00f6\u00f3 \u00f2 \u00f3\u00fb\u00f2 \u00f6\u00f3\u00f9 \u00f0\u00fd \u00f2\u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00ba \u00f0\u00f0 \u00f8 \u00f6 \u00f3 \u00f8 \u00d7 \u00f2\u00f3 \u00f0 \u00f8 \u00d7 \u00fb \u00d7\u00f6 \u00f3\u00fa \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f9\u00f0 \u00f2 \u00b8\u00f0\u00f3 \u00f6 \u00f8 \u00d7 \u00f9\u00f0 \u00f2 \u00f2 \u00fa\u00fd \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f9\u00f0 \u00f2 \u00b8 \u00f2 \u00fc \u00f0\u00fd \u00f2 \u00f8\u00f3 \u00b9 \u00f6 \u00f2\u00f8 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00f3\u00f9\u00f8 \u00f8 \u00f2 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f9\u00f4\u00f4 \u00f6 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f8 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00d7\u00f8 \u00ba \u00ba\u00bd \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00d7 \u00f8\u00f9\u00f4 \u00e5\u00f3\u00d7\u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6\u00d7 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00fa \u00f8\u00fb\u00f3 \u00f1 \u00f2 \u00d7\u00f4 \u00f8\u00d7 \u00f3 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00d7 \u00f8\u00f9\u00f4 \u00f8\u00f3\u00f4\u00f3\u00f0\u00f3 \u00fd \u00f2 \u00f8\u00f6 \u00f4 \u00f8\u00f8 \u00f6\u00f2 \u00f3\u00f2\u00b9 \u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2\u00ba \u00ec\u00f3\u00f4\u00f3\u00f0\u00f3 \u00fd \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2 \u00f6 \u00f8 \u00d7 \u00f2\u00f3 \u00d7 \u00f2 \u00f3\u00f2\u00b9 \u00f2 \u00f8\u00d7 \u00f8 \u00f1 \u00fb \u00f8 \u00fb \u00f6 \u00f0 \u00f2 \u00d7\u00b8\u00f3\u00f6 \u00f2 \u00f8 \u00d7 \u00f3 \u00fb \u00f6 \u00f0 \u00d7\u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7\u00b8\u00f3\u00f2 \u00f9\u00f6 \u00d7 \u00f2\u00f3 \u00d7 \u00fb \u00f8 \u00fb \u00f6 \u00f0 \u00d7\u00d7 \u00f2\u00f8 \u00f6 \u00d7\u00ba \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00f8 \u00d7 \u00f0\u00d7\u00f3 \u00f6 \u00f8 \u00f3\u00f6 \u00f2\u00f3 \u00fb \u00d7 \u00f1\u00f9\u00b9 \u00f0 \u00f8 \u00d7 \u00f8 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0\u00d7 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f9\u00f2 \u00f6 \u00d7\u00f8\u00f9 \u00fd\u00ba \u00f8 \u00f6 \u00f8 \u00f8\u00f3\u00f4\u00f3\u00f0\u00f3 \u00fd \u00d7 \u00f2 \u00f6 \u00f8 \u00b8\u00f8\u00f6 \u00d7 \u00f1\u00f3 \u00f0 \u00fd \u00d7\u00f8 \u00b9 \u00f0 \u00d7 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f2 \u00d7 \u00f2 \u00d7\u00b8 \u00f2 \u00d7\u00d7 \u00f2 \u00f2 \u00d7\u00f3\u00f1 \u00f2 \u00f3 \u00f8\u00f6 \u00f4 \u00f8\u00f8 \u00f6\u00f2 \u00f3\u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7\u00ba \u00f9\u00d7 ae \u00f6\u00d7 \u00d7 \u00d7\u00f8\u00f6 \u00f8\u00d7 \u00fb \u00fd \u00f8 \u00f4 \u00fd\u00d7 \u00f0 \u00f8\u00f3\u00f4\u00f3\u00f0\u00f3 \u00fd \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8\u00f8 \u00f8\u00f3\u00f4\u00f3\u00f0\u00f3 \u00fd \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2 \u00f4 \u00d7 \u00d7 \u00f0 \u00f1\u00b9 \u00bd \u00f8 \u00f8\u00f3 \u00f2 \u00f2 \u00f2 \u00fb \u00f8 \u00f2 \u00f0 \u00f8 \u00f2\u00fd \u00f6 \u00f8 \u00f6 \u00d7\u00f8 \u00d7 \u00f3 \u00f2 \u00f2\u00f3 \u00d7 \u00f2 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f2 \u00d7\u00f8 \u00f3\u00f6 \u00f2\u00f3 \u00ba \u00f8 \u00f8 \u00d7 \u00d7\u00f8 \u00b8\u00f8 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00f0\u00d7\u00f3 \u00d7 \u00f8\u00d7 \u00f9\u00f4 \u00f8 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00b9 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f2\u00f3 \u00f0 \u00f8 \u00d7 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2 \u00b8\u00f0\u00f3 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00fb \u00f2 \u00f8 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00d7\u00f6 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00f6 \u00f6 \u00f3\u00fb \u00d7 \u00f9\u00f0 \u00f2 \u00b8\u00f6 \u00f2 \u00f3\u00f1 \u00f0 \u00f2 \u00f6 \u00f6 \u00f8\u00b8 \u00f2 \u00f1\u00f3 \u00f9\u00f0 \u00f6 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f8 \u00f3\u00f2\u00b9 \u00d7 \u00b8 \u00d7 \u00d7\u00f6 \u00f3\u00fa \u00ba \u00f4 \u00f6\u00f8 \u00f6\u00f3\u00f1 \u00f8 \u00f2\u00f3 \u00d7\u00b8 ae \u00f6\u00d7 \u00d7 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00f2 \u00d7 \u00f2 \u00fa \u00f6\u00d7 \u00f6\u00fd\u00ba \u00ec \u00fa \u00f6\u00d7 \u00f6\u00fd \u00d7 \u00f8 \u00f4 \u00f3 \u00f0\u00f3 \u00f8 \u00f8 \u00fc\u00b9 \u00f9\u00f8 \u00d7 \u00f8 \u00f8\u00f9 \u00f0 \u00d7 \u00f2 \u00f6 \u00f3 \u00fb \u00f6 \u00f8 \u00d7\u00f8 \u00f2 \u00b8 \u00f2 \u00f8 \u00f6 \u00fb \u00fd\u00d7\u00ba \u00f6\u00d7\u00f8\u00b8\u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f1 \u00fd \u00f9\u00d7 \u00f2\u00f3 \u00d7 \u00f8\u00f3 \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f0 \u00f0 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00b8 \u00f3\u00f6 \u00fc \u00f1\u00f4\u00f0 \u00b8 \u00f8 \u00f1 \u00fd \u00f9\u00d7 \u00f8 \u00f6\u00f6 \u00fa \u00f0 \u00f3 \u00f2 \u00fb \u00f8\u00f6 \u00f2 \u00f6 \u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f2\u00f3 \u00d7\u00ba \u00eb \u00b9 \u00f3\u00f2 \u00b8\u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f1 \u00fd \u00f4 \u00f6 \u00f8\u00f6 \u00f6 \u00f0\u00fd \u00f2\u00f3 \u00f8\u00f3 \u00d7\u00f9 \u00b9 \u00fa \u00f6\u00f8 \u00f6 \u00f8 \u00f2\u00f3\u00fb\u00b8\u00f2\u00f3 \u00d7 \u00f1 \u00fd \u00f3\u00f2\u00f0\u00fd \u00f9\u00d7 \u00f8\u00f3 \u00f2 \u00f3\u00f9\u00f6 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7\u00ba \u00ec \u00f6 \u00b8\u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f1 \u00fd \u00f9\u00d7 \u00f6 \u00f8\u00f6 \u00f6\u00fd \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fc \u00f4\u00f8 \u00f3\u00f2\u00d7\u00b8\u00d7\u00f9 \u00d7 \u00f8 \u00f0\u00f3\u00d7\u00d7 \u00f3\u00f6 \u00f0 \u00fd \u00f3 \u00f3\u00fb\u00b8 \u00f0\u00fb \u00fd\u00d7 \u00fb \u00f8 \u00f2 \u00f8 \u00f0 \u00f1 \u00f8\u00d7 \u00f1\u00f4\u00f3\u00d7 \u00fd \u00f3\u00f9\u00f6 \u00d7\u00d7\u00f9\u00f1\u00f4\u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00ba\u00bf\u00ba \u00ef \u00f2 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00f8 \u00f1 \u00f2\u00d7\u00b8ae \u00f6\u00d7 \u00d7 \u00fc \u00f9\u00f8 \u00d7 \u00f8 \u00f2 \u00f6\u00f3\u00f9\u00f8 \u00f2 \u00f3 \u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd\u00b8\u00fb \u00f2 \u00d7 \u00f8 \u00f9\u00f4 \u00f0 \u00f6\u00f1\u00d7 \u00f3\u00f6 \u00f9\u00f6\u00f8 \u00f6 \u00fa \u00f6\u00d7 \u00f6 \u00f0 \u00f8 \u00fa \u00f8\u00fd\u00b8\u00f3\u00f6 \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f3\u00f3\u00f8\u00d7\u00f8\u00f6 \u00f4\u00f4 \u00f2 \u00f3\u00f2 \u00f8 \u00f2\u00f3 \u00d7\u00ba \u00e7\u00f2 \u00f8 \u00f2 \u00f8 \u00f0 \u00fe \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00d7 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00b8\u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f3 \u00f8 \u00fa \u00f2\u00f8 \u00f5\u00f9 \u00f9 \u00f2\u00d7\u00ba \u00ef \u00f2 \u00f2\u00f3 \u00f1\u00f3\u00f6 \u00f2\u00f3 \u00f3\u00f6 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00fa \u00f2\u00f8\u00d7 \u00f3\u00f9\u00f4\u00fd \u00f8 \u00f5\u00f9 \u00f9 \u00b8\u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00d7\u00ba \u00f0\u00f8 \u00f3\u00f9 \u00fb \u00f9 \u00f0\u00f8 \u00f8 ae \u00f6\u00d7 \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00fa \u00f0\u00f9 \u00f8 \u00f2 \u00f8 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0\u00d7 \u00f8 \u00f8 \u00f3\u00f1\u00f4\u00f6 \u00d7 \u00f3\u00f9\u00f6 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00fb \u00f0 \u00fa \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u00f1 \u00fd \u00f9\u00d7 \u00f9\u00f0 \u00f3\u00f6 \u00fa \u00f0\u00f9 \u00f8 \u00f2 \u00f3\u00f8 \u00f6 \u00f0 \u00f6 \u00b9\u00d7 \u00f0 \u00f0\u00f3\u00f2 \u00b9\u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8 \u00fa \u00f8 \u00d7\u00ba \u00e1\u00f2 \u00d7 \u00f4\u00b9 \u00f6 \u00f8 \u00f3\u00f2\u00f9\u00f6\u00f6 \u00f2\u00f8 \u00fb\u00f3\u00f6 \u00fb \u00f6 \u00fa \u00f0\u00f9 \u00f8 \u00f2 \u00f8 \u00f9\u00f6 \u00fd \u00f2 \u00d7\u00f4 \u00f3 ae \u00f6\u00d7 \u00d7 \u00fb \u00f2 \u00f3\u00f1\u00f4 \u00f6 \u00fb \u00f8 \u00f4 \u00f8\u00b9\u00f0 \u00fa \u00f0 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00ba \u00ec \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f6 \u00f4\u00f3\u00f6\u00f8 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00f0\u00f0 \u00f8\u00f3\u00b9 \u00f8 \u00f6 \u00f8\u00f3\u00f3 \u00f8\u00f3\u00f8 \u00f0 \u00f8 \u00f1 \u00f3 \u00f3\u00f9\u00f8 \u00f1 \u00f2\u00f9\u00f8 \u00d7 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f3\u00f2 \u00f9 \u00f0 \u00e8 \u00f2\u00f8 \u00f9\u00f1 \u00bf \u00f3\u00f2 \u00f8 \u00bd \u00e0\u00fe \u00f4 \u00f6 \u00f4\u00f6\u00f3 \u00d7\u00d7\u00f3\u00f6 \u00f2 \u00f3\u00f2 \u00fd\u00f8 \u00f3 \u00f1 \u00f2 \u00f1 \u00f1\u00f3\u00f6\u00fd\u00ba \u00fa \u00f0\u00f9 \u00f8 \u00f3\u00f2 \u00e1\u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00fb \u00d7 \u00f8\u00f3 \u00f8 \u00d7\u00f8 \u00fb \u00f8 \u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f8\u00f6\u00f9\u00d7\u00f8 \u00d7 \u00f6\u00fa \u00f9\u00d7 \u00f2 \u00f6 \u00f2 \u00f3\u00f1 \u00fe \u00fd\u00fe \u00f2\u00f8 \u00f2 \u00f6 \u00f1 \u00f2\u00f8 \u00f2 \u00f6 \u00f0 \u00d7\u00f8 \u00f3\u00f6 \u00f3\u00f9\u00f6 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f1 \u00f2\u00ba \u00ec \u00d7\u00f0\u00f3\u00fb \u00f6 \u00f8 \u00b9\u00f3 \u00b9 \u00f2 \u00f3 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f2 \u00f6 \u00f2\u00f8 \u00f2 \u00f4\u00f9 \u00f0 \u00fd \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f9\u00d7 \u00f1 \u00f8 \u00f3 \u00d7 \u00f8 \u00f8 \u00f1 \u00f8 \u00f3\u00f8 \u00f6\u00fb \u00d7 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00ba \u00ec \u00d7 \u00f9 \u00f0 \u00f2 \u00f0\u00f3 \u00f9\u00d7 \u00f9\u00f6 \u00f2 \u00fa \u00f6\u00fd \u00f6\u00f3\u00f9\u00f2 \u00f2 \u00d7 \u00f8 \u00d7\u00fd\u00f2 \u00f6\u00f3\u00f2\u00f3\u00f9\u00d7 \u00e5\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00fd\u00fe \u00f2\u00f8 \u00f2 \u00f6 \u00f1 \u00f2\u00f8 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00b8\u00fb \u00d7 \u00f2\u00fa\u00f3 \u00fd \u00f1 \u00f1 \u00f6\u00d7 \u00f8 \u00f6 \u00f8 \u00f1 \u00d7 \u00f8\u00f3 \u00f6 \u00f3\u00f2 \u00f8 \u00f2 \u00fb \u00f6\u00f3\u00f9\u00f4 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00f3\u00f6 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00f6\u00f3\u00f9\u00f2 \u00b4 \u00f2 \u00fd \u00fc\u00f8 \u00f2\u00d7 \u00f3\u00f2\u00b8\u00f3\u00f2 \u00f8 \u00fc \u00f8 \u00d7 \u00b9 \u00f9\u00f6 \u00bd\u00bc \u00ec \u00d7 \u00f6 \u00f4 \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f2\u00f6 \u00d7 \u00f2 \u00f8 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f8 \u00f1 \u00f3 \u00f8 \u00f6 \u00f2\u00f8 \u00f4 \u00d7 \u00d7 \u00f3 \u00d7 \u00f2 \u00f0 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00fd\u00fe \u00f2\u00f8 \u00f2 \u00f6 \u00f1 \u00f2\u00f8 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00f2\u00d7\u00f8 \u00f2 \u00ba \u00ec \u00f0\u00f3\u00fb \u00d7\u00f8 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f4\u00f6\u00f3\u00b9 \u00f4\u00f3\u00d7 \u00f0 \u00f6\u00f3 \u00d7\u00f8 \u00b4 \u00f3\u00b5 \u00f4 \u00d7 \u00b8\u00ec \u00d7 \u00f3\u00f2 \u00f0\u00f3\u00fb \u00d7\u00f8 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f8 \u00f1 \u00f3\u00f6 \u00f8 \u00fa\u00f3\u00f8 \u00f6\u00f3 \u00d7\u00f8 \u00f4 \u00d7 \u00ba \u00ec \u00f8 \u00f6 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f8 \u00f1 \u00f8\u00f3 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00d7 \u00f2 \u00f0 \u00f2 \u00f6\u00fd \u00f6 \u00f1 \u00f2\u00f8\u00ba \u00ec \u00f8\u00f3\u00f4 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f8 \u00f1 \u00f8 \u00f2 \u00fd \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00f6 \u00f1 \u00f2\u00f8\u00ba \u00be\u00bc \u00f9\u00f6 \u00d7 \u00f6 \u00f3 \u00f2 \u00f8\u00f3 \u00f9\u00d7 \u00f8 \u00f6 \u00f2\u00b5\u00b8 \u00f2 \u00f8\u00f3 \u00f6 \u00f3\u00f2 \u00f8 \u00f6 \u00f0\u00b9\u00f8 \u00f1 \u00d7\u00d7\u00f3 \u00f8 \u00f3\u00f2 \u00f3 \u00f6\u00f3\u00f9\u00f2 \u00b8\u00b4\u00f8 \u00f8 \u00f1 \u00f8 \u00f8 \u00fb \u00f0\u00f0 \u00f2\u00f0\u00f9 \u00f2 \u00fa \u00f6\u00fd \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00d7\u00d7\u00f9 \u00f9\u00f6 \u00f2 \u00f8 \u00f2 \u00fc\u00f8 \u00f6\u00f3\u00f9\u00f2 \u00b5\u00ba \u00ec \u00f6 \u00f1 \u00f2\u00f8 \u00d7 \u00d7 \u00fa \u00f6 \u00f0 \u00f4 \u00d7 \u00d7\u00b8\u00f2 \u00f1 \u00f0\u00fd \u00f8 \u00f3 \u00f4 \u00d7 \u00b8\u00fb \u00f6 \u00f2\u00f3 \u00d7 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8\u00f0\u00fd \u00f6\u00f3 \u00d7\u00f8 \u00f8 \u00f6 \u00fa \u00f0\u00b9 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0\u00b8\u00f8 \u00fa\u00f3\u00f8 \u00f4 \u00d7 \u00b8\u00fb \u00f6 \u00f2\u00f3 \u00d7 \u00f6\u00f3 \u00d7\u00f8 \u00f8 \u00f6 \u00fd \u00d7\u00bb\u00f2\u00f3 \u00fa\u00f3\u00f8 \u00f3\u00f2 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0 \u00fd \u00d7\u00f4 \u00f2\u00f3 \u00b8 \u00f2 \u00f8 \u00f6 \u00f1 \u00f2\u00f8 \u00f4 \u00d7 \u00b8\u00fb \u00d7 \u00f8 \u00f4 \u00d7 \u00f9\u00f6\u00b9 \u00f2 \u00fb \u00f2\u00f3 \u00d7 \u00f8\u00f8 \u00f1\u00f4\u00f8 \u00f8\u00f3 \u00f6 \u00f3\u00f2\u00d7 \u00f2\u00d7\u00f9\u00d7 \u00f3\u00f2 \u00fb \u00f8 \u00f6 \u00f3\u00f6 \u00f2\u00f3\u00f8 \u00f8\u00f3 \u00f9\u00d7 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00fa \u00f0 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0 \u00f3\u00f6 \u00f2\u00f3\u00f8\u00ba \u00f9\u00f6 \u00bd\u00bc \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3 \u00f3\u00f9\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00ec \u00d7 \u00f6 \u00f4 \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f2\u00f6 \u00d7 \u00f2 \u00f8 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f8 \u00f1 \u00f3 \u00f8 \u00f6 \u00f2\u00f8 \u00f4 \u00d7 \u00d7 \u00f3 \u00d7 \u00f2 \u00f0 \u00e5\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00fd\u00fe \u00f2\u00f8 \u00f2 \u00f6 \u00b9 \u00f1 \u00f2\u00f8 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00f2\u00d7\u00f8 \u00f2 \u00d7 \u00f8 \u00f6\u00f3\u00f9\u00f4 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00d7 \u00fe \u00f2\u00f6 \u00d7 \u00d7\u00ba \u00ec \u00f1 \u00fc \u00f1\u00f9\u00f1 \u00f6\u00f3\u00f9\u00f4 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00d7 \u00fe \u00d7 \u00f1\u00b9 \u00f9\u00f0 \u00f8 \u00d7 \u00bd \u00f2\u00f3 \u00d7\u00ba \u00ec \u00f0\u00f3\u00fb \u00d7\u00f8 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f3 \u00f4 \u00d7 \u00b8\u00fb \u00f4\u00f4 \u00f2\u00d7 \u00fc \u00f8\u00f0\u00fd \u00f3\u00f2 \u00f4 \u00f6 \u00f6 \u00f1 \u00f2\u00f8\u00ba \u00ec \u00d7 \u00f3\u00f2 \u00f0\u00f3\u00fb \u00d7\u00f8 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f8 \u00f1 \u00f8 \u00f2 \u00f3\u00f6 \u00f8 \u00fa\u00f3\u00f8 \u00f6\u00f3 \u00d7\u00f8 \u00f4 \u00d7 \u00b8\u00fb \u00d7 \u00f1\u00f9 \u00d7 \u00f3\u00f6\u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0 \u00b4 \u00f3\u00b5 \u00f6\u00f3 \u00d7\u00f8 \u00f4 \u00d7 \u00b8 \u00f9\u00d7 \u00f8 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f6 \u00b9 \u00f5\u00f9 \u00f6 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8 \u00f6\u00f3 \u00d7\u00f8\u00ba \u00ec \u00f8 \u00f6 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f8 \u00f1 \u00f8 \u00f2 \u00f8\u00f3 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00d7 \u00f2 \u00f0 \u00f2 \u00f6\u00fd \u00f6 \u00b9 \u00f1 \u00f2\u00f8\u00ba \u00ec \u00f8\u00f3\u00f4 \u00f9\u00f6\u00fa \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f8 \u00f1 \u00f8 \u00f2 \u00fd \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00f6 \u00f1 \u00f2\u00f8\u00ba \u00ec \u00d7\u00f6 \u00f4 \u00f2\u00fd \u00f8\u00fb \u00f2 \u00f8 \u00f8\u00f3\u00b9 \u00f8 \u00f0 \u00f8 \u00f1 \u00f2 \u00f8 \u00f8 \u00f1 \u00f8\u00f3 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f8 \u00f2 \u00f6\u00fd \u00f6 \u00f1 \u00f2\u00f8 \u00d7 \u00f9 \u00f8\u00f3 \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00fa\u00f3\u00f8 \u00f2 \u00f2 \u00f6\u00fd \u00f6 \u00f1 \u00f2\u00f8 \u00f4 \u00d7 \u00d7 \u00f1 \u00fd \u00f4\u00f4 \u00f2 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00b8 \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0 \u00f3\u00d7 \u00f2 \u00f8\u00f3 \u00fa\u00f3\u00f8 \u00f3\u00f2\u00ba \u00eb \u00f2 \u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f2\u00f3\u00fb\u00d7 \u00f2 \u00fa \u00f2 \u00f2 \u00fb \u00f3\u00f6 \u00f6 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0\u00d7 \u00f6 \u00fa\u00f3\u00f8 \u00f3\u00f2\u00b8 \u00f8 \u00f2 \u00d7 \u00f9\u00f0 \u00f8 \u00f3\u00f6\u00f6\u00f9\u00f4\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f6\u00d7\u00f8 f \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f6\u00d7\u00b8 \u00f9\u00d7 \u00f2 \u00f8 \u00fa \u00f2\u00f8\u00f9 \u00f0 \u00f6 \u00f1 \u00f2\u00f8 \u00f8\u00f3 \u00f0 \u00fd \u00f9 \u00f8\u00f3 \u00f6 \u00f4 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00fa\u00f3\u00f8 \u00f2 \u00f2 \u00f2 \u00f6\u00fd \u00f6 \u00f1 \u00f2\u00f8 \u00f4 \u00d7 \u00d7\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f2\u00f2\u00f3\u00f8 \u00f9\u00d7 \u00f1\u00f3\u00f6 \u00f8 \u00f2 2f \u00d7\u00f9 \u00f6 \u00f4 \u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00e3\u00e8\u00eb\u00bc\u00bd\u2104\u00ba \u00fa \u00f2 \u00bd \u00f2\u00f3 \u00d7\u00b8\u00f8 \u00d7 \u00f1 \u00f2\u00d7 2 \u00d7 49 \u00f8\u00f3\u00f8 \u00f0 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f6 \u00f4 \u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00fa\u00f3\u00f8 \u00f2 \u00f2 \u00f6 \u00b9 \u00f1 \u00f2\u00f8 \u00f4 \u00d7 \u00d7 \u00f3\u00f6 \u00d7 \u00f2 \u00f0 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00f6 \u00f1 \u00f2\u00f8\u00ba \u00f6\u00f3\u00f1 \u00f8 \u00f6 \u00f4 \u00b8\u00fb \u00d7 \u00f8 \u00f8 \u00f8 \u00d7 \u00f4 \u00d7 \u00d7 \u00f8\u00f3 \u00f8 \u00f6 \u00f3\u00f9\u00f2\u00f8 \u00f3\u00f6 \u00f3\u00f9\u00f8 \u00bd\u00bc \u00d7 \u00f3\u00f2 \u00d7 \u00f3\u00f6 \u00d7 \u00f2 \u00f0 \u00f6 \u00f4 \u00f8 \u00f8 \u00f3\u00f2\u00ba \u00f2 \u00f8 \u00be\u00bc \u00d7 \u00f3\u00f2 \u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f3\u00f6 \u00f8 \u00f3 \u00f4 \u00d7 \u00b8 \u00d7 \u00f2 \u00f0 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00f6 \u00f1 \u00f2\u00f8 \u00f1 \u00fd \u00f8 \u00f3\u00f9\u00f8 \u00bd \u00f3\u00f9\u00f6\u00d7\u00ba \u00eb \u00f2 \u00f8 \u00f6 \u00d7\u00f9 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f6 \u00f6 \u00f5\u00f9 \u00f6 \u00f3\u00f6 \u00f3\u00f2 \u00f6\u00f3\u00f9\u00f2 \u00b8\u00f8 \u00d7 \u00f1 \u00f2\u00d7 \u00f8 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f2 \u00f9\u00d7 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00f6\u00f3\u00f9\u00f2 \u00f8\u00f3 \u00f8 \u00f3\u00f9\u00f8 \u00be \u00f3\u00f9\u00f6\u00d7\u00b8\u00f3\u00f6 \u00f0\u00f1\u00f3\u00d7\u00f8 \u00f8\u00fb\u00f3 \u00fd\u00d7\u00ba \u00ec \u00d7 \u00d7 \u00f2 \u00fb\u00f3\u00f6\u00d7\u00f8\u00b9 \u00d7 \u00d7 \u00f2 \u00f6 \u00f3\u00b8 \u00f3\u00f6 \u00f8\u00fb\u00f3 \u00f6 \u00d7\u00f3\u00f2\u00d7\u00ba \u00f6\u00d7\u00f8\u00b8 \u00f0\u00f8 \u00f3\u00f9 \u00fb \u00fa \u00f2\u00f3\u00f8 \u00f3\u00f2 \u00d7\u00f3\u00b8\u00f8 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00f2 \u00f6 \u00f0\u00b9\u00f8 \u00f1 \u00d7\u00d7\u00f3 \u00f8 \u00f3\u00f2 \u00f6 \u00f1 \u00f2\u00f8 \u00d7\u00f8 \u00f4\u00d7 \u00f3 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00f1 \u00fd \u00f2 \u00f8 \u00f3\u00f1 \u00f2 \u00b8\u00f6 \u00b9 \u00f5\u00f9 \u00f6 \u00f2 \u00f3\u00f2\u00f0\u00fd \u00f8\u00fb\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f4 \u00f6 \u00f6\u00f3\u00f9\u00f2 \u00ba \u00eb \u00b9 \u00f3\u00f2 \u00b8 \u00f2 \u00f6 \u00f4\u00f3\u00f6\u00f8\u00d7 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00fb \u00f8 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fc\u00f4 \u00f8 \u00f6\u00f3\u00f9\u00f2 \u00d7 \u00e3\u00e8\u00eb\u00bc\u00bd\u2104 \u00f3\u00f6 \u00f1\u00f9\u00f0\u00f8 \u00fa \u00f0\u00f9 \u00f6 \u00f1 \u00f2\u00f8 \u00fb \u00f0\u00d7\u00f3 \u00f6 \u00f0 \u00d7 \u00f3\u00f2 \u00f6 \u00f2 \u00f3\u00f1 \u00fe \u00f8 \u00f3\u00f2\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00fb \u00fa \u00f2\u00f3\u00f8 \u00fd \u00f8 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f8 \u00d7 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0\u00ba \u00ec \u00f9\u00d7 \u00f8 \u00d7 \u00f6 \u00d7\u00f3\u00f2 \u00f0 \u00f8\u00f3 \u00d7\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00f6\u00f3\u00f9\u00f2 \u00f3 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00f3\u00f6 \u00bd \u00f2\u00f3 \u00d7 \u00fb \u00f8 \u00f2 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f9\u00d7 \u00f2 \u00f1 \u00fc \u00f1 \u00f0 \u00f1 \u00f2 \u00d7\u00f8 \u00f0\u00f0 \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f0 \u00d7\u00d7 \u00f8 \u00f2 \u00f3\u00f9\u00f4\u00f0 \u00f3 \u00fd\u00d7\u00ba \u00ea \u00f0 \u00f8 \u00fb\u00f3\u00f6 \u00f0\u00f8 \u00f3\u00f9 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f1\u00d7 \u00f8\u00f3 \u00d7\u00d7 \u00f2\u00f8 \u00f0 \u00f8\u00f3 \u00f3\u00f2\u00b9 \u00f9\u00f8 \u00d7 \u00f9\u00f6 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f8 \u00f0 \u00d7\u00f8 \u00f2 \u00f8\u00d7 \u00f2 \u00f8 \u00f8 \u00f0 \u00fb\u00f3\u00f6\u00f0 \u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8\u00b8\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f6 \u00d7 \u00f6 \u00f6\u00d7 \u00fc\u00f4\u00f0\u00f3\u00f6\u00b9 \u00f2 \u00f8 \u00d7 \u00f8\u00f3\u00f4 \u00d7 \u00d7\u00f9\u00f6\u00f4\u00f6 \u00d7 \u00f2 \u00f0\u00fd \u00d7\u00f1 \u00f0\u00f0\u00ba \u00e1\u00f2 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00fb\u00f3\u00f6 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bd\u00b8\u00f1\u00f3\u00d7\u00f8 \u00f2\u00f3\u00b9 \u00f8 \u00f0\u00fd \u00e2\u00f9\u00d7\u00f8 \u00e2\u00f9\u00d7 \u2104 \u00d7\u00f6 \u00d7 \u00f8 \u00f2\u00f8\u00f6 \u00d7 \u00f3 \u00f6 \u00f0\u00fd \u00f2 \u00f3\u00f2 \u00f8 \u00f8\u00f6\u00f9\u00d7\u00f8\u00fb\u00f3\u00f6\u00f8 \u00f2 \u00d7\u00d7 \u00f3 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f6 \u00f8\u00f3 \u00f2\u00d7\u00f9\u00f6 \u00f8 \u00f1\u00b9 \u00f1\u00f9\u00f8 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00f3\u00f9\u00f1 \u00f2\u00f8 \u00f8 \u00f1 \u00f0 \u00f2 \u00b8 \u00f2 \u00fb \u00fd\u00d7 \u00f2 \u00fb \u00f6\u00f0 \u00f6 \u00fb\u00f3\u00f6 \u00f0\u00d7 \u00f8\u00f3 \u00f1 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f6\u00d7 \u00f3\u00f9\u00f2\u00f8 \u00f0 \u00ba \u00ec \u00d7 \u00fb\u00f3\u00f6 \u00b8 \u00f0\u00f8 \u00f3\u00f9 \u00f2\u00f3\u00f8 \u00f6 \u00f8\u00f0\u00fd \u00f4\u00f4\u00f0 \u00f0 \u00f8\u00f3 \u00f8 \u00f3\u00f6 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7\u00f6 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00b4\u00fb \u00f6 \u00f6 \u00f0 \u00f8 \u00fa \u00f3\u00f6\u00b9 \u00f6 \u00f3 \u00f4\u00f9 \u00f0 \u00fd\u00d7 \u00fb \u00f8 \u00f2 \u00f6\u00f3\u00f9\u00f2 \u00d7 \u00f2\u00d7 \u00f2 \u00f2\u00f8\u00b5\u00b8 \u00d7 \u00fa \u00f6\u00fd \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00f3\u00f6 \u00f8 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f4\u00f3\u00f8 \u00f2\u00f8 \u00f0 \u00f3\u00f9\u00f1 \u00f2\u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00d7 \u00f6\u00f9\u00f2 \u00fd \u00f8 \u00d7 \u00f3 \u00f3\u00f9\u00f6 \u00f2 \u00f8\u00b9 \u00fb\u00f3\u00f6 \u00b8 \u00fd \u00f8 \u00f6\u00f3\u00f9\u00f4 \u00f1 \u00f1 \u00f6 \u00f2\u00f3 \u00d7 \u00f2 \u00fa \u00f9 \u00f0\u00f0\u00fd\u00ba \u00fa \u00f6\u00fd \u00f8 \u00f0 \u00d7\u00f4 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00d7 \u00f2 \u00f4\u00f6\u00f3 \u00f9 \u00f2 \u00f8 \u00ec\u00e1\u00e5 \u00eb \u00f4\u00f6\u00f3 \u00f8 \u00e9\u00e5 + \u2104\u00ba \u00e8\u00f6 \u00f8 \u00f0 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00d7 \u00f8 \u00f8 \u00f8\u00f3\u00f0 \u00f6 \u00f8 \u00fd\u00fe \u00f2\u00f8 \u00f2 \u00f9\u00f0\u00f8\u00d7 \u00fa \u00f2 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f2 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f2 \u00f8 \u00f4 \u00d7\u00f8 \u00b4 \u00ba \u00ba\u00b8 \u00e4 \u0229 \u2104\u00b5\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f3\u00f2\u00f0\u00fd \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00fa \u00f2 \u00f9\u00d7 \u00b8 \u00f9 \u00f8\u00f3 \u00f8 \u00f8 \u00f8 \u00f8 \u00f6 \u00f2 \u00f3\u00f1 \u00fe \u00f8 \u00f3\u00f2 \u00fb \u00d7 \u00f8\u00f6 \u00b9 \u00f8 \u00f3\u00f2 \u00f0\u00f0\u00fd \u00f3\u00f2\u00d7 \u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00fa \u00f8\u00f3 \u00f9\u00d7 \u00ba \u00ec\u00f3 \u00f6\u00f9\u00f1\u00fa \u00f2\u00f8 \u00f8 \u00f1\u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f3 \u00e4\u00e8 \u2104\u00b8\u00fa \u00f6 \u00f3\u00f9\u00d7 \u00fa \u00f2\u00f9 \u00d7 \u00f6 \u00f3\u00f0\u00f0\u00f3\u00fb \u00b8 \u00f2\u00f0\u00f9 \u00f2 \u00f8 \u00f9\u00d7 \u00f3 \u00f0\u00f9\u00f6 \u00f8 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f6 \u00fa \u00f6\u00fd \u00f6 \u00f8\u00f3 \u00f9 \u00f0 \u00f2 \u00f4\u00f6\u00f3\u00fa \u00f3\u00f6\u00f6 \u00f8 \u00f2 \u00f8 \u00d7 \u00f3 \u00d7\u00fd\u00d7\u00b9 \u00f8 \u00f1\u00d7 \u00fb \u00f6 \u00f6\u00f3\u00f9\u00f4 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00f1\u00f9\u00d7\u00f8 \u00f2 \u00b8\u00f3\u00f6 \u00f8 \u00f1\u00b9 \u00f4\u00f3\u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f8 \u00f8 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00f8 \u00f8 \u00d7 \u00f4\u00f6 \u00f3\u00f2 \u00f9\u00f6 \u00fd \u00f8 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00b3\u00d7 \u00f1 \u00f2 \u00d7\u00f8\u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00ed\u00f2 \u00f3\u00f6\u00f8\u00f9\u00f2 \u00f8 \u00f0\u00fd\u00b8\u00fb \u00f3 \u00f2\u00f3\u00f8 \u00fa \u00f8 \u00f0\u00f9\u00fc\u00f9\u00f6\u00fd \u00f3 \u00f2\u00f3\u00fb \u00f2 \u00fb \u00f0\u00f0 \u00f2 \u00fa \u00f2 \u00fb \u00f8 \u00f8 \u00f4\u00f6\u00f3\u00b9 \u00f8 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00f3 \u00f3\u00f9\u00f6 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00b3\u00d7 \u00f6\u00f3\u00f9\u00f4 \u00fb \u00f0\u00f0 \u00f6 \u00f2\u00f8\u00f3 \u00f8 \u00f9\u00f8\u00f9\u00f6 \u00b8\u00f2\u00f3\u00f6 \u00f2 \u00fb \u00d7\u00d7\u00f9\u00f1 \u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00f1 \u00f2 \u00d7\u00f8\u00f6 \u00b9 \u00f8 \u00fa \u00f3\u00f6 \u00f2 \u00fe \u00f8 \u00f3\u00f2 \u00f2 \u00f6 \u00fb \u00f8 \u00f1 \u00f2\u00f8 \u00f2 \u00f2 \u00f8 \u00d7 \u00d7 \u00f1 \u00f2 \u00f8\u00b8\u00fb \u00f1\u00f3\u00d7\u00f8 \u00f6\u00f8 \u00f2\u00f0\u00fd \u00f3 \u00f2\u00f3\u00f8 \u00fb \u00f2\u00f8 \u00d7 \u00f2 \u00f0 \u00f3\u00f6 \u00f2 \u00fe \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f8 \u00d7 \u00f8 \u00d7 \u00f0\u00f0 \u00fd \u00f8\u00d7 \u00f0 \u00ba \u00e1\u00f8 \u00d7 \u00f1\u00d7 \u00f8 \u00f8 \u00f2 \u00d7\u00f9 \u00d7 \u00f8\u00f8 \u00f2 \u00b8\u00fb \u00f6 \u00fb \u00f2 \u00f9\u00d7 \u00f2 \u00f8 \u00f6 \u00f4\u00f6\u00f3 \u00f8 \u00fa \u00f6 \u00f3\u00fa \u00f6\u00fd \u00e4\u00bc\u00bc\u2104\u00b8\u00f2\u00f3\u00f6 \u00d7\u00f8 \u00f8 \u00f6\u00f3\u00f9\u00f4 \u00f1 \u00f1 \u00f6\u00d7 \u00f4\u00b8\u00f6 \u00f2 \u00f3\u00f1\u00b9 \u00fe \u00f8 \u00f3\u00f2 \u00d7 \u00f8 \u00f3\u00f2\u00f0\u00fd \u00fb \u00fd \u00f8\u00f3 \u00f3\u00ba \u00f3\u00f6\u00f8\u00f9\u00f2 \u00f8 \u00f0\u00fd\u00b8\u00f8 \u00f8 \u00f1 \u00f2 \u00f6 \u00b9 \u00f5\u00f9 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f3 \u00f3\u00f9\u00f6 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00fc \u00f2\u00f3\u00f9 \u00f8 \u00f8 \u00fb \u00f2 \u00f1\u00f4\u00f0\u00f3\u00fd \u00f8 \u00f1\u00f3\u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00fa \u00f6 \u00f2 \u00f3\u00f1 \u00fe \u00f6 \u00f1 \u00f2\u00f8 \u00f8 \u00b9 \u00f2 \u00f5\u00f9 \u00d7 \u00d7\u00f6 \u00f6 \u00fb \u00f8 \u00f3\u00f9\u00f8 \u00d7 \u00f2 \u00f2\u00f8 \u00d7 \u00f6\u00fa \u00f5\u00f9 \u00f0 \u00f8\u00fd \u00f6 \u00f9\u00f8 \u00f3\u00f2\u00ba \u00ea \u00f2\u00f8\u00f0\u00fd\u00b8 \u00f2 \u00bc\u00bd\u2104 \u00d7\u00f6 \u00f2 \u00f6 \u00b9 \u00f8 \u00f8\u00f9\u00f6 \u00f3\u00f6 \u00d7 \u00f9\u00f6 \u00f2 \u00f9\u00f0\u00f8\u00b9\u00f8\u00f3\u00f0 \u00f6 \u00f2\u00f8 \u00d7 \u00f6\u00fa \u00f6 \u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f2 \u00be\u00bd \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f9\u00d7 \u00f2 \u00f8 \u00d7 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00fb \u00f9\u00d7 \u00f2 \u00f8 \u00d7 \u00fb\u00f3\u00f6 \u00b8 \u00f0\u00f8 \u00f3\u00f9 \u00f8 \u00fb\u00f3\u00f6 \u00f6 \u00f0 \u00d7 \u00f3\u00f2 \u00f8 \u00f6\u00f3\u00f9\u00f4 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00f2 \u00d7\u00f8 \u00f8 \u00ba \u00e7\u00f8 \u00f6 \u00f6 \u00d7 \u00f6 \u00f6\u00d7 \u00fa \u00fc\u00f4\u00f0\u00f3\u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00f3\u00f6 \u00fc\u00b9 \u00f8\u00f6 \u00f8 \u00f2 \u00f3\u00f9\u00f8 \u00f8 \u00f0 \u00f2 \u00f2 \u00f6 \u00f9 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f1\u00f4\u00f0 \u00fc \u00f8\u00fd \u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f0 \u00f6 \u00b9\u00d7 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00ba \u00f0\u00f3\u00fb\u00d7 \u00f1 \u00ec \u00bf\u2104 \u00d7\u00f8\u00f6 \u00f8\u00d7 \u00fb \u00fd \u00d7\u00f3\u00f1 \u00f3 \u00f8 \u00f8 \u00f0 \u00f3 \u00f4 \u00f8\u00b9\u00f0 \u00fa \u00f0 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6\u00d7 \u00fd \u00f6\u00f3\u00f9\u00f4 \u00f2 \u00f4 \u00f8\u00d7 \u00fb \u00f8 \u00f0\u00f3\u00d7 \u00f0\u00fd \u00d7\u00f4 \u00d7 \u00f2 \u00f8 \u00f1 \u00d7 \u00f8\u00f3 \u00f8 \u00f6 \u00f2\u00f8\u00f3 \u00d7 \u00f2 \u00f0 \u00fa \u00f2\u00f8 \u00f0\u00f0 \u00f4 \u00f8 \u00f8\u00f6 \u00f2\u00ba \u00ec \u00d7 \u00d7 \u00f1\u00f3\u00f8 \u00fa \u00f8 \u00fd \u00f8 \u00f3 \u00d7 \u00f6\u00fa \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f0 \u00f2 \u00d7 \u00f3\u00f2 \u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f6 \u00f6 \u00f5\u00f9 \u00f2\u00f8\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f3\u00f0 \u00f0\u00fd \u00fd \u00f4 \u00f8\u00d7 \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00f1 \u00f3\u00fb\u00ba \u00e1\u00f2 \u00f8 \u00f3\u00f2\u00b8 \u00e0 \u00e0 \u2104 \u00fa \u00f0\u00f3\u00f4\u00d7 \u00f8\u00fb\u00f3 \u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f2 \u00f0 \u00f6 \u00d7 \u00f0 \u00f1\u00f9\u00f0\u00f8 \u00d7\u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00ba \u00ec \u00f6\u00d7\u00f8 \u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f0 \u00f1 \u00f2 \u00f8 \u00f1 \u00f2\u00f8 \u00f2 \u00f2 \u00f1 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f1 \u00f2\u00f8 \u00f2 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00d7\u00f8 \u00f8\u00f6 \u00ba \u00ec \u00d7 \u00f3\u00f2 \u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f2\u00b8 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3\u00d7\u00f8 \u00f6 \u00f0 \u00f8 \u00f8\u00f3 \u00f3\u00f9\u00f6 \u00fb\u00f3\u00f6 \u00b8 \u00d7 \u00f8 \u00f8 \u00f8 \u00fd \u00f3 \u00fb \u00fd \u00fb \u00f8 \u00f3\u00f4\u00b9 \u00fd\u00b9 \u00f3\u00f4 \u00f6\u00f3\u00f9\u00f8 \u00f2 \u00f2 \u00f2\u00d7\u00f8 \u00d7 \u00f9\u00f0 \u00f4 \u00f8 \u00b9 \u00f0 \u00fa \u00f6\u00fd \u00f6 \u00f8\u00f0\u00fd \u00f6\u00f3\u00f1 \u00d7\u00f3\u00f9\u00f6 \u00f8\u00f3 \u00d7\u00f8 \u00f2 \u00f8 \u00f3\u00f2\u00ba \u00ec \u00fd \u00f6\u00b9 \u00f2 \u00d7 \u00f8 \u00f8 \u00f8 \u00fd \u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f5\u00f9 \u00f9 \u00f2 \u00f0 \u00fd \u00f2\u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8\u00fb \u00f1 \u00f2\u00d7 \u00f8 \u00f8 \u00f6\u00f3\u00d7\u00d7 \u00f8\u00f6 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00b9 \u00f1 \u00d7\u00d7 \u00f3\u00f2 \u00f3 \u00f4 \u00f8\u00d7\u00ba \u00ef \u00f8 \u00f2\u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8 \u00f5\u00f9 \u00f9 \u00f2 \u00f0 \u00fd \u00fd \u00fa \u00f2 \u00f9\u00f4 \u00f2 \u00fb \u00f8 \u00f8\u00fb \u00f2 \u00f3\u00f2\u00f9\u00f6\u00f6 \u00f2\u00f8 \u00f3\u00fb\u00d7 \u00f2 \u00f3\u00f6 \u00f3\u00f9\u00f8 \u00f3 \u00f8 \u00d7 \u00f1 \u00f2\u00f3 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00fb \u00f0\u00d7\u00f3 \u00f2\u00f3\u00f6 \u00f6\u00f3\u00d7\u00d7 \u00f8\u00f6 \u00f8 \u00f8 \u00d7 \u00f9\u00f2\u00f6 \u00f0 \u00f8 \u00f8\u00f3 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7\u00b8 \u00f2 \u00f4\u00f6 \u00f8 \u00f2 \u00f8 \u00f6 \u00d7 \u00f2\u00f3 \u00f3\u00f8 \u00f6 \u00d7 \u00f6\u00fa \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f2 \u00f8 \u00fb\u00f3\u00f6\u00f0 \u00ba \u00f9\u00f8\u00f9\u00f6 \u00fb\u00f3\u00f6 \u00ec \u00f6 \u00f6 \u00d7 \u00fa \u00f6 \u00f0 \u00fa \u00f2\u00f9 \u00d7 \u00f3 \u00f9\u00f8\u00f9\u00f6 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00f9\u00d7\u00ba \u00eb\u00f3\u00f1 \u00f3 \u00fa \u00f3\u00f9\u00d7 \u00f6 \u00d7 \u00f6 \u00f4\u00f6\u00f3\u00f3 \u00f3 \u00f3\u00f6\u00f6 \u00f8\u00f2 \u00d7\u00d7 \u00f3 \u00f8 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0\u00d7\u00b8 \u00f9\u00f6\u00f8 \u00f6 \u00fa \u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 ae \u00f6\u00d7 \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6\u00b8 \u00f2 \u00fa \u00f0\u00f9 \u00f8 \u00f3\u00f2 \u00f3 \u00f6 \u00d7\u00f3\u00f2 \u00f0\u00fd\u00b9\u00d7 \u00fe \u00f4\u00f0\u00f3\u00fd\u00f1 \u00f2\u00f8 \u00f3 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7\u00ba \u00ef \u00f0 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00d7 \u00f1 \u00f6 \u00f0\u00fd \u00ec\u00eb\u00eb \u00f3\u00f6 \u00f4\u00f9 \u00f0 \u00fd \u00f2\u00b9 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2\u00b8 \u00d7 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bd \u00f8 \u00d7 \u00f8\u00f6 \u00fa \u00f0 \u00f8\u00f3 \u00fc\u00b9 \u00f8 \u00f2 \u00f8 \u00f8\u00f3 \u00f2 \u00f6 \u00f8\u00f6 \u00f6\u00fd \u00f3\u00f9\u00f1 \u00f2\u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f2\u00d7 \u00b8\u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f3\u00f1 \u00d7 \u00f8 \u00d7 \u00f9\u00f6 \u00f4\u00f9 \u00f0 \u00f8 \u00f3\u00f2 \u00f1 \u00f9\u00f1 \u00f3\u00f6 \u00f0\u00f3 \u00f0\u00f0\u00fd \u00f4\u00f6\u00f3\u00fa \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00d7 \u00f8 \u00f8 \u00f2 \u00f0 \u00f8 \u00f8 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00ef \u00f4\u00f0 \u00f2 \u00f8\u00f3 \u00fc\u00f8 \u00f2 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f2 \u00f8 \u00d7 \u00fb \u00fd\u00b8\u00d7 \u00f2 \u00fb \u00f6 \u00f5\u00f9 \u00f6 \u00f3\u00f9\u00f1 \u00f2\u00f8 \u00ec\u00eb\u00eb \u00f3\u00f6 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00f4\u00f6\u00f3 \u00f8\u00ba \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00d7 \u00f9\u00f8 \u00f3\u00f2 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 \u00f3 \u00f0 \u00f6 \u00f6 \u00f4\u00f6\u00f3 \u00f8 \u00f3\u00b9 \u00f9\u00d7 \u00f3\u00f2 \u00f4\u00f6\u00f3\u00fa \u00f2 \u00d7\u00f8\u00f3\u00f6 \u00d7 \u00f3 \u00f3\u00f2\u00f0 \u00f2 \u00f2 \u00f1 \u00d7\u00ba \u00f2 \u00f3\u00f2\u00f0 \u00f2 \u00f2 \u00f1 \u00f1 \u00f8 \u00f2 \u00f1 \u00f0 \u00f6 \u00d7\u00d7\u00b8 \u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f1 \u00d7\u00d7 \u00f2 \u00f2\u00b9 \u00f8 \u00f6\u00b8\u00f3\u00f6 \u00f4 \u00f6 \u00f4\u00d7 \u00fa \u00f2 \u00f8 \u00f0 \u00f4 \u00f3\u00f2 \u00f2\u00f9\u00f1 \u00f6\u00ba \u00e1\u00f8 \u00d7 \u00f0 \u00f0\u00fd \u00f8\u00f3 \u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00f8 \u00fb\u00f3\u00f6 \u00d7 \u00f3\u00fa \u00f6 \u00d7 \u00fa \u00f6 \u00f0 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f6 \u00f3\u00f2\u00f0 \u00f2 \u00f1 \u00ba \u00eb\u00f9 \u00f2 \u00f1 \u00d7 \u00f6 \u00f9\u00d7 \u00f9\u00f0 \u00f3\u00f6 \u00d7 \u00fa \u00f6 \u00f0 \u00f4\u00f9\u00f6\u00f4\u00f3\u00d7 \u00d7\u00b8 \u00f2\u00f0\u00f9 \u00f2 \u00f3\u00f2\u00f8 \u00f8 \u00f2 \u00f4 \u00f3\u00f4\u00f0 \u00f3\u00f6 \u00d7\u00d7 \u00f2 \u00f2 \u00f2\u00f8 \u00f8 \u00d7 \u00f8\u00f3 \u00f3\u00f2\u00b9 \u00f0 \u00f2 \u00f3\u00f2\u00f8\u00f6 \u00f8\u00d7\u00ba \u00ef \u00f0 \u00f8 \u00f6 \u00f6 \u00d7 \u00fa \u00f6 \u00f0 \u00f4\u00f6\u00f3 \u00f8\u00d7 \u00f2 \u00f3\u00f1\u00b9 \u00f4 \u00f2 \u00d7 \u00f8 \u00f8 \u00f1 \u00f8\u00f3 \u00f4\u00f6\u00f3\u00fa \u00f9\u00f2 \u00f5\u00f9 \u00f3\u00f2\u00f0 \u00f2 \u00f2\u00f8 \u00f6\u00d7 \u00f3\u00f6 \u00f4 \u00f3\u00f4\u00f0 \u00b4 \u00ea\u00e3\u00e2\u00bc\u00bc\u00b8\u00e5 \u00bc\u00bc\u2104 \u00f3\u00f6 \u00fb\u00fb\u00fb\u00ba\u00f3\u00f2 \u00f2 \u00f1 \u00ba\u00f3\u00f1\u00b5\u00b8\u00fb \u00f6 \u00f3 \u00b9 \u00f2 \u00fe \u00f8 \u00f8 \u00f4 \u00f3\u00f4\u00f0 \u00b3\u00d7 \u00f3\u00f2\u00f0 \u00f2 \u00f2 \u00f1 \u00d7 \u00f6 \u00f0 \u00f0\u00fd \u00f8\u00f3 \u00f2 \u00f9 \u00f8\u00f3 \u00f2 \u00d7 \u00f2 \u00f1\u00f4\u00f0\u00f3\u00fd\u00f1 \u00f2\u00f8 \u00f3\u00f6 \u00f3 \u00f6 \u00f4 \u00f0 \u00f6 \u00d7\u00d7 \u00f3\u00f6 \u00b9 \u00f9\u00d7 \u00f8 \u00f3\u00f1\u00f4 \u00f2 \u00d7 \u00f3\u00d7\u00f8 \u00f2 \u00f8 \u00f3\u00f2\u00f0 \u00f2 \u00f2 \u00f1 \u00d7 \u00f3 \u00f3\u00f9\u00f8 \u00f3 \u00f9\u00d7 \u00f2 \u00d7\u00d7 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f0\u00fa \u00d7 \u00f2 \u00f2 \u00f1 \u00d7\u00ba \u00e3\u00f2\u00f3\u00fb \u00f2 \u00f2 \u00f3\u00f0 \u00f3\u00f2\u00f0 \u00f2 \u00f2 \u00f1 \u00f3\u00f6 \u00f4 \u00f6\u00d7\u00f3\u00f2 \u00d7 \u00f8 \u00f9\u00d7 \u00f2\u00f3 \u00f0\u00f4 \u00f2 \u00f6 \u00f2 \u00f8 \u00f8 \u00f4 \u00f6\u00d7\u00f3\u00f2 \u00f8 \u00f6 \u00d7 \u00f2\u00f3 \u00fb \u00fd \u00f8\u00f3 \u00f2 \u00f8 \u00f2 \u00fb \u00f2 \u00f1 \u00f6\u00f3\u00f1 \u00f8 \u00f3\u00f0 \u00f3\u00f2 \u00ba \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f2\u00fd\u00f3\u00f2 \u00fb \u00d7 \u00d7 \u00f8\u00f3 \u00f3 \u00d7\u00f3\u00b8\u00f3\u00f9\u00f6 \u00f2 \u00f1 \u00f2 \u00d7\u00f8\u00f3\u00f6\u00fd \u00d7 \u00f6\u00fa \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f4 \u00f3\u00f4\u00f0 \u00f8\u00f3 \u00f4\u00f6\u00f3\u00fa \u00f2 \u00f9\u00f8 \u00f2\u00f8 \u00f8 \u00d7\u00b9 \u00f8\u00f3\u00f6\u00fd \u00f3 \u00f8 \u00f6 \u00f3\u00f2\u00f0 \u00f2 \u00f2 \u00f1 \u00d7\u00b8\u00fb \u00d7 \u00f0 \u00d7\u00f8 \u00f3 \u00d7 \u00f2 \u00f1 \u00f4\u00b9 \u00f4 \u00f2 \u00d7 \u00f8\u00fb \u00f2 \u00f2 \u00f1 \u00f2 \u00f8 \u00f2 \u00fc\u00f8 \u00f1\u00f3\u00d7\u00f8 \u00f6 \u00f2\u00f8 \u00f2 \u00f1 \u00ba \u00ef \u00f2 \u00fa \u00f2 \u00f2 \u00f3\u00f0 \u00f2 \u00f1 \u00b4 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f8 \u00f1 \u00f6 \u00f1 \u00f9\u00f6 \u00f2 \u00fb \u00f8 \u00f8 \u00f2 \u00f1 \u00fb \u00d7 \u00fa \u00f0 \u00b5\u00b8\u00f8 \u00d7\u00f8\u00f3\u00f6\u00fd \u00d7 \u00f6\u00fa \u00f6 \u00f8\u00f9\u00f6\u00f2\u00d7 \u00f8 \u00f2 \u00fb \u00d7\u00f8 \u00f3\u00f2\u00f0 \u00f2 \u00f2\u00f8 \u00f6 \u00f3\u00f6 \u00f8 \u00f8 \u00f4 \u00f6\u00d7\u00f3\u00f2\u00ba \u00ec \u00d7\u00f8\u00f3\u00f6\u00fd \u00d7 \u00f6\u00fa \u00d7 \u00f2 \u00fc \u00f1\u00f4\u00f0 \u00f3 \u00f9\u00f8 \u00f2\u00f8 \u00f8 \u00f6 \u00fa \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2\u00ba \u00e5 \u00f4\u00f4 \u00f2 \u00d7 \u00f8\u00fb \u00f2 \u00f2 \u00f3\u00f0 \u00f2 \u00f1 \u00f2 \u00f2 \u00fb \u00f6 \u00f2 \u00f1 \u00f2 \u00f8 \u00d7 \u00f6\u00fa \u00f1 \u00fd \u00f9\u00f8 \u00f2\u00f8 \u00f8 \u00f9\u00d7 \u00f2 \u00f4\u00f9 \u00f0 \u00fd \u00f8 \u00f8 \u00d7 \u00f2\u00f3 \u00f0\u00f3\u00f2 \u00f6 \u00fa \u00f0 \u00ba \u00ec \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00d7 \u00f8 \u00f9\u00d7 \u00f2 \u00d7\u00d7 \u00f2\u00f8 \u00f0 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 \u00f8 \u00f8 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00fa \u00f0 \u00f8 \u00f8 \u00f9\u00f8 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f0 \u00f2 \u00f2 \u00f4 \u00f6\u00d7\u00f3\u00f2\u00b3\u00d7 \u00f2 \u00f1 \u00f2 \u00d7\u00f8\u00f3\u00f6\u00fd\u00b8 \u00f2 \u00fb \u00fb\u00f3\u00f9\u00f0 \u00f0 \u00f8\u00f3 \u00f2 \u00d7 \u00f9 \u00f0 \u00f2 \u00f8 \u00d7\u00f8\u00f3\u00f6\u00fd \u00d7 \u00f6\u00fa \u00f2 \u00fa \u00f0\u00f9 \u00f8 \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00f2 \u00f8 \u00f8 \u00f3\u00f2\u00f8 \u00fc\u00f8\u00ba \u00bd\u00bc \u00f3\u00f2\u00f0\u00f9\u00d7 \u00f3\u00f2 \u00e1\u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00fb \u00d7 \u00f3\u00fb \u00f8 \u00f8 \u00f8 \u00d7 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00f3 \u00f9 \u00f0 \u00d7 \u00f9\u00f6 \u00f6 \u00f0 \u00f0 \u00f2 \u00d7\u00f9\u00f6\u00fa \u00fa \u00f0 \u00d7 \u00f6\u00fa \u00d7 \u00f2 \u00f4 \u00f6\u00b9\u00f8\u00f3\u00b9\u00f4 \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f9\u00d7 \u00f2 \u00fd\u00fe \u00f2\u00f8 \u00f2 \u00f9\u00f0\u00f8\u00b9\u00f8\u00f3\u00f0 \u00f6 \u00f2\u00f8 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0\u00d7\u00ba \u00e8\u00f6\u00f3 \u00f3\u00f4 \u00f9\u00d7 \u00d7 \u00f0 \u00f8\u00f3 \u00f3 \u00f6 \u00f4\u00f9 \u00f0 \u00fd \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00f6\u00f3\u00f9\u00f2 \u00d7 \u00f3\u00f2 \u00f8 \u00f3\u00f6\u00b9 \u00f6 \u00f3 \u00f3\u00f9\u00f4\u00f0 \u00f3 \u00fd\u00d7 \u00f3\u00f6 \u00bd \u00b9\u00f2\u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fa \u00f2 \u00f2 \u00f8 \u00d7 \u00fb \u00f6 \u00f2 \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f9\u00d7 \u00d7 \u00f8 \u00f1 \u00fc \u00f1\u00f9\u00f1 \u00f1 \u00f0\u00b9 \u00f0\u00f3\u00fb \u00fb \u00f8 \u00f2 \u00f3\u00f9\u00f6 \u00f9\u00f0\u00f8 \u00f1\u00f3 \u00f0\u00ba \u00ea\u00f3\u00f9\u00f2 \u00d7 \u00f3\u00f2 \u00f8 \u00f3\u00f6 \u00f6 \u00f3 \u00f3\u00f9\u00f4\u00f0 \u00f3 \u00fd\u00d7\u00b8\u00f3\u00f6 \u00fa \u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f6 \u00f6 \u00f3 \u00fb \u00b8 \u00f6 \u00d7\u00f9 \u00b9 \u00f2\u00f8 \u00f8\u00f3 \u00d7\u00f9\u00f4\u00f4\u00f3\u00f6\u00f8 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2\u00d7\u00b8\u00d7\u00f9 \u00d7 \u00f6 \u00fa \u00f0 \u00f3 \u00f4\u00f9 \u00b9 \u00f0 \u00fd \u00d7\u00f2 \u00f4\u00d7 \u00f3\u00f8\u00d7\u00b8\u00fb \u00f6 \u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f8\u00d7 \u00f0 \u00f2 \u00d7 \u00d7\u00f0\u00f3\u00fb\u00f0\u00fd\u00ba \u00e1\u00f2 \u00f3\u00f2\u00f8\u00f6 \u00d7\u00f8 \u00f8\u00f3 \u00f2\u00f8\u00f6 \u00f0 \u00fe \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00b8\u00f8 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00d7 \u00f6\u00fa \u00f2 \u00d7\u00f9\u00f6\u00fa \u00fa \u00f2 \u00d7 \u00f2 \u00f4\u00f9 \u00f0 \u00fd\u00d7 \u00f2 \u00fa \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f2 \u00f2 \u00d7 \u00f6\u00fa \u00f4\u00f6\u00f3\u00fa \u00f6 \u00f1 \u00f1 \u00f6\u00d7 \u00f4 \u00f3\u00fa \u00f6 \u00f8 \u00f1 \u00ba \u00ec \u00d7 \u00f6\u00fa \u00f2 \u00fa \u00f0 \u00f8 \u00f3\u00f9\u00f1 \u00f2\u00f8\u00d7 \u00d7 \u00f2 \u00f2 \u00f8 \u00f4 \u00d7\u00f8 \u00fb \u00f8 \u00fd\u00d7 \u00f2\u00f3 \u00f0\u00f3\u00f2 \u00f6 \u00f2 \u00d7 \u00f6\u00fa \u00f2 \u00fd \u00f2\u00f8 \u00f8 \u00d7 \u00f8 \u00f8 \u00fa \u00d7 \u00f8\u00f3 \u00fc \u00d7\u00f8\u00ba \u00ec \u00d7 \u00f4\u00f9 \u00f0 \u00fd \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00f2 \u00f0\u00d7\u00f3 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f6 \u00f3 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00d7 \u00f6\u00fa \u00f3\u00f6 \u00f3\u00f8 \u00f6 \u00f2 \u00d7 \u00f3 \u00f3\u00f9\u00f1 \u00f2\u00f8\u00d7\u00b8 \u00f0\u00d7\u00f3 \u00f9 \u00f0\u00f8 \u00f2 \u00f4 \u00f6\u00b9\u00f8\u00f3\u00b9\u00f4 \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00b8 \u00f2 \u00fa \u00f9 \u00f0 \u00f2\u00f3 \u00d7 \u00f2 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f1 \u00fd \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f8 \u00f3\u00f9\u00f1 \u00f2\u00f8\u00d7 \u00d7\u00f9 \u00f1 \u00f8\u00f8 \u00f8\u00f3 \u00f8 \u00f1 \u00fb \u00f8 \u00f3\u00f9\u00f8 \u00f3\u00f2\u00d7\u00f9\u00f0\u00f8 \u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00f2\u00f3 \u00d7\u00b8 \u00f2 \u00f8 \u00f9\u00d7 \u00fb \u00f8 \u00f3\u00f2\u00f0\u00fd \u00f0\u00f3 \u00f0 \u00f3\u00fa \u00f6 \u00f3\u00f6 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4\u00ba \u00fa \u00f6\u00fd \u00f3\u00f2 \u00f2 \u00fb \u00f0 \u00b8\u00f8 \u00d7 \u00f2\u00f3 \u00d7 \u00d7\u00f9 \u00f1 \u00f8 \u00be\u00be \u00f8 \u00f6\u00f3\u00f9\u00f2 \u00d7 \u00d7 \u00f3 \u00f8 \u00f6 \u00f2 \u00fa \u00f9 \u00f0 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00f3\u00f6\u00f8\u00d7 \u00f8\u00f3 \u00f8 \u00f6\u00f3\u00f9\u00f4 \u00f3\u00f6 \u00f6 \u00f1 \u00f2\u00f8\u00ba \u00bd\u00bd \u00f2\u00f3\u00fb\u00f0 \u00f1 \u00f2\u00f8\u00d7 \u00ec \u00d7 \u00fb\u00f3\u00f6 \u00d7 \u00d7\u00f9\u00f4\u00f4\u00f3\u00f6\u00f8 \u00fd \u00f8 \u00eb\u00f8 \u00f2 \u00f3\u00f6 ae \u00f8\u00fb\u00f3\u00f6 \u00f2 \u00ea \u00b9 \u00d7 \u00f6 \u00f2\u00f8 \u00f6\u00b8 \u00f2 \u00fd \u00ea\u00e8 \u00b4\u00f3\u00f2\u00f8\u00f6 \u00f8 ae \u00bc\u00bc\u00bd\u00b9\u00bc\u00bc\u00b9 \u00b9 \u00bc\u00bd \u00b5\u00ba \u00e8 \u00f8\u00f6\u00f3\u00d7 \u00e5 \u00f2 \u00f8 \u00d7 \u00d7 \u00d7\u00f9\u00f4\u00f4\u00f3\u00f6\u00f8 \u00fd \u00ed\u00eb ae\u00e1 \u00eb \u00f3\u00f0 \u00f6 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f4\u00ba \u00ec \u00f6 \u00d7 \u00f6 \u00f2\u00f0\u00f9 \u00f2 \u00f8 \u00d7 \u00fb\u00f3\u00f6 \u00d7 \u00f2 \u00f8\u00f8 \u00f6 \u00f8\u00f0\u00fd \u00f6\u00f3\u00f1 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f2\u00d7 \u00fb \u00f8 \u00f2 \u00f8 \u00f4 \u00f6\u00b9\u00f8\u00f3\u00b9\u00f4 \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b9 \u00f2 \u00f6 \u00d7 \u00f6 \u00f6\u00f3\u00f9\u00f4 \u00f8 \u00eb\u00f8 \u00f2 \u00f3\u00f6 \u00b8 \u00d7 \u00fb \u00f0\u00f0 \u00d7 \u00fb \u00f8 \u00e3 \u00fa \u00f2 \u00e4 \u00b8 \u00f2 \u00f3\u00f2 \u00b8\u00e8 \u00f8\u00f6 \u00e4 \u00f2\u00f3\u00f0\u00f2 \u00f2 \u00e5 \u00f1 \u00ea\u00f3\u00f9\u00d7\u00d7\u00f3\u00f4\u00f3\u00f9\u00f0\u00f3\u00d7\u00ba \u00ef \u00f8 \u00f2 \u00f8 \u00f1 \u00f3\u00f6 \u00f8 \u00f6 \u00f2\u00fa \u00f0\u00f9 \u00f0 \u00f0\u00f4\u00ba \u00ea \u00f6 \u00f2 \u00d7 \u00ec \u00bf\u2104 \u00e2\u00f3\u00f2 \u00b9\u00eb\u00f9 \u00f2\u00b8\u00e8 \u00f8 \u00f6 \u00ba \u00f2\u00fe \u00b8 \u00f3\u00f6 \u00d7\u00f8\u00f6 \u00f2\u00b8 \u00f2 \u00f6 \u00f2 \u00ec \u00f1\u00f1 \u00f6\u00f1 \u00f2\u00ba \u00e0\u00fd \u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f2 \u00f2 \u00fb \u00f8 \u00b9 \u00f0 \u00fd \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00f2 \u00f8\u00b9 \u00fb\u00f3\u00f6 \u00d7\u00ba \u00e1\u00f2 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00bd \u00bf \u00e5 \u00eb\u00e1 \u00e5 \u00ec\u00b9 \u00ea\u00e1 \u00eb \u00f3\u00f2 \u00f6 \u00f2 \u00f3\u00f2 \u00e5 \u00d7\u00f9\u00f6 \u00f1 \u00f2\u00f8 \u00f2 \u00f1\u00f3 \u00f0 \u00f2 \u00f3 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00d7\u00b8\u00f4 \u00d7 \u00be \u00bc \u00be \u00bd\u00b8\u00eb \u00f2\u00f8 \u00f0 \u00f6 \u00b8 \u00b8\u00ed\u00eb \u00b8\u00e5 \u00fd \u00bd \u00d7 \u00f3 \u00f8 \u00be\u00f2 \u00e5 \u00eb\u00fd\u00f1\u00b9 \u00f4\u00f3\u00d7 \u00f9\u00f1 \u00f3\u00f2 \u00e8\u00f6 \u00f2 \u00f4\u00f0 \u00d7 \u00f3 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f2 \u00b4\u00e8\u00e7 \u00b5\u00b8\u00f4 \u00d7 \u00be \u00bf\u00bc\u00b8\u00e5\u00f3\u00f2\u00f8\u00f6 \u00f0\u00b8 \u00f2 \u00b8 \u00f9\u00b9 \u00f9\u00d7\u00f8 \u00bd \u00bf\u00ba \u00e5 \u00e8\u00f6 \u00d7\u00d7\u00ba \u00bc\u00bd\u2104 \u00f6 \u00d7\u00f8 \u00f2 \u00f2\u00ba \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f2 \u00f8\u00f6\u00f9\u00d7\u00f8 \u00f3\u00f2 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00b9 \u00f2 \u00f8\u00ba \u00e1\u00f2 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f2 \u00f6\u00b9 \u00f2 \u00f3\u00f2 \u00f4 \u00f2 \u00f0 \u00eb\u00fd\u00d7\u00f8 \u00f1\u00d7 \u00f2 ae \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00b4 \u00ebae\u00b9 \u00be\u00bc\u00bc\u00bd\u00b5\u00b8 \u00f8 \u00f3\u00f6 \u00b8\u00eb\u00fb \u00f2\u00b8\u00e2\u00f9\u00f2 \u00be\u00bc\u00bc\u00bd\u00ba \u00e1 \u00f2 \u00ba \u00e1\u00f2 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00bf\u00f6 \u00eb\u00fd\u00f1\u00f4\u00f3\u00d7 \u00f9\u00f1 \u00f3\u00f2 \u00e7\u00f4 \u00f6 \u00f8 \u00f2 \u00eb\u00fd\u00d7\u00f8 \u00f1\u00d7 \u00d7 \u00f2 \u00f2 \u00e1\u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00b4\u00e7\u00eb \u00e1 \u00bd \u00b5\u00b8ae \u00fb \u00e7\u00f6\u00f0 \u00f2\u00d7\u00b8\u00e4 \u00ed\u00eb \u00f3\u00f4 \u00f3\u00f2 \u00d7 \u00f2 \u00e1\u00d7\u00d7\u00f9 \u00d7 \u00f2 \u00f2\u00f3\u00f2\u00fd\u00f1 \u00f8\u00fd \u00f2 \u00ed\u00f2\u00f3 \u00d7 \u00f6\u00fa \u00f0 \u00f8\u00fd\u00b8\u00fa\u00f3\u00f0\u00f9\u00f1 \u00be\u00bc\u00bc \u00f3 \u00e4 \u00f8\u00f9\u00f6 ae\u00f3\u00f8 \u00d7 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00eb \u00f2 \u00b8\u00f4 \u00d7 \u00b8 \u00f6 \u00f0 \u00fd\u00b8 \u00ed\u00eb \u00b8\u00e2\u00f9\u00f0\u00fd \u00be\u00bc\u00bc\u00bc\u00ba \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f2\u00b9 \u00f6 \u00f2 \u00f3\u00f2 \u00f8 \u00ec \u00f3\u00f6\u00fd \u00f2 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f6\u00fd\u00f4\u00b9 \u00f8\u00f3 \u00f6 \u00f4 \u00ec \u00f2 \u00f5\u00f9 \u00d7 \u00b4 \u00ed\u00ea\u00e7 \u00ea \u00e8\u00ec \u00be\u00bc\u00bc\u00bd\u00b5\u00b8\u00fa\u00f3\u00f0\u00b9 \u00f9\u00f1 \u00be\u00bc \u00f3 \u00e4 \u00f8\u00f9\u00f6 ae\u00f3\u00f8 \u00d7 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00eb \u00f2 \u00f4 \u00d7 \u00bd \u00be \u00bd \u00b8\u00e1\u00f2\u00f2\u00d7 \u00f6\u00f9 \u00b8\u00ec\u00fd\u00f6\u00f3\u00f0\u00b8 \u00f9\u00d7\u00f8\u00f6 \u00b8\u00e5 \u00f0 \u00f3\u00f2 \u00f6 \u00f2 \u00f3\u00f2 \u00f8 \u00ec \u00f3\u00f6\u00fd \u00f2 \u00f4\u00f4\u00f0 \u00b9 \u00f8 \u00f3\u00f2 \u00f3 \u00f6\u00fd\u00f4\u00f8\u00f3 \u00f6 \u00f4 \u00ec \u00f2 \u00f5\u00f9 \u00d7 \u00b4 \u00ed\u00ea\u00e7 \u00ea \u00e8\u00ec \u00b5\u00b8\u00fa\u00f3\u00f0\u00f9\u00f1 \u00bd \u00be \u00f3 \u00e4 \u00f8\u00f9\u00f6 ae\u00f3\u00f8 \u00d7 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00eb \u00f2 \u00b8\u00f4 \u00d7 \u00be \u00bf\u00bd\u00bc\u00b8\u00e8\u00f6 \u00f9 \u00b8 \u00fe \u00ea \u00f4\u00f9 \u00f0 \u00e1\u00f2 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00eb \u00fc\u00f8 \u00e1\u00f2\u00b9 \u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00eb\u00fd\u00f1\u00f4\u00f3\u00d7 \u00f9\u00f1 \u00f3\u00f2 \u00e5\u00f3 \u00f0 \u00f2 \u00f2 \u00f0\u00fd\u00d7 \u00d7 \u00f2 \u00eb \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00f2 \u00ec \u00f0 \u00f3\u00f1\u00f1\u00f9\u00f2 \u00f8 \u00f3\u00f2\u00d7 \u00eb\u00fd\u00d7\u00f8 \u00f1\u00d7 \u00b4\u00e5 \u00eb \u00e7\u00ec\u00eb \u00b3 \u00b5\u00b8\u00f4 \u00d7 \u00be \u00bd \u00f2\u00f8\u00ba \u00e2\u00f3\u00f9\u00f6\u00f2 \u00f0 \u00f3 \u00f6\u00fd\u00f4\u00b9 \u00f8\u00f3\u00f0\u00f3 \u00fd \u00f8 \u00f3\u00f9\u00f6\u00f2 \u00f0 \u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00d7\u00d7\u00f3 \u00b9 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f6\u00fd\u00f4\u00f8\u00f3\u00f0\u00f3 \u00ea \u00d7 \u00f6 \u00b8\u00bf\u00b4\u00be\u00b5 \u00bd\u00bd\u00bd\u00b8\u00bd \u00bd\u00ba \u00e2\u00f9\u00d7 \u2104 \u00e5 \u00f0 \u00e2\u00f9\u00d7\u00f8\u00ba \u00eb\u00f3\u00f1 \u00f8 \u00f1 \u00d7\u00f8 \u00f1\u00f4 \u00f2 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00f0\u00b9 \u00f9\u00f6 \u00d7\u00ba \u00e1\u00f2 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00eb\u00fd\u00f1\u00f4\u00f3\u00d7 \u00f9\u00f1 \u00f3\u00f2 ae \u00f8\u00b9 \u00fb\u00f3\u00f6 \u00f2 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00eb \u00f9\u00f6 \u00f8\u00fd \u00b4ae \u00eb\u00eb \u00b5\u00b8\u00eb \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f2 \u00f6 \u00f2 \u00f3\u00f2 \u00f6 \u00f8 \u00f8\u00f9\u00f6 \u00f0 \u00d7\u00f9\u00f4\u00b9 \u00f4\u00f3\u00f6\u00f8 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00f1 \u00f2 \u00f0 \u00f2 \u00f9 \u00d7 \u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f2 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00d7 \u00b4 \u00eb\u00e8\u00e4\u00e7\u00eb \u00be\u00bc\u00bc\u00bc\u00b5\u00b8\u00f4 \u00d7 \u00bd \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00ba \u00e5 \u00ec\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f2 \u00e8\u00f6\u00f3 \u00f6 \u00f1\u00f1 \u00f2 \u00e4 \u00f2 \u00f9 \u00d7 \u00f2 \u00eb\u00fd\u00d7\u00f8 \u00f1\u00d7\u00b8 \u00b4\u00bf\u00b5 \u00bf \u00be \u00bc\u00bd\u00b8\u00e2\u00f9\u00f0\u00fd \u00bd \u00be\u00ba \u00e4\u00ee \u00f2\u00f2\u00fd \u00e8 \u00f2 \u00d7\u00b8 \u00f2 \u00e7\u00f1 \u00f6 \u00ea \u00f2 \u00f3\u00f0 \u00ba \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f4\u00d7 \u00f9 \u00f3\u00b9\u00f6 \u00f2 \u00f3\u00f1 \u00f9\u00f2\u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00e3 \u00d7\u00ba \u00e1\u00f2 \u00e2 \u00f5\u00f9 \u00d7 \u00eb\u00f8 \u00f6\u00f2\u00b8 \u00f8\u00f3\u00f6\u00b8\u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00b9 \u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f2 \u00f6 \u00f2 \u00f3\u00f2 \u00f8 \u00ec \u00f3\u00f6\u00fd \u00f2 \u00f4\u00f4\u00f0 \u00b9 \u00f8 \u00f3\u00f2 \u00f3 \u00f6\u00fd\u00f4\u00f8\u00f3 \u00f6 \u00f4 \u00ec \u00f2 \u00f5\u00f9 \u00d7 \u00b4 \u00ed\u00ea\u00e7 \u00ea \u00e8\u00ec \u00b5\u00b8\u00fa\u00f3\u00f0\u00f9\u00f1 \u00bd \u00be \u00f3 \u00e4 \u00f8\u00f9\u00f6 ae\u00f3\u00f8 \u00d7 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00eb \u00f2 \u00b8\u00f4 \u00d7 \u00bf\u00be \u00bf \u00b8\u00e8\u00f6 \u00f9 \u00b8 \u00fe \u00ea \u00f4\u00f9 \u00f0 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f2 \u00f6 \u00f2 \u00f3\u00f2 \u00f8 \u00ec \u00f3\u00f6\u00fd \u00f2 \u00f4\u00b9 \u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f6\u00fd\u00f4\u00f8\u00f3 \u00f6 \u00f4 \u00ec \u00f2 \u00f5\u00f9 \u00d7 \u00b4 \u00ed\u00ea\u00e7\u00b9 \u00ea \u00e8\u00ec \u00bd \u00bd\u00b5\u00b8\u00fa\u00f3\u00f0\u00f9\u00f1 \u00f3 \u00e4 \u00f8\u00f9\u00f6 ae\u00f3\u00f8 \u00d7 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f6 \u00eb \u00f2 \u00b8\u00f4 \u00d7 \u00be\u00be \u00be \u00b8 \u00f6 \u00f8\u00f3\u00f2\u00b8\u00ed\u00e3\u00b8 \u00f4\u00f6 \u00f0 \u00bd \u00bd\u00ba \u00e1\u00f2\u00f8 \u00f6\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00d7\u00d7\u00f3 \u00f2 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00ba \u00e1\u00f2 \u00e8\u00f6\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 \u00f8\u00ed\u00eb ae\u00e1 \u00eb \u00f9\u00f6 \u00f8\u00fd \u00eb\u00fd\u00f1\u00f4\u00f3\u00d7 \u00f9\u00f1\u00b8\u00f4 \u00d7 \u00be\u00b8 \u00f2\u00fa \u00f6\u00b8 \u00e7\u00b8\u00ed\u00eb \u00b8 \u00f9 \u00f9\u00d7\u00f8 \u00be\u00bc\u00bc\u00bc\u00ba \u00ed\u00eb ae\u00e1 \u00d7\u00d7\u00f3 \u00f8 \u00f3\u00f2\u00b8\u00ed\u00eb ae\u00e1 \u00d7\u00d7\u00f3 \u00f8 \u00f3\u00f2 \u00e8\u00f6 \u00d7\u00d7\u00ba \u00b0\u00e1 \u00ec \u00ea \u00f4\u00f3\u00f6\u00f8\u00ba\u00f8 \u00fc\u00b8\u00fa \u00bd\u00ba \u00bc \u00be\u00bc\u00bc\u00bd\u00bb\u00bc \u00bb\u00be \u00be\u00be \u00bf\u00bd \u00f1 \u00f2 \u00f8 \u00d7 \u00fc\u00f4 \u00b0\u00be",
        "prob": 0.891111111111111
    }, {
        "ID": 1064,
        "phrase": " sia allora x l'insieme degli 'upper bound' relativi ai sistemi numerici di ciascun elemento di x, determinati per ciascun elemento x i di x come segue: 1",
        "prob": 0.5352941176470588
    }, {
        "ID": 1359,
        "phrase": " if the gold standard reflects a systematic conceptualization of a person, machine learning algorithms can learn to replicate these conceptualization (categorizations in this case), and achieve high degrees of agreement with the person behind the gold standard",
        "prob": 0.27307692307692316
    }, {
        "ID": 1704,
        "phrase": " for example, under reasonable assumptions about pr \u2212 , o = 1 has much lower explanatory power than, say, ml 1 = 1",
        "prob": 0.29285714285714287
    }, {
        "ID": 1704,
        "phrase": " in particular, they agree that o = 1 has very low explanatory power, while ml 1 = 1 has high explanatory power",
        "prob": 0.4692307692307693
    }, {
        "ID": 1705,
        "phrase": " for example, under reasonable assumptions about pr \u2212 , o = 1 has much lower explanatory power than, say, ml 1 = 1",
        "prob": 0.29285714285714287
    }, {
        "ID": 1705,
        "phrase": " in particular, they agree that o = 1 has very low explanatory power, while ml 1 = 1 has high explanatory power",
        "prob": 0.4692307692307693
    }, {
        "ID": 1706,
        "phrase": " for example, under reasonable assumptions about pr \u2212 , o = 1 has much lower explanatory power than, say, ml 1 = 1",
        "prob": 0.3642857142857143
    }, {
        "ID": 1706,
        "phrase": " in particular, they agree that o = 1 has very low explanatory power, while ml 1 = 1 has high explanatory power",
        "prob": 0.4692307692307693
    }, {
        "ID": 2333,
        "phrase": "y \u2032 n x \u2032\u2032 r=0 \u00b5 ai 1 (yx rn+1 ",
        "prob": 0.18333333333333335
    }, {
        "ID": 3031,
        "phrase": " \n\t\t\t this notation has also been used in the standard ml of new jersey compiler (shao et al",
        "prob": 0.5916666666666667
    }, {
        "ID": 3180,
        "phrase": " \n concurrent ml the language we use to express our concurrent framework is concurrent ml (cml)  [18] , a concurrent extension of the mostly-functional language standard ml (sml)  [11] ",
        "prob": 0.3227272727272727
    }, {
        "ID": 3180,
        "phrase": " concurrent ml is currently distributed with the standard ml of new jersey compiler  [1] ",
        "prob": 0.5461538461538462
    }, {
        "ID": 3180,
        "phrase": " first, this project is but a first step in implementing a win32 interface to standard ml of new jersey",
        "prob": 0.4066666666666667
    }, {
        "ID": 3181,
        "phrase": " this paper describes a library for the programming language standard ml (sml)  [24]  that implements the essence of the reactive paradigm, as described by boussinot  [6] : the notions of instants and activations",
        "prob": 0.3380952380952381
    }, {
        "ID": 3181,
        "phrase": " the library was implemented with the standard ml of new jersey compiler  [2] ",
        "prob": 0.5545454545454546
    }, {
        "ID": 3181,
        "phrase": " sample reactive code would look like: if we were to implement the reactive \"instructions\" approach in sml via a datatype description as above, we would obtain something like the following: a reactive library implemented via reactive instructions (using the model of sugarcubes) is part of the standard ml of new jersey library 3 ",
        "prob": 0.2657894736842106
    }, {
        "ID": 3183,
        "phrase": " sp\u00e9cifiquement, nous \u00e9tudions la programmation d'applications dites natives win32 sous un syst\u00e8me windows avec le langage fonctionnel standard ml (sml)  [7] ",
        "prob": 0.6894736842105263
    }, {
        "ID": 3183,
        "phrase": " un prototype du syst\u00e8me existe, et est implant\u00e9 avec le compilateur standard ml of new jersey  [1] ",
        "prob": 0.7000000000000001
    }, {
        "ID": 3183,
        "phrase": " l'argument n'est pas si grave pour standard ml qui poss\u00e8de un support respectable pour la programmation imp\u00e9rative, mais rend l'expression de programmes win32 natifs en haskell (ou tout langage fonctionnel pur) probl\u00e9matique",
        "prob": 0.6839999999999998
    }, {
        "ID": 3183,
        "phrase": " il est possible de contourner ce probl\u00e8me en utilisant concurrent ml  [11] ",
        "prob": 0.21000000000000002
    }, {
        "ID": 3183,
        "phrase": " le probl\u00e8me de cette approche dans notre cas est que cr\u00e9er des librairies dynamiques avec standard ml of new jersey n'est pas r\u00e9ellement support\u00e9",
        "prob": 0.44999999999999996
    }, {
        "ID": 3183,
        "phrase": " un prototype existe pour le compilateur standard ml of new jersey, et sert comme base exp\u00e9rimentale pour explorer diff\u00e9rentes id\u00e9es",
        "prob": 0.5611111111111111
    }, {
        "ID": 3183,
        "phrase": " pour standard ml, une direction int\u00e9ressante consiste en l'implantation d'une librairie dans le style de exene  [3] , une interface graphique pour le syst\u00e8me x, qui utilise concurrent ml  [11]  pour traiter le parall\u00e9lisme implicite des interfaces graphiques",
        "prob": 0.444
    }, {
        "ID": 3183,
        "phrase": " une remarque finale: notre infrastructure est bas\u00e9 sur le compilateur standard ml of new jersey, mais n'est certainement pas restreinte \u00e0 ce syst\u00e8me",
        "prob": 0.6529411764705882
    }, {
        "ID": 3183,
        "phrase": " a standard ml compiler",
        "prob": 0.4428571428571429
    }, {
        "ID": 3184,
        "phrase": " we take as our starting point the language standard ml (sml)  [20] ",
        "prob": 0.31
    }, {
        "ID": 4407,
        "phrase": " how would the infinitesimal squared distance, ds, change under a change of coordinate systems? here it is: (ds \u2032 ) 2 = l k i \u2202x \u2032i \u2202x k \u2202x \u2032i \u2202x l dx k dx l (20) by introducing the quantities g kl = i \u2202x \u2032i \u2202x k \u2202x \u2032i \u2202x l (21) we can rewrite the formula as ds 2 = g kl dx k dx l (22) notice that g kl dx l = \u2202 \u2202x k g ml dx m dx l = \u2202 \u2202x k ds 2 (23) if we take the infinitesimal squared distance, ds 2 , to be unity, multiplying by g kl accomplished a conversion from the infinitesimal quantity dx l to \u2202/\u2202x k ",
        "prob": 0.7977272727272726
    }, {
        "ID": 4408,
        "phrase": " how would the infinitesimal squared distance, ds, change under a change of coordinate systems? here it is: (ds \u2032 ) 2 = l k i \u2202x \u2032i \u2202x k \u2202x \u2032i \u2202x l dx k dx l (20) by introducing the quantities g kl = i \u2202x \u2032i \u2202x k \u2202x \u2032i \u2202x l (21) we can rewrite the formula as ds 2 = g kl dx k dx l (22) notice that g kl dx l = \u2202 \u2202x k g ml dx m dx l = \u2202 \u2202x k ds 2 (23) if we take the infinitesimal squared distance, ds 2 , to be unity, multiplying by g kl accomplished a conversion from the infinitesimal quantity dx l to \u2202/\u2202x k ",
        "prob": 0.7977272727272726
    }, {
        "ID": 4438,
        "phrase": " essentially by introducing the prefilter 1 ai and the postfilter a i , the quantizer q 1 (\u2022) is converted to the quantizer q i,1 (\u2022) for which q i,1 (x) = a i q 1 ( x a i )",
        "prob": 0.4636363636363637
    }, {
        "ID": 4804,
        "phrase": " for coherent demodulation ml receivers based on a trellis search and on a sphere/lattice decoder have been implemented",
        "prob": 0.22142857142857145
    }, {
        "ID": 5077,
        "phrase": " for example, instead of representing a delimited continuation as a function and apply it as such, we could represent it as a continuation and apply it with a 'throw' operator as in maclisp and standard ml of new jersey",
        "prob": 0.8227272727272725
    }, {
        "ID": 5078,
        "phrase": " for example, instead of representing a delimited continuation as a function and apply it as such, we could represent it as a continuation and apply it with a 'throw' operator as in maclisp and standard ml of new jersey",
        "prob": 0.8227272727272725
    }, {
        "ID": 5079,
        "phrase": " for example, instead of representing a delimited continuation as a function and apply it as such, we could represent it as a continuation and apply it with a 'throw' operator as in maclisp and standard ml of new jersey",
        "prob": 0.8227272727272725
    }, {
        "ID": 5080,
        "phrase": " for example, instead of representing a delimited continuation as a function and apply it as such, we could represent it as a continuation and apply it with a 'throw' operator as in maclisp and standard ml of new jersey",
        "prob": 0.8227272727272725
    }, {
        "ID": 5397,
        "phrase": " , \u03c9 n ) to the chips, and consider the (complex) weight d\u00b5 n,k y (x, \u03c9) = 1 z n,k y n a=1 e \u2212 1 2 \u03c3 2 \u03c9 2 a +jya\u03c9a k i=1 d\u03bd(x i ) i,a exp \u2212 j \u221a n s ai \u03c9 a x i d\u03c9",
        "prob": 0.4692307692307693
    }, {
        "ID": 5398,
        "phrase": " , \u03c9 n ) to the chips, and consider the (complex) weight d\u00b5 n,k y (x, \u03c9) = 1 z n,k y n a=1 e \u2212 1 2 \u03c3 2 \u03c9 2 a +jya\u03c9a k i=1 d\u03bd(x i ) i,a exp \u2212 j \u221a n s ai \u03c9 a x i d\u03c9",
        "prob": 0.4692307692307693
    }, {
        "ID": 5697,
        "phrase": " there also exists a reactive library very close to reactive-c written in standard ml  [24] ",
        "prob": 0.3416666666666667
    }, {
        "ID": 5888,
        "phrase": "input: integers ai and bi for i = 1 to n such that (a) ai \u2265 wmin;(b) bi \u2264 wmax; (c) bi \u2212 ai \u2264 \u2206",
        "prob": 0.2625
    }, {
        "ID": 5913,
        "phrase": " \u00ec \u00d7 \u00f4\u00f6\u00f3\u00fa \u00d7 \u00ec \u00f3\u00f6 \u00f1 \u00be\u00ba \u00f3\u00f9\u00f2 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 b\u00b3\u00d7 \u00f3\u00f6 \u00fa \u00f2 a \u00fd 2 \u2022 2 \u03c9(a) \u00d7 \u00f1\u00f9 \u00fd\u00f3\u00f2 \u00fb \u00f8 \u00f2 \u00fc\u00f4 \u00f8 \u00f3\u00f2 \u00fa \u00f6 \u00ba \u00e1\u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f8 \u00d7 \u00fb \u00f6 \u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f9\u00f0\u00f3 \u00f0\u00f0 \u00f4\u00f6 \u00f1 \u00fa \u00d7\u00f3\u00f6\u00d7 \u00f3 a\u00ba \u00ec \u00f2 \u00f2\u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00d7 \u00f3\u00f9\u00f6\u00d7 \u00fb \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3\u00f9\u00f8 1 2 \u03c9(a) \u00f2 \u00f8 \u00f8 \u00f2 \u00f0\u00f0 \u00f3\u00f8 \u00f6 \u00d7 \u00d7 \u00f8 \u00f6 \u00d7 \u00f2\u00f3 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2\u00b8\u00f3\u00f2 \u00fb\u00f3\u00f9\u00f0 \u00f6 \u00f8 \u00f6 \u00fc\u00f4 \u00f8 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 b\u00b3\u00d7 \u00f4 \u00f6 a\u00ba \u00ec \u00f2 h i=1 1 ai \u00fa \u00d7 \u00d7 |d| 3 n=1 1 n \u2208 o(log |d|)\u00ba \u00eb\u00f3 \u00f3\u00f2 \u00fa \u00f6 \u00b8\u00f3\u00f2 \u00fb\u00f3\u00f9\u00f0 \u00fc\u00f4 \u00f8 \u00f8\u00f3 \u00f2 \u00f0\u00f3 \u00f6 \u00f8 \u00f1 \u00f8\u00f3\u00f6 \u00fb \u00f8 \u00f6 \u00d7\u00f4 \u00f8 \u00f8\u00f3 \u00f8 \u00fb\u00f3\u00f6\u00d7\u00f8 \u00d7 \u00d7\u00f8 \u00f1 \u00f8 \u00f3\u00f2\u00b8\u00fb \u00fb\u00f3\u00f9\u00f0 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00fc \u00f8\u00fd \u00f3 o(|d| log 4 |d| log log |d|) \u00f2 \u00ec \u00f3\u00f6 \u00f1 \u00bd\u00ba \u00e1\u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00ec \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f3 \u00f8 \u00d7 \u00f6\u00f8 \u00f0 \u00fa \u00f2 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f9\u00d7 \u00f2 \u00f1\u00f4 \u00be \u2104 \u00fb \u00f8 \u00f2 \u00d7\u00d7 \u00f1 \u00f0\u00fd \u00f4 \u00f8 \u00f3\u00f6 \u00f8 \u00e5 \u00f4\u00f6\u00f3 \u00d7\u00d7\u00f3\u00f6\u00d7 \u00be \u2104\u00b8\u00f1\u00f4 \u00f6 \u00be \u2104 \u00f2 \u00f1\u00f4 \u00be\u00bc\u2104 \u00f3\u00f6 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f6 \u00d7 \u00f3\u00f2 \u00f6 \u00f8 \u00f1 \u00f8 \u00f2 \u00f0 \u00f6 \u00f6\u00fd \u00f3 \u00f8 \u00f9\u00f8 \u00f3\u00f6\u00b3\u00d7 \u00f3\u00f6 \u00f8 \u00f4\u00f3\u00f0\u00fd\u00f2\u00f3\u00f1 \u00f0 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00ec \u00f0 \u00bd \u00f4\u00f6\u00f3\u00fa \u00d7 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f3\u00f6 \u00f0 \u00d7\u00d7 \u00f2\u00f9\u00f1 \u00f6\u00d7 \u00f8\u00fb \u00f2 2500 \u00f2 100000\u00b8\u00f3 \u00f8 \u00f2 \u00f3\u00f2 \u00f2 \u00e5 \u00e7\u00f4\u00f8 \u00f6\u00f3\u00f2 \u00be \u00bc \u00fb \u00f8 2",
        "prob": 0.2625
    }, {
        "ID": 6971,
        "phrase": " \n added-hyper-plane (ahp) bound in  [20] , yousefi and khandani introduce a new upper bound on the ml decoding block error probability, called the added hyper plane (ahp) bound",
        "prob": 0.38846153846153847
    }, {
        "ID": 6971,
        "phrase": " then both the itsb and the ahp upper bounds on the average ml decoding error probability of c are lower bounded by the function \u03c8(c) where \u03c8(c) min w pr \u03b2 w (z 1 ) \u2264 z 2 \u2264 r z 1 , v \u2264 r 2 z 1 \u2212 z 2 2 + h a h pr \u03b2 h (z 1 ) \u2264 z 2 \u2264 r z 1 , \u2212r z 1 \u2264 z 3 \u2264 min{l w,h (z 1 , z 2 ), r z 1 }, w \u2264 r 2 z 1 \u2212 z 2 2 \u2212 z 2 3 + pr y \u2265 r 2 z 1 ( 48 ) where l w,h (z 1 , z 2 ) is defined in (42)",
        "prob": 0.3521739130434783
    }, {
        "ID": 6972,
        "phrase": " \n added-hyper-plane (ahp) bound in  [16] , yousefi and khandani introduce a new upper bound on the ml decoding block error probability, called the added hyper plane (ahp) bound",
        "prob": 0.4269230769230769
    }, {
        "ID": 6972,
        "phrase": " then both the itsb and ahp upper bounds on the average ml decoding error probability of c are lower bounded by the function \u03c8(c) where \u03c8(c) min w e c pr z 1 \u2264 ne s , \u03b2 w (z 1 ) \u2264 z 2 \u2264 r z 1 , v \u2264 r 2 z 1 \u2212 z 2 2 + h a h pr z 1 \u2264 ne s , \u03b2 h (z 1 ) \u2264 z 2 \u2264 r z 1 , \u2212 r z 1 \u2264 z 3 \u2264 min{l w,h (z 1 , z 2 ), r z 1 }, w \u2264 r 2 z 1 \u2212 z 2 2 \u2212 z 2 3 + pr z 1 \u2264 ne s , y \u2265 r 2 z 1 (48) and l w,h (z 1 , z 2 ) is defined in (42)",
        "prob": 0.3521739130434783
    }, {
        "ID": 6995,
        "phrase": "\u00d7\u00f8\u00f6 \u00f8 \u00ec \u00d7 \u00f4 \u00f4 \u00f6 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00d7 \u00f2 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00d7 \u00d7 \u00f8\u00f3 \u00f1 \u00f2 \u00f1 \u00d7 \u00f8 \u00fa \u00f6 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00ba \u00ec \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00f2\u00f3 \u00f6 \u00f1 \u00fd \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00f3 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00f8 \u00f3\u00f8\u00f8\u00f3\u00f1\u00b9\u00f9\u00f4 \u00b4\u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00b5 \u00f2 \u00f8\u00f3\u00f4\u00b9 \u00f3\u00fb\u00f2 \u00b4 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0\u00b5 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00f8 \u00f9\u00f2 \u00d7 \u00d7 \u00fa \u00f6 \u00f0 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3\u00f2 \u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00ba \u00bd \u00e1\u00f2\u00f8\u00f6\u00f3 \u00f9\u00f8 \u00f3\u00f2 \u00ec \u00f6 \u00d7 \u00f9\u00f6\u00f6 \u00f2\u00f8\u00f0\u00fd \u00f6 \u00f8 \u00f0 \u00f3 \u00f2\u00f8 \u00f6 \u00d7\u00f8 \u00f2 \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2\u00d7 \u00f8\u00fd \u00f9\u00f2\u00f8 \u00f3\u00f2\u00d7 \u00b4\u00e8 \u00b5\u00ba \u00ec \u00d7 \u00f6 \u00d7 \u00f6 \u00d7 \u00f1\u00f3\u00f8 \u00fa \u00f8 \u00fd \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00f3 \u00f2\u00f8 \u00e8 \u00f3 \u00d7 \u00f8 \u00f3 \u00fa \u00f6 \u00f0 \u00d7 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f9 \u00f2\u00fd \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00e8 \u00fb \u00f2\u00b9 \u00fa\u00f3\u00f0\u00fa \u00d7 \u00f8 \u00d7 \u00fa \u00f6 \u00f0 \u00d7 \u00f0\u00f3\u00f2 \u00b8\u00fb \u00f8 \u00f9\u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f0\u00f0 \u00f2 \u00f6 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00d7 \u00f2 \u00f8 \u00d7\u00f4 \u00f3 \u00f8 \u00d7 \u00fa \u00f6 \u00f0 \u00d7 \u00f8\u00f3 \u00f6 \u00d7\u00d7 \u00f5\u00f9 \u00f2\u00f8 \u00f8 \u00f8 \u00fa \u00f0\u00fd\u00ba \u00ec \u00f3\u00f2\u00f0\u00fd \u00f0 \u00f1 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f4\u00f4\u00f6\u00f3 \u00f8\u00f3 \u00d7\u00f3\u00f0\u00fa \u00f2 \u00f2 \u00f6 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00d7 \u00d7 \u00f8 \u00f8 \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00e8 \u00d7 \u00f9\u00d7 \u00b8\u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f8\u00f9 \u00f0 \u00e8 \u00f8\u00d7 \u00f0 \u00b8\u00fb \u00f2 \u00f0 \u00f8\u00f3 \u00f2 \u00f9\u00f6 \u00f8 \u00f2 \u00f6\u00b9 \u00f2 \u00d7\u00ba \u00ec \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00e8 \u00f1\u00f3 \u00f0 \u00d7 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00f8\u00f3 \u00f1 \u00fc\u00b9 \u00f1 \u00d7 \u00f8 \u00f0\u00f3 \u00b9\u00f0 \u00f0 \u00f3\u00f3 \u00f8 \u00f8 \u00f8 \u00f3\u00f9\u00f0 \u00f2 \u00f6 \u00f8 \u00f8 \u00f8\u00f6 \u00f2 \u00f2 \u00d7 \u00f8 \u00ba \u00ba \u00f1 \u00fc \u00f1 \u00d7 log (\u00f1\u00f3 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd) \u00f8\u00f6 \u00f2 \u00f2 \u00d7 \u00f8 \u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00f3 \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f8 \u00e8 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00fb \u00f0\u00f0 \u00d7\u00f8\u00f9 \u00ba \u00e1\u00f2 \u00f8 \u00f0 \u00f2 \u00f9 \u00f3 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00b8\u00f8 \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00d7\u00f3\u00f9\u00f6 \u00f2 \u00fa \u00fb \u00d7 \u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00fb \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 \u00f6 \u00f8\u00f0\u00fd \u00f2 \u00f9 \u00f2 \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f3\u00f2\u00f0\u00fd \u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f1\u00f1 \u00f8 \u00f0\u00fd \u00f3\u00fa \u00f2 \u00f0\u00f3\u00fb \u00f8\u00ba \u00ec \u00f3\u00f4\u00f8 \u00f1 \u00f0 \u00e8 \u00f1\u00f3 \u00f0 \u00f8 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00e8 \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3\u00f6 \u00f8 \u00f0 \u00d7\u00f8 \u00d7\u00f3\u00f1 \u00d7\u00f9 \u00d7 \u00f8 \u00f3 \u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8\u00fb \u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00fb \u00f8 \u00d7 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0\u00f0\u00fd \u00f3\u00f2 \u00f2 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00e8 \u00f1\u00f3 \u00f0\u00d7\u00ba \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00d7 \u00f2\u00f8 \u00f6 \u00d7\u00f8 \u00f2 \u00f9\u00d7 \u00f8 \u00f9\u00f2 \u00d7 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fc \u00d7\u00f8 \u00f2 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00f2\u00f8\u00f3 \u00d7 \u00f2 \u00f0 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00f1 \u00fd \u00f0\u00d7\u00f3 \u00fa \u00fb \u00d7 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f4 \u00f6\u00d7\u00f4 \u00f8 \u00fa \u00f3\u00f2 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f6 \u00f4\u00f3\u00f6\u00f8 \u00f2 \u00bd\u00bc\u2104\u00ba \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00b8 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 * \u00eb\u00f9 \u00f1 \u00f8\u00f8 \u00f8\u00f3 ae \u00f9\u00f6 \u00f0 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f2 \u00be \u00f6\u00f9 \u00f6\u00fd \u00bd \u00ba \u00e5 \u00f2\u00f9\u00d7\u00f6 \u00f4\u00f8 \u00f2\u00f3\u00ba \u00bd \u00be \u00ba \u00e1\u00f8 \u00fb \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f8 \u00f3\u00f6 \u00f4\u00f9 \u00f0 \u00f8 \u00f3\u00f2\u00b8 \u00f9\u00f8 \u00f8 \u00f9\u00f2 \u00f6\u00f4 \u00f2\u00d7 \u00d7 \u00fa \u00f6 \u00f0 \u00d7\u00f9 \u00d7 \u00f5\u00f9 \u00f2\u00f8\u00f0\u00fd \u00f4\u00f9 \u00f0 \u00d7 \u00f4 \u00f4 \u00f6\u00d7\u00ba \u00bd \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00bf\u2104 \u00f1 \u00f6 \u00d7 \u00f6\u00f3\u00f1 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00e8 \u00f3 \u00f8 \u00f2\u00f4\u00f9\u00f8 \u00f2 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00bf\u00b9\u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f0\u00d7\u00f3 \u00f1 \u00f6 \u00f2 \u00f8\u00f9\u00f6 \u00f0\u00f0\u00fd \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00be \u00f8 \u00f6 \u00f0 \u00fa \u00f2\u00f8 \u00f4 \u00f6\u00f8\u00d7 \u00f3 \u00f8 \u00eb \u00f2\u00f2\u00f3\u00f2 \u00f8 \u00f3\u00f6\u00fd \u00f3 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00bd\u00be\u2104\u00b8 \u00f2 \u00f8 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f3 \u00f2 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f8\u00fd\u00f4 \u00d7 \u00f3 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f6 \u00fa \u00bd\u00bd\u2104 \u00f2 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6\u00b8\u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f6 \u00d7\u00f9\u00d7\u00d7 \u00b8 \u00f9\u00d7 \u00f8 \u00fd \u00f6 \u00f8 \u00fd \u00f8\u00f3 \u00f8 \u00f4\u00f4\u00f6\u00f3 \u00f8 \u00f8 \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6\u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf \u00f8 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f3 \u00f2 \u00f8\u00f3 \u00f9\u00f2\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00f8 \u00f0\u00b8 \u00f2\u00f0\u00f9 \u00f2 \u00f8 \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00bf\u2104\u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00b4 \u00f2 \u00f4\u00f4 \u00f2 \u00fc \u00b5 \u00f6 \u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00f9\u00d7 \u00f2 \u00f2 \u00f4\u00f8 \u00fa \u00f0\u00f9\u00d7\u00f8 \u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00b4 \u00b5 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u2104\u00b8 \u00f2 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00b4 \u00f2 \u00f4\u00f4 \u00f2 \u00fc \u00b5 \u00f8\u00f3\u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00f9\u00d7 \u00f2 \u00f4 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00b4\u00e8\u00e5 \u00b5 \u00f6 \u00d7\u00f9\u00d7\u00d7 \u2104\u00ba \u00f2 \u00f0\u00f0\u00fd \u00f2 \u00f4\u00f4 \u00f2 \u00fc \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00d7 \u00f3\u00f1\u00f4 \u00f6 \u00fb \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f9\u00d7 \u00f2 \u00e0 \u00f0\u00f1 \u00f3\u00f0\u00f8\u00fe \u00f1 \u00f2 \u00be\u2104\u00ba \u00be \u00f3 \u00f2 \u00ec \u00f3\u00f6\u00fd \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bd \u00f8 \u00d7 \u00d7 \u00f3 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00f6\u00fd \u00f6 \u00f3\u00f9\u00f8\u00f0 \u00f2 \u00b4\u00f8 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f2 \u00d7 \u00f2\u00d7\u00f4 \u00f6 \u00fd \u00f8 \u00f6 \u00d7\u00f3\u00f2 \u00f2 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00bd\u00be\u2104\u00b5\u00b8 \u00f2 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be \u00f8 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f3 \u00f9\u00d7 \u00f2 \u00f1\u00f3 \u00f0 \u00f8\u00f3 \u00f3 \u00d7\u00f3\u00f9\u00f6 \u00d7\u00f6 \u00f2 \u00f8 \u00f0\u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bf \u00f8 \u00d7 \u00d7 \u00fc\u00f8 \u00f2 \u00f8\u00f3 \u00f8 \u00d7 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00be\u00ba \u00f8 \u00f6 \u00f0 \u00f8 , \u2022 \u2022 \u2022 , p m ) \u00b4\u00bd\u00b5 \u00fb \u00d7\u00f6 \u00d7 \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00f6 \u00f5\u00f9 \u00f2\u00fd \u00fb \u00f8 \u00fb \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00d7 \u00f6 \u00fb\u00f2 \u00f2 \u00b9 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f6\u00f3\u00f1 \u00f8 \u00d7\u00f3\u00f9\u00f6 p\u00ba \u00f8\u00f6 \u00fa \u00f0 \u00fc \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f9\u00f2 \u00d7\u00d7 \u00b8\u00fb \u00d7 m = 6 \u00f2 p i = 1 6 \u00f3\u00f6 i = 1, 2, \u2022 \u2022 \u2022 , 6\u00ba \u00ec \u00f3\u00f6 \u00f6 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7 \u00f6 \u00fb\u00f2 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f6\u00f3\u00f1 \u00d7\u00f3\u00f9\u00f6 \u00f1 \u00fd \u00f4 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00f2\u00f8\u00f3 \u00d7\u00f9 \u00d7 \u00f5\u00f9 \u00f2 \u00d7 \u00f3 n \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7\u00b8 \u00f2 \u00d7\u00f9 \u00d7\u00f9 \u00d7 \u00f5\u00f9 \u00f2 \u00fb \u00f0\u00f0 \u00f0\u00f0 \u00f1 \u00d7\u00d7 \u00ba \u00e1 n \u00d7 \u00fa \u00f6\u00fd \u00f0 \u00f6 \u00b8\u00f8 \u00f2 \u00f1 \u00d7\u00d7 \u00d7 \u00f0\u00f0 \u00f0 \u00f0\u00fd \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00f6 \u00f5\u00f9 \u00f2\u00fd \u00f3 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00f3 \u00f8\u00d7 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00d7 p\u00b8\u00f3\u00f8 \u00f6\u00fb \u00d7 \u00f8 \u00d7 \u00f0\u00f0 \u00f9\u00f2\u00f0 \u00f0\u00fd \u00ba \u00d7 n \u2192 \u221e \u00f8 \u00d7 \u00f8 \u00f3 \u00f0 \u00f0\u00fd \u00f1 \u00d7\u00d7 \u00d7 \u00d7 \u00fa \u00f6\u00fd \u00d7 \u00f6\u00f4\u00f0\u00fd \u00f2 \u00b8 \u00f2 \u00f8 \u00d7 \u00f2\u00d7 \u00f8 \u00f8 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f3 \u00f0\u00f0 \u00f1 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f0 \u00f2 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f6 \u00f3\u00f2 \u00f8\u00fb \u00f2 \u00f2 \u00f0 \u00f0\u00fd \u00f2 \u00f2 \u00f9\u00f2\u00f0 \u00f0\u00fd \u00f3\u00f1 \u00d7 \u00fa \u00f2 \u00d7 \u00f2 \u00f0\u00fd \u00d7\u00f1 \u00f0\u00f0\u00ba \u00ec \u00f9\u00d7 \u00f8 \u00f6 \u00d7 \u00d7 \u00f8 \u00f3 \u00f0 \u00f0\u00fd \u00f1 \u00d7\u00d7 \u00d7 \u00f0\u00f0 \u00fb \u00f8 \u00f5\u00f9 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00b4 \u00f9\u00d7 \u00f0 \u00f0\u00fd \u00f1 \u00d7\u00d7 \u00d7 \u00f8 \u00d7 \u00f1 \u00f6 \u00f0 \u00f8 \u00fa \u00f6 \u00f5\u00f9 \u00f2\u00fd \u00f3 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00f3 \u00f3 \u00f8 m \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7\u00b5\u00b8 \u00f2 \u00d7 \u00f8 \u00f3 \u00f9\u00f2\u00f0 \u00f0\u00fd \u00f1 \u00d7\u00d7 \u00d7 \u00b4 \u00ba \u00ba \u00f0\u00f0 \u00f8 \u00f1 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f6 \u00f2\u00f3\u00f8 \u00f0 \u00f0\u00fd \u00f1 \u00d7\u00d7 \u00d7\u00b5 \u00f8 \u00f8 \u00fa \u00d7\u00d7 \u00f2\u00f8 \u00f0\u00f0\u00fd \u00fe \u00f6\u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00ba \u00e1\u00f8 \u00d7 \u00f8 \u00d7 \u00d7 \u00f4 \u00f6 \u00f8 \u00f3\u00f2 \u00f3 \u00f1 \u00d7\u00d7 \u00d7 \u00f2\u00f8\u00f3 \u00f0 \u00f0\u00fd \u00d7 \u00f8 \u00b4 \u00f0\u00f0 \u00fb \u00f8 \u00f5\u00f9 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b5 \u00f2 \u00be \u00f2 \u00f9\u00f2\u00f0 \u00f0\u00fd \u00d7 \u00f8 \u00b4 \u00f0\u00f0 \u00fb \u00f8 \u00fe \u00f6\u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b5 \u00f8 \u00f8 \u00f9\u00f2 \u00f6\u00f0 \u00d7 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00f6\u00fd\u00b8 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00bd\u00be\u2104\u00ba \u00f0 \u00f0\u00fd \u00f1 \u00d7\u00d7 \u00f6\u00f3\u00f1 p \u00fb \u00f0\u00f0 \u00f0\u00f0 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00ba \u00d7 n \u2212\u2192 \u221e \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8 \u00f1 \u00d7 n i \u00f8 \u00f8 \u00d7\u00fd\u00f1 \u00f3\u00f0 i \u00f3\u00f9\u00f6\u00d7 \u00f2 p\u00b9\u00f1 \u00d7\u00d7 \u00f3 \u00f0 \u00f2 \u00f8 n \u00d7 n i = n p i \u00b8\u00fb \u00f6 m i=1 p i = 1 \u00f9 \u00f6 \u00f2\u00f8 \u00d7 \u00f8 \u00f8 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f2 m i=1 n i = n \u00d7 \u00d7 \u00f8 \u00d7 \u00ba \u00ec \u00f0\u00f3 \u00f6 \u00f8 \u00f1 \u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f6 \u00f2\u00f8 \u00f0 \u00f0\u00fd p\u00b9 \u00f1 \u00d7\u00d7 \u00d7 \u00d7 \u00fa \u00f2 \u00fd \u00b4\u00f9\u00d7 \u00f2 \u00eb\u00f8 \u00f6\u00f0 \u00f2 \u00b3\u00d7 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f3\u00f2 log x! \u2248 x log x \u2212 x \u00fb \u00f2 x \u00d7 \u00f0 \u00f6 \u00b5 log n ! n 1 !n 2 ! \u2022 \u2022 \u2022 n m ! \u2248 \u2212n m i=1 p i log p i \u00b4\u00be\u00b5 ae\u00f3\u00fb \u00f2 \u00f8 \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd h (p) \u00f3 \u00d7\u00f3\u00f9\u00f6 p \u00d7 \u00f8 \u00f0\u00f3 \u00f6 \u00f8 \u00f1 \u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f6 \u00f2\u00f8 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00b4\u00f1 \u00d7\u00f9\u00f6 \u00f4 \u00f6 \u00f1 \u00d7\u00d7 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00b5 h (p) \u2261 \u2212 m i=1 p i log p i \u2265 0 \u00b4\u00bf\u00b5 \u00ec \u00f9\u00d7 h (p) \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00b4\u00f3\u00f2 \u00fa \u00f6 \u00b5 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f4 \u00f6 \u00f8 \u00f2\u00f3 \u00f6\u00b5\u00b8 \u00f9\u00d7 \u00f8 \u00f3\u00f2\u00f0\u00fd \u00f1 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f4\u00f6\u00f3 \u00f9 \u00f2 \u00f6 \u00f8 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00ba \u00e1\u00f8 \u00d7 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00fa \u00f6\u00fd \u00f9\u00f0\u00f8 \u00f8\u00f3 \u00f2\u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 p \u00f9\u00d7 \u00f2 h (p) \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f3\u00f2 \u00fa \u00f6 \u00ba \u00ec \u00d7 \u00d7 \u00f9\u00d7 \u00f0\u00f8 \u00f3\u00f9 \u00f8 \u00f3\u00f9\u00f2 \u00f6\u00fd \u00f8\u00fb \u00f2 \u00f8 \u00d7 \u00f8 \u00f3 \u00f0 \u00f0\u00fd p\u00b9 \u00f1 \u00d7\u00d7 \u00d7 \u00f2 \u00f8 \u00d7 \u00f8 \u00f3 \u00f9\u00f2\u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00d7 \u00d7 \u00f6\u00f4\u00f0\u00fd \u00f2 \u00f2 \u00f4\u00f6 \u00f2 \u00f4\u00f0 \u00b8 \u00f2 \u00f4\u00f6 \u00f8 \u00f8 \u00d7 \u00fa \u00f6\u00fd \u00f6 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f1 \u00f8 \u00f1 \u00f8 \u00f0\u00f0\u00fd\u00ba \u00e1 \u00f8 \u00d7 \u00f3\u00f9\u00f2 \u00f6\u00fd \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f6 \u00d7 \u00f0\u00fd \u00f2 \u00b8\u00f8 \u00f2 \u00f8 \u00d7 \u00f1\u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00f3 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00fa \u00f0\u00f9 \u00f3 h (p) \u00f9\u00f6 \u00f8 \u00f0\u00fd\u00ba \u00e1\u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f2\u00d7\u00f9\u00f6 \u00f8 \u00f8 \u00f0\u00f0 \u00f3 \u00f8 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f6 \u00f3\u00f9\u00f2\u00f8 \u00f3\u00f6\u00b8 \u00f8 \u00d7 \u00f2 \u00d7\u00d7 \u00f6\u00fd \u00f3\u00f6 \u00f8 \u00f1 \u00f8 \u00f1 \u00f8 \u00f0 \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00f3\u00f9\u00f2 \u00f6\u00fd \u00f8\u00f3 \u00f0 \u00f3\u00f9\u00f8\u00d7 \u00f8 \u00f8\u00f6\u00f9 \u00f3\u00f9\u00f2 \u00f6\u00fd\u00b8\u00fb \u00f8 \u00f9\u00d7 \u00f3\u00fa \u00f6 \u00d7\u00f8 \u00f1 \u00f8 \u00d7 \u00f8 \u00fa \u00f0\u00f9 \u00f3 h (p)\u00ba \u00ec \u00d7 \u00f1\u00f3\u00f2\u00d7\u00f8\u00f6 \u00f8 \u00d7 \u00f8 \u00f8 h (p) \u00d7 \u00f2 \u00f8 \u00f0\u00f3\u00fb \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 \u00f8 \u00f8\u00f6\u00f9 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f8 \u00f8 \u00f1\u00f9\u00d7\u00f8 \u00f9\u00d7 \u00f8\u00f3 \u00f2\u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 p\u00ba \u00be\u00ba\u00be \u00eb\u00f3\u00f9\u00f6 \u00f3 \u00f2 \u00ec \u00f1 \u00f8 \u00f1 \u00f8 \u00f0 \u00f1\u00f3 \u00f0 \u00b4\u00f3\u00f6\u00b8\u00d7 \u00f1\u00f4\u00f0\u00fd\u00b8\u00f8 \u00f1\u00f3 \u00f0\u00b5 \u00f3 \u00f8 \u00f3\u00f9\u00f2 \u00f6\u00fd \u00f8\u00fb \u00f2 \u00f8 \u00d7 \u00f8 \u00f3 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f2 \u00f8 \u00d7 \u00f8 \u00f3 \u00f9\u00f2\u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f1 \u00fd \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00f2\u00f3\u00f8 \u00f6 \u00fa \u00f8\u00f3\u00f6 \u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7\u00b8 \u00f2\u00f3\u00f8 \u00d7 q\u00b8\u00fb \u00f3\u00d7 m \u00f0 \u00f1 \u00f2\u00f8\u00d7 \u00f1\u00f3 \u00f0 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6 \u00fb\u00f2 \u00f6\u00f3\u00f1 \u00f2 \u00f0\u00f4 \u00f8 \u00f3 m \u00d7\u00f8 \u00f2\u00f8 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7\u00ba \u00e1 q = p \u00f8 \u00f2 \u00f8 \u00f3\u00f9\u00f2 \u00f6\u00fd \u00d7 \u00f1\u00f3 \u00f0\u00f0 \u00f4 \u00f6 \u00f8\u00f0\u00fd\u00b8 \u00f2 \u00f2 \u00f2 \u00f4\u00f6 \u00f2 \u00f4\u00f0 \u00f8 \u00f0\u00f3\u00fb \u00f6 \u00f3\u00f9\u00f2 h (p) \u00f3\u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f1 \u00fd \u00f8\u00f8 \u00f2 \u00b8 \u00f0\u00f8 \u00f3\u00f9 \u00fa \u00f2 \u00f8 \u00d7 \u00d7 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00f9\u00f0\u00f8 \u00f8\u00f3 \u00f6 \u00f0 \u00d7 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00fa \u00f0\u00fd \u00f2 \u00f4\u00f6 \u00f8 \u00ba \u00e1\u00f2 \u00f4\u00f6 \u00f8 \u00f0 \u00d7 \u00f8\u00f9 \u00f8 \u00f3\u00f2\u00d7 q = p \u00d7 \u00f2\u00fa \u00f6 \u00f0\u00fd \u00f8 \u00d7 \u00b8\u00d7\u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00f3 \u00f3 \u00f2 \u00d7\u00f3\u00f9\u00f6 \u00fb \u00f8 \u00f2 \u00f2 \u00f9\u00f6 \u00f8 \u00f1\u00f3 \u00f0 \u00f2\u00f2\u00f3\u00f8 \u00fa\u00f3 \u00ba \u00eb \u00f2 \u00f8 \u00f3\u00f2\u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f2 \u00f3\u00f9\u00f6 \u00f6 \u00f8 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00b4\u00fb \u00f0\u00f0 \u00f3\u00f9\u00f6 \u00fb \u00f8 \u00f5\u00f9 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b5\u00b8\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00fb \u00f2 \u00f9\u00d7 \u00f2 q \u00bf \u00f8\u00f3 \u00f2\u00f3 p \u00d7 \u00b4\u00f1 \u00f2\u00f9\u00d7\u00b5 \u00f8 \u00f0\u00f3 \u00f6 \u00f8 \u00f1 \u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u03c0 n (p, q) \u00f8 \u00f8 q\u00b9 \u00f1 \u00d7\u00d7 \u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7\u00ba \u03c0 n (p, q) \u00d7 \u00fa \u00f2 \u00fd \u03c0 n (p, q) = log n ! n 1 !n 2 ! \u2022 \u2022 \u2022 n m ! q n1 1 q n2 2 \u2022 \u2022 \u2022 q nm m \u2248 \u2212n m i=1 p i log p i q i \u2264 0 \u00b4 \u00b5 \u00fb \u00d7 \u00f2 \u00f8 \u00fa \u00f9\u00d7 \u00f8 \u00f1\u00f3 \u00f0 q \u00f2 \u00f6 \u00f8 \u00d7 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00fb \u00f8 \u00f0 \u00d7\u00d7 \u00f8 \u00f2 \u00f9\u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00ba \u00ec \u00f1\u00f3 \u00f0 q \u00f1\u00f9\u00d7\u00f8 \u00f9\u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00f2\u00f3\u00f9 q\u00b9 \u00f1 \u00d7\u00d7 \u00d7 \u00f8\u00f3 \u00f2\u00d7\u00f9\u00f6 \u00f8 \u00f8 \u00f0\u00f0 \u00f3 \u00f8 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f6 \u00f6 \u00f4\u00f6\u00f3 \u00f9 \u00b8\u00fb \u00f6 \u00f5\u00f9 \u00f6 \u00d7 \u00f8 \u00d7 h (p) \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00b4\u00f8 \u00f8 \u00fb\u00f3\u00f9\u00f0 \u00f6 \u00f5\u00f9 \u00f6 q = p\u00b5\u00f4 \u00f0\u00f9\u00d7 \u00d7\u00f3\u00f1 \u00fc\u00f8\u00f6 \u00f8\u00d7 \u00f8\u00f3 \u00f3\u00f1\u00f4 \u00f2\u00d7 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00d7\u00d7 \u00f8 \u00f2 100% \u00f2\u00fd \u00fb \u00f8 \u00fb q \u00f2 \u00f6 \u00f8 \u00d7 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00b4 \u00f9\u00d7 q = p\u00b5\u00ba \u00ec \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fc\u00f8\u00f6 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00d7 \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd g (p, q) g (p, q) \u2261 m i=1 p i log p i q i \u2265 0 \u00b4 \u00b5 \u00fb \u00d7 \u2212 \u03c0n (p,q) n \u00b8\u00f3\u00f6 \u00f1 \u00f2\u00f9\u00d7 \u00f8 \u00f0\u00f3 \u00f6 \u00f8 \u00f1 \u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f8 \u00f8 q\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00ba \u00ec \u00f9\u00d7 q \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00fc \u00f8\u00f0\u00fd \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fc\u00f8\u00f6 q\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f3\u00f1\u00f4 \u00f2\u00d7 \u00f8 \u00f3\u00f6 \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 q\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f0 \u00f0\u00fd p\u00b9\u00f1 \u00d7\u00d7 \u00d7 \u00f0 \u00d7\u00d7 \u00f8 \u00f2 \u00f9\u00f2 \u00f8\u00fd \u00b4 \u00ba \u00ba \u03c0 n (p, q) \u2264 0\u00b5\u00ba g (p, q) \u00b4 \u00ba \u00ba \u00f6 \u00f0 \u00f8 \u00fa \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd\u00b5 \u00d7 \u00f8 \u00f1\u00f3\u00f9\u00f2\u00f8 \u00fd \u00fb \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00fc \u00d7 \u00f8 \u00f0\u00f3\u00fb \u00f6 \u00f3\u00f9\u00f2 h (p) \u00b4 \u00ba \u00ba \u00d7\u00f3\u00f9\u00f6 \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd\u00b5\u00ba \u00f3\u00f6 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f2 \u00d7\u00d7\u00b8 \u00f0\u00d7\u00f3 \u00f2 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 h (p) + g (p, q) \u00d7 l (p, q)\u00fb \u00d7 \u00fa \u00f2 \u00fd l (p, q) \u2261 h (p) + g (p, q) = \u2212 m i=1 p i log q i \u2265 0 \u00b4 \u00b5 \u00ec \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 g (p, q) \u00f4\u00f6\u00f3\u00fa \u00d7 \u00f1 \u00f2\u00d7 \u00f3 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00f8 \u00f1\u00f3 \u00f0 q\u00ba \u00e1 \u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f6 \u00f8 \u00f6 \u00f3\u00f2 \u00d7 \u00f8 \u00f8 \u00f8 \u00fa \u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6 \u00f5\u00f9 \u00f6 \u00fb \u00f2 \u00f9\u00d7 \u00f2 q \u00f8\u00f3 \u00f2\u00f3 p \u00d7 \u00f3\u00f9\u00f0 \u00f1 \u00f2 \u00f1 \u00d7 \u00b8\u00f8 \u00f2 \u00f8 \u00f3\u00f4\u00f8 \u00f1\u00f9\u00f1 \u00f1\u00f3 \u00f0 q opt \u00d7 \u00f3\u00f9\u00f0 \u00f1 \u00f2 \u00f1 \u00d7 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 g (p, q) \u00fb \u00f8 \u00f6 \u00d7\u00f4 \u00f8 \u00f8\u00f3 q\u00b8\u00f8 \u00f9\u00d7 q opt = arg min q g (p, q) \u00b4 \u00b5 \u00ec \u00d7 \u00f6 \u00f8 \u00f6 \u00f3\u00f2 \u00f3\u00f6 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00f1\u00f3 \u00f0 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f2\u00f0\u00f9 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f6 \u00b9 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00d7\u00f4 \u00fd \u00f8 \u00f1\u00f3 \u00f0 \u00f8\u00d7 \u00f0 \u00b8\u00d7\u00f9 \u00d7 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00f1 \u00f2 \u00f1\u00f9\u00f1 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00f0 \u00f2 \u00f8 \u00f4\u00f4\u00f6\u00f3 \u00bd\u00bd\u2104\u00b8 \u00f0\u00f8 \u00f3\u00f9 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f3\u00f9\u00f0 \u00fc\u00f8 \u00f2 \u00f8\u00f3 \u00f2\u00b9 \u00f0\u00f9 \u00d7\u00f9 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2\u00d7\u00ba g (p, q) \u00d7 \u00f6 \u00f5\u00f9 \u00f2\u00f8\u00f0\u00fd \u00f9\u00d7 \u00d7 \u00f2 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00fb \u00f6 \u00f8 \u00d7\u00f3\u00f9\u00f6 p \u00d7 \u00f8 \u00fa \u00f8\u00f3\u00f6 \u00f3 \u00f3 \u00d7 \u00f6\u00fa \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6 \u00f5\u00f9 \u00f2 \u00d7\u00ba \u00eb \u00f2 q opt \u00f1\u00f9\u00d7\u00f8\u00b8 \u00f2 \u00d7\u00f3\u00f1 \u00d7 \u00f2\u00d7 \u00b8 \u00f0\u00f3\u00d7 \u00f8\u00f3 p\u00b8\u00f8 \u00d7 \u00f3\u00f6 \u00d7 \u00f4\u00f6 \u00f8 \u00f0 \u00fb \u00fd \u00f3 \u00f2\u00d7\u00f9\u00f6 \u00f2 \u00f8 \u00f8 \u00f8 \u00f3\u00f4\u00f8 \u00f1\u00f9\u00f1 \u00f1\u00f3 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 q opt \u00f6 \u00d7 \u00f1 \u00f0 \u00f6 \u00f8\u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6 \u00f5\u00f9 \u00f2 \u00d7 p\u00b8\u00fb \u00d7 \u00f8 \u00f3 \u00f0 \u00f3 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00ba \u00be\u00ba\u00bf \u00e5 \u00f6 \u00f3\u00fa \u00eb\u00f3\u00f9\u00f6 \u00f3 \u00f2 \u00ec \u00f3\u00fa \u00d7 \u00f1 \u00f3\u00f6 \u00f9\u00d7 \u00f2 \u00f1\u00f3 \u00f0 q \u00f8\u00f3 \u00f2\u00f3 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7 \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00d7\u00f3\u00f9\u00f6 p \u00f1 \u00fd \u00fc\u00f8 \u00f2 \u00f8\u00f3 \u00f8 \u00d7 \u00fb \u00f6 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00f2 \u00f8 \u00f1\u00f3 \u00f0 \u00f6 l\u00b9\u00f0 \u00fd \u00f6 \u00f6\u00d7\u00f8 \u00f3\u00f6 \u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7\u00ba \u00ec \u00fb\u00f3\u00f6 \u00f0 \u00fd \u00f6 \u00d7 \u00f9\u00d7 \u00f2 \u00f2\u00f8 \u00f4 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f8 \u00f8 \u00fb \u00f0\u00f0 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00ec \u00f9\u00d7 \u00d7\u00f4\u00f0 \u00f8 \u00f9\u00f4 \u00f3\u00f8 \u00f3 p \u00f2 q \u00f2\u00f8\u00f3 \u00f8 \u00f6 \u00f3\u00f2\u00d7\u00f8 \u00f8\u00f9 \u00f2\u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 p = p 0 , p 1|0 , \u2022 \u2022 \u2022 , p l\u22121|l\u22122 , p l|l\u22121 = p 0|1 , p 1|2 , \u2022 \u2022 \u2022 , p l\u22121|l , p l q = q 0 , q 1|0 , \u2022 \u2022 \u2022 , q l\u22121|l\u22122 , q l|l\u22121 = q 0|1 , q 1|2 , \u2022 \u2022 \u2022 , q l\u22121|l , q l \u00b4 \u00b5 \u00ec \u00d7 \u00f8\u00fb\u00f3 \u00fb \u00fd\u00d7 \u00f3 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00f2 p \u00b4 \u00f2 q\u00b5 \u00f6 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8\u00b8 \u00f9\u00d7 \u00f3\u00f6\u00fb \u00f6 \u00f4 \u00d7\u00d7 \u00f8 \u00f6\u00f3\u00f9 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f1 \u00fd \u00f3\u00f2\u00fa \u00f6\u00f8 \u00f2\u00f8\u00f3 \u00fb \u00f6 \u00f4 \u00d7\u00d7 \u00f8 \u00f6\u00f3\u00f9 \u00f6 \u00f2\u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00b8\u00fb \u00f3\u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f6 \u00f9\u00f2 \u00f5\u00f9 \u00f0\u00fd \u00f8 \u00f6\u00f1 \u00f2 \u00fd \u00f4\u00f4\u00f0\u00fd \u00f2 \u00fd \u00d7\u00b3 \u00f8 \u00f3\u00f6 \u00f1 \u00f8\u00f3 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00ba p k|l \u00b4 \u00f2 q k|l \u00b5 \u00d7 \u00f8 \u00f1 \u00f8\u00f6 \u00fc \u00f3 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f6\u00f3\u00f1 \u00f0 \u00fd \u00f6 l \u00f8\u00f3 \u00f0 \u00fd \u00f6 k \u00f3 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00f2 \u00f1\u00f3 \u00f0\u00b5\u00b8p 0 \u00b4q0 \u00b5 \u00d7 \u00f8 \u00fa \u00f8\u00f3\u00f6 \u00f3 \u00f1 \u00f6 \u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f2 \u00f0 \u00fd \u00f6 0\u00b8p l \u00b4 \u00f2 q l \u00b5 \u00d7 \u00f8 \u00fa \u00f8\u00f3\u00f6 \u00f3 \u00f1 \u00f6 \u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f2 \u00f0 \u00fd \u00f6 l\u00ba \u00ec \u00d7 \u00f1 \u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f3\u00f9\u00f8 \u00f2 \u00f8 \u00f0 \u00d7 p 0 i0 = \u00f8\u00f6\u00f9 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 0 \u00d7 \u00d7\u00f8 \u00f8 i 0 p l il = \u00f8\u00f6\u00f9 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l \u00d7 \u00d7\u00f8 \u00f8 i l p l+1|l i l+1 ,i l = \u00f8\u00f6\u00f9 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l + 1 \u00d7 \u00d7\u00f8 \u00f8 i l+1 \u00fa \u00f2 \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l \u00d7 \u00d7\u00f8 \u00f8 i l p l|l+1 i l ,i l+1 = \u00f8\u00f6\u00f9 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l \u00d7 \u00d7\u00f8 \u00f8 i l \u00fa \u00f2 \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l + 1 \u00d7 \u00d7\u00f8 \u00f8 i l+1 \u00b4 \u00b5 q 0 i0 = \u00f1\u00f3 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 0 \u00d7 \u00d7\u00f8 \u00f8 i 0 q l il = \u00f1\u00f3 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l \u00d7 \u00d7\u00f8 \u00f8 i l q l+1|l i l+1 ,i l = \u00f1\u00f3 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l + 1 \u00d7 \u00d7\u00f8 \u00f8 i l+1 \u00fa \u00f2 \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l \u00d7 \u00d7\u00f8 \u00f8 i l q l|l+1 i l ,i l+1 = \u00f1\u00f3 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l \u00d7 \u00d7\u00f8 \u00f8 i l \u00fa \u00f2 \u00f8 \u00f8 \u00f0 \u00fd \u00f6 l + 1 \u00d7 \u00d7\u00f8 \u00f8 i l+1 \u00b4\u00bd\u00bc\u00b5 \u00ec \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fc\u00f8\u00f6 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 g (p, q) \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b5 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6\u00f3\u00f1 \u00f8 \u00d7\u00f3\u00f9\u00f6 p \u00f9\u00d7 \u00f2 \u00f8 \u00f1\u00f3 \u00f0 q \u00f1 \u00fd \u00f8 \u00f2 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 g (p, q) = m0 i0=1 \u2022 \u2022 \u2022 ml il=1 p 0|1 i0,i1 p 1|2 i1,i2 \u2022 \u2022 \u2022 p l\u22121|l il\u22121,il p l il \u00d7 log p 0|1 i0,i1 p 1|2 i1,i2 \u2022 \u2022 \u2022 p l\u22121|l il\u22121,il p l il q 0|1 i0,i1 q 1|2 i1,i2 \u2022 \u2022 \u2022 q l\u22121|l il\u22121,il q l il = l\u22121 l=0 m l+1 i l+1 =1 p l+1 i l+1 g i l+1 p l|l+1 , q l|l+1 + g p l , q l \u00b4\u00bd\u00bd\u00b5 \u00fb \u00f6 \u00f8 \u00f3\u00fb \u00f3 \u00f2 \u00f9 \u00f2 \u00f2 \u00f3\u00f8 p \u00f2 q \u00d7 \u00f6\u00f3\u00f1 \u00f0 \u00fd \u00f6 0 \u00f8\u00f3 \u00f0 \u00fd \u00f6 l\u00ba \u00ec \u00d7\u00f9 \u00fc i l+1 \u00f8 \u00f8 \u00f4\u00f4 \u00f6\u00d7 \u00f3\u00f2 \u00f8 g i l+1 p l|l+1 , q l|l+1 \u00f2 \u00f8 \u00d7 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 l + 1 \u00d7 \u00fc \u00f9\u00f6 \u00f2 \u00f8 \u00fa \u00f0\u00f9 \u00f8 \u00f3\u00f2 \u00f3 g i l+1 p l|l+1 , q l|l+1 \u00b4 \u00ba \u00ba \u00f8 \u00d7 \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd \u00f3 \u00f0 \u00fd \u00f6 l\u00b8 \u00fa \u00f2 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 l + 1 \u00d7 \u00f2\u00f3\u00fb\u00f2\u00b5\u00ba \u00eb \u00f1 \u00f0 \u00f6\u00f0\u00fd\u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6\u00f3\u00f1 \u00f8 \u00d7\u00f3\u00f9\u00f6 p \u00f9\u00d7 \u00f2 \u00f8 \u00f1\u00f3 \u00f0 q \u00d7 l (p, q) \u00b4 \u00ba \u00ba h (p) + g (p, q)\u00b5\u00b8\u00fb \u00d7 \u00fa \u00f2 \u00fd l (p, q) = l\u22121 l=0 m l+1 i l+1 =1 p l+1 i l+1 l i l+1 p l|l+1 , q l|l+1 + l p l , q l \u00b4\u00bd\u00be\u00b5 \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 \u00fa \u00f6\u00fd \u00f2 \u00f8\u00f9\u00f6 \u00f0 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2\u00ba \u00f3\u00f8 \u00f8 \u00d7\u00f3\u00f9\u00f6 p \u00f2 \u00f8 \u00f1\u00f3 \u00f0 q \u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7\u00b8 \u00f2 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f4 \u00f6\u00f8\u00d7 \u00f3 \u00f8 \u00f1\u00f3 \u00f0 \u00f6 \u00f1 \u00f8 \u00f9\u00f4 \u00fb \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f4 \u00f6\u00f8\u00d7 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00ba \u00f6\u00d7\u00f8 \u00f3 \u00f0\u00f0\u00b8\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00f8 l th \u00f0 \u00fd \u00f6 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 l p l , q l \u00ba \u00e0 \u00fa \u00f2 \u00f3\u00f2 \u00f8 \u00f8\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00f8 l \u2212 1 th \u00f0 \u00fd \u00f6 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00b8 \u00fa \u00f2 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 l th \u00f0 \u00fd \u00f6 \u00d7 \u00f0\u00f6 \u00fd \u00f2\u00f3\u00fb\u00f2\u00b8 \u00d7 l p l\u22121|l , q l\u22121|l \u00b8\u00fb \u00f1\u00f9\u00d7\u00f8 \u00f8 \u00f2 \u00fa \u00f6 \u00f3\u00fa \u00f6 \u00f8 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 l th \u00f0 \u00fd \u00f6 \u00f8\u00f3 \u00fd \u00f0 ml il=1 p l il l p l\u22121|l , q l\u22121|l \u00ba \u00ec \u00d7 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f8 \u00f2 \u00f6 \u00f4 \u00f8 \u00f8\u00f3 \u00f2\u00f3 \u00f8 l \u2212 2 th \u00f0 \u00fd \u00f6 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00b8 \u00fa \u00f2 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 l \u2212 1 th \u00f0 \u00fd \u00f6 \u00d7 \u00f0\u00f6 \u00fd \u00f2\u00f3\u00fb\u00f2\u00b8 \u00f2 \u00d7\u00f3 \u00f3\u00f2 \u00f8\u00f3 \u00f0 \u00fd \u00f6 0\u00ba \u00ec \u00d7 \u00fd \u00f0 \u00d7 \u00f4\u00f6 \u00d7 \u00f0\u00fd \u00f8 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 l (p, q) \u00fa \u00f2 \u00f3\u00fa \u00ba \u00fd \u00d7\u00b3 \u00f8 \u00f3\u00f6 \u00f1 \u00b4 \u00f2 \u00f8 \u00f3\u00f6\u00f1 p l+1 i l+1 p l|l+1 i l ,i l+1 = p l i l p l+1|l i l+1 ,i l \u00b5 \u00f1 \u00fd \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00fb\u00f6 \u00f8 \u00f8 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 l (p, q) \u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00f3\u00fb \u00f3 \u00f2 \u00f9 \u00f2 \u00f2 p \u00f2 q \u00f6\u00f9\u00f2\u00d7 \u00f2 \u00f3\u00f4\u00f4\u00f3\u00d7 \u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00ec \u00f9\u00d7 l (p, q) = l\u22121 l=0 m l i l =1 p l i l k i l p l+1|l , q l|l+1 + l p l , q l \u00b4\u00bd\u00bf\u00b5 \u00fb \u00f6 k i l p l+1|l , q l|l+1 \u00d7 \u00f2 \u00d7 k i l p l+1|l , q l|l+1 \u2261 \u2212 m l+1 i l+1 =1 p l+1|l i l+1 ,i l log q l|l+1 i l ,i l+1 \u00b4\u00bd \u00b5 \u00ec \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 l (p, q) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf \u00d7 \u00f2 \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00be\u00ba \u00e7\u00f8 \u00f6 \u00f8\u00fd\u00f4 \u00d7 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f1 \u00fd \u00f0\u00d7\u00f3 \u00f3\u00f2\u00d7 \u00f6 \u00b8\u00d7\u00f9 \u00d7 \u00f3\u00f2 \u00d7 \u00f2 \u00fb \u00d7\u00f3\u00f1 \u00f3 \u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f6 \u00f2\u00f3\u00f8 \u00f2\u00f0\u00f9 \u00f2 \u00f8 \u00f0\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00ba \u00e7\u00f2 \u00d7\u00f9 \u00fc \u00f1\u00f4\u00f0 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00ba \u00be\u00ba \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00ee \u00fb\u00f4\u00f3 \u00f2\u00f8\u00d7 \u00ec \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f4 \u00f8\u00fb \u00f2 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00d7 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00b9 \u00f0\u00d7 \u00f2 \u00d7\u00f8 \u00f8 \u00f6\u00f3\u00f1 \u00f8 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb \u00f3 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f6\u00ba \u00ec \u00f3 \u00f0 \u00d7 \u00f8\u00f3 \u00f9 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0 q 0 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 p 0 \u00b8\u00d7\u00f9 \u00f8 \u00f8 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 l p 0 , q 0 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 p 0 \u00d7 \u00f1 \u00f2 \u00f1 \u00d7 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00f8 \u00d7\u00f3\u00f9\u00f6 p 0 \u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00f8 \u00f6\u00f3\u00f9 l \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f9 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00d7\u00f3\u00f9\u00f6 p l \u00b8\u00f8 \u00f2 l p 0 , q 0 \u2264 l (p, q) \u00fb \u00f6 l (p, q) \u00d7 \u00fa \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00be\u00b8\u00fb \u00d7 \u00f8 \u00d7\u00f9\u00f1 \u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 l p l , q l \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 p l \u00b8\u00f4\u00f0\u00f9\u00d7 \u00b4 \u00f3\u00f6 l = 0, 1, \u2022 \u2022 \u2022 , l \u2212 1\u00b5 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 m l+1 i l+1 =1 p l+1 i l+1 l i l+1 p l|l+1 , q l|l+1 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 p l|l+1 \u00ba \u00ec \u00f9\u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00f3 \u00f2\u00f3 \u00f2 \u00f8 \u00d7\u00f3\u00f9\u00f6 p 0 \u00f2 \u00d7\u00f4\u00f0 \u00f8 \u00f2\u00f8\u00f3 \u00f8 \u00f6 \u00d7\u00f8 \u00f4\u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00f6\u00f3\u00f1 p 0 \u00f8\u00f3 p l \u00b8 \u00f2\u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00d7\u00f3\u00f9\u00f6 p l \u00b8 \u00f2 \u00f2\u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2\u00d7 p l|l+1 \u00b4 \u00f3\u00f6 l = 0, 1, \u2022 \u2022 \u2022 , l \u2212 1\u00b5 \u00f8\u00f3 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00f8\u00f3 \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f6\u00f3\u00f1 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00d7\u00f3\u00f9\u00f6 \u00ba \u00ec \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 l (p, q) \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 p l \u00f2 p l|l+1 \u00b4 \u00f3\u00f6 l = 0, 1, \u2022 \u2022 \u2022 , l\u22121\u00b5 \u00d7 \u00f8 \u00f2 \u00f2 \u00f9\u00f4\u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 l p 0 , q 0 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 p 0 \u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f4 \u00f8\u00f9\u00f6 \u00b8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f3\u00f2\u00f2 \u00f8 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 p 0 \u00f8\u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00d7\u00f3\u00f9\u00f6 p l \u00b8\u00d7\u00f3 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f6 \u00f0 \u00f8 \u00d7 \u00f3\u00f2 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00b4 \u00ba \u00ba \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 q 0 \u00b5 \u00f8\u00f3 \u00f2\u00f3\u00f8 \u00f6 \u00b4 \u00ba \u00ba \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 q l \u00b5\u00ba \u00ec \u00f3\u00fa \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f4 \u00f8\u00fb \u00f2 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00b9 \u00f0\u00d7 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00d7 \u00fb \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f6\u00f3\u00f1 \u00f8 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb \u00f3 \u00f3\u00f2\u00b9 \u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f6\u00b8\u00fb \u00f3 \u00d7\u00d7 \u00f6\u00f8\u00d7 \u00f8 \u00f8 \u00f8 \u00f3 \u00f0 \u00d7 \u00f8\u00f3 \u00f9 \u00f0 \u00f2 \u00f3\u00f4\u00f8 \u00f1\u00f9\u00f1 \u00b4 \u00ba \u00ba \u00f1 \u00f2 \u00f1\u00f9\u00f1 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00b5 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0 q 0 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 p 0 \u00ba \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb\u00b8\u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f1 \u00f6 \u00f0\u00fd \u00f1 \u00f2\u00d7 \u00f3 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00f6\u00f3\u00f1 \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f8 \u00d7\u00f3\u00f9\u00f6 p 0 \u00f8\u00f3 \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00d7\u00f3\u00f9\u00f6 p l \u00ba \u00ec \u00f8 \u00f8 \u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f1\u00f4 \u00f6 \u00f8 \u00d7 \u00f6 \u00f8 \u00f2 \u00f8 \u00f8 \u00f8 \u00f8 \u00f1\u00f3\u00f6 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f2\u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00d7\u00f3\u00f9\u00f6 p l \u00b4\u00f4\u00f0\u00f9\u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f8 \u00f8 \u00f2 \u00f6 \u00f8 \u00d7 \u00f8\u00b5 \u00f8 \u00f2 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 p 0 \u00ba \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f6 \u00f1 \u00f8 \u00f6 \u00d7\u00f3\u00f2 \u00f0\u00fd \u00d7 \u00fb \u00f8 \u00d7 \u00f8 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00f9\u00d7 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00d7\u00b8 \u00f8 \u00fd \u00fa \u00f3\u00f2\u00f0\u00fd \u00f2 \u00f9\u00f4\u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f3\u00f6 \u00f2\u00f3 \u00f2 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 p 0 \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00f0\u00f0 \u00f0 \u00f6 \u00f8 \u00f8 \u00f8 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f6 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00f3\u00f6\u00f6 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00f4\u00f0 \u00ba \u00ef \u00fd \u00d7 \u00f3\u00f9\u00f0 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f3\u00f6 \u00f2\u00f3 \u00f2 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 p 0 \u00d7\u00f4 \u00f0\u00f0\u00fd \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00e1\u00f8 \u00d7 \u00d7 \u00f8 \u00fb\u00f3\u00f6\u00f0 \u00d7 \u00f2 \u00d7 \u00f4 \u00f6 \u00f8 \u00f2\u00f8\u00f3 \u00f2 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00fb\u00f3\u00f6\u00f0 \u00b4 \u00ba \u00ba p 0 \u00b5 \u00f2 \u00f2 \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00fb\u00f3\u00f6\u00f0 \u00b4 \u00ba \u00ba \u00f8 p l+1|l \u00f3\u00f6 l = 0, 1, \u2022 \u2022 \u2022 , l \u2212 1\u00b5\u00b8 \u00f2 \u00d7\u00f4 \u00f0 \u00d7\u00f8 \u00f8\u00f9\u00d7 \u00d7 \u00f3\u00f6 \u00f8\u00f3 \u00f8 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00fb\u00f3\u00f6\u00f0 \u00b8\u00fb \u00f1\u00d7 \u00f8 \u00f8 \u00f8 \u00d7 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f8\u00d7 \u00f2\u00d7 \u00f8\u00fd p 0 \u00f9\u00f6 \u00f8 \u00f0\u00fd\u00b8 \u00f8 \u00f8 \u00fc\u00f4 \u00f2\u00d7 \u00f3 \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f8 p l+1|l \u00f9\u00f6 \u00f8 \u00f0\u00fd\u00ba \u00e1\u00f2 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00b8\u00f8 \u00d7 \u00f6\u00f8 \u00f0 \u00f3\u00f9\u00f2 \u00f6\u00fd \u00f8\u00fb \u00f2 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00f2 \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00fb\u00f3\u00f6\u00f0 \u00d7 \u00d7 \u00f6 \u00f1\u00f3\u00fa \u00b8 \u00f9\u00d7 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00f2\u00d7 \u00f8\u00fd p 0 , p 1|0 , \u2022 \u2022 \u2022 , p l|l\u22121 \u00b8\u00fb \u00f6 p 0 \u00f2 \u00f8 p l+1|l \u00f6 \u00f0\u00f0 \u00f3\u00f6 \u00f5\u00f9 \u00f0 \u00d7\u00f8 \u00f8\u00f9\u00d7\u00ba \u00ec \u00d7 \u00fa \u00f2\u00b9 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00f1\u00f9 \u00f1\u00f3\u00f6 \u00f2 \u00f8\u00f9\u00f6 \u00f0 \u00f8 \u00f2 \u00f3\u00f2 \u00f2 \u00fb \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba \u00f8 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00b5 \u00d7 \u00f3\u00f6 \u00d7\u00f4 \u00f0 \u00d7\u00f8 \u00f8\u00f9\u00d7\u00ba \u00e1\u00f2 \u00f8 \u00f0 \u00f2 \u00f9 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00b8\u00f8 \u00fa \u00f8\u00f3\u00f6 p 0 , p 0|1 , \u2022 \u2022 \u2022 , p l|l\u22121 \u00d7 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00fb \u00f3\u00f1\u00f4\u00f6 \u00d7 \u00d7 \u00f8 \u00f3\u00f8\u00f8\u00f3\u00f1\u00b9\u00f9\u00f4 \u00f8\u00f6 \u00f2\u00d7\u00b9 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2\u00d7 \u00b4\u00f3\u00f6 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00b5 \u00fb \u00f2 \u00f6 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00f8 \u00fa \u00f8\u00f3\u00f6 q 0|1 , q 1|2 , \u2022 \u2022 \u2022 , q l \u00d7 \u00f8 \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00fb \u00f3\u00f1\u00f4\u00f6 \u00d7 \u00d7 \u00f8 \u00f8\u00f3\u00f4\u00b9 \u00f3\u00fb\u00f2 \u00f8\u00f6 \u00f2\u00d7 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2\u00d7 \u00b4\u00f3\u00f6 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0\u00d7\u00b5\u00ba \u00ec \u00f9\u00d7 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00d7 \u00f0 \u00b9\u00f6 \u00f6 \u00f2\u00f8 \u00f0\u00b8 \u00f9\u00d7 \u00f8 \u00f3\u00f6\u00f1\u00d7 \u00f1\u00f3 \u00f0 \u00f3 \u00d7\u00f3\u00f9\u00f6 \u00f8 \u00f8 \u00f2\u00f0\u00f9 \u00d7 \u00f8\u00d7 \u00f3\u00fb\u00f2 \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00ec \u00d7 \u00d7 \u00f0 \u00b9\u00f6 \u00f6 \u00f2\u00f8 \u00f0 \u00fa \u00f3\u00f9\u00f6 \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f3\u00f8 \u00f8 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f2 \u00f2 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00d7\u00b8 \u00f9\u00f8 \u00fb \u00f6 \u00d7 \u00f2 \u00f8 \u00f3\u00f6\u00f1 \u00f6 \u00d7 \u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00f2 \u00fa \u00f2\u00b9 \u00f2 \u00d7 \u00f3\u00f2\u00b8 \u00f2 \u00f8 \u00f0 \u00f8\u00f8 \u00f6 \u00d7 \u00f8 \u00d7 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00f2 \u00fa \u00f2\u00b9 \u00f2 \u00d7 \u00f3\u00f2\u00ba \u00bf \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00ec\u00f3 \u00ed\u00f2\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 ae \u00f9\u00f6 \u00f0 ae \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00bd \u00f8 \u00f8 \u00f3\u00f6\u00fd \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f3 \u00f2 \u00b4\u00f8 \u00f8 \u00fb \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bf\u00b5 \u00d7 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be \u00f8 \u00d7 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00be\u00b9\u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 \u00d7\u00f3 \u00f8 \u00fa \u00f8\u00f3\u00f6 \u00f5\u00f9 \u00f2\u00f8 \u00d7 \u00f6 \u00b4\u00ee\u00e9\u00b5\u00b8\u00fb \u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00bf \u00f8\u00f3 \u00f3 \u00f8 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3 \u00f3\u00f9\u00f4\u00f0 \u00d7\u00f3 \u00f8 \u00ee\u00e9\u00d7\u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00f8 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f3\u00fb \u00f2 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00e3\u00f3 \u00f3\u00f2 \u00f2\u00b3\u00d7 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2 \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00f8 \u00f8 \u00f3\u00f6\u00fd \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f3 \u00f2 \u00ba \u00f2 \u00f0\u00f0\u00fd\u00b8\u00d7\u00f3\u00f1 \u00f8 \u00f3\u00f2 \u00f0 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f6 \u00f6 \u00fd \u00f9\u00d7\u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00ba \u00bf\u00ba\u00bd \u00eb\u00f3\u00f9\u00f6 \u00e5\u00f3 \u00f0 \u00f3 \u00e4 \u00fd \u00f6 ae \u00f8\u00fb\u00f3\u00f6 \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00e8 \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f2 (l + 1)\u00b9\u00f0 \u00fd \u00f6 \u00f2\u00f3 \u00f6 \u00f3 \u00f8 \u00f8\u00fd\u00f4 \u00f8 \u00f8 \u00fb \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bf \u00fb \u00f0\u00f0 \u00f3\u00f2\u00d7 \u00f6 \u00ba \u00e1\u00f8 \u00f8\u00f9\u00f6\u00f2\u00d7 \u00f3\u00f9\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f0 \u00d7 \u00f8\u00f3 \u00f2 \u00fb \u00f2\u00d7 \u00f8\u00d7 \u00f2\u00f8\u00f3 \u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f9\u00f2\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00ba \u00ec \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7\u00f3\u00f9\u00f6 p = p 0 , p 1|0 , \u2022 \u2022 \u2022 , p l\u22121|l\u22122 , p l|l\u22121 \u00b4\u00f3\u00f6\u00b8 \u00f5\u00f9 \u00fa\u00b9 \u00f0 \u00f2\u00f8\u00f0\u00fd\u00b8p = p 0|1 , p 1|2 , \u2022 \u2022 \u2022 , p l\u22121|l , p l \u00b5 \u00f1 \u00fd \u00f9\u00d7 \u00f8\u00f3 \u00d7\u00f6 \u00f8 \u00f8\u00f6\u00f9 \u00fa \u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba \u00f2\u00f3\u00f8 \u00f1 \u00f6 \u00f0\u00fd \u00f1\u00f3 \u00f0\u00b5 \u00f3 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7\u00ba p 0 \u00d7 \u00f2 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00b8 \u00f2 p 1|0 , \u2022 \u2022 \u2022 , p l\u22121|l\u22122 , p l|l\u22121 \u00d7 \u00f2 \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00fb \u00f6 \u00fc\u00f8 \u00f6\u00f2 \u00f0\u00bb \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f6 \u00d7 \u00fb \u00f8 \u00f6 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f3\u00f9\u00f8\u00d7 \u00bb \u00f2\u00d7 \u00f8 \u00f0 \u00fd\u00b9 \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8\u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd\u00ba p l+1|l \u00d7 \u00f2\u00f3\u00f8 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00f8\u00d7 \u00f0 \u00b4 \u00ba \u00ba \u00f8 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00b5\u00b8\u00f6 \u00f8 \u00f6 \u00f8 \u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f1 \u00f8\u00f6 \u00fc \u00f8 \u00f8 \u00d7\u00f6 \u00d7 \u00f8 \u00fb \u00fd \u00f2 \u00fb \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 l \u00f3 \u00f8 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2 \u00f9 \u00f2 \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 l + 1\u00ba \u00ec \u00f6 \u00d7 \u00f2 \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 p l \u00f2 \u00f8 p l|l+1 \u00ba \u00ec \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f1\u00f3 \u00f0 q = q 0 , q 1|0 , \u2022 \u2022 \u2022 , q l\u22121|l\u22122 , q l|l\u22121 \u00b4\u00f3\u00f6\u00b8 \u00f5\u00f9 \u00fa\u00b9 \u00f0 \u00f2\u00f8\u00f0\u00fd\u00b8q = q 0|1 , q 1|2 , \u2022 \u2022 \u2022 , q l\u22121|l , q l \u00b5 \u00f1 \u00fd \u00f8 \u00f2 \u00f9\u00d7 \u00d7 \u00f1\u00f3 \u00f0 \u00b4 \u00ba \u00ba \u00f2\u00f3\u00f8 \u00f8\u00f9 \u00f0\u00f0\u00fd \u00f8 \u00f8\u00f6\u00f9 \u00fa \u00f3\u00f9\u00f6\u00b5 \u00f3 \u00f0 \u00fd \u00f6 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba q \u00d7 \u00f2 \u00f2 \u00f0\u00b9 \u00f3 \u00f3\u00f9\u00d7 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00f3 p\u00b8 \u00fc \u00f4\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00b8\u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f8\u00f6\u00f9 \u00fa \u00f3\u00f9\u00f6 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00ba \u00e1\u00f8 \u00f8\u00f9\u00f6\u00f2\u00d7 \u00f3\u00f9\u00f8 \u00f8\u00f3 \u00f9\u00d7 \u00f9\u00f0 \u00f3\u00f6 \u00f8 \u00f8\u00f6\u00f9 \u00e5 \u00f6 \u00f3\u00fa \u00fa \u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba p\u00b5 \u00f2 \u00f8 \u00f1\u00f3 \u00f0 \u00e5 \u00f6 \u00f3\u00fa \u00fa \u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba q\u00b5 \u00f8\u00f3 \u00f6\u00f9\u00f2 \u00f2 \u00f3\u00f4\u00f4\u00f3\u00d7 \u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8 \u00f6\u00f3\u00f9 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00ba \u00ec \u00f9\u00d7 p = p 0 , p 1|0 , \u2022 \u2022 \u2022 , p l\u22121|l\u22122 , p l|l\u22121 \u00b4 \u00f3\u00fb \u00f3 \u00f2 \u00f9 \u00f2 \u00f6\u00f3\u00f1 \u00f0 \u00fd \u00f6 0 \u00f8\u00f3 \u00f0 \u00fd \u00f6 l \u00f3 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00b5 \u00f2 q = q 0|1 , q 1|2 , \u2022 \u2022 \u2022 , q l\u22121|l , q l \u00b4 \u00f3\u00fb \u00f3 \u00f2 \u00f9 \u00f2 \u00f6\u00f3\u00f1 \u00f0 \u00fd \u00f6 l \u00f8\u00f3 \u00f0 \u00fd \u00f6 0 \u00f3 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00b5\u00ba \u00e1\u00f2 \u00f8 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f0 \u00f2 \u00f9 \u00f3 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00b8p \u00d7 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00f2 q \u00d7 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0 \u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f9\u00d7 \u00f3 \u00f8 \u00fb\u00f3\u00f6 \u00f1\u00f3 \u00f0 \u00f2 \u00f8 \u00f8 \u00f6\u00f1 \u00f2\u00f3\u00f0\u00f3 \u00fd \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00d7\u00f8\u00f6 \u00f8\u00f0\u00fd \u00d7\u00f4 \u00f2 \u00f2\u00f3\u00f8 \u00f9\u00f6 \u00f8 \u00f2 \u00f8 \u00d7 \u00f3\u00f2\u00f8 \u00fc\u00f8\u00b8 \u00f9\u00d7 p \u00d7 \u00d7\u00f3\u00f9\u00f6 \u00f2\u00f3\u00f8 \u00f1\u00f3 \u00f0\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00f6\u00f1 \u00f2\u00f3\u00f0\u00f3 \u00fd \u00f4 \u00f2 \u00d7 \u00f3\u00f2 \u00f3\u00f2 \u00b3\u00d7 \u00fa \u00fb\u00f4\u00f3 \u00f2\u00f8\u00ba \u00e1\u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 p \u00d7 \u00d7\u00f3\u00f9\u00f6 \u00fb \u00f2 \u00fa \u00fb \u00f6\u00f3\u00f1 \u00f8 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb \u00f3 \u00f8 \u00f1\u00f3 \u00f0 q\u00ba \u00ef \u00f6 \u00d7\u00b8 \u00f2 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 p 0 \u00d7 \u00d7\u00f3\u00f9\u00f6 \u00fb \u00f2 \u00fa \u00fb \u00f6\u00f3\u00f1 \u00f8 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00f1\u00f3 \u00f0 q 0 \u00b8 \u00f2 \u00fb \u00d7 p 1|0 , \u2022 \u2022 \u2022 , p l\u22121|l\u22122 , p l|l\u22121 \u00d7 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00f2 q 0|1 , q 1|2 , \u2022 \u2022 \u2022 , q l\u22121|l , q l \u00d7 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0\u00ba \u00bf\u00ba\u00be \u00be\u00b9\u00e4 \u00fd \u00f6 \u00eb\u00f3 \u00f8 \u00ee \u00f8\u00f3\u00f6 \u00e9\u00f9 \u00f2\u00f8 \u00d7 \u00f6 \u00b4\u00ee\u00e9\u00b5 ae \u00f8\u00fb\u00f3\u00f6 \u00ec \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 l (p, q) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00fb \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8 \u00f8\u00f3 \u00d7\u00fd\u00d7\u00f8 \u00f1 \u00f8 \u00f0\u00f0\u00fd \u00f2 \u00f0\u00fd\u00d7 \u00ba \u00ec \u00f9\u00d7 \u00f4\u00f4\u00f0\u00fd \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf \u00f8\u00f3 \u00be\u00b9\u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fb \u00f6 p = p 0 , p 1|0 q = q 0|1 , q 1 \u00b4\u00bd \u00b5 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l (p, q) = \u2212 m0 i0=1 p 0 i0 m1 i1=1 p 1|0 i1,i0 log q 0|1 i0,i1 + l p 1 , q 1 \u00b4\u00bd \u00b5 ae\u00f3\u00fb \u00f2 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f1 \u00f3\u00f2\u00f8 \u00f8 \u00fb \u00f8 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3\u00f2 \u00fa \u00f8\u00f3\u00f6 \u00f5\u00f9 \u00f2\u00f8 \u00d7 \u00f6\u00d7 \u00b4\u00ee\u00e9\u00b5 i 0 \u2192 x m0 i0=1 \u2192 dx \u00f2\u00f4\u00f9\u00f8 \u00fa \u00f8\u00f3\u00f6 i 1 \u2192 y m1 i1=1 \u2192 m y=1 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f3 \u00f2 \u00fc p 0 i0 \u2192 pr (x) \u00f2\u00f4\u00f9\u00f8 \u00e8 p 1|0 i1,i0 \u2192 pr (y|x) \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 q 0|1 i0,i1 \u2192 v 1 ( \u221a 2\u03c0\u03c3) dim x exp \u2212 x\u2212x \u2032 (y) 2 2\u03c3 2 \u00f9\u00d7\u00d7 \u00f2 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0 q 1 i1 \u2192 q (y) \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f4\u00f6 \u00f3\u00f6 \u00b4\u00bd \u00b5 \u00fb \u00f6 x \u00d7 \u00f3\u00f2\u00f8 \u00f2\u00f9\u00f3\u00f9\u00d7\u00b9\u00fa \u00f0\u00f9 \u00f2\u00f4\u00f9\u00f8 \u00fa \u00f8\u00f3\u00f6 \u00b4 \u00ba \u00ba \u00f8 \u00f8 \u00fa \u00f8\u00fd \u00f4 \u00f8\u00f8 \u00f6\u00f2 \u00f2 \u00f0 \u00fd \u00f6 \u00bc\u00b5\u00b8\u03c3 \u00d7 \u00f8 \u00b4 \u00d7\u00f3\u00f8\u00f6\u00f3\u00f4 \u00b5 \u00fa \u00f6 \u00f2 \u00f3 \u00f8 \u00f9\u00d7\u00d7 \u00f2 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0\u00b8v \u00d7 \u00f2 \u00f2\u00b9 \u00f2 \u00f8 \u00d7 \u00f1 \u00f0 \u00fa\u00f3\u00f0\u00f9\u00f1 \u00f0 \u00f1 \u00f2\u00f8 \u00f2 \u00f2\u00f4\u00f9\u00f8 \u00d7\u00f4 \u00fb \u00f1 \u00fd \u00f9\u00d7 \u00f8\u00f3 \u00f3\u00f2\u00fa \u00f6\u00f8 \u00f8 \u00f9\u00d7\u00d7 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2\u00d7 \u00f8\u00fd \u00f2\u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b8 \u00f2 y \u00d7 \u00d7\u00f6 \u00f8 \u00b9\u00fa \u00f0\u00f9 \u00f3\u00f9\u00f8\u00b9 \u00f4\u00f9\u00f8 \u00f2 \u00fc \u00b4 \u00ba \u00ba \u00f8 \u00f0\u00f3 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2 \u00fc\u00f8 \u00f2 \u00f9\u00f6\u00f3\u00f2 \u00f8\u00f3 \u00f6 \u00f2 \u00f0 \u00fd \u00f6 \u00bd\u00b5\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f4 \u00f6 \u00f1 \u00f8 \u00f6 v \u00f1\u00f9\u00d7\u00f8 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f6 \u00f9\u00f0 \u00f6 \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00d7\u00f4 \u00fd \u00d7\u00f3\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u00ba \u00e1\u00f2 \u00f8\u00b8v \u00d7\u00f4 \u00d7 \u00f6 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00d7 \u00f0 \u00d7\u00f9 \u00f8 \u00f8 \u00f8 \u00f0\u00d7 \u00f3\u00f2 \u00d7\u00f1 \u00f0\u00f0 \u00f6 \u00d7 \u00f0 \u00d7 \u00f6 \u00f2\u00f3\u00f6 \u00ba \u00ec \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f0\u00f0\u00f3\u00fb\u00d7 l (p, q) \u00f8\u00f3 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 l (p, q) = d v q 4\u03c3 2 + l p 1 , q 1 \u2212 log v \u221a 2\u03c0\u03c3 dim x \u00b4\u00bd \u00b5 \u00fb \u00f6 d v q \u00d7 \u00f2 \u00d7 d v q \u2261 2 dx pr (x) m y=1 pr (y|x) x \u2212 x \u2032 (y) 2 \u00b4\u00bd \u00b5 \u00ec \u00f6\u00d7\u00f8 \u00f8 \u00f6\u00f1 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00d7 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00f3 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 d v q \u00f3\u00f6 \u00d7\u00f3 \u00f8 \u00fa \u00f8\u00f3\u00f6 \u00f5\u00f9 \u00f2\u00f8 \u00d7 \u00f6 \u00b4\u00ee\u00e9\u00b5\u00b8\u00fb \u00f6 pr (y|x) \u00d7 \u00d7\u00f3 \u00f8 \u00f2\u00f3 \u00f6\u00b8 \u00f2 x \u2032 (y) \u00d7 \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2 \u00fa \u00f8\u00f3\u00f6 \u00f8\u00f8 \u00f8\u00f3 \u00f3 \u00f2 \u00fc y\u00b8 \u00f2 x \u2212 x \u2032 (y) 2 \u00d7 \u00f8 l 2 \u00f2\u00f3\u00f6\u00f1 \u00f3 \u00f8 \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2 \u00f6\u00f6\u00f3\u00f6\u00ba \u00d7\u00f8 \u00f2 \u00f6 \u00ee\u00e9 \u2104 \u00b4 \u00ba \u00ba \u00fb \u00f2\u00f2 \u00f6\u00b9\u00f8 \u00b9 \u00f0\u00f0 \u00f2\u00f3 \u00f6\u00b5 \u00d7 pr (y|x) = \u03b4 y,y(x) \u00b8\u00fb \u00f1 \u00f6 \u00d7 \u00d7 \u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00f0 \u00f3\u00f6\u00f1 \u00fb \u00f2 \u00f8 \u00d7 \u00ee\u00e9 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00d7 \u00f1 \u00f2 \u00f1 \u00d7 \u00fb\u00ba\u00f6\u00ba\u00f8\u00ba pr (y|x) \u00b4\u00d7 \u00bd\u00bc\u2104 \u00f3\u00f6 \u00f8 \u00f0 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00d7\u00d7\u00f9 \u00d7\u00b5\u00ba \u00ec \u00d7 \u00f3\u00f2 \u00f8 \u00f6\u00f1 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00b4 \u00ba \u00ba l p 1 , q 1 \u00b5 \u00d7 \u00f8 \u00f3\u00d7\u00f8 \u00f3 \u00f3 \u00f2 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f0 \u00fd \u00f6\u00b8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 \u00f6\u00f1 \u00d7 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8\u00ba \u00ec \u00f8 \u00f3 \u00f8 l p 1 , q 1 \u00f8 \u00f6\u00f1 \u00f2 l (p, q) \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00b5 \u00d7 \u00f8\u00f3 \u00f2\u00f3\u00f9\u00f6\u00b9 p 1 i \u2192 \u03b4 i,i0 \u00b4\u00f3\u00f2\u00f0\u00fd \u00f3\u00f2 \u00d7\u00f8 \u00f8 \u00f2 \u00f0 \u00fd \u00f6 \u00bd \u00d7 \u00f9\u00d7 \u00b5 \u00f2 q 1 \u2192 p 1 \u00b4\u00f4 \u00f6 \u00f8 \u00f1\u00f3 \u00f0 \u00f2 \u00f0 \u00fd \u00f6 \u00bd\u00b5\u00ba \u00ec \u00fa \u00f3\u00f9\u00f6 p 1 i \u2192 \u03b4 i,i0 \u00d7 \u00f2 \u00f3\u00f2 \u00f8 \u00fb \u00f8 \u00f8 \u00f6 \u00f5\u00f9 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f3 \u00f8 \u00f6\u00d7\u00f8 \u00f8 \u00f6\u00f1 \u00b4 \u00ba \u00ba \u00f8 \u00d7\u00f3 \u00f8 \u00ee\u00e9\u00b5 \u00f2 l (p, q)\u00b8\u00fb \u00f6 \u00f5\u00f9 \u00f6 \u00d7 \u00f8 \u00f8 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7\u00f8 \u00f8 \u00f2 \u00f0 \u00fd \u00f6 \u00bd \u00d7 \u00f9\u00d7 \u00b8 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f1 \u00f2 \u00f1 \u00d7 \u00f8 \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2 \u00d7\u00f8\u00f3\u00f6\u00f8 \u00f3\u00f2\u00ba \u00ec \u00f6 \u00d7 \u00f8\u00f6 \u00f3 \u00f8\u00fb \u00f2 \u00f2\u00f6 \u00d7 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8 \u00fa \u00d7\u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00fd \u00f6 \u00bd \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f2 \u00f0 \u00f8 \u00f9\u00d7\u00d7 \u00f2 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0 \u00b4q0 \u00d7 \u00f9\u00d7\u00d7 \u00f2 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2\u00b5 \u00f8\u00f3 \u00f1 \u00f3\u00f3 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 p 0 \u00b8 \u00f2 \u00f6 \u00d7 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8 \u00fa \u00d7\u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00fd \u00f6 \u00bd \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f1 \u00f8 \u00fa \u00f6 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 l p 1 , q 1 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00d7\u00f4 \u00fd \u00f2 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00d7\u00f1 \u00f0\u00f0 \u00d7 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00ba \u00bf\u00ba\u00bf \u00f3\u00f9\u00f4\u00f0 \u00eb\u00f3 \u00f8 \u00ee\u00e9 ae \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be \u00fb \u00f0\u00f0 \u00f2\u00f3\u00fb \u00f2 \u00f6 \u00f0 \u00d7 \u00f8\u00f3 \u00f2 (l + 1)\u00b9\u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00ec \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f3 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf\u00b5 \u00f2 \u00fb\u00f6 \u00f8\u00f8 \u00f2\u00f9 \u00d7 \u00f2 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00fb \u00d7 \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7 \u00f8\u00f3 \u00f8 \u00f8 \u00fa \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00d7 l (p, q) = l\u22121 l=0 d l v q 4 (\u03c3 l ) 2 + l p l , q l \u2212 l\u22121 l=0 log v l \u221a 2\u03c0\u03c3 l dim x l \u00b4\u00be\u00bc\u00b5 \u00fb \u00f6 d l v q \u00d7 \u00f2 \u00d7 \u00b4d0 v q = d v q \u00d7 \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00b5 d l v q \u2261 2 dx l pr (x l ) m l+1 y l+1 =1 pr (y l+1 |x l ) x l \u2212 x \u2032 l (y l ) 2 \u00b4\u00be\u00bd\u00b5 \u00bd\u00bc \u00fb \u00f6 x l \u00f2 y l \u00f6 \u00f3\u00f8 \u00f9\u00d7 \u00f8\u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 l\u00ba \u00ec \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 x l \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f2\u00f4\u00f9\u00f8 \u00f8\u00f3 \u00f8 \u00f2\u00f3 \u00f6 \u00f8 \u00f8 \u00f3\u00f2\u00f2 \u00f8\u00d7 \u00f0 \u00fd \u00f6\u00d7 l \u00f2 l + 1\u00b8\u00fb \u00f6 \u00d7 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 y l \u00f2\u00f3\u00f8 \u00d7 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f3 \u00f8 \u00f2\u00f3 \u00f6 \u00f8 \u00f8 \u00f3\u00f2\u00f2 \u00f8\u00d7 \u00f0 \u00fd \u00f6\u00d7 l \u2212 1 \u00f2 l\u00ba \u00ec \u00d7 \u00f6 \u00f9\u00f2 \u00f2\u00fd \u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f2\u00f3\u00f8 \u00f8\u00f9 \u00f0\u00f0\u00fd \u00f2 \u00d7\u00d7 \u00f6\u00fd\u00b8 \u00f9\u00f8 \u00d7 \u00f9\u00d7 \u00f6 \u00f8\u00f3 \u00f4\u00f6 \u00d7 \u00f6\u00fa \u00f8 \u00d7\u00f8 \u00f2\u00f8 \u00f3\u00f2 \u00f8\u00fb \u00f2 \u00f2\u00f4\u00f9\u00f8 \u00fa \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f3 \u00d7\u00ba \u00ec \u00f6\u00d7\u00f8 \u00f8 \u00f6\u00f1 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bc \u00d7 \u00fb \u00f8 \u00d7\u00f9\u00f1 \u00b4\u00fb \u00f6 \u00f8 \u00f6\u00f1 \u00d7 \u00fb \u00f8 \u00fd (\u03c3 l ) \u22122 \u00b5 \u00f3 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f6 \u00d7 \u00f8 \u00f3 \u00d7\u00f3 \u00f8 \u00ee\u00e9\u00d7 \u00f3\u00f2\u00f2 \u00f8 \u00f2 \u00f3 \u00f8 l \u00f2 \u00f3\u00f9\u00f6 \u00f2 \u00f4 \u00f6\u00d7 \u00f3 \u00f0 \u00fd \u00f6\u00d7 \u00f2 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00ec \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00fb \u00f0\u00f0 \u00f0\u00f0 \u00ee\u00e9\u00b9\u00f0 \u00f6\u00ba \u00ec \u00d7 \u00f3\u00f2 \u00f8 \u00f6\u00f1 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bc \u00b4 \u00ba \u00ba l p l , q l \u00b5 \u00d7 \u00f8 \u00f3\u00d7\u00f8 \u00f3 \u00f3 \u00f2 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f0 \u00fd \u00f6\u00b8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 \u00f6\u00f1 \u00d7 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8\u00ba \u00e1 \u00f8 \u00f3\u00d7\u00f8 l p l , q l \u00f3 \u00f3 \u00f2 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f0 \u00fd \u00f6 \u00d7 \u00f2\u00f3\u00f6 \u00b8\u00f8 \u00f2 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00b9 \u00f0 \u00fd \u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f3 \u00f2 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l (p, q) \u00d7 \u00f1 \u00f2 \u00f1 \u00d7 \u00fd \u00f1 \u00f2 \u00f1 \u00d7\u00b9 \u00f2 \u00f8 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l\u22121 l=0 d l v q (\u03c3 l ) 2 \u00f3\u00f6 \u00ee\u00e9\u00b9\u00f0 \u00f6 \u00b4\u00d7 \u00bd\u00bc\u2104 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f4\u00f3 \u00f2\u00f8 \u00f2 \u00f8 \u00f3\u00f2\u00f8 \u00fc\u00f8 \u00f3 \u00f3\u00f0 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00b4 \u00e5 \u00b5\u00b5\u00ba \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 l \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f0 \u00fd \u00f6\u00d7 \u00d7 \u00f2\u00f6 \u00d7 \u00b8\u00f8 \u00f8 \u00f3 \u00f8 l p l , q l \u00f8 \u00f6\u00f1 \u00d7 \u00f0 \u00d7\u00d7 \u00f2 \u00f0 \u00d7\u00d7 \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2\u00b8 \u00f9\u00d7 \u00f8\u00d7 \u00f8 \u00d7 \u00d7\u00fb \u00f1\u00f4 \u00fd \u00f8 \u00ee\u00e9\u00b9\u00f0 \u00f6 \u00f8 \u00f6\u00f1\u00ba \u00bf\u00ba \u00ec\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00e5 \u00f4\u00f4 \u00f2 ae \u00f8\u00fb\u00f3\u00f6 \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3 \u00f8 \u00f2 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be \u00f3\u00f6 \u00d7\u00f3 \u00f8 \u00ee\u00e9 \u00f1 \u00fd \u00f2 \u00f6 \u00f0 \u00d7 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fb \u00f3\u00d7 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f0\u00f3\u00d7 \u00f0\u00fd \u00f6 \u00d7 \u00f1 \u00f0 \u00f8 \u00f3\u00d7 \u00f3 \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00bf\u2104\u00ba \u00ec \u00d7 \u00f6 \u00fa \u00f8 \u00f3\u00f2 \u00d7 \u00d7 \u00f3\u00f2 \u00f8 \u00f4\u00f4\u00f6\u00f3 \u00f8\u00f3 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00d7 \u00f8 \u00f8 \u00fb \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u2104\u00ba \u00ec \u00f9\u00d7 \u00f4\u00f4\u00f0\u00fd \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf \u00f8\u00f3 \u00bf\u00b9\u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 p = p 0 , p 1|0 , p 2|1 q = q 0|1 , q 1|2 , q 2 \u00b4\u00be\u00be\u00b5 \u00fb \u00f6 \u00f3\u00f2\u00f0\u00fd \u00f0 \u00fd \u00f6\u00d7 0 \u00f2 2 \u00f6 \u00f2\u00f0\u00f9 \u00f2 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2\u00b8\u00f8\u00f3 \u00f3 \u00f8 \u00f2 l (p, q) = \u2212 m0 i0=1 p 0 i0 m2 i2=1 p 2|0 i2,i0 log q 0|2 i0,i2 + l p 2 , q 2 \u00b4\u00be\u00bf\u00b5 \u00fb \u00d7 \u00f3\u00f9\u00f0 \u00f3\u00f1\u00f4 \u00f6 \u00fb \u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00ba \u00f2 \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7 \u00f2 \u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00f8 \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f2 \u00f1 i 0 \u2192 x m0 i0=1 \u2192 dx \u00f2\u00f4\u00f9\u00f8 \u00fa \u00f8\u00f3\u00f6 i 1 \u2192 y \u00f2 \u00f3 \u00f2 \u00fc i 2 \u2192 z \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f3 \u00f2 \u00fc p 0 i0 \u2192 pr (x) \u00f2\u00f4\u00f9\u00f8 \u00e8 p 1|0 i1,i0 \u2192 pr (y|x) \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00b4 \u00f6\u00d7\u00f8 \u00d7\u00f8 \u00b5 p 2|1 i2,i1 \u2192 pr (z|y) \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00b4\u00d7 \u00f3\u00f2 \u00d7\u00f8 \u00b5 q 0|2 i0,i2 \u2192 v 1 ( \u221a 2\u03c0\u03c3) dim x exp \u2212 x\u2212x \u2032 (z) 2 2\u03c3 2 \u00f9\u00d7\u00d7 \u00f2 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0 q 2 i2 \u2192 q (z) \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f4\u00f6 \u00f3\u00f6 \u00b4\u00be \u00b5 \u00bd\u00bd \u00f8\u00f3 \u00f3 \u00f8 \u00f2 l (p, q) = d v q 4\u03c3 2 + l p 2 , q 2 \u2212 log v \u221a 2\u03c0\u03c3 dim x \u00b4\u00be \u00b5 \u00fb \u00f6 d v q \u00d7 \u00f2 \u00d7 d v q \u2261 2 dx pr (x) m2 z=1 pr (z|x) x \u2212 x \u2032 (z) 2 \u00b4\u00be \u00b5 \u00fb \u00d7 \u00f3\u00f9\u00f0 \u00f3\u00f1\u00f4 \u00f6 \u00fb \u00f8 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00ba \u00ec \u00d7 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 d v q \u00fc\u00f4\u00f0 \u00f8\u00f0\u00fd \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f0 \u00fd \u00f6\u00d7 0 \u00f2 2 \u00f3 \u00bf\u00b9\u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00f8 \u00fb \u00f0\u00f0 \u00f2\u00f3\u00fb \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f2\u00f8\u00f3 \u00f3\u00f6\u00f1 \u00f8 \u00f8 \u00fc\u00f4\u00f0 \u00f8\u00f0\u00fd \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f0 \u00fd \u00f6\u00d7 0 \u00f2 1\u00ba \u00e1\u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00fd \u00f8 \u00d7 \u00f0\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00b8d v q \u00fb \u00f0\u00f0 \u00f6 \u00f4\u00f0 \u00fd \u00f8 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00bd\u00bc\u2104 d v q \u2261 dx pr (x) m2 z=1 pr (z|x) dx \u2032 pr (x \u2032 |z) x \u2212 x \u2032 2 \u00b4\u00be \u00b5 ae\u00f3\u00fb \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f9\u00f1\u00f1\u00fd \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00fa \u00f6 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 1 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 d v q \u2261 dx pr (x) m1 y=1 pr (y|x) \n m2 z=1 pr (z|y) m1 y \u2032 =1 pr (y \u2032 |z) \u00d7 dx \u2032 pr (x \u2032 |y \u2032 ) x \u2212 x \u2032 2 \u00b4\u00be \u00b5 \u00f2 \u00f6 \u00f6\u00f6 \u00f2 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 d v q \u2261 dx pr (x) m1 y \u2032 =1 pr (y \u2032 |x) dx \u2032 pr (x \u2032 |y \u2032 ) x \u2212 x \u2032 2 \u00b4\u00be \u00b5 \u00fb \u00f6 pr (y \u2032 |y) = m2 z=1 pr (y \u2032 |z) pr (z|y)   pr (y \u2032 |x) = m1 y=1 pr(y \u2032 |y) pr (y|x) \u00b4\u00bf\u00bc\u00b5 \u00fb \u00f1 \u00fd \u00f6 \u00f4\u00f0 \u00fd \u00f8 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 d v q \u2261 2 dx pr (x) m1 y \u2032 =1 pr (y \u2032 |x) x \u2212 x \u2032 (y \u2032 ) 2 \u00b4\u00bf\u00bd\u00b5 \u00fb \u00d7 \u00f3\u00f9\u00f0 \u00f3\u00f1\u00f4 \u00f6 \u00fb \u00f8 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00ba \u00bd\u00be \u00ec \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f8 \u00f3 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f2\u00f8\u00f3 \u00f8 \u00f3\u00f6\u00f1 \u00fa \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00bd \u00d7 \u00f8\u00f3 \u00f3\u00f2\u00fa \u00f6\u00f8 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f6\u00f3\u00f1 \u00f3\u00f2 \u00f8 \u00f8 \u00fc\u00f4\u00f0 \u00f8\u00f0\u00fd \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f0 \u00fd \u00f6\u00d7 0 \u00f2 2\u00b8\u00f8\u00f3 \u00f3\u00f2 \u00f8 \u00f8 \u00fc\u00f4\u00f0 \u00f8\u00f0\u00fd \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f0 \u00fd \u00f6\u00d7 0 \u00f2 1\u00ba \u00ec \u00d7 \u00f2 \u00d7 \u00f6 \u00f8 \u00f2 \u00f8 \u00f6 \u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f3 pr (z|x) \u00fd pr (y \u2032 |x)\u00ba \u00ec \u00d7 \u00f2 \u00fb \u00f3\u00f6\u00f1 \u00f3\u00f6 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00bd\u00b5 \u00d7 \u00fc \u00f8\u00f0\u00fd \u00f8 \u00d7 \u00f1 \u00d7 \u00f3\u00f6 \u00d7\u00f8 \u00f2 \u00f6 \u00ee\u00e9 \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00b5\u00b8 \u00fc \u00f4\u00f8 \u00f8 \u00f8 \u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr (y|x) \u00d7 \u00f2\u00f3\u00fb \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f8 \u00f6\u00f3\u00f9 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f1 \u00f8\u00f6 \u00fc pr(y \u2032 |y) \u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f9 pr (y \u2032 |x)\u00ba \u00f9\u00d7 pr(y \u2032 |y) = m2 z=1 pr (y \u2032 |z) pr (z|y)\u00b8 \u00f8 \u00f8 \u00d7 \u00f3\u00f9\u00f2\u00f8 \u00f3 \u00f8 \u00f8 \u00f3 \u00f8 \u00d7\u00f8 \u00f8 z \u00f3 \u00f0 \u00fd \u00f6 2 \u00f3\u00f2 \u00f8 \u00f8\u00f6 \u00f2 \u00f2 \u00f3 \u00f0 \u00fd \u00f6 1\u00b8\u00fb \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00d7 \u00f0 \u00b9\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f3\u00f2 \u2104 \u00f2 \u00fb \u00f6 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3\u00f3\u00f6 \u00f2 \u00f8 \u00f8 \u00f8\u00f6 \u00f2 \u00f2 \u00f3 \u00f0\u00f3\u00fb \u00f6 \u00f0 \u00fd \u00f6\u00d7\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00fa \u00fb \u00f6\u00f3\u00f1 \u00f8 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb \u00f3 \u00f0 \u00fd \u00f6 1\u00b8\u00f8 \u00f8 \u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f1 \u00f8\u00f6 \u00fc pr(y \u2032 |y) \u00d7 \u00f8\u00f3 \u00f3 \u00f1 \u00f8\u00f3 \u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00fd \u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f1\u00f3\u00f2 \u00d7\u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f0 \u00fd \u00f6 1\u00ba \u00ec \u00d7 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f8 \u00f9\u00d7 \u00f0\u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f0 \u00b8 \u00f2 pr(y \u2032 |y) \u00d7 \u00f0\u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f0 \u00f1 \u00f8\u00f6 \u00fc\u00ba \u00ec \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00bd \u00fa \u00d7 \u00f6 \u00d7 \u00f8\u00f3 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8 \u00f8 \u00f0\u00f3\u00d7 \u00f0\u00fd \u00f6 \u00d7 \u00f1 \u00f0 \u00d7 \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00bf\u2104\u00b8\u00fb \u00f6 pr(y \u2032 |y) \u00f1 \u00fd \u00f2\u00f8 \u00d7 \u00f8 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f2 \u00f3\u00f9\u00f6 \u00f3\u00f3 \u00f9\u00f2\u00f8 \u00f3\u00f2\u00b8 \u00d7 \u00fb \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u2104\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f2 \u00f3\u00f6 \u00f6 \u00f3\u00f6 \u00f8 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f2 \u00f3\u00f9\u00f6 \u00f3\u00f3 \u00f8\u00f3 \u00f0\u00f3 \u00f0 \u00d7 \u00b4 \u00ba \u00ba pr(y \u2032 |y) > 0 \u00f3\u00f2\u00f0\u00fd \u00f3\u00f6 y \u2032 \u00f2 \u00d7\u00f3\u00f1 \u00f0\u00f3 \u00f0 \u00f2 \u00f3\u00f9\u00f6 \u00f3\u00f3 \u00f3 y\u00b5\u00b8\u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f1 \u00f8\u00f6 \u00fc pr (z|y) \u00f8 \u00f8 \u00f2 \u00f6 \u00f8 \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 2 \u00f6\u00f3\u00f1 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 1 \u00f1\u00f9\u00d7\u00f8 \u00f2 \u00f6 \u00f8 z \u00d7\u00f8 \u00f8 \u00f6\u00f3\u00f1 y \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f8 \u00f6 \u00f0\u00f0 \u00f0\u00f3\u00d7 \u00f8\u00f3 \u00f3\u00f8 \u00f6\u00ba \u00ec \u00d7 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00b8 \u00f9\u00d7 \u00f8 \u00f8\u00f6 \u00f2 \u00f2 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00fd \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00f1 \u00f2 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f2\u00fd \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2\u00ba \u00f2 \u00f6 \u00f0 \u00d7 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fb \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8\u00f3\u00f6 \u00f0 \u00f3 \u00f8\u00f3 \u00f1 \u00f6 \u00f1 \u00fd \u00f6 \u00fa \u00f9\u00d7 \u00f2 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u2104\u00ba \u00bf\u00ba \u00f8 \u00f3\u00f2 \u00f0 \u00ea \u00d7\u00f9\u00f0\u00f8\u00d7 \u00ec \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l\u22121 l=0 d l v q 4(\u03c3 l ) 2 \u00f3\u00f6 \u00ee\u00e9\u00b9\u00f0 \u00f6 \u00f3\u00f9\u00f4\u00f0 \u00d7 \u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2 \u00fa \u00f9 \u00f0 \u00be\u00b9\u00f0 \u00fd \u00f6 \u00ee\u00e9\u00d7 \u00f8\u00f3 \u00f8 \u00f6\u00ba \u00f9\u00d7 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f3 \u00f8 l th \u00ee\u00e9 \u00d7 \u00f8 \u00f2\u00f4\u00f9\u00f8 \u00f8\u00f3 \u00f8 (l + 1) th \u00ee\u00e9 \u00b4 \u00f3\u00f6 l = 0, 1, 2 \u2022 \u2022 \u2022 , l \u2212 1 \u00b5\u00b8\u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 k th \u00ee\u00e9 \u00d7 \u00d7 \u00f8\u00d7 \u00f3\u00f2 \u00f8 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 l th \u00ee\u00e9\u00d7 \u00b4 \u00f3\u00f6 l = k + 1, k + 2, \u2022 \u2022 \u2022 , l \u2212 1\u00b5\u00ba \u00ec \u00d7 \u00f0 \u00d7 \u00f8\u00f3 \u00f8 \u00f8 \u00f0\u00f0 \u00d7 \u00f0 \u00b9\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f3\u00f2\u00b8 \u00f2 \u00fb \u00f8\u00f3\u00f4\u00b9 \u00f3\u00fb\u00f2 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2\u00d7 \u00f6\u00f3\u00f1 \u00f6 \u00f8\u00f3 \u00f0\u00f3\u00fb \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f0 \u00fd \u00f6\u00d7 \u00f6 \u00f9\u00f8\u00f3\u00f1 \u00f8 \u00f0\u00f0\u00fd \u00f2 \u00f6 \u00f8 \u00f8\u00f3 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00f0\u00f3\u00fb \u00f6 \u00f0 \u00fd \u00f6\u00d7 \u00f8\u00f3 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f8 \u00f6 \u00f2\u00f4\u00f9\u00f8 \u00f1\u00f3\u00f6 \u00f8 \u00fa \u00f0\u00fd \u00f2 \u00f8 \u00f0 \u00f8 \u00f3 \u00fb \u00f8 \u00f8 \u00f6 \u00f0 \u00fd \u00f6\u00d7 \u00d7\u00f3\u00fa \u00f6 \u00f2 \u00f8 \u00f8 \u2104\u00ba \u00ec \u00d7 \u00d7 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00fc\u00f8 \u00f2\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f0 \u00b9\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f3\u00f2 \u00f8 \u00f8 \u00f8 \u00f0 \u00f8\u00f3 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00ba \u00ec \u00f2 \u00f6 \u00f0 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 l (p, q) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf \u00d7 \u00f8 \u00d7\u00f9\u00f1 \u00f3 \u00f8\u00fb\u00f3 \u00f8 \u00f6\u00f1\u00d7 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l\u22121 l=0 m l i l =1 p l i l k i l p l+1|l , q l|l+1 \u00f3\u00f6 \u00f0 \u00f6 \u00b4 \u00f9\u00d7 q \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00d7\u00d7 \u00f6 \u00f0\u00fd \u00f9\u00d7\u00d7 \u00f2\u00b8\u00f8 \u00f0 \u00f6 \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00d7\u00d7 \u00f6 \u00f0\u00fd \u00ee\u00e9\u00b9\u00f0 \u00f6\u00b5\u00b8\u00f4\u00f0\u00f9\u00d7 \u00f8 \u00f3\u00d7\u00f8 l p l , q l \u00f3 \u00f2\u00f3 \u00f2 \u00f0 \u00fd \u00f6 l\u00ba \u00ec l p l , q l \u00f8 \u00f6\u00f1 \u00d7 \u00f4\u00f6 \u00d7 \u00f0\u00fd \u00f8 \u00f3\u00f6\u00f1 \u00f8 \u00f8 \u00d7 \u00f3\u00f1\u00f1\u00f3\u00f2\u00f0\u00fd \u00f9\u00d7 \u00f2 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00b8\u00d7\u00f3 \u00f2\u00fd \u00f3\u00f2\u00fa \u00f2 \u00f2\u00f8 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0 \u00f3\u00f9\u00f0 \u00f9\u00d7 \u00f8\u00f3 \u00f4 \u00f6 \u00f1 \u00f8 \u00f6 \u00d7 q l \u00f2 \u00f0 \u00fd \u00f6 l\u00ba \u00f8\u00fd\u00f4 \u00f0 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00b9 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f8\u00fd\u00f4 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8 \u00f8 \u00f1 \u00f2 \u00f1 \u00d7 \u00d7 l (p, q) \u00f8 \u00f9\u00d7 \u00d7\u00f4\u00f0 \u00f8\u00d7 \u00f2\u00f8\u00f3 \u00f8\u00fb\u00f3 \u00f4 \u00d7 \u00bd\u00bf \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f8\u00f3 \u00f8 \u00f8\u00fb\u00f3 \u00f6 \u00f2\u00f8 \u00f8\u00fd\u00f4 \u00d7 \u00f3 \u00f8 \u00f6\u00f1 \u00f2 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2\u00ba \u00e1\u00f2 \u00f8 \u00d7\u00f4 \u00f0 \u00d7 \u00fb \u00f6 l = 0 \u00b4 \u00ba \u00ba \u00f2\u00f3 \u00f0 \u00f6 \u00d7 \u00f9\u00d7 \u00b5 \u00f8 \u00d7 \u00f4\u00f4\u00f6\u00f3 \u00f6 \u00f9 \u00d7 \u00f8\u00f3 \u00d7\u00f8 \u00f2 \u00f6 \u00f2\u00f4\u00f9\u00f8 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00ba \u00e0 \u00f6 \u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00f9\u00d7 \u00f2 \u00f2 \u00f4\u00f8 \u00fa \u00f0\u00f9\u00d7\u00f8 \u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00b4 \u00b5 \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f8 \u00f4\u00f8 \u00fa \u00f0\u00f9\u00d7\u00f8 \u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00b4 \u00b5 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u2104\u00ba \u00d7 \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8\u00fb \u00f3\u00d7 \u00f4\u00f9\u00f6\u00f4\u00f3\u00d7 \u00d7 \u00f8\u00f3 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00b9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00f2\u00f4\u00f9\u00f8 \u00fa \u00f8\u00f3\u00f6\u00d7 \u00f2\u00f8\u00f3 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f0\u00f3\u00fb \u00f6 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00f4 \u00d7\u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00ba\u00bd \u00f8 \u00d7 \u00f3 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00d7\u00f3\u00f9\u00f6 \u00f2 \u00f4 \u00f6 \u00f8 \u00f1\u00f3 \u00f0 \u00d7 \u00f3\u00f2\u00d7 \u00f6 \u00b8 \u00f2 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00ba\u00be \u00f8 \u00d7 \u00f3 \u00f9\u00d7\u00d7 \u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00ba \u00ba\u00bd \u00ec\u00f6 \u00b9\u00eb\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f2\u00d7 \u00f8\u00fd ae \u00f8\u00fb\u00f3\u00f6 \u00f3\u00f2\u00d7 \u00f6 \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l (p, q) \u00f3\u00f6 \u00f2\u00f3 \u00f2 \u00f2 l + 1 \u00f0 \u00fd \u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf\u00b5\u00b8 \u00f2 \u00d7\u00d7\u00f9\u00f1 \u00f8 \u00f8 \u00f8 q l|l+1 i l ,i l+1 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00f1\u00f3 \u00f0 \u00d7 \u00f4 \u00f6 \u00f8 \u00d7\u00f3 \u00f8 \u00f8 q l|l+1 i l ,i l+1 = p l|l+1 i l ,i l+1 \u00b4 \u00f3\u00f6 l = 0, 1, \u2022 \u2022 \u2022 , l \u2212 1\u00b5\u00b8 \u00f2 \u00f8 \u00f8 \u00f8 p l+1|l i l+1 ,i l \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00d7\u00f3 \u00f8 \u00f8 p l+1|l i l+1 ,i l = \u03b4 i l+1 ,i l+1 (i l ) \u00b4 \u00f3\u00f6 l = 0, 1, \u2022 \u2022 \u2022 , l \u2212 1\u00b5\u00b8 \u00f2 \u00fb \u00d7 l (p, q) \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00b4\u00d7 \u00f4\u00f4 \u00f2 \u00fc \u00ba\u00bd\u00b5 l (p, q) = h p 0 \u2212 h p l + l p l , q l \u00b4\u00bf\u00be\u00b5 \u00fb \u00f6 h p 0 \u2212 h p l \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8\u00d7 \u00f4 \u00f6 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00f3\u00f2\u00fa \u00f6\u00f8 p l \u00b9\u00f1 \u00d7\u00d7 \u00f2\u00f8\u00f3 p 0 \u00b9\u00f1 \u00d7\u00d7 \u00b8 \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00f8 \u00f8 p l+1|l i l+1 ,i l \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00b8 \u00f2 \u00f8 \u00f8 \u00f8 \u00f1\u00f3 \u00f0 \u00d7 \u00f4 \u00f6 \u00f8\u00ba \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00fa \u00f6\u00fd \u00f2\u00f8 \u00f6 \u00d7\u00f8 \u00f2 \u00f2 \u00f8\u00d7 \u00f0 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00f8 p l+1|l i l+1 ,i l \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f2\u00f3\u00f8 \u00f3\u00f2\u00f0\u00fd \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00b8 \u00f9\u00f8 \u00d7 \u00f0\u00d7\u00f3 \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00b8 \u00f2 \u00f8 \u00f1\u00f3 \u00f0 \u00d7 \u00d7 \u00f1 \u00f0 \u00f6\u00f0\u00fd \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00b8\u00f8 \u00f2 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f1\u00f9\u00d7\u00f8 \u00f1\u00f3 \u00f8 \u00f9\u00d7 i l \u2192 i l = i 1 l , i 2 l , \u2022 \u2022 \u2022 i l+1 \u2192 i l+1 = i 1 l+1 , i 2 l+1 , \u2022 \u2022 \u2022 p l+1|l i l+1 ,i l \u2192 p l+1|l i l+1 ,i l = p l+1|l i 1 l+1 ,i 1 l p l+1|l i 2 l+1 ,i 2 l \u2022 \u2022 \u2022 = \u03b4 i 1 l+1 ,i 1 l+1 (i 1 l ) \u03b4 i 2 l+1 ,i 2 l+1 (i 2 l ) \u2022 \u2022 \u2022 q l|l+1 i l ,i l+1 \u2192 q l|l+1 i l ,i l+1 = p l|l+1 i 1 l ,i 1 l+1 p l|l+1 i 2 l ,i 2 l+1 \u2022 \u2022 \u2022 \u00b4\u00bf\u00bf\u00b5 \u00fb \u00f6 \u00f8 \u00d7\u00f8 \u00f8 i l \u00f3 \u00f0 \u00fd \u00f6 l \u00f3 \u00f8 \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f1\u00f3\u00f6 \u00f2 \u00f8\u00b9 \u00f9\u00f6 \u00f0\u00f0\u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 \u00fa \u00f8\u00f3\u00f6 \u00d7\u00f8 \u00f8 i l \u00f8 \u00f8 \u00d7\u00f4 \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f6 \u00f2 \u00f3 \u00f0 \u00fd \u00f6 l \u00f3 \u00f8 \u00f8\u00f6 \u00b4\u00f8 i l \u00d7\u00f8\u00fd\u00f0 \u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f3\u00f6 \u00d7\u00f9 \u00f8 \u00f0 \u00f3\u00f6 \u00f2\u00f3\u00f2\u00b9\u00f8\u00f6 \u00b9 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00b5\u00ba \u00f9\u00f6\u00f8 \u00f6\u00f1\u00f3\u00f6 \u00b8\u00f8 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00f3 \u00f8 \u00fa \u00f8\u00f3\u00f6 i l \u00f6 \u00f4 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00d7 i 1 l , i 2 l , \u2022 \u2022 \u2022 \u00b8\u00fb \u00f6 i c l \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00d7\u00f9 \u00d7 \u00f8 c \u00f3 \u00f2\u00f3 \u00d7 \u00f2 \u00f0 \u00fd \u00f6 l\u00b8\u00fb \u00f6 \u00f0\u00f0 \u00f8 \u00f2\u00f3 \u00d7 \u00f2 \u00d7\u00f9 \u00d7 \u00f8 \u00f6 \u00f0\u00f0 \u00d7 \u00f0 \u00f2 \u00d7 \u00d7 \u00d7 \u00f2 \u00f6\u00f3\u00f1 \u00f8 \u00bd \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb \u00f3 \u00f0 \u00fd \u00f6 l + 1\u00ba \u00eb\u00f9 \u00d7 \u00f8 \u00f3 \u00d7 \u00f0 \u00f2 \u00d7 \u00d7 \u00f0\u00f0 \u00f0\u00f9\u00d7\u00f8 \u00f6\u00ba \u00ec \u00f3\u00f1\u00b9 \u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00f3 \u00f8 \u00fa \u00f8\u00f3\u00f6 i l+1 \u00f6 \u00f4 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00d7 i 1 l+1 , i 2 l+1 , \u2022 \u2022 \u2022 \u00b8\u00fb \u00f6 i c l+1 \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00f4 \u00f6 \u00f2\u00f8 \u00b4 \u00f2 \u00f0 \u00fd \u00f6 l + 1\u00b5 \u00f3 \u00f8 \u00d7 \u00f0 \u00f2 \u00d7 \u00f2 \u00f0\u00f9\u00d7\u00f8 \u00f6 c \u00f2 \u00f0 \u00fd \u00f6 l\u00ba \u00ec \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f1 \u00fd \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00f6\u00f6 \u00f2 l (p, q) \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00b4\u00d7 \u00f4\u00f4 \u00f2 \u00fc \u00ba\u00be\u00b5 l (p, q) = l\u22121 l=0 \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p l c \u2212 l l=1 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c h p l c + l p l , q l \u00b4\u00bf \u00b5 \u00ec \u00d7 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 l (p, q) \u00f2 \u00f6 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f2 \u00f8 \u00f6\u00f1\u00d7 \u00f3 \u00f8 \u00f1\u00f9\u00f8\u00f9 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 i p l c \u00f8\u00fb \u00f2 \u00f8 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00f3 \u00f0\u00f9\u00d7\u00f8 \u00f6 i c l+1 \u00d7 \u00b4\u00d7 \u00f4\u00f4 \u00f2 \u00fc \u00ba\u00be\u00b5 l (p, q) = \u2212 l l=1 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i p l c + \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p 0 c \u2212 \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p l c + l p l , q l \u00b4\u00bf \u00b5 ae\u00f3\u00fb \u00d7\u00d7\u00f9\u00f1 \u00f8 \u00f8 \u00f8 \u00f1\u00f3 \u00f0 \u00d7 \u00f4 \u00f6 \u00f8 \u00f2 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f0 \u00fd \u00f6\u00b8\u00d7\u00f3 \u00f8 \u00f8 q l \u00d7 \u00fa \u00f2 \u00fd q l il = p l i 1 l p l i 2 l \u2022 \u2022 \u2022 \u00ba \u00ec \u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 l p l , q l \u00f8\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 l p l , q l = \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p l c \u00b8\u00d7\u00f3 \u00f8 \u00f8 l (p, q) \u00f1 \u00fd \u00f2 \u00f0\u00f0\u00fd \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00d7 l (p, q) = \u2212 l l=1 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i p l c + \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p 0 c \u00b4\u00bf \u00b5 \u00ec \u2212 l l=1 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i p l c \u00f8 \u00f6\u00f1 \u00d7 \u00b4\u00f1 \u00f2\u00f9\u00d7\u00b5 \u00f8 \u00d7\u00f9\u00f1 \u00f3 \u00f8 \u00f1\u00f9\u00f8\u00f9 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f8 \u00f2 \u00f0\u00f0 \u00f3 \u00f8 \u00f0\u00f9\u00d7\u00f8 \u00f6\u00d7 \u00f2 \u00f8 l + 1 \u00f0 \u00fd \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8 \u00f2 \u00f8 \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p 0 c \u00f8 \u00f6\u00f1 \u00d7 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f3\u00f6 \u00fa \u00f2 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 p 0 \u00ba \u00ec \u00d7 \u00f1 \u00f2\u00d7 \u00f8 \u00f8 \u00f1 \u00f2 \u00f1 \u00d7 \u00f2 l (p, q) \u00d7 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f8\u00f3 \u00f1 \u00fc \u00f1 \u00d7 \u00f2 l l=1 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i p l c \u00ba \u00ec \u00d7 \u00d7 \u00f8 \u00f1 \u00fc \u00b9 \u00f1\u00f9\u00f1 \u00f1\u00f9\u00f8\u00f9 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f3\u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u2104\u00b8\u00fb \u00f2\u00f0\u00f9 \u00d7 \u00f8 \u00f1\u00f9\u00f8\u00f9 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f1 \u00fc \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00f4\u00f6 \u00f2 \u00f4\u00f0 \u00f2 \u00bd\u2104 \u00d7 \u00d7\u00f4 \u00f0 \u00d7 \u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00f2 \u00f8 \u00f1\u00f3 \u00f0 \u00d7 \u00f4 \u00f6 \u00f8 \u00b4 \u00d7 \u00f8 \u00fd \u00f6 \u00f6 \u00b5\u00b8\u00f8 \u00f2 l p 0 , q 0 = l (p, q)\u00b8\u00fb \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f8 \u00f2\u00f4\u00f9\u00f8 \u00f2\u00d7 \u00f8\u00fd \u00f3\u00f4\u00f8 \u00b9 \u00f1 \u00d7 \u00f8 \u00f3\u00f2 \u00d7 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f8\u00f3 \u00f3 \u00f2\u00f8 \u00f2\u00d7 \u00f8\u00fd \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8 \u00f3\u00f2\u00ba \u00ec \u00d7 \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00fb \u00d7 \u00f9\u00d7 \u00f2 \u2104\u00b8\u00fb \u00f6 \u00f8 \u00d7\u00f9\u00f1\u00b9\u00f3 \u00b9\u00f1\u00f9\u00f8\u00f9 \u00f0\u00b9 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00fb \u00d7 \u00f6 \u00fa \u00fd \u00f1 \u00f2 \u00f1 \u00d7 \u00f2 l p 0 , q 0 \u00ba \u00ba\u00be \u00e0 \u00f6 \u00f6 \u00f0 \u00ee \u00f8\u00f3\u00f6 \u00e9\u00f9 \u00f2\u00f8 \u00d7 \u00f6 \u00e1 \u00f8 \u00f3\u00fa \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f1\u00f3 \u00d7\u00f0 \u00f8\u00f0\u00fd\u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00f1\u00f3 \u00f0 q \u00d7 \u00fc \u00f8\u00f0\u00fd \u00f8 \u00d7 \u00f1 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00d7 \u00f3\u00f6 \u00b8 \u00f9\u00f8 \u00d7 \u00f9\u00d7\u00d7 \u00f2 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f4 \u00f6 \u00f8\u00b8\u00f8 \u00f2 q l|l+1 i l ,i l+1 \u00f3\u00f1 \u00d7 q l|l+1 i l ,i l+1 \u2192 q l|l+1 i l ,i l+1 = q l|l+1 i 1 l ,i 1 l+1 q l|l+1 i 2 l ,i 2 l+1 \u2022 \u2022 \u2022 \u00b4\u00bf \u00b5 \u00bd \u00fb \u00f6 \u00f8 \u00f2 \u00fa \u00f9 \u00f0 q l|l+1 i c l ,i c l+1 \u00f6 \u00f9\u00d7\u00d7 \u00f2\u00ba \u00ec \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 l (p, q) \u00f1 \u00fd \u00f8 \u00f2 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f3\u00fb\u00f2 \u00fd \u00f2 \u00f0\u00f3 \u00fd \u00fb \u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bc l (p, q) = l\u22121 l=0 \u00f0\u00f9\u00d7\u00f8 \u00f6 c d l,c v q 4 (\u03c3 l,c ) 2 + l p l , q l \u2212 l\u22121 l=0 \u00f0\u00f9\u00d7\u00f8 \u00f6 c log v l,c \u221a 2\u03c0\u03c3 l,c dim i c l \u00b4\u00bf \u00b5 \u00ec \u00f9\u00d7 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8\u00fb \u00f8 \u00f9\u00d7\u00d7 \u00f2 \u00f1\u00f3 \u00f0 q\u00b8 \u00d7 \u00f6 \u00f6 \u00f0 \u00ee\u00e9\u00b9\u00f0 \u00f6 \u00b4\u00f3\u00f6 \u00ee\u00e9\u00b9\u00f8\u00f6 \u00b5\u00b8 \u00f2 \u00fb \u00f0 \u00fd \u00f6 \u00f2\u00f3 \u00d7 \u00f8 \u00f0\u00f9\u00d7\u00f8 \u00f6\u00d7 \u00f2 \u00f8 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7 \u00f0 \u00fd \u00f6 \u2104\u00ba \u00f8\u00f3\u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00f9\u00d7 \u00f2 \u00e8 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00e5 \u00fc\u00b9 \u00f8\u00f9\u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00b4\u00e8\u00e5 \u00b5 \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f9\u00d7 \u00f9\u00f0 \u00f4 \u00f6 \u00f1 \u00f8 \u00f6 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd p l+1|l \u00f3\u00f6 \u00f9 \u00f0 \u00f2 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f2\u00f3\u00f9\u00f6 p l+1|l \u00f8\u00f3 \u00f3\u00f6\u00f1 \u00f8\u00f3\u00f6 \u00f0 \u00f3 \u00d7 \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 l\u00ba \u00e1\u00f8 \u00f8\u00f9\u00f6\u00f2\u00d7 \u00f3\u00f9\u00f8 \u00f8 \u00f8 \u00f8 \u00f6 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00fb \u00fd \u00f3 \u00f0\u00f0\u00f3\u00fb \u00f2 \u00d7\u00f9 \u00f3 \u00d7 \u00f8\u00f3 \u00fa \u00f0\u00f3\u00f4\u00b8\u00fb \u00d7 \u00f0\u00f0 \u00f8 \u00f4 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00b4\u00e8\u00e5 \u00b5 \u2104\u00ba \u00e8\u00e5 \u00fa \u00d7 \u00f8 \u00d7 \u00fd \u00f2\u00f3 \u00f2 \u00f8\u00d7 \u00f2\u00f4\u00f9\u00f8 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f2 \u00b9 \u00f3\u00f9\u00d7\u00f0\u00fd \u00fb \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f6 \u00f2\u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00b8 \u00f3 \u00fb \u00f4\u00f3\u00f8 \u00f2\u00f8 \u00f0\u00f0\u00fd \u00f2 \u00f2\u00f3 \u00f6 \u00f2\u00f8 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00f2\u00f4\u00f9\u00f8\u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00ba\u00bd \u00f8\u00fb\u00f3 \u00fb \u00fd\u00d7 \u00f2 \u00fb \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00f2 \u00f9\u00d7 \u00f3\u00f6 \u00f8\u00f3\u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00f6 \u00d7\u00f9\u00d7\u00d7 \u00b8 \u00f2 \u00fd \u00f6 \u00f4\u00f4\u00f6\u00f3 \u00b4\u00fb \u00d7 \u00e8\u00e5 \u00b5 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00ba\u00be\u00ba \u00ba\u00bd \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00ea \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00e5\u00f3 \u00f0\u00d7 \u00e1\u00f2 \u00f8 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 \u00f8 l (p, q) \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf\u00b5 \u00f8 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0\u00d7 q l|l+1 \u00f1 \u00fd \u00f4 \u00f6 \u00f1 \u00f8 \u00f6 \u00d7 \u00d7 \u00f9\u00d7\u00d7 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2\u00d7 \u00f8 \u00d7\u00b8\u00fb \u00f6 \u00d7 \u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 p l+1|l \u00f1 \u00fd \u00f4 \u00f6 \u00f1 \u00f8 \u00f6 \u00d7 \u00f2 \u00f1\u00f3\u00f6 \u00f2 \u00f6 \u00f0 \u00fb \u00fd \u00d7 p l+1|l i l+1 ,i l = p l|l+1 i l ,i l+1 p l+1 i l+1 m l+1 i \u2032 l+1 =1 p l|l+1 i l ,i \u2032 l+1 p l+1 i \u2032 l+1 \u00b4\u00bf \u00b5 \u00fb \u00f9 \u00f6 \u00f2\u00f8 \u00d7 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f2 m l+1 i l+1 =1 p l+1|l i l+1 ,i l = 1\u00ba \u00f0 \u00f1 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00f8 \u00f8 \u00f8 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f3\u00f2\u00f0\u00fd \u00d7 \u00f2 \u00f0 \u00fc\u00f4\u00f0 \u00f2 \u00f8 \u00f3\u00f2 i l+1 \u00f3 \u00f8 \u00f8 i l \u00b4 \u00f2 \u00f8 \u00d7 \u00f3 \u00f6 p l+1|l i l+1 ,i l \u00b5\u00b8\u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f3\u00fa \u00f6 \u00d7 \u00f2 \u00f0 \u00fc\u00f4\u00f0 \u00f2 \u00f8 \u00f3\u00f2\u00d7 \u00b4 \u00f2 \u00f8 \u00d7 \u00f3 \u00d7\u00f3 \u00f8 p l+1|l i l+1 ,i l \u00b5\u00b8\u00d7\u00f3 \u00f8 \u00f2\u00f2\u00f3\u00f8 \u00f0 \u00f8\u00f3 \u00f8\u00f3\u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00f3 \u00f8 \u00f8 \u00ba \u00ec \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8 \u00fb \u00fd \u00f3 \u00f0\u00f0\u00f3\u00fb \u00f2 \u00f8\u00f3\u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00f8\u00f3 \u00fa \u00f0\u00f3\u00f4 \u00d7 \u00f8\u00f3 \u00f1 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f2 \u00f3\u00f9\u00d7 \u00f9\u00d7 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00ba \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00bd \u00f9\u00d7 \u00d7 \u00f8\u00d7 \u00f3\u00fb\u00f2 p l+1 \u00fa \u00f8\u00f3\u00f6 \u00f2 p l|l+1 \u00f1 \u00f8\u00f6 \u00fc \u00f8\u00f3 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00f8\u00fd\u00f4 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00d7 \u00f2\u00d7 \u00f8 \u00d7 \u00f8\u00f3 \u00f6 \u00f2\u00f8 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00f2\u00f4\u00f9\u00f8\u00b8\u00f8 \u00f2 \u00f8\u00f3\u00f6 \u00f0 \u00f3 \u00f2 \u00fa \u00f0\u00f3\u00f4\u00ba \u00ec \u00d7 \u00f4\u00f4\u00f6\u00f3 \u00f2 \u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00fd \u00f1 \u00f2 \u00f8 \u00f6 \u00f4\u00f0 \u00f1 \u00f2\u00f8 i l+1 \u2192 i l+1 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00b4 \u00ba \u00ba \u00f6 \u00f4\u00f0 \u00f8 \u00d7 \u00f0 \u00f6 \u00f3 \u00f2 \u00fc \u00fd \u00fa \u00f8\u00f3\u00f6 \u00f3 \u00f2 \u00fc\u00b8\u00fb \u00f6 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fa \u00f8\u00f3\u00f6 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00b5\u00ba \u00e1 \u00f8 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00f3 i l+1 \u00f6 \u00f8 \u00f6\u00f1 \u00f2 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f3 \u00f3\u00f8 \u00f6\u00b8\u00f8 \u00f2 \u00f8 \u00f6 \u00f3 \u00f2\u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd p l+1|l i l+1 ,i l \u00d7 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7\u00b8\u00fb \u00f6 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f3\u00f2 \u00f3 \u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00b8 \u00f2 \u00f8 \u00f9\u00d7 \u00d7 \u00f8\u00d7 \u00f3\u00fb\u00f2 p l+1 \u00fa \u00f8\u00f3\u00f6 \u00f2 p l|l+1 \u00f1 \u00f8\u00f6 \u00fc\u00ba \u00e1 \u00f8 \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b8\u00fb \u00d7 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 n \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00b9 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f6 \u00f6 n \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00b8 \u00d7 \u00f8 \u00f2 \u00f2\u00d7 \u00f6\u00f8 \u00f2\u00f8\u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f8 \u00fd \u00f0 \u00d7 \u00b4\u00d7 \u00f4\u00f4 \u00f2 \u00fc \u00b5 d v q \u2264 2 dx pr (x) m1 y1=1 m2 y2=1 \u2022 \u2022 \u2022 mn yn=1 pr (y 1 |x, 1) pr (y 2 |x, 2) \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 pr (y n |x, n) x \u2212 1 n n k=1 x \u2032 k (y k ) 2 \u00b4 \u00bc\u00b5 \u00e1 \u00d7 \u00f2 \u00f0 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f9\u00d7 n \u00f8 \u00f1 \u00d7\u00b8\u00f6 \u00f8 \u00f6 \u00f8 \u00f2 n \u00f2 \u00b9 \u00f4 \u00f2 \u00f2\u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f2 \u00f9\u00d7 \u00f3\u00f2 \u00b8\u00f8 \u00f2 \u00f8 \u00f3\u00fa \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f3\u00f1 \u00d7 d v q \u2264 2 n dx pr (x) m y=1 pr (y|x) x \u2212 x \u2032 (y) 2 + 2 (n \u2212 1) n dx pr (x) x \u2212 m y=1 pr (y|x) x \u2032 (y) 2 \u00b4 \u00bd\u00b5 \u00e1\u00f2 \u00f8 \u00d7 n = 1 \u00f8 \u00d7 \u00f3\u00f6\u00f6 \u00f8\u00f0\u00fd \u00f6 \u00f9 \u00d7 \u00f8\u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00b4\u00f8 \u00f2 \u00f5\u00f9 \u00f0 \u00f8\u00fd \u00f6 \u00f9 \u00d7 \u00f8\u00f3 \u00f2 \u00f5\u00f9 \u00f0 \u00f8\u00fd \u00f2 \u00f8 \u00d7 \u00d7 \u00b5\u00ba \u00ef \u00f2 n > 1 \u00f8 \u00d7 \u00f3\u00f2 \u00f8 \u00f6\u00f1 \u00f3 \u00f6\u00d7 \u00f8 \u00f4\u00f3\u00d7\u00d7 \u00b9 \u00f0 \u00f8\u00fd \u00f3 \u00f8\u00f3\u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00b8 \u00f9\u00d7 \u00f8 \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00fb \u00f8 \u00f0 \u00f2 \u00f6 \u00f3\u00f1 \u00f2 \u00f8 \u00f3\u00f2 m y=1 pr (y|x) x \u2032 (y) \u00f3 \u00fa \u00f8\u00f3\u00f6\u00d7\u00ba \u00ba\u00be \u00fa \u00f6 \u00e7\u00fa \u00f6 \u00ea \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00e5\u00f3 \u00f0\u00d7 ae\u00f3\u00fb \u00f3\u00f1 \u00f2 \u00f8 \u00f3\u00fa \u00f8\u00fb\u00f3 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00f8\u00f3 \u00f8\u00f3\u00f6 \u00f0 \u00f2\u00f3 \u00f2 \u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00f9\u00d7 \u00b4 \u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00b5\u00b8\u00fb \u00d7 \u00f4 \u00f6 \u00f1 \u00f8 \u00f6 \u00d7 \u00f2 \u00d7\u00f9 \u00fb \u00fd \u00f8 \u00f8 \u00f8 \u00f2 \u00f1\u00f9\u00f0 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00b4 \u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bc\u00b5\u00ba \u00ec \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00fd \u00d7 \u00f8\u00f3 \u00f6\u00d7\u00f8\u00f0\u00fd \u00f1 \u00f8 \u00f6 \u00f4\u00f0 \u00f1 \u00f2\u00f8 p l+1 i l+1 \u2192 a l+1 k,i l+1 p l+1 i l+1 \u00b4\u00fb \u00f6 a l+1 k,i l+1 \u2265 0\u00b5 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00b8\u00fb \u00f6 k \u00d7 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00f2 \u00fc \u00fb \u00f6 \u00f2 \u00d7 \u00f3\u00fa \u00f6 k = 1, 2, \u2022 \u2022 \u2022 , k \u00b4\u00f2\u00f3\u00f8 \u00f8 \u00f8 k \u00d7 \u00f2\u00f3\u00f8 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2 \u00f8\u00f3 \u00f8 \u00d7 \u00f1 \u00d7 \u00bd n\u00b5\u00b8 \u00f2 \u00f8 \u00f2 \u00d7 \u00f3\u00f2 \u00f0\u00fd \u00f8\u00f3 \u00fa \u00f6 \u00f3\u00fa \u00f6 k\u00b8\u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f9 p l+1|l i l+1 ,i l \u2192 1 k k k=1 p l|l+1 i l ,i l+1 a l+1 k,i l+1 p l+1 i l+1 m l+1 i \u2032 l+1 =1 p l|l+1 i l ,i \u2032 l+1 a l+1 k,i \u2032 l+1 p l+1 i \u2032 l+1 \u00b4 \u00be\u00b5 \u00e1\u00f2 \u00f8\u00b8k \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00f6 \u00f1 \u00f8\u00fb \u00f2 \u00f0 \u00fd \u00f6 l \u00f2 \u00f0 \u00fd \u00f6 l + 1\u00b8 \u00f2 \u00f8 a l+1 \u00f1 \u00f8\u00f6 \u00fc \u00d7\u00f4 \u00d7 \u00fb \u00f2 \u00d7 i l+1 \u00f2 \u00f0 \u00fd \u00f6 l + 1 \u00f6 \u00d7\u00d7\u00f3 \u00f8 \u00fb \u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 k\u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00d7 \u00f1 \u00d7 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f8 \u00f8 \u00fb\u00f3\u00f9\u00f0 \u00fa \u00f2 \u00f3 \u00f8 \u00f2 \u00f9\u00d7 \u00f2 \u00fd \u00d7 \u00f2 \u00f2 \u00f0\u00fd\u00d7 \u00d7\u00b8 \u00f2 \u00fb \u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f2 \u00f6\u00b9 \u00f8 \u00fd \u00f6 \u00f2\u00f8 \u00f1\u00f3 \u00f0\u00d7 \u00f6 \u00f3\u00f1 \u00f2 \u00f8\u00f3 \u00fd \u00f0 \u00d7 \u00f2 \u00f0 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00ba \u00e1\u00f2 \u00f4\u00f4 \u00f2 \u00fc \u00f8 \u00f6 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f4 \u00f8\u00fb \u00f2 \u00f8 \u00f3\u00fa \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00e8\u00e5 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00f2 \u00f9\u00f0\u00f0 \u00fd \u00d7 \u00f2 \u00fa \u00f6 \u00f3\u00fa \u00f6 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00ba \u00f4 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00b4\u00e8\u00e5 \u00b5 \u00d7 \u00f4\u00f6 \u00d7 \u00f0\u00fd \u00f8 \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f1 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8 \u00f8\u00fd\u00f4 \u00f3 \u00e8\u00e5 \u00f8 a l+1 \u00f1 \u00f8\u00f6 \u00fc \u00d7 \u00f3\u00d7 \u00f2 \u00f8\u00f3 \u00f3\u00f2\u00f8 \u00f2 \u00f3\u00f2\u00f0\u00fd \u00bc\u00b3\u00d7 \u00f2 \u00bd\u00b3\u00d7\u00b8\u00fb \u00f6 \u00f6\u00f6 \u00f2 \u00d7\u00f3 \u00f8 \u00f8 \u00f8 k \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00f4 \u00f6\u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00fd \u00f6 l + 1 \u00f2\u00f8\u00f3 k \u00f3\u00fa \u00f6\u00f0 \u00f4\u00f4 \u00f2 \u00f4 \u00f8 \u00d7 \u2104\u00ba \u00fb \u00f6 \u00f2 \u00f3 \u00f8\u00fd\u00f4 \u00d7 \u00f3 \u00e8\u00e5 \u00f2 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00fd \u00f3\u00f3\u00d7 \u00f2 a l+1 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f0\u00fd\u00ba \u00e1\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00f8 \u00fb \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f3\u00fb \u00e3\u00f3 \u00f3\u00f2 \u00f2 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00f1 \u00f6 \u00fb \u00f2 \u00bf\u00b9\u00f0 \u00fd \u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fb \u00d7 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00ba \u00e1 \u00f8 \u00e8\u00e5 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00b5 \u00f2 \u00f9\u00d7 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00b8\u00f8 \u00f2 \u00f1\u00f3\u00f6 \u00f2 \u00f6 \u00f0 \u00f3\u00f6\u00f1 \u00f3 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00b4 \u00ba \u00ba \u00f8\u00f3\u00f6 \u00f0 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f1 \u00f4\u00f4 \u00f2 \u00b5 \u00fb\u00f3\u00f9\u00f0 \u00fa \u00f1 \u00f6 \u00b4\u00f8 \u00d7 \u00d7 \u00f6 \u00fd \u00d7\u00f9\u00d7\u00d7 \u00f2 \u2104\u00b5\u00ba \u00f3\u00f2\u00f0\u00f9\u00d7 \u00f3\u00f2\u00d7 \u00ec \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00f8 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f1 \u00fd \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00f3 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00f2\u00d7 \u00f8\u00fd \u00f3 \u00f0\u00f0 \u00f8 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba \u00ec \u00d7 \u00d7 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f9\u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f0 \u00fd \u00f6\u00d7 \u00f1 \u00fd \u00fa \u00fb \u00d7 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00b4 \u00f0 \u00fd \u00f6 \u00d7 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2\u00f0\u00fd \u00f8\u00f3 \u00f2\u00f8 \u00f0 \u00fd \u00f6\u00d7\u00b5\u00ba \u00ec \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f1 \u00d7 \u00f3\u00f2\u00f8 \u00f8 \u00fb \u00f8 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f8 \u00f8 \u00fb \u00f6 \u00f6 \u00f4\u00f3\u00f6\u00f8 \u00f2 \u00bd\u00bc\u2104\u00b8 \u00f2 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f1 \u00f2\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f8\u00f3 \u00f9\u00f2 \u00f2\u00f8\u00f3 \u00d7 \u00f2 \u00f0 \u00f4\u00f4\u00f6\u00f3 \u00b4 \u00ba \u00ba \u00d7 \u00f2 \u00f0 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2\u00b5\u00ba \u00ec \u00f1\u00f3\u00d7\u00f8 \u00d7 \u00f2 \u00f2\u00f8 \u00d7\u00f4 \u00f8 \u00f3 \u00f8 \u00d7 \u00f9\u00f2 \u00f8 \u00f3\u00f2 \u00d7 \u00f8 \u00f8 \u00f8 \u00f8 \u00f0\u00f0 \u00f0 \u00fd \u00f6\u00d7 \u00f3 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f6 \u00f8\u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f0 \u00f3\u00f3\u00f8 \u00f2 \u00b8\u00f9\u00f2\u00f0 \u00f2 \u00f8 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f4\u00f6\u00f3 \u00f8\u00f3 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00fb \u00f6 \u00f8 \u00f2\u00f4\u00f9\u00f8 \u00f0 \u00fd \u00f6 \u00d7 \u00f3\u00f6 \u00d7\u00f4 \u00f0 \u00d7\u00f8 \u00f8\u00f9\u00d7\u00ba \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00b8\u00f8 \u00d7 \u00f0 \u00d7 \u00f8\u00f3 \u00f1\u00f3 \u00f9\u00f0 \u00f6 \u00f4\u00f4\u00f6\u00f3 \u00f8\u00f3 \u00f9 \u00f0 \u00f2 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00fb \u00f6 \u00f0\u00f0 \u00f3 \u00f8 \u00f1\u00f3 \u00f9\u00f0 \u00d7 \u00fa \u00f8 \u00d7 \u00f1 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00ba \u00f2\u00f3\u00fb\u00f0 \u00f1 \u00f2\u00f8\u00d7 \u00e1 \u00f8 \u00f2 \u00f6 \u00d7 \u00ef \u00f6 \u00f3\u00f6 \u00f1 \u00f2\u00fd \u00f9\u00d7 \u00f9\u00f0 \u00f3\u00f2\u00fa \u00f6\u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00f8 \u00f8 \u00fb \u00f9\u00f6 \u00f2 \u00f8 \u00f3\u00f9\u00f6\u00d7 \u00f3 \u00f8 \u00d7 \u00f6 \u00d7 \u00f6 \u00ba \u00e1 \u00f0\u00d7\u00f3 \u00f8 \u00f2 \u00e8 \u00f8 \u00f6 \u00fd \u00f2 \u00f2 \u00f3 \u00f6 \u00fd \u00e0 \u00f2\u00f8\u00f3\u00f2 \u00f3\u00f6 \u00f3\u00f2\u00b9 \u00fa \u00f6\u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00f8 \u00f8 \u00fb \u00f3\u00f9\u00f8 \u00f8 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f4 \u00f8\u00fb \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00bd \u00f2 \u00e0 \u00f0\u00f1 \u00f3\u00f0\u00f8\u00fe \u00f1 \u00f2 \u00d7 \u00f9\u00f6 \u00f2 \u00f8 \u00bd ae \u00f9\u00f6 \u00f0 ae \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f2 \u00e5 \u00f2 \u00e4 \u00f6\u00f2\u00b9 \u00f2 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00f1 \u00f8 \u00f8 ae \u00fb\u00f8\u00f3\u00f2 \u00e1\u00f2\u00d7\u00f8 \u00f8\u00f9\u00f8 \u00f2 \u00f1 \u00f6 \u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f4\u00f4 \u00f2 \u00fc \u00d7\u00f3\u00f1 \u00f3 \u00f8 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f0 \u00f8 \u00f0\u00d7 \u00f6 \u00f0 \u00fa \u00f2\u00f8 \u00f8\u00f3 \u00d7 \u00f8 \u00f3\u00f2 \u00f6 \u00fa \u00f2\u00ba \u00ba\u00bd \u00e8 \u00f6 \u00f8 \u00e5\u00f3 \u00f0\u00b8 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00eb\u00f3\u00f9\u00f6 \u00ec \u00f6 \u00fa \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00be \u00f3\u00f6 \u00f4 \u00f6 \u00f8 \u00f1\u00f3 \u00f0 \u00b4 \u00ba \u00ba q = p\u00b5 \u00f2 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba p l+1|l i l+1 ,i l = \u03b4 i l+1 ,i l+1 (i l ) \u00f9\u00d7 \u00f2 \u00d7 \u00f0 \u00f6 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 i l \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00fa \u00f8\u00f3\u00f6 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 i l \u00f3\u00f6 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 l\u00b8 \u00f9\u00d7 \u00f6 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f2\u00f3\u00f8 \u00d7\u00d7\u00f9\u00f1 \u00f8\u00f3 \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00b5 \u00d7 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7\u00ba \u00ec \u00d7 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 l (p, q) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf \u00f1 \u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 l (p, q) \u2212 l p l , q l = \u2212 l\u22121 l=0 m l i l =1 p l i l m l+1 i l+1 =1 p l+1|l i l+1 ,i l log p l|l+1 i l ,i l+1 \u00b4 \u00bf\u00b5 \u00ec \u00d7 \u00f1 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00fd \u00f2\u00f3\u00f8 \u00f2 \u00f8 \u00f8 p l+1|l i l+1 ,i l = \u03b4 i l+1 ,i l+1 (i l ) \u00b8 \u00f2 \u00f8 \u00f8 \u00fd \u00d7\u00b3 \u00f8 \u00f3\u00f6 \u00f1 \u00fa \u00d7 p l|l+1 i l ,i l+1 = p l+1|l i l+1 ,i l p l i l p l+1 i l+1 \u00b8\u00fb \u00fd \u00f0 \u00d7 l (p, q) \u2212 l p l , q l = \u2212 l\u22121 l=0 m l i l =1 p l i l m l+1 i l+1 =1 \u03b4 i l+1 ,i l+1 (i l ) log \u03b4 i l+1 ,i l+1 (i l ) p l i l p l+1 i l+1 \u00b4 \u00b5 ae\u00f3\u00fb \u00f9\u00d7 \u00f8 \u00f8 m l+1 i l+1 =1 \u03b4 i l+1 ,i l+1 (i l ) = 1\u00b8 m l+1 i l+1 =1 \u03b4 i l+1 ,i l+1 (i l ) log \u03b4 i l+1 ,i l+1 (i l ) = 0 \u00f2 m l i l =1 p l i l \u03b4 i l+1 ,i l+1 (i l ) = p l+1 i l+1 \u00f8\u00f3 \u00f6 \u00f9 \u00f8 \u00d7 \u00f8\u00f3 l (p, q) \u2212 l p l , q l = \u2212 l\u22121 l=0 m l i l =1 p l i l log p l i l + l\u22121 l=0 m l+1 i l+1 =1 p l+1 i l+1 log p l+1 i l+1 \u00b4 \u00b5 \u00ec \u00f8 \u00f6\u00f1\u00d7 \u00f2 \u00f8 \u00d7 \u00f8\u00fb\u00f3 \u00d7 \u00f6 \u00d7 \u00f1\u00f3\u00d7\u00f8\u00f0\u00fd \u00f2 \u00f0 \u00f3\u00f8 \u00f6 \u00f8\u00f3 \u00fd \u00f0 l (p, q) \u2212 l p l , q l = \u2212 m0 i0=1 p 0 i0 log p 0 i0 + ml il=1 p l il log p l i l \u00b4 \u00b5 \u00f2 \u00f9\u00d7 \u00f2 \u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00b5 \u00f8 \u00d7 \u00f1 \u00fd \u00f2 \u00f0\u00f0\u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 l (p, q) \u2212 l p l , q l = h p 0 \u2212 h p l \u00b4 \u00b5 \u00bd \u00ba\u00be \u00e8 \u00f6 \u00f8 \u00e5\u00f3 \u00f0\u00b8 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00eb\u00f3\u00f9\u00f6 \u00ec\u00f6 \u00b9 \u00eb\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00d7 \u00ec \u00f6 \u00fa \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00f3\u00f6 \u00f4 \u00f6 \u00f8 \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f1\u00f3 \u00f0 \u00f2 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f1 \u00fd \u00f3 \u00f8 \u00f2 \u00fd \u00f0\u00f8 \u00f6 \u00f2 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00f4\u00f4 \u00f2 \u00fc \u00ba\u00bd \u00f8\u00f3 \u00f6 \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00f3\u00f8 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f2 \u00f1\u00f3 \u00f0 \u00f6 \u00f2\u00f3\u00fb \u00f8\u00f6 \u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00ba \u00ec \u00f9\u00d7 \u00f9\u00d7 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00bf \u00f8\u00f3 \u00fb\u00f6 \u00f8 l (p, q) \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf\u00b5 \u00d7 l (p, q) \u2212 l p l , q l = \u2212 l\u22121 l=0 i l p l i l i l+1 p l+1|l i l+1 ,i l \u00f0\u00f9\u00d7\u00f8 \u00f6 c log p l|l+1 i c l ,i c l+1 \u00b4 \u00b5 ae\u00f3\u00fb \u00f9\u00d7 \u00fd \u00d7\u00b3 \u00f8 \u00f3\u00f6 \u00f1 \u00f2 \u00f8 \u00f3\u00f6\u00f1 p l|l+1 i c l ,i c l+1 = p l+1|l i c l+1 ,i c l p l i c l p l+1 i c l+1 \u00f8\u00f3 \u00fb\u00f6 \u00f8 \u00f8 \u00d7 \u00d7 l (p, q) \u2212 l p l , q l = \u2212 l\u22121 l=0 i l p l i l i l+1 p l+1|l i l+1 ,i l \u00f0\u00f9\u00d7\u00f8 \u00f6 c log \uf8eb \uf8ed p l+1|l i c l+1 ,i c l p l i c l p l+1 i c l+1 \uf8f6 \uf8f8 \u00b4 \u00b5 \u00ec \u00d7 \u00f1 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00fd \u00f9\u00d7 \u00f2 \u00f8 \u00f8 i l+1 p l+1|l i l+1 ,i l = 1 \u00b4 \u00f3\u00f6 \u00f8 log p l i c l \u00f8 \u00f6\u00f1\u00b5\u00b8 i l p l i l i l+1 p l+1|l i l+1 ,i l (\u2022 \u2022 \u2022 ) = i l+1 p l+1 i l+1 (\u2022 \u2022 \u2022 ) \u00b4 \u00f3\u00f6 \u00f8 log p l+1 i c l+1 \u00f8 \u00f6\u00f1\u00b5\u00b8 \u00f2 m l+1 i l+1 =1 \u03b4 i c l+1 ,i c l+1 (i c l ) log \u03b4 i c l+1 ,i c l+1 (i c l ) = 0 \u00b4 \u00f3\u00f6 \u00f8 log p l+1|l i c l+1 ,i c l \u00f8 \u00f6\u00f1\u00b5\u00b8\u00f8\u00f3 \u00fd \u00f0 l (p, q) \u2212 l p l , q l = \u2212 l\u22121 l=0 i l p l i l \u00f0\u00f9\u00d7\u00f8 \u00f6 c log p l i c l + l\u22121 l=0 i l+1 p l+1 i l+1 \u00f0\u00f9\u00d7\u00f8 \u00f6 c log p l+1 i c l+1 \u00b4 \u00bc\u00b5 \u00ec \u00f6\u00d7\u00f8 \u00f8 \u00f6\u00f1 \u00f1 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00fd \u00f2\u00f8 \u00f6 \u00f2 \u00f2 \u00f8 \u00f3\u00f6 \u00f6 \u00f3 \u00d7\u00f9\u00f1\u00b9 \u00f1 \u00f8 \u00f3\u00f2 i l c (\u2022 \u2022 \u2022 ) = c i l (\u2022 \u2022 \u2022 )\u00b8 \u00f2 \u00f8 \u00f2 \u00f1 \u00f6 \u00f2 \u00f0 \u00d7 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00b9 \u00f0 \u00f8 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00f8 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i l p l i l log p l i c l = \u00f0\u00f9\u00d7\u00f8 \u00f6 c i c l p l i c l log p l i c l \u00ba \u00ec \u00d7 \u00f3\u00f2 \u00f8 \u00f6\u00f1 \u00f1 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00fd \u00f2\u00f8 \u00f6 \u00f2 \u00f2 \u00f8 \u00f3\u00f6 \u00f6 \u00f3 \u00d7\u00f9\u00f1\u00f1 \u00f8 \u00f3\u00f2 i l+1 \u00f0\u00f9\u00d7\u00f8 \u00f6 c (\u2022 \u2022 \u2022 ) = \u00f0\u00f9\u00d7\u00f8 \u00f6 c i l+1 (\u2022 \u2022 \u2022 )\u00b8\u00f8 \u00f2 \u00f1 \u00f6 \u00f2 \u00f0 \u00d7 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0\u00b9 \u00f8 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00f8 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i l+1 p l+1 i l+1 log p l+1 i c l+1 = \u00f0\u00f9\u00d7\u00f8 \u00f6 c i c l+1 p l+1 i c l+1 log p l+1 i c l+1 \u00b8 \u00f2 \u00f8 \u00f2 \u00f9\u00d7 \u00f2 \u00f8 \u00f8 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c \u00f2 \u00f0 \u00fd \u00f6 l + 1 \u00d7 \u00f8 \u00f4 \u00f6 \u00f2\u00f8 \u00f3 \u00f0\u00f9\u00d7\u00f8 \u00f6 c \u00f2 \u00f0 \u00fd \u00f6 l\u00b8\u00f8\u00f3 \u00f3 \u00f8 \u00f2 l (p, q) \u2212 l p l , q l = \u2212 l\u22121 l=0 i c l p l i c l \u00f0\u00f9\u00d7\u00f8 \u00f6 c log p l i c l + l l=1 i c l p l i c l \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c log p l i c l \u00b4 \u00bd\u00b5 \u00be\u00bc \u00f2 \u00f9\u00d7 \u00f2 \u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00b5 \u00f8 \u00d7 \u00f1 \u00fd \u00f2 \u00f0\u00f0\u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 l (p, q) \u2212 l p l , q l = l\u22121 l=0 \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p l c \u2212 l l=1 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c h p l c \u00b4 \u00be\u00b5 \u00fb \u00f6 h p l c \u00d7 \u00f8 \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd \u00f3 \u00f0\u00f9\u00d7\u00f8 \u00f6 c \u00f2 h p l c \u00d7 \u00f8 \u00f2\u00f8\u00f6\u00f3\u00f4\u00fd \u00f3 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c \u00b4 \u00f3\u00f8 \u00f2 \u00f0 \u00fd \u00f6 l\u00b5\u00ba \u00ec \u00f1\u00f9\u00f8\u00f9 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 i p l c \u00f8\u00fb \u00f2 \u00f8 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 c \u2032 \u00f3 \u00f0\u00f9\u00d7\u00f8 \u00f6 c \u00d7 \u00f2 \u00d7 i p l c \u2261 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c \u2032 \u00f2 \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p l c \u2032 \u2212 h p l c \u00b4 \u00bf\u00b5 \u00f2 \u00f9\u00d7 \u00f2 \u00f8 \u00f8 \u00f0\u00f9\u00d7\u00f8 \u00f6 c \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c \u2032 \u00f2 \u00f0\u00f9\u00d7\u00f8 \u00f6 c (\u2022 \u2022 \u2022 ) = \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c \u2032 \u00f8 \u00d7 \u00fd \u00f0 \u00d7 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i p l c \u2261 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 c h p l c \u2212 \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p l c \u00b4 \u00b5 \u00fb \u00f0\u00f0\u00f3\u00fb\u00d7 l (p, q) \u2212 l p l , q l \u00f8\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00f8\u00f3 l (p, q) \u2212 l p l , q l = \u2212 l l=1 \u00f0\u00f9\u00d7\u00f8 \u00f6 c i p l c + \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p 0 c \u2212 \u00f0\u00f9\u00d7\u00f8 \u00f6 c h p l c \u00b4 \u00b5 \u00e8\u00e5 \u00e1\u00f2 \u00f8 \u00d7 \u00f4\u00f4 \u00f2 \u00fc \u00d7\u00f3\u00f1 \u00f3 \u00f8 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f0 \u00f8 \u00f0\u00d7 \u00f6 \u00f0 \u00fa \u00f2\u00f8 \u00f8\u00f3 \u00d7 \u00f8 \u00f3\u00f2 \u00f6 \u00fa \u00f2\u00ba \u00ba\u00bd \u00e8\u00e5 \u00ea \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00e5\u00f3 \u00f0 \u00e1 \u00f8 \u00f8\u00fd\u00f4 \u00f3 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00ba\u00bd\u00b8\u00fb \u00d7 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 n \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f6 \u00f6 n \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00b8 \u00d7 \u00f8 \u00f2 \u00f2\u00d7 \u00f6\u00f8 \u00f2\u00f8\u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f8 \u00fd \u00f0 \u00d7 d v q \u00f3 \u00f8 \u00f3\u00f6\u00f1 d v q = 2 dx pr (x) m1 y1=1 m2 y2=1 \u2022 \u2022 \u2022 mn yn=1 pr (y 1 |x, 1) pr (y 2 |x, 2) \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 pr (y n |x, n) x \u2212 x \u2032 (y 1 , y 2 , \u2022 \u2022 \u2022 , y n ) 2 \u00b4 \u00b5 \u00fb \u00f6 pr (y k |x, k) \u00f2\u00f3\u00f8 \u00d7 \u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00b4 \u00fa \u00f2 \u00f2\u00f4\u00f9\u00f8 x\u00b5 \u00f3 \u00f2 \u00fc y k \u00f3\u00f9\u00f6\u00d7 \u00f2 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 k\u00ba \u00e1 x \u2032 (y 1 , y 2 , \u2022 \u2022 \u2022 , y n ) \u00d7 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00b4 \u00ba \u00ba \u00f8 \u00d7 \u00f8 \u00fa \u00f0\u00f9 \u00f8 \u00f8 \u00f1 \u00f2 \u00f1 \u00d7 \u00d7 d v q \u00b5 \u00f8 \u00f2 \u00f8 \u00f3\u00f1 \u00d7 x \u2032 (y 1 , y 2 , \u2022 \u2022 \u2022 , y n ) = dx pr (y 1 |x) pr (y 2 |x) \u2022 \u2022 \u2022 pr (y n |x) x \u00b4 \u00b5 \u00be\u00bd \u00ec x \u2212 x \u2032 (y 1 , y 2 , \u2022 \u2022 \u2022 , y n ) 2 \u00f8 \u00f6\u00f1 \u00f1 \u00fd \u00fc\u00f4 \u00f2 \u00f8 \u00f9\u00d7 \u00b4 \u00fd \u00f2 \u00f2 \u00d7\u00f9 \u00b9 \u00f8\u00f6 \u00f8 \u00f2 1 n n k=1 x \u2032 k (y k )\u00b5 x \u2212 x \u2032 (y 1 , y 2 , \u2022 \u2022 \u2022 , y n ) 2 \u2261 x \u2212 1 n n k=1 x \u2032 k (y k ) + 1 n n k=1 x \u2032 k (y k ) \u2212 x \u2032 (y 1 , y 2 , \u2022 \u2022 \u2022 , y n ) 2 \u00b4 \u00b5 \u00ed\u00d7 \u00f2 \u00f8 \u00d7 \u00f8\u00fb\u00f3 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7\u00b8\u00f8\u00f3 \u00f8 \u00f6 \u00fb \u00f8 \u00fd \u00d7\u00b3 \u00f8 \u00f3\u00f6 \u00f1\u00b8 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f2 \u00f9\u00f4\u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 d v q \u00f8\u00f3 \u00f6 \u00fa \u00d7 d v q \u2264 2 dx pr (x) m1 y1=1 m2 y2=1 \u2022 \u2022 \u2022 mn yn=1 pr (y 1 |x, 1) pr (y 2 |x, 2) \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 pr (y n |x, n) x \u2212 1 n n k=1 x \u2032 k (y k ) 2 \u00b4 \u00b5 \u00e1\u00f2 \u00f8 \u00d7 \u00f9\u00f4\u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00b8\u00f8 pr (y k |x, k) \u00f6 \u00f9\u00d7 \u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f9 \u00d7\u00f3 \u00f8 \u00f2\u00f3 \u00f2 \u00d7 \u00f2 \u00f3 \u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00b4k = 1, 2, \u2022 \u2022 \u2022 , n\u00b5\u00b8\u00f8 \u00f2 \u00d7\u00f9\u00f1 1 n n k=1 x \u2032 k (y k ) \u00f3 \u00f8 \u00fa \u00f8\u00f3\u00f6\u00d7 x \u2032 k (y k ) \u00d7 \u00f9\u00d7 \u00d7 \u00f8 \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2\u00f4\u00f9\u00f8 x\u00ba \u00e1\u00f2 \u00f8 \u00d7\u00f4 \u00f0 \u00d7 \u00fb \u00f6 \u00f6 \u00f2\u00f3 \u00f2 \u00d7 \u00f6 \u00f9\u00d7 \u00b8\u00d7\u00f3 \u00f8 \u00f8 pr (y k |x, k) = \u03b4 y k ,y k (x) \u00b8\u00f8 \u00f2 \u00f8 \u00f9\u00f4\u00b9 \u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 d v q \u00f6 \u00f9 \u00d7 \u00f8\u00f3 d v q \u2264 2 dx pr (x) x\u2212 1 n n k=1 x \u2032 k (y k (x)) 2 \u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f3 \u00fa \u00f8\u00f3\u00f6\u00d7 \u00f9\u00d7 \u00f3\u00f6 \u00f8 \u00f2\u00f3 \u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2 y k (x) \u00f6 \u00f2\u00f3\u00f8 \u00f2 \u00b9 \u00d7\u00d7 \u00f6 \u00f0\u00fd \u00f8 \u00d7 \u00f1 \u00d7 \u00f8 x \u2032 k (y k )\u00b8 \u00fc \u00f4\u00f8 \u00f2 \u00f8 \u00d7\u00f4 \u00f0 \u00d7 n = 1\u00ba \u00eb\u00f9\u00f4\u00f4\u00f3\u00d7 \u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f9\u00d7 n \u00f8 \u00f1 \u00d7\u00b8\u00f6 \u00f8 \u00f6 \u00f8 \u00f2 n \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f2 \u00f9\u00d7 \u00f3\u00f2 \u00ba \u00ec \u00d7 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2 \u00f2 \u00f8 p l+1 \u00fa \u00f8\u00f3\u00f6\u00d7 \u00f2 p l|l+1 \u00f1 \u00f8\u00f6 \u00d7 \u00f8\u00f3 \u00f8 \u00d7 \u00f1 \u00f3\u00f6 \u00f3 \u00f8 n \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00ba \u00ec \u00f9\u00f4\u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 d v q \u00f2 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f2\u00f8\u00f3 \u00f8 \u00f3\u00f6\u00f1 d v q \u2264 2 n dx pr (x) m y=1 pr (y|x) x \u2212 x \u2032 (y) 2 + 2 (n \u2212 1) n dx pr (x) x \u2212 m y=1 pr (y|x) x \u2032 (y) 2 \u00b4 \u00bc\u00b5 \u00fb \u00f6 \u00f8 k \u00f2 \u00fc \u00d7 \u00f2\u00f3 \u00f0\u00f3\u00f2 \u00f6 \u00f2 \u00ba \u00ba\u00be \u00f9\u00f0\u00f0 \u00fd \u00d7 \u00f2 \u00fa \u00f6 \u00e7\u00fa \u00f6 \u00ea \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00e5\u00f3 \u00f0\u00d7 \u00e7\u00f2 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f6 \u00f8 \u00d7\u00f1 \u00f3 \u00f8 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00fa \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00d7 \u00f8 \u00f8 \u00f8 \u00d7 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00f3 k \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7\u00b8\u00fb \u00f6 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f2 \u00f1\u00f3 \u00f0 \u00d7 \u00d7\u00d7 \u00f2 \u00f8 \u00d7 \u00f1 \u00fb \u00f8 1 k \u00ba ae\u00f3\u00f6\u00f1 \u00f0\u00f0\u00fd\u00b8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr (y|x) \u00d7 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00d7 \u00d7\u00f9\u00f1 \u00f3\u00fa \u00f6 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 pr (y|x, k) \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f2 \u00f1\u00f3 \u00f0\u00b8 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 pr (y|x) = k k=1 pr (y|x, k) pr (k|x) \u00b4 \u00bd\u00b5 \u00be\u00be \u00fb \u00f6 \u00f3 \u00f8 k \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00d7 \u00d7\u00d7 \u00f2 \u00f6 \u00f2\u00f8 \u00f8 \u00b9 \u00f4 \u00f2 \u00f2\u00f8 \u00fb \u00f8 pr (k|x)\u00ba \u00ec \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 pr (k|x) \u00f2 pr (y|x) \u00f2 \u00fa \u00f0\u00b9 \u00f9 \u00f8 \u00f8\u00f3 \u00fd \u00f0 pr (k|x) = m y=1 pr (x|y, k) pr (y|k) pr (k) k k \u2032 =1 m y \u2032 =1 pr (x|y \u2032 , k \u2032 ) pr (y \u2032 |k \u2032 ) pr (k \u2032 ) pr (y|x, k) = pr (x|y, k) pr (y|k) pr (k) m y \u2032 =1 pr (x|y \u2032 , k) pr (y \u2032 |k) pr (k) \u00b4 \u00be\u00b5 \u00d7\u00f3 \u00f8 \u00f8 pr (y|x) = k k=1 pr (x|y, k) pr (y|k) pr (k) k k \u2032 =1 m y \u2032 =1 pr (x|y \u2032 , k \u2032 ) pr (y \u2032 |k) pr (k \u2032 ) \u00b4 \u00bf\u00b5 \u00e1 \u00f8 \u00f6 \u00f4\u00f0 \u00f1 \u00f2\u00f8\u00d7 pr (k) \u2192 1\u00b8pr (y|k) \u2192 a l+1 k,i l+1 p l+1 i l+1 \u00b8pr (x|y, k) \u2192 p l|l+1 i l ,i l+1 \u00b8 \u00f2 pr (y|x) \u2192 p l+1|l i l+1 ,i l \u00f6 \u00f1 \u00b8\u00f8 \u00f2 pr (y|x) \u00f6 \u00f9 \u00d7 \u00f8\u00f3 p l+1|l i l+1 ,i l = k k=1 p l|l+1 i l ,i l+1 a l+1 k,i l+1 p l+1 i l+1 k k \u2032 =1 m l+1 i \u2032 l+1 =1 p l|l+1 i l ,i \u2032 l+1 a l+1 k \u2032 ,i \u2032 l+1 p l+1 i \u2032 l+1 \u00b4 \u00b5 \u00fb \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00d7 \u00f1 \u00d7 \u00f8 \u00e8\u00e5 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00ba \u00ec \u00f6 \u00f2 \u00f8\u00fb \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f6 \u00d7 \u00d7 \u00f9\u00d7 \u00f8 \u00f9\u00f0\u00f0 \u00fd \u00d7 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f2\u00d7\u00f9\u00f6 \u00d7 \u00f8 \u00f8 \u00f8 \u00f1\u00f3 \u00f0 \u00f2 \u00fc k \u00f2 \u00f8 \u00f2\u00f4\u00f9\u00f8 x \u00f6 \u00f1\u00f9\u00f8\u00f9 \u00f0\u00f0\u00fd \u00f4 \u00f2 \u00f2\u00f8 \u00b4\u00fa \u00f8 \u00f8\u00f3\u00f6 pr (k|x)\u00b5\u00b8\u00fb \u00f6 \u00d7 \u00f8 \u00e8\u00e5 \u00f4\u00f4\u00f6\u00f3 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f2\u00f3\u00f6 \u00d7 \u00d7\u00f9 \u00f4 \u00f2 \u00f2 \u00d7\u00ba \u00e1\u00f2 \u00f8 \u00f9\u00f0\u00f0 \u00fd \u00d7 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b5 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f8 \u00f6\u00f1 \u00f2 \u00f8 \u00f2\u00f3\u00f1 \u00f2 \u00f8\u00f3\u00f6 \u00d7 \u00f3\u00f9 \u00f0 \u00d7\u00f9\u00f1\u00f1 \u00f8 \u00f3\u00f2 k k=1 m l+1 i l+1 =1 p l|l+1 i l ,i l+1 a l+1 k,i l+1 p l+1 i l+1 \u00b8\u00fb \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00f0\u00f0 \u00f4 \u00f6\u00d7 \u00f3 \u00f2 \u00d7 k \u00f2 i l+1 \u00fb \u00f8 a l+1 k,i l+1 > 0\u00b8\u00fb \u00f8 \u00f9\u00d7 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f0\u00f3\u00f2 \u00b9\u00f6 \u00f2 \u00f0 \u00f8 \u00f6 \u00f0 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00f0 \u00fd \u00f6 l + 1\u00ba \u00e7\u00f2 \u00f8 \u00f3\u00f8 \u00f6 \u00f2 \u00b8 \u00f2 \u00f8 \u00e8\u00e5 \u00f4\u00f4\u00f6\u00f3 \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00b5 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f8 \u00f6\u00f1 \u00f2 \u00f8 \u00f2\u00f3\u00f1 \u00f2 \u00f8\u00f3\u00f6 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00d7 \u00f2 \u00f0 \u00d7\u00f9\u00f1\u00f1 \u00f8 \u00f3\u00f2 m l+1 i l+1 =1 p l|l+1 i l ,i l+1 a l+1 k,i l+1 p l+1 i \u2032 l+1 \u00b8\u00d7\u00f3 \u00f8 \u00f0 \u00f8 \u00f6 \u00f0 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00f0 \u00fd \u00f6 l + 1 \u00f6 \u00f8 \u00f6\u00f1 \u00f2 \u00fd \u00f8 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f3 \u00f8 \u00f1 \u00f8\u00f6 \u00fc a l+1 k,i l+1 \u00b8\u00fb \u00f2 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00d7 \u00f3\u00f6\u00f8\u00b9\u00f6 \u00f2 \u00f0 \u00f8 \u00f6 \u00f0 \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f2\u00d7 \u00b4 \u00ba \u00ba \u00f3\u00f6 \u00fa \u00f2 \u00f6 \u00f3 \u00f2 \u00f8 \u00f3\u00f2 \u00f1\u00f3 \u00f0 k\u00b8\u00f3\u00f2\u00f0\u00fd \u00f0 \u00f1 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f2 \u00fc \u00fa \u00f0\u00f9 \u00d7 i l+1 \u00d7 \u00f8 \u00d7 \u00fd a l+1 k,i l+1 > 0\u00ba \u00f3\u00f1\u00f4 \u00f6 \u00d7\u00f3\u00f2 \u00fb \u00f8 \u00f8 \u00e0 \u00f0\u00f1 \u00f3\u00f0\u00f8\u00fe \u00e5 \u00f2 \u00e1\u00f2 \u00f8 \u00d7 \u00f4\u00f4 \u00f2 \u00fc \u00f8 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f4 \u00f8\u00fb \u00f2 \u00f8\u00fb\u00f3 \u00f8\u00fd\u00f4 \u00d7 \u00f3 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0 \u00d7 \u00d7\u00b9 \u00f9\u00d7\u00d7 \u00ba \u00ec \u00f6\u00d7\u00f8 \u00f8\u00fd\u00f4 \u00d7 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0 \u00f8 \u00f8 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00d7 \u00f8 \u00f2\u00f4\u00f9\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2\u00d7 \u00f8\u00fd \u00b4 \u00ba \u00ba \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00d7 l p 0 , q 0 \u00b5\u00b8 \u00f2 \u00f8 \u00d7 \u00f3\u00f2 \u00f8\u00fd\u00f4 \u00d7 \u00f8 \u00f3\u00f2 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f6 \u00f8 \u00f8 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2\u00d7 \u00f8\u00fd \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba \u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00d7 l (p, q)\u00b5\u00ba \u00e1\u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00be\u00bf \u00f6 \u00f0 \u00f8 l p 0 , q 0 \u00f8\u00f3 l (p, q) \u00f8 \u00d7 \u00f2 \u00d7\u00d7 \u00f6\u00fd \u00f8\u00f3 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f8 \u00f3\u00f2 \u00f0 \u00f0 \u00fd \u00f6\u00d7 \u00b4 \u00ba \u00ba \u00f0 \u00fd \u00f6\u00d7 1, 2, \u2022 \u2022 \u2022 , l\u00b5 \u00f2\u00f8\u00f3 l p 0 , q 0 \u00f2 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00d7 \u00f3\u00f2\u00ba \u00ec \u00e0 \u00f0\u00f1 \u00f3\u00f0\u00f8\u00fe \u00f1 \u00f2 \u00b4\u00e0\u00e5\u00b5 \u00be\u2104 \u00f3 \u00d7 \u00f8 \u00d7 \u00fd \u00f6 \u00f4\u00f0 \u00f2 l p 0 , q 0 \u00fd \u00f6 \u00f2\u00f8 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00b4\u00fb \u00d7 \u00f8 \u00d7 \u00f8 \u00f3\u00f2 \u00f0 \u00f0 \u00fd \u00f6\u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00d7 \u00b9 \u00f2 \u00fa \u00f6 \u00f0 \u00d7\u00b5\u00b8 \u00f2 \u00fb \u00d7 \u00f2 \u00f9\u00f4\u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l p 0 , q 0 \u00ba \u00e1\u00f8 \u00f8\u00f9\u00f6\u00f2\u00d7 \u00f3\u00f9\u00f8 \u00f8 \u00f8 \u00e0 \u00f0\u00f1 \u00f3\u00f0\u00f8\u00fe \u00f1 \u00f2 \u00b4\u00e0\u00e5\u00b5 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 d hm \u00f2 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00f3 \u00f8 \u00fa \u00f9\u00f2\u00f8 \u00f3\u00f2 l (p, q) \u00f6 \u00f0\u00f3\u00d7 \u00f0\u00fd \u00f6 \u00f0 \u00f8 \u00ba \u00ec \u00d7\u00b9 \u00d7 \u00f2\u00f8 \u00f0 \u00f6 \u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f8\u00fb\u00f3 \u00d7 \u00f8 \u00f8 d hm \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f2\u00f0\u00f9 \u00f8 \u00f3\u00d7\u00f8 \u00f3 \u00d7\u00f4 \u00fd \u00f2 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6\u00d7 1, 2, \u2022 \u2022 \u2022 , l \u00fa \u00f2 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 \u00bc \u00d7 \u00f2\u00f3\u00fb\u00f2\u00fb \u00f8 \u00f9\u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8 \u00f8\u00f3 \u00fa \u00f0\u00f3\u00f4 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3 \u00d7 \u00b4\u00fb \u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00fa \u00f8\u00f3 \u00d7\u00f4 \u00fd\u00b5 \u00f1\u00f3\u00f6 \u00d7 \u00f0\u00fd\u00ba \u00e1\u00f2 \u00f8 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00f8\u00f3 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00b8\u00f8 \u00f6 \u00f6 \u00f8\u00fb\u00f3 \u00d7 \u00f0 \u00d7\u00d7 \u00d7 \u00f3 \u00f1\u00f3 \u00f0\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f3 \u00f3\u00f8 \u00f9\u00f2\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f2 \u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 p 0 \u00b8\u00fb \u00d7 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f4\u00f9\u00f8 \u00b4\u00f9\u00f2\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00d7 \u00b5 \u00f3\u00f6 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00b4\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00d7 \u00b5\u00ba \u00f8 \u00f3\u00f2 \u00f0\u00f0\u00fd\u00b8 \u00f2 \u00f8 \u00d7 \u00f3 \u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 p 0 \u00d7 \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f3\u00f2 \u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f4\u00f9\u00f8 \u00d7 p 0| \u00f2\u00f4\u00f9\u00f8 \u00ba \u00ec \u00f9\u00d7 \u00f2 \u00f3\u00f8 \u00d7 \u00d7 \u00f8 \u00f6 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00f2 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba \u00d7\u00f3\u00f9\u00f6 \u00f0 \u00fd \u00f6\u00d7 1, 2, \u2022 \u2022 \u2022 , l \u00f6 \u00f2\u00f3\u00f8 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00b5\u00b8\u00fb \u00d7 \u00f1\u00f3 \u00f0\u00f0 \u00fd q 0 \u00b4\u00f9\u00f2\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00d7 \u00b5 \u00f3\u00f6 q 0| \u00f2\u00f4\u00f9\u00f8 \u00b4\u00d7\u00f9\u00f4 \u00f6\u00fa \u00d7 \u00d7 \u00b5\u00ba q 0 \u00f3\u00f6 q 0| \u00f2\u00f4\u00f9\u00f8 \u00f2 \u00f1\u00f3 \u00f0\u00f0 \u00f2 \u00f2\u00fd \u00fb \u00fd \u00f8 \u00f8 \u00d7 \u00f3\u00f2\u00fa \u00f2 \u00f2\u00f8\u00ba \u00f6 \u00f5\u00f9 \u00f2\u00f8\u00f0\u00fd \u00f1\u00f9\u00f0\u00f8 \u00f0 \u00fd \u00f6 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00f3\u00f6\u00f1 q 0 i0 = i1,i2,\u2022\u2022\u2022 ,il q 0|1 i0,i1 \u2022 \u2022 \u2022 q l|l+1 i l ,i l+1 \u2022 \u2022 \u2022 q l il \u00b4 \u00b5 \u00d7 \u00f9\u00d7 \u00b8\u00fb \u00f6 \u00f8 i l \u00b4 \u00f3\u00f6 1 \u2264 l \u2264 l\u00b5 \u00f6 \u00f2 \u00fa \u00f6 \u00f0 \u00d7\u00b8\u00fb \u00f2 \u00f8\u00f3 \u00d7\u00f9\u00f1\u00f1 \u00f3\u00fa \u00f6 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f0\u00f9\u00f0 \u00f8 \u00f8 \u00f6 \u00f5\u00f9 \u00f6 \u00f1 \u00f6 \u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd q 0 i0 \u00b8 \u00f2 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f0 \u00f6 \u00f8 \u00f0\u00fd \u00f3\u00d7 \u00f2 \u00f8\u00f3 \u00f8 \u00d7 \u00f1 \u00d7 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00f1\u00f3 \u00f0 q i0,i1,\u2022\u2022\u2022 ,il = q 0|1 i0,i1 \u2022 \u2022 \u2022 q l|l+1 i l ,i l+1 \u2022 \u2022 \u2022 q l il \u00b4 \u00b5 \u00e0 \u00f0\u00f1 p 0 i0 k i0 p 1|0 , q 0|1 + m0 i0=1 p 0 i0 g i0 p 1|0 , q 1 \u00b4 \u00b5 \u00ec m0 i0=1 p 0 i0 k p 1|0 , q 0|1 \u00f4 \u00f6\u00f8 \u00f2 \u00f8 m0 i0=1 p 0 i0 g p 1|0 , q 1 \u00f4 \u00f6\u00f8 \u00f3\u00f1\u00b9 \u00f4 \u00f8 \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00fb \u00f2 d hm \u00d7 \u00f1 \u00f2 \u00f1 \u00d7 \u00ba \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00f8 p 0 i0 > 0\u00b8\u00f8 m0 i0=1 p 0 i0 g p 1|0 , q 1 \u00f4 \u00f6\u00f8 \u00f0 \u00d7 \u00f8\u00f3 \u00f1 q 1 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 p 1|0 \u00b8\u00fb \u00f8 \u00f2 \u00d7 \u00f8\u00f3 \u00f1 p 1|0 \u00fa \u00f0 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f2\u00f3 \u00f6\u00ba \u00e7\u00f2 \u00f8 \u00f3\u00f8 \u00f6 \u00f2 \u00b8 \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00f8 p 1 i1 > 0\u00b8\u00f8 m0 i0=1 p 0 i0 k p 1|0 , q 0|1 \u00f4 \u00f6\u00f8 \u00f0 \u00d7 \u00f8\u00f3 \u00f1 q 0|1 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 p 0|1 \u00fb \u00f8 \u00f2 \u00d7 = \u00f3\u00f0\u00f8\u00fe \u00f1 \u00f2 \u00d7 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f6 \u00f6 \u00f0 \u00f8 \u00f8\u00f3 \u00f3\u00f8 \u00f6\u00ba \u00ec \u00f9\u00d7 \u00f8 l p 0 , q 0 \u00f8 \u00f8 \u00d7 \u00f1 \u00f2 l p 0 , p 1|0 , q 0 , q 1|0 \u2212 \u00f8\u00fd l p 0 , q 0 \u2264 d hm \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00f6\u00f3\u00f1 g i0 p 1|0 , q 1|0 \u2265 0 \u00b4 \u00ba \u00ba \u00f8 \u00f1\u00f3 \u00f0 q 1|0 \u00d7 \u00f1\u00f4 \u00f6 \u00f8\u00b8\u00d7\u00f3 \u00f8 \u00f8 q 1|0 = p 1|0 \u00b5\u00ba \u00ec \u00f2 \u00f5\u00f9 \u00f0 \u00f8\u00fd d hm \u2264 l (p, q) \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00f6\u00f3\u00f1 h i0 p 1|0 \u2265 0 \u00b4 \u00ba \u00ba \u00f8 \u00d7\u00f3\u00f9\u00f6 p 1|0 \u00d7 \u00d7\u00f8\u00f3 \u00d7\u00f8 \u00b5\u00ba \u00e1 \u00f8 \u00f1\u00f3 \u00f0 \u00d7 \u00f4 \u00f6 \u00f8 \u00b4q1|0 = p 1|0 \u00b5 \u00f2 \u00f8 \u00d7\u00f3\u00f9\u00f6 \u00d7 \u00f8 \u00f6\u00f1 \u00f2 \u00d7\u00f8 \u00b4p1|0 \u00d7 \u00d7\u00f9 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 \u00bd \u00d7 \u00f2\u00f3\u00fb\u00f2 \u00f3\u00f2 \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0 \u00fd \u00f6 \u00bc \u00d7 \u00fa \u00f2\u00b5\u00b8\u00f8 \u00f2 \u00f8 \u00d7 \u00f8\u00fb\u00f3 \u00f2 \u00f5\u00f9 \u00f0 \u00f8 \u00d7 \u00f6 \u00f9 \u00f8\u00f3 l p 0 , q 0 = l (p, \n k i0 p 1|0 , q 0|1 + l p l , q l \u00ba \u00e2\u00ba\u00b8\u00ec \u00f1 \u00f8 \u00f1 \u00f8 \u00f0 \u00f8 \u00f3\u00f6\u00fd \u00f3 \u00f3\u00f1\u00b9 \u00f1\u00f9\u00f2 \u00f8 \u00f3\u00f2\u00b8\u00be \u00b8\u00bf \u00b9 \u00be\u00bf \u00f2 \u00be\u00bf\u00b9 \u00ba",
        "prob": 0.9732203389830506
    }, {
        "ID": 7119,
        "phrase": "5, 11 \u00d7 \u00f8 \u00f8 \u00f1 \u00f2 \u00f8\u00f3 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8 \u00f4 \u00f8 \u00f8 \u00f8 \u00f6 \u00f8 i\u00e5 \u00f4\u00d7\u00ba t i \u00f2\u00f0\u00f9 \u00d7 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f4\u00f3\u00f6\u00f8 \u00f0 \u00fd \u00f6 \u00f6\u00b8\u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f0 \u00fd \u00f6 \u00f6\u00b8\u00f8 \u00e5 \u00f0 \u00fd \u00f6 \u00f6 \u00f2 \u00e8\u00e0 \u00f0 \u00fd \u00f6 \u00f6\u00ba \u00ef \u00f2 \u00d7 \u00f0\u00fd \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f8 \u00f1 \u00f9\u00d7 \u00fd \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 i \u00d7 agg i = n ai \u00d7 (t i + t ack) + (n ai \u2212 1) \u00d7 t sif s \u00b4 \u00b5 agg i \u00d7 \u00f8 \u00f8 \u00f1 \u00f6 \u00f5\u00f9 \u00f6 \u00f3\u00f6 \u00f8 \u00f6 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00d7\u00d7 \u00f3\u00f2 \u00f3 \u00f2\u00f3 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 i\u00b8\u00fb \u00f6 n ai = t p max/t i \u00ba \u00f6\u00f3\u00f1 \u00f8 \u00f1 \u00f9\u00f1 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb\u00b8\u00f8 \u00f8 \u00f1 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f9\u00d7 \u00f3\u00f6 \u00f2 \u00f6 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00d7\u00d7 \u00f3\u00f2 \u00f3 \u00f3\u00f2 \u00f2\u00f3 \u00d7 occ i = agg i j (agg j \u00d7 n j ) + n * dif s \u00b4 \u00b5 \u00e1ae\u00ea\u00e1 \u00e8 \u00eb \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00eb\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00bd\u00bd \u00fb \u00f6 n j \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 j\u00b8\u00fb \u00f8 j n j = n \u00ba \u00ef \u00d7\u00d7\u00f9\u00f1 \u00f6 \u00f8 \u00f8 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3 \u00d7\u00d7 \u00f8 \u00f1 \u00f9\u00f1 \u00d7 \u00f8 \u00d7 \u00f1 \u00f3\u00f6 \u00f0\u00f0 \u00f8 \u00f2\u00f3 \u00d7 \u00f2 \u00f8 \u00f8 \u00f9\u00f6 \u00f2 \u00f8 \u00f1 \u00f2\u00f8 \u00f6\u00fa \u00f0\u00b8 \u00f2\u00f3 \u00d7 \u00d7\u00d7 \u00f8 \u00f1 \u00f9\u00f1 \u00fc \u00f8\u00f0\u00fd \u00f3\u00f2 \u00ba \u00ec \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7 \u00d7 \u00f2\u00f8 \u00fd \u00f2\u00f3 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 i\u00b8 \u00f2 \u00f8 \u00f1 \u00f2\u00f8 \u00f6\u00fa \u00f0 t\u00b8 \u00d7 n bp i = n ai j (agg j \u00d7 n j ) + n \u00d7 (dif s + avg bckf ) \u00d7 t \u00b4 \u00b5 \u00fb \u00f6 avg bckf \u00d7 \u00f8 \u00fa \u00f6 \u00f3 \u00ba \u00ef \u00f2 \u00f8 \u00f9\u00d7 \u00f6 \u00fa \u00f8 \u00fa \u00f6 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f2 \u00f4\u00d7 \u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 i \u00fb \u00f8 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 t h i = n bp i \u00d7 l \u00d7 8 \u00b4 \u00b5 \u00f0\u00f0 \u00f8 \u00f3\u00fa \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00f4\u00f4\u00f0 \u00fb \u00f8 \u00f6 \u00f2\u00f8 \u00f4 \u00f8 \u00d7 \u00fe \u00d7\u00b8\u00f8 \u00f1 \u00f2 \u00f4 \u00f6 \u00f1 \u00f8 \u00f6 \u00f8\u00f3 \u00f2\u00f3\u00fb \u00d7 t p max\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f2 \u00f0\u00fd\u00d7 \u00d7\u00b8\u00fb \u00d7\u00d7\u00f9\u00f1 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00d7 \u00f8\u00f3 \u00f8 \u00f1 \u00f9\u00f1 \u00f2 \u00ec \u00e5 \u00f1\u00f3 \u00b8 \u00ba \u00ba \u00f3\u00f2 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f8 \u00f6 \u00f8 \u00f3\u00f8 \u00f6\u00ba \u00ec \u00d7 \u00d7\u00d7\u00f9\u00f1\u00f4\u00f8 \u00f3\u00f2 \u00d7 \u00f0 \u00f8 \u00f1 \u00f8 \u00f9 \u00f8 \u00f6 \u00d7\u00d7 \u00f4\u00f6\u00f3\u00fa \u00fd \u00f8 \u00f3 \u00d7 \u00f1 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f2 \u00f8 \u00f3 \u00e1 \u00bc\u00be\u00ba\u00bd\u00bd\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00fb \u00fb \u00f0\u00f0 \u00d7 \u00b8 \u00f2 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00d7 \u00f8 \u00f3\u00f2\u00b8\u00f8 \u00f8 \u00f8 \u00f6 \u00f6 \u00d7\u00f3\u00f1 \u00d7\u00f1 \u00f0\u00f0 \u00f6 \u00f2 \u00d7 \u00f8\u00fb \u00f2 \u00f8 \u00f2 \u00f0\u00fd\u00f8 \u00f0 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00f8 \u00f8 \u00f8 \u00d7 \u00f6 \u00f2 \u00d7 \u00f3\u00f1 \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00d7\u00d7\u00f9\u00f1\u00f4\u00f8 \u00f3\u00f2\u00ba \u00e1\u00f2 \u00b8\u00e1 \u00bc\u00be\u00ba\u00bd\u00bd \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f6\u00f3\u00fa \u00f4 \u00f6 \u00f8 \u00ec \u00e5 \u00d7 \u00f9\u00f0 \u00f2 \u00f2 \u00f8 \u00d7 \u00f3\u00f6\u00f8\u00b9\u00f8 \u00f6\u00f1\u00ba \u00f9\u00f6 \u00bd \u00d7 \u00f3\u00fb\u00d7\u00b8 \u00f3\u00f6 \u00f8\u00fb\u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7\u00b8\u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f3 \u00f1 \u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f8 \u00f1 \u00ba \u00e7\u00f2 \u00f3 \u00f8 \u00f8\u00fb\u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00d7 \u00f8 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00fb \u00f0 \u00f8 \u00f3\u00f8 \u00f6 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00d7 \u00f8 \u00bd\u00b8\u00be\u00b8 \u00ba \u00b8\u00f3\u00f6 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00b4\u00f3\u00f2 \u00f8 \u00fc\u00b9 \u00fc \u00d7\u00b8i\u00e5 \u00f4\u00d7 \u00f2 \u00f8 \u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f1 \u00f8\u00d7 \u00f8 i\u00e5 \u00f4\u00d7 \u00fb \u00f0 \u00f8 \u00f3\u00f8 \u00f6 \u00f1 \u00f8\u00d7 \u00f8 \u00bd\u00bd\u00e5 \u00f4\u00d7\u00b5\u00ba \u00e8 \u00f8 \u00d7 \u00fe \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00bd\u00bc\u00bc\u00bc \u00fd\u00f8 \u00d7\u00ba \u00f3\u00f6 i\u00b8\u00f8 \u00d7 \u00f9\u00f6 \u00fa \u00d7 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f1 \u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f8 \u00f1 \u00f3 \u00f8 \u00d7\u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00b4\u00bd\u00bd\u00e5 \u00f4\u00d7\u00b5 \u00f2 \u00f3 \u00f8 \u00d7\u00f0\u00f3\u00fb \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00b4i\u00e5 \u00f4\u00d7\u00b5 \u00f2 \u00f8 \u00f8 \u00f1 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00fb \u00f2 \u00f8 \u00f1 \u00f9\u00f1 \u00d7 \u00f6 \u00ba \u00ef \u00f2 \u00d7 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00d7 \u00f0 \u00f6 \u00f6 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f3 \u00f1 \u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f8 \u00f2 \u00f8 \u00d7\u00f0\u00f3\u00fb \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f8 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f2\u00f3\u00f8 50% \u00d7 \u00f8 \u00d7 \u00f3\u00f9\u00f0 \u00fb \u00f8 \u00f4 \u00f6 \u00f8 \u00f8 \u00f1 \u00b9 \u00d7 \u00f6\u00f2 \u00d7\u00d7\u00ba \u00ec \u00d7 \u00f6 \u00f2 \u00f1 \u00fd \u00d7 \u00f0\u00fd \u00fc\u00f4\u00f0 \u00f2 \u00fd \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00f0\u00f0\u00f3\u00fb \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00d7\u00d7 \u00f3\u00f2 \u00f8 \u00f1 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00fb \u00f8 \u00e8 \u00eb \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00f2\u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8 \u00f8 \u00f2\u00f3\u00fb\u00f0 \u00f1 \u00f2\u00f8\u00d7 \u00f8 \u00f8 \u00f3\u00f2\u00d7\u00f9\u00f1 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00d7\u00d7 \u00f3\u00f2 \u00f8 \u00f1 \u00ba \u00ef \u00f2 \u00f0\u00d7\u00f3 \u00d7 \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00f9\u00f6 \u00f8 \u00f8 \u00f8 \u00f6 \u00f8 \u00f8 \u00f6 \u00f8 \u00f3 \u00f8 \u00d7\u00f0\u00f3\u00fb \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00b8\u00f8 \u00f6 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f3 \u00f1 \u00f9\u00f1 \u00f6 \u00ba \u00ec \u00d7 \u00d7 \u00f9 \u00f8\u00f3 \u00f8 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f3 \u00f8 \u00f1 \u00f2 \u00f8 \u00f1 \u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f8 \u00f1 \u00f8 \u00f8 \u00f2\u00f6 \u00d7 \u00d7\u00ba \u00ec \u00f0 \u00bd \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00f8 \u00f2 \u00fd \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00ba \u00ef \u00f2\u00f0\u00f9 \u00f8 \u00e2 \u00f2 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u2104 \u00f8\u00f3 \u00fa \u00f0\u00f9 \u00f8 \u00f8 \u00f6\u00f2 \u00d7\u00d7 \u00f3 \u00f3\u00f9\u00f6 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2\u00ba \u00ec \u00e2 \u00f2 \u00f2 \u00fc \u00d7 \u00f2 \u00d7 ( i ri/r * i ) 2 n i (ri/r * i ) 2 \u00fb \u00f6 r i \u00d7 \u00f8 \u00f6 \u00f8 \u00fa \u00f3\u00f2 \u00f3\u00fb i\u00b8n \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3\u00fb\u00d7\u00b8 \u00f2 r * i \u00d7 \u00f8 \u00f6 \u00f6 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00fb i\u00ba \u00d7 \u00f6 \u00f6 \u00f2 \u00f6 \u00f8 \u00fb \u00f9\u00d7 \u00f8 \u00f3\u00f2 \u00f2 \u00fd \u00ec \u00f2 \u00f8 \u00f0\u00ba\u00ba \u00ec \u00d7 \u00f6 \u00f8 r * i \u00d7 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00d7 \u00f0\u00f0 \u00f8 \u00f3\u00fb\u00d7 \u00f2 \u00f8 \u00fb \u00f6 \u00f0 \u00d7\u00d7 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00fb \u00f6 \u00f1 \u00f8\u00f8 \u00f8 \u00f8 \u00d7 \u00f1 \u00f8 \u00f6 \u00f8 \u00d7 \u00f3\u00fb i\u00ba \u00f3\u00f6 \u00fc \u00f1\u00f4\u00f0 \u00b8 \u00fb \u00f3\u00f2\u00d7 \u00f6 \u00f8\u00fb\u00f3 \u00f2\u00f3 \u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f8 11 \u00b4 \u00f3\u00fb 1\u00b5 \u00f2 1\u00e5 \u00f4\u00d7 \u00b4 \u00f3\u00fb 2\u00b5\u00ba \u00ec \u00f2 r * 1 \u00fb \u00f0\u00f0 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00f3\u00fb 1 \u00f3\u00fb 2 \u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f8 11\u00e5 \u00f4\u00d7\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f1 \u00fb \u00fd\u0157 * 2 \u00fb \u00f0\u00f0 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00f3\u00fb 2 \u00f3\u00fb 1 \u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f8 1\u00e5 \u00f4\u00d7\u00ba \u00ec \u00fa \u00f0\u00f9 \u00f3 r * i \u00d7 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00fa \u00f0\u00f9 \u00fb \u00f2 \u00f8 \u00f1 \u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f8 \u00f1 \u00d7 \u00f5\u00f9 \u00f0 \u00f3\u00f6 \u00f0\u00f0 \u00f2\u00f3 \u00d7\u00ba \u00ec \u00d7 \u00d7 \u00f8 \u00f6 \u00d7\u00f3\u00f2 \u00fb \u00fd \u00f8 \u00f2 \u00fc \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f2 \u00f8 \u00f0 \u00bd \u00f6 \u00f2\u00f3\u00f8 \u00f5\u00f9 \u00f0 \u00f8\u00f3 1\u00ba \u00ea\u00ea \u00f2 \u00bc\u00bd\u00be\u00bf \u00f9\u00f6 \u00bd \u00e8\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f3 \u00f1 \u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f8 \u00f1 \u00f3\u00f6 \u00f8\u00fb\u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00e8 \u00f8 \u00f2 \u00ba \u00b4\u00bb\u00d7\u00b5 \u00e1\u00f2 \u00fc \u00ba \u00e5 \u00f4\u00d7 \u00bd \u00ba\u00be \u00bd \u00bf\u00ba \u00bc\u00ba \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bf\u00bc \u00ba\u00be \u00bf \u00ba \u00be\u00e5 \u00f4\u00d7 \u00be \u00ba \u00ba\u00bd \u00bc\u00ba \u00bf \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bf \u00ba \u00ba \u00bd\u00e5 \u00f4\u00d7 \u00bf \u00ba \u00bf\u00ba\u00bd \u00bc\u00ba \u00be \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bf \u00bd\u00ba\u00be \u00bf\u00ba \u00ec \u00f0 \u00bd \u00e8 \u00eb \u00f2 \u00f0\u00fd\u00f8 \u00f0 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00e1ae\u00ea\u00e1 \u00e8 \u00eb \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00eb\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00bd\u00bf \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00bc\u00be\u00ba\u00bd\u00bd \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00ba\u00bc \u00be \u00bf\u00bd\u00ba\u00bf \u00be \u00be\u00ba \u00be\u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00be\u00ba \u00bc \u00be \u00bf \u00ba \u00bc \u00be \u00ba \u00bd\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00ba \u00bd\u00ba\u00bc\u00be \u00bc \u00ba \u2104 \u00e1\u00f2 \u00fc \u00bc\u00ba \u00e8 \u00eb \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00bc\u00ba \u00bd \u00be \u00be \u00ba \u00bd \u00be \u00ba\u00bf\u00bc\u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00bf\u00ba \u00bd \u00be \u00bc\u00ba \u00bd \u00be \u00ba \u00be\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00ba\u00bf\u00be \u00ba \u00bc\u00be\u00ba \u2104 \u00e1\u00f2 \u00fc \u00bc\u00ba \u00ec \u00f3\u00f6 \u00f8 \u00f0 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00bc\u00be\u00ba \u00bd \u00b4 \u00f4\u00d7\u00b5 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00bc\u00be\u00ba \u00bd \u00b4 \u00f4\u00d7\u00b5 \u00ec\u00f3\u00f8 \u00f0 \u00bc \u00ba\u00bd \u00bf \u00b4 \u00f4\u00d7\u00b5 \u00ec \u00f0 \u00be \u00e5\u00f3 \u00f0 \u00fa \u00f0 \u00f8 \u00f3\u00f2 \u00eb \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00ec ae\u00eb\u00b9\u00be \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6 \u2104 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00fa \u00f0\u00f9 \u00f8 \u00e8 \u00eb\u00b8\u00fb \u00d7 \u00f3 \u00d7 \u00f2 \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00e5 \u00ba \u00e5\u00f9\u00f0\u00f8 \u00b9\u00f6 \u00f8 \u00f8\u00f9\u00f6 \u00d7 \u00f6 \u00f0\u00d7\u00f3 \u00f8\u00f3 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8\u00f3\u00f6\u00b8 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f6 \u00f8 \u00f8 \u00e1 \u00bc\u00be\u00ba\u00bd\u00bd \u00f1\u00f3 \u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00f0\u00f0 \u00f8 \u00d7\u00f8\u00f9 \u00d7 \u00f0 \u00d7\u00f8 \u00f0\u00f3\u00fb \u00f6 \u00f3\u00f2 \u00f2 \u00d7\u00f8 \u00fd \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00f2\u00ba \u00e1\u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f6 \u00f9 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f8 \u00f1 \u00f2 \u00f8\u00f3 \u00f8\u00f8 \u00f6 \u00fa \u00f0\u00f9 \u00f8 \u00f8 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0\u00b8 \u00ea\u00e8 \u00f2 \u00f6\u00f3\u00f9\u00f8 \u00f2 \u00f4\u00f6\u00f3\u00f8\u00f3\u00f3\u00f0 \u00fc \u00f2 \u00d7 \u00f6 \u00d7 \u00f0 \u00ba \u00e1\u00f2 \u00f0\u00f0 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00ed \u00e8 \u00d7 \u00f8\u00f9\u00f6 \u00f8 \u00f8\u00f6 \u00d7 \u00f9\u00d7 \u00ba \u00e1 \u00f2\u00f3\u00f8 \u00f6 \u00f2\u00f8\u00f0\u00fd \u00d7\u00f4 \u00b8 \u00f4 \u00f8 \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00bd\u00bc\u00bc\u00bc \u00fd\u00f8 \u00d7 \u00f3 \u00f8 \u00ba ae \u00fa \u00f6\u00f8 \u00f0 \u00d7\u00d7\u00b8\u00fb \u00f0\u00d7\u00f3 \u00fa \u00f0\u00f3\u00f4 \u00f1\u00f3 \u00f9\u00f0 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00f4 \u00f8\u00d7 \u00f3 \u00f6 \u00f2 \u00f3\u00f1 \u00d7 \u00fe \u00b8\u00f9\u00f2 \u00f3\u00f6\u00f1\u00f0\u00fd \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f2 \u00d7\u00f4 \u00f2\u00f8 \u00f6\u00fa \u00f0\u00ba \u00ba\u00bd \u00e5\u00f3 \u00f0 \u00fa \u00f0 \u00f8 \u00f3\u00f2 \u00e1\u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00fa \u00f0 \u00f8 \u00f8 \u00f1\u00f4\u00f6\u00f3\u00fa \u00f1 \u00f2\u00f8\u00d7 \u00f8\u00f3 ae\u00eb\u00b9\u00be \u00f2 \u00f8 \u00f3 \u00f3 \u00f3\u00f9\u00f6 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0\u00b8\u00fb \u00f6\u00d7\u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f8\u00fb\u00f3 \u00f4 \u00f6\u00d7 \u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f8 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00fb \u00f8 \u00bd\u00bc\u00bc\u00bc \u00fd\u00f8 \u00d7 \u00f3 \u00f8 \u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00f2 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00f3\u00f2 \u00f9\u00d7 \u00f8 \u00f1 \u00fc \u00f1\u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f8 \u00f1 \u00f4 \u00f6 \u00fa \u00fd \u00f2\u00f3 \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00f8 \u00f8 \u00f1 \u00f6 \u00f5\u00f9 \u00f6 \u00f8\u00f3 \u00d7 \u00f2 \u00f4 \u00f8\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00d7\u00f4 \u00d7 \u00b8\u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00bc\u00be\u00ba\u00bd\u00bd \u00f2 \u00e8 \u00eb \u00d7 \u00f3\u00f9\u00f0 \u00f8 \u00d7 \u00f1 \u00ba \u00ec \u00d7 \u00d7 \u00f3\u00f2 \u00f6\u00f1 \u00fd \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00ec \u00f0 \u00be\u00b8\u00fb \u00f2\u00f0\u00f9 \u00d7 \u00f8 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f6 \u00fa \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00b8 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00d7 \u00f3\u00fb \u00f8 \u00f9\u00f6 \u00fd \u00f3 \u00f3\u00f9\u00f6 \u00f1\u00f3 \u00f0\u00ba \u00ba\u00be \u00d7 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00ec \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00f8 \u00f6\u00d7\u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3 \u00e8 \u00eb\u00ba \u00ec \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6\u00f6 \u00f3\u00f9\u00f8 \u00d7 \u00d7 \u00f3\u00f2 \u00f8 \u00f0 \u00d7\u00d7 \u00f0 \u00d7 \u00f2 \u00f6 \u00f3 \u00fb \u00f6 \u00f8\u00fb\u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8 \u00f4 \u00f8\u00d7 \u00f3 \u00bd\u00bc\u00bc\u00bc \u00fd\u00f8 \u00d7\u00b8\u00f3\u00f2 \u00f8 \u00fc\u00e5 \u00f4\u00d7 \u00b4\u00fc \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00bd\u00b8\u00be \u00f3\u00f6 \u00ba \u00b5 \u00f2 \u00f8 \u00f3\u00f8 \u00f6 \u00f8 \u00bd\u00bd\u00e5 \u00f4\u00d7\u00ba \u00ec \u00f0 \u00d7 \u00bf\u00b8 \u00f2 \u00fa \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00f8 \u00d7 \u00d7 \u00f2 \u00f6 \u00f3\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f8 \u00f0 \u00d7\u00b8\u00fb \u00fa \u00f8 \u00fa \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u0229 \u00ea \u00f2 \u00bc\u00bd\u00be\u00bf \u00bd \u00ea \u00fe \u00f2 \u00f6 \u00f0 \u00f1 \u00f3\u00b8 \u00f9 \u00f6 \u00f2\u00b9\u00f0 \u00d7\u00d7\u00f3\u00f9\u00d7\u00b8\u00e1 \u00f2\u00f2\u00f3\u00f2 \u00b8 \u00f8 \u00fa \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8\u00b8\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f2\u00f8 \u00f4 \u00f8\u00d7 \u00fd \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00f2 \u00f8\u00f3\u00f8 \u00f0\u00b8 \u00d7 \u00fb \u00f0\u00f0 \u00d7 \u00f8 \u00e2 \u00f2 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc\u00b8 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00ba \u00e7\u00f2 \u00f2 \u00d7 \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00f8 \u00f0 \u00d7 \u00f8 \u00f8 \u00f8 \u00f6 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00e8 \u00eb \u00d7 \u00f0\u00fb \u00fd\u00d7 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00bc\u00be\u00ba\u00bd\u00bd\u00b8\u00f8 \u00f9\u00d7 \u00e8 \u00eb \u00d7 \u00f1\u00f3\u00f6 \u00f2\u00f8\u00ba \u00e1\u00f8 \u00f2 \u00f0\u00d7\u00f3 \u00f3 \u00d7 \u00f6\u00fa \u00f8 \u00f8 \u00fb \u00f2 \u00f9\u00d7 \u00f2 \u00e8 \u00eb\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7 \u00f2 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00f8 \u00d7\u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f1 \u00f2 \u00f0\u00f1\u00f3\u00d7\u00f8 \u00f8 \u00d7 \u00f1 \u00b8 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f3 \u00f8 \u00f6 \u00f8 \u00f9\u00d7 \u00fd \u00f8 \u00d7\u00f0\u00f3\u00fb \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00ba \u00ec \u00d7 \u00d7 \u00f9\u00d7 \u00f8 \u00f8 \u00f1 \u00f3\u00f9\u00f4 \u00f8 \u00f3\u00f2 \u00d7 \u00f6\u00f3\u00f9 \u00f0\u00fd \u00fa \u00fd \u00be \u00f8\u00fb \u00f2 \u00f8 \u00d7\u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00d7\u00f0\u00f3\u00fb \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00ba \u00ec \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00e8 \u00eb \u00fa \u00d7 \u00fa \u00f6\u00fd \u00f3\u00f3 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00f8 \u00f6\u00f1\u00d7 \u00f3 \u00f1 \u00f9\u00f1 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f2 \u00f8 \u00d7 \u00d7 \u00f2 \u00f6 \u00f3\u00d7\u00ba \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00e8 \u00f8\u00d7\u00bb\u00d7 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u00bc\u00be\u00ba\u00bd\u00bd \u00ba \u00e5 \u00f4\u00d7 \u00be\u00bd \u00ba\u00bc\u00be \u00be\u00bd \u00ba \u00be\u00bd \u00ba\u00bd \u2104 \u00be \u00ba \u00be \u00ba\u00bf \u00be \u00bc\u00ba\u00be \u2104 \u00bc\u00ba \u00be \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be\u00bd\u00bd\u00bd\u00ba \u00be\u00bc \u00ba \u00be\u00bd\u00be\u00bf\u00ba \u00bd\u2104 \u00be \u00ba\u00bf \u00be \u00bf\u00ba\u00be\u00bd \u00be \u00ba \u2104 \u00ec\u00f3\u00f8 \u00f0 \u00be \u00ba \u00bd \u00be \u00bc\u00ba \u00bf \u00be \u00ba\u00bd\u00bc\u2104 \u00be\u00bf\u00ba\u00bd\u00bf \u00be\u00be\u00ba\u00bd\u00be \u00be \u00ba\u00bd \u2104 \u00e8 \u00eb \u00ba \u00e5 \u00f4\u00d7 \u00bd \u00ba \u00bd \u00bd\u00ba\u00be\u00bf \u00bd \u00ba \u2104 \u00be\u00bd \u00ba \u00be\u00bd \u00ba \u00bf \u00be\u00bd \u00ba \u2104 \u00bc\u00ba \u00be \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00bf\u00ba\u00bc \u00be \u00be \u00ba \u00be \u00be \u00ba\u00bf\u00be\u2104 \u00bf \u00bc\u00ba \u00bf \u00ba \u00bc \u00bf \u00be\u00ba \u00bf\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bd\u00be\u00ba \u00bc\u00bf\u00ba\u00bc\u00be \u00be\u00be\u00ba \u00bd\u2104 \u00ba \u00ba\u00bf \u00ba \u2104 \u00ec \u00f0 \u00bf \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4\u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7\u00b5 \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00e8 \u00f8\u00d7\u00bb\u00d7 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u00bc\u00be\u00ba\u00bd\u00bd \u00be\u00e5 \u00f4\u00d7 \u00bd\u00be \u00bc\u00ba \u00bf \u00bd\u00be\u00bf \u00ba\u00bc\u00bf \u00bd\u00be \u00ba \u2104 \u00bd \u00be\u00ba\u00bc \u00bd \u00bd\u00ba \u00bd \u00be\u00ba \u2104 \u00bc\u00ba \u00bf \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bd\u00be\u00bd \u00ba \u00bd\u00be\u00bc\u00bf\u00ba \u00bd\u00be\u00bf \u00ba\u00bf \u2104 \u00bd \u00ba \u00bc \u00bd \u00ba \u00bd \u00bd\u00ba \u00bd\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00be \u00bc\u00ba \u00bd \u00be \u00ba\u00bc \u00be \u00ba \u2104 \u00bf\u00bc\u00bd\u00ba \u00be \u00ba \u00bf\u00bc\u00bf\u00ba\u00be \u2104 \u00e8 \u00eb \u00be\u00e5 \u00f4\u00d7 \u00bd \u00ba \u00bd \u00bd\u00bd\u00ba\u00bd \u00be\u00bd\u00ba \u00bf\u2104 \u00bd\u00bc\u00bc\u00ba\u00bc \u00ba \u00bd \u00bd\u00bc\u00bc\u00ba \u00bd\u2104 \u00bc\u00ba \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bf\u00bc \u00ba \u00bf\u00bc\u00be\u00bf\u00ba\u00bd\u00bf \u00bf\u00bc \u00bc\u00ba \u00be\u2104 \u00bf \u00bf\u00ba\u00bf \u00bf \u00bc\u00ba \u00bf \u00ba\u00bf\u00bc\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bf \u00bf\u00ba\u00bf \u00bf \u00bf\u00ba\u00bd \u00bf \u00bf\u00ba \u2104 \u00bf\u00ba \u00bc\u00ba \u00ba \u00bf\u2104 \u00ec \u00f0 \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4\u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7\u00b5 \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00e8 \u00f8\u00d7\u00bb\u00d7 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u00bc\u00be\u00ba\u00bd\u00bd \u00bd\u00e5 \u00f4\u00d7 \u00bc\u00ba \u00bc \u00bf \u00ba\u00bf\u00bd \u00bf\u00ba \u2104 \u00bc\u00ba \u00bc\u00ba\u00bf \u00bd\u00ba\u00bd \u2104 \u00bc\u00ba \u00bf \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00ba \u00bd\u00bc\u00ba \u00be\u00ba\u00be \u2104 \u00ba\u00bc\u00bf \u00ba\u00bc \u00bc\u00ba \u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bd \u00ba\u00bc \u00bd \u00be\u00ba\u00bd \u00bd \u00bd\u00ba \u2104 \u00bd \u00ba \u00bd \u00ba \u00bd \u00bd\u00ba \u00bd\u2104 \u00e8 \u00eb \u00bd\u00e5 \u00f4\u00d7 \u00bd\u00ba \u00bd \u00ba \u00ba\u00bd \u2104 \u00ba \u00ba\u00bc \u00ba\u00bd\u00bf\u2104 \u00bc\u00ba \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00bd\u00ba\u00bf\u00be \u00be \u00bd\u00bc\u00ba \u00bd \u00be \u00bd\u00ba \u00bf\u2104 \u00bf \u00bc\u00ba \u00bf \u00ba \u00be \u00bf \u00ba\u00bd \u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bf \u00bc\u00bf\u00ba\u00bd\u00bf \u00bf\u00bf \u00ba \u00bd \u00bf \u00bf\u00bc\u00ba \u2104 \u00bd \u00ba\u00bc \u00bd\u00bf\u00ba \u00be\u00bc\u00ba \u2104 \u00ec \u00f0 \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4\u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7\u00b5 \u00e1ae\u00ea\u00e1 \u00e8 \u00eb \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00eb\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00bd \u00ec \u00f6 \u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4\u00ec \u00f0 \u00bd\u00b5 \u00f2 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00fc\u00f4\u00f0 \u00f2 \u00fd \u00f8 \u00f3 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00e1 \u00bc\u00be\u00ba\u00bd\u00bd \u00e5 \u00ba \u00e1\u00f2 \u00b8\u00f8 \u00f3 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f6\u00f3\u00fa \u00ec \u00e5 \u00b9\u00f0 \u00d7\u00d7 \u00f8\u00f3 \u00f8 \u00f1 \u00f9\u00f1\u00ba \u00ef \u00f2 \u00f8 \u00f6 \u00f6 \u00f3\u00f2\u00f0\u00fd \u00f8\u00fb\u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7\u00b8 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f2 \u00d7\u00d7 \u00d7\u00f9 \u00d7\u00d7 \u00fa \u00f0\u00fd \u00f8 \u00f1 \u00f9\u00f1\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f3 \u00e8 \u00eb\u00b8\u00f8 \u00d7\u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00fb \u00f0\u00f0 \u00f6\u00d7\u00f8 \u00f6 \u00f8 \u00f8\u00d7 \u00f4 \u00f8\u00d7 \u00f9\u00f6 \u00f2 \u00f8\u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00d7\u00d7 \u00f3\u00f2 \u00f8 \u00f1 \u00f2 \u00fb \u00f2 \u00f8\u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00d7\u00d7 \u00f3\u00f2 \u00f8 \u00f1 \u00f0 \u00f4\u00d7 \u00d7\u00b8 \u00f8 \u00fb \u00f0\u00f0 \u00d7 \u00f2 \u00f8\u00d7 \u00f4 \u00f8\u00d7 \u00f0 \u00d7\u00d7 \u00f0\u00f0\u00fd \u00fb \u00f8 \u00e1 \u00bc\u00be\u00ba\u00bd\u00bd \u00f8 \u00d7\u00d7 \u00d7 \u00d7\u00f9 \u00d7\u00d7 \u00fa \u00f0\u00fd \u00f8\u00f3 \u00f8 \u00f1 \u00f9\u00f1\u00ba \u00ec \u00f6 \u00f3\u00f6 \u00b8\u00f8 \u00d7 \u00f8\u00f9\u00f6 \u00f3 \u00e8 \u00eb \u00f6 \u00f9 \u00d7 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f3 \u00f8 \u00d7\u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f9\u00d7 \u00f8 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f0\u00fb \u00fd\u00d7 \u00f6 \u00f8 \u00f8\u00d7 \u00f4 \u00f8\u00d7\u00ba \u00ec \u00d7 \u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f2 \u00fb\u00f3\u00f6\u00d7 \u00f2 \u00fb \u00f2 \u00f8 \u00d7\u00f0\u00f3\u00fb \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f2 \u00d7 \u00f0\u00d7\u00f3 \u00d7\u00f9 \u00d7\u00d7 \u00fa \u00f4 \u00f8\u00d7\u00ba \u00ec \u00f6 \u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f2 \u00f0\u00fd\u00f8 \u00f0 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2\u00f6 \u00d7 \u00d7 \u00fb \u00f2 \u00f8 \u00f6 \u00f2 \u00f2 \u00f8 \u00f8 \u00f6 \u00f8 \u00f3 \u00f8 \u00f8\u00fb\u00f3 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f2\u00f6 \u00d7 \u00d7\u00ba \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00e8 \u00f8\u00d7\u00bb\u00d7 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u00bc\u00be\u00ba\u00bd\u00bd \u00bd\u00e5 \u00f4\u00d7 \u00be\u00bf\u00ba\u00bc \u00bd \u00ba \u00bf\u00bc\u00ba \u2104 \u00bd\u00ba \u00bc\u00ba \u00be\u00ba \u2104 \u00bc\u00ba \u00bc \u00be\u00e5 \u00f4\u00d7 \u00bd\u00bf\u00ba \u00bc\u00bf\u00ba \u00be\u00bf\u00ba \u00bc\u2104 \u00bc\u00ba \u00bc \u00ba \u00bd\u00ba \u00bc\u2104 \u00ba \u00e5 \u00f4\u00d7 \u00bc\u00bd\u00ba \u00bc \u00bf \u00ba \u00bd\u00bf\u00ba \u2104 \u00ba\u00be \u00ba \u00bc\u00ba \u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bf \u00be\u00ba\u00bc \u00bf \u00ba \u00bf \u00bc \u00ba\u00be \u2104 \u00ba\u00bc \u00ba \u00ba \u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bd \u00bf\u00bc\u00ba \u00bd \u00bd \u00ba\u00be \u00bd \u00ba\u00bc \u2104 \u00bd \u00ba \u00bd \u00ba \u00bf \u00be\u00bc\u00bd\u00ba \u2104 \u00e8 \u00eb \u00bd\u00e5 \u00f4\u00d7 \u00be\u00bf \u00ba\u00bc\u00be \u00be\u00bf\u00bc\u00ba\u00bd\u00bc \u00be \u00bd\u00ba \u2104 \u00be \u00ba \u00be \u00be \u00ba\u00be\u00bc \u00be \u00ba \u2104 \u00bc\u00ba \u00be \u00bf \u00be\u00e5 \u00f4\u00d7 \u00bf \u00ba \u00bd \u00bf \u00ba\u00bd \u00bf \u00ba \u00be\u2104 \u00ba\u00bd \u00ba \u00ba \u2104 \u00ba \u00e5 \u00f4\u00d7 \u00bf\u00ba\u00be \u00bd \u00ba \u00bf \u00ba \u2104 \u00bd\u00bd \u00ba \u00bd\u00bd\u00be\u00ba \u00bd\u00bd \u00ba \u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bd \u00ba \u00bd \u00bf\u00ba \u00be \u00bd \u00ba \u2104 \u00bd \u00bf\u00ba \u00bd \u00ba\u00bd \u00bd \u00ba \u00bd\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bf\u00bc \u00ba \u00bf\u00bc\u00be\u00bd\u00ba\u00bf \u00bf\u00bc \u00bc\u00ba\u00bd \u2104 \u00bf \u00ba \u00bf \u00bc\u00ba\u00be \u00bf \u00ba \u00bc\u2104 \u00ec \u00f0 \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4\u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7\u00b5 \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00e8 \u00f8\u00d7\u00bb\u00d7 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u00bc\u00be\u00ba\u00bd\u00bd \u00bd\u00e5 \u00f4\u00d7 \u00be \u00bc\u00ba \u00bd \u00be \u00bd\u00ba \u00be \u00ba \u00bf\u2104 \u00bf\u00bd\u00ba \u00bf\u00bc\u00ba \u00bf \u00bf\u00bf\u00ba\u00bc \u2104 \u00bc\u00ba \u00be\u00be\u00be \u00bd\u00bd \u00bd\u00e5 \u00f4\u00d7 \u00be \u00bf\u00ba \u00be \u00ba \u00be \u00be\u00ba \u00be\u2104 \u00bf\u00bd\u00ba\u00bc \u00bf\u00bc\u00ba\u00bc\u00bd \u00bf\u00be\u00ba\u00bd \u2104 \u00bd\u00e5 \u00f4\u00d7 \u00be \u00ba\u00bf \u00be \u00bc\u00ba \u00be \u00ba \u2104 \u00bf\u00bd\u00ba \u00bf\u00bc\u00ba \u00bf \u00bf\u00be\u00ba \u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00be \u00ba\u00be\u00bd \u00be \u00ba\u00be \u00be \u00ba\u00bd \u2104 \u00bf\u00be\u00ba \u00bf\u00bd\u00ba \u00bc \u00bf \u00ba\u00bc \u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bd\u00bc \u00bc\u00ba \u00bd\u00bc\u00bf\u00bc\u00ba \u00bd \u00bd\u00bc \u00bd\u00ba\u00bd\u00bf\u2104 \u00bd\u00be \u00ba \u00bd\u00be \u00ba\u00bf\u00be \u00bd\u00be \u00ba \u00bd\u2104 \u00e8 \u00eb \u00bd\u00e5 \u00f4\u00d7 \u00be\u00bd\u00bf\u00ba \u00bc \u00be\u00bc \u00ba \u00be\u00be\u00bc\u00ba \u2104 \u00be \u00ba\u00bd \u00be \u00ba\u00bf\u00bd \u00be \u00ba\u00bc\u00be\u2104 \u00bc\u00ba \u00bc\u00be\u00be \u00bd\u00e5 \u00f4\u00d7 \u00be\u00bd\u00bc\u00ba\u00bf\u00bc \u00be\u00bc\u00be\u00ba \u00be \u00be\u00bd \u00ba \u2104 \u00be \u00ba \u00be \u00ba \u00be \u00ba \u00bc\u2104 \u00bd\u00e5 \u00f4\u00d7 \u00be\u00bc\u00be\u00ba \u00bd \u00bf\u00ba\u00be \u00be\u00bd\u00bd\u00ba \u00bd\u2104 \u00be \u00ba \u00bd \u00be\u00bf\u00ba \u00be \u00ba \u00bf\u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bd \u00bc\u00ba \u00bd \u00ba \u00bf \u00bd \u00be\u00ba\u00be \u2104 \u00bd \u00ba \u00bc \u00bd \u00be\u00ba \u00bd \u00ba\u00bd\u00bf\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00be\u00bd \u00ba \u00be\u00bd\u00be\u00bc\u00ba \u00be\u00be\u00bd\u00be\u00ba \u00bd\u2104 \u00be \u00ba \u00be \u00ba \u00be \u00be \u00bd\u00ba\u00bd \u2104 \u00ec \u00f0 \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4\u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7\u00b5 \u00ea\u00ea \u00f2 \u00bc\u00bd\u00be\u00bf \u00bd \u00ea \u00fe \u00f2 \u00f6 \u00f0 \u00f1 \u00f3\u00b8 \u00f9 \u00f6 \u00f2\u00b9\u00f0 \u00d7\u00d7\u00f3\u00f9\u00d7\u00b8\u00e1 \u00f2\u00f2\u00f3\u00f2 \u00b8 \u00ec \u00ba \u00b4 \u00f4\u00d7\u00b5 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00e8 \u00f8\u00d7\u00bb\u00d7 \u00f3\u00f2 \u00ba \u00e1\u00f2\u00f8\u00ba \u00b4\u00bc\u00ba\u00bc \u00b5 \u00f6\u00f2 \u00d7\u00d7 \u00f2 \u00fc \u00bc\u00be\u00ba\u00bd\u00bd \u00bd\u00e5 \u00f4\u00d7 \u00bf\u00bf\u00bc\u00ba \u00bf \u00bf\u00be\u00bc\u00ba \u00bf \u00bc\u00ba \u00bd\u2104 \u00bc\u00ba \u00bd \u00bf \u00ba\u00be \u00bd\u00ba \u2104 \u00bc\u00ba \u00be\u00be\u00be\u00bd \u00bd\u00e5 \u00f4\u00d7 \u00bf \u00ba \u00bd \u00bf\u00bf \u00ba\u00bf\u00be \u00bf \u00ba \u00bc\u2104 \u00be\u00ba\u00bf \u00bd\u00ba\u00be\u00be \u00bf\u00ba \u2104 \u00ba \u00e5 \u00f4\u00d7 \u00bf \u00bd\u00ba \u00bf\u00be \u00ba \u00bf \u00ba\u00bd\u00bf\u2104 \u00bd\u00ba \u00bc \u00bc\u00ba\u00be \u00bf\u00ba \u00be\u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bf\u00bf\u00be\u00ba \u00bc \u00bf\u00bd \u00ba \u00bf \u00ba\u00be\u00bc\u2104 \u00bc\u00ba \u00bf \u00ba\u00be\u00bd \u00be\u00ba\u00bf\u00bc\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00bd\u00bf \u00bc\u00ba \u00bf \u00bd\u00bf\u00bf \u00ba \u00bd\u00bf \u00ba \u00bf\u2104 \u00bd \u00ba \u00bd \u00bd \u00bf\u00ba \u00bd \u00ba\u00bf\u00bf\u2104 \u00e8 \u00eb \u00bd\u00e5 \u00f4\u00d7 \u00be\u00bc \u00ba\u00bd\u00bf \u00be\u00bc\u00bd\u00ba \u00be\u00bd \u00ba \u00be\u2104 \u00be \u00ba \u00bd \u00be \u00ba \u00bc \u00be \u00ba\u00bf\u00bd\u2104 \u00bc\u00ba \u00bd \u00bd\u00e5 \u00f4\u00d7 \u00be\u00bd \u00ba\u00be\u00bf \u00be\u00bc \u00ba\u00bd\u00bc \u00be\u00be\u00bc\u00ba\u00bf \u2104 \u00be \u00ba\u00be \u00be \u00ba \u00bc \u00be \u00ba\u00bc\u00bc\u2104 \u00ba \u00e5 \u00f4\u00d7 \u00ba \u00be\u00be\u00ba \u00be \u00ba\u00bf\u00bd\u2104 \u00bd\u00bd \u00ba \u00bd \u00bd\u00bd\u00bf\u00ba\u00bc \u00bd\u00bd \u00ba \u2104 \u00bd\u00bd\u00e5 \u00f4\u00d7 \u00bd \u00bd\u00bc\u00ba\u00bf\u00be \u00bd \u00ba\u00bc \u00bd \u00ba \u2104 \u00bd \u00ba\u00bc \u00bd \u00ba \u00bd \u00bc\u00ba \u00bf\u2104 \u00ec\u00f3\u00f8 \u00f0 \u00be \u00be\u00ba \u00be \u00ba \u00be \u00bd \u00ba\u00be\u00bd\u2104 \u00bf \u00bf\u00ba\u00be \u00bf \u00ba\u00bd\u00bf \u00bf \u00ba\u00bf \u2104 \u00ec \u00f0 \u00e8 \u00f6 \u00f3\u00f6\u00f1 \u00f2 \u00f2\u00f3\u00f1 \u00f0\u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4\u00f8 \u00f6\u00f3\u00f9 \u00f4\u00f9\u00f8 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4 \u00f8\u00d7\u00b5 \u00ec \u00f0 \u00d7 \u00b8 \u00f2 \u00d7 \u00f3\u00fb \u00f8 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00fb \u00f8 \u00f3\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f1 \u00f8\u00f8 \u00f2 \u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd \u00f8 {1, 2, 5",
        "prob": 0.8033333333333332
    }, {
        "ID": 7362,
        "phrase": " , h l } \u00f2 \u00f2 \u00f6\u00f6 \u00f2\u00d7\u00f8 \u00f3 \u00d7 \u00f2 \u00f0 \u00f8\u00f3\u00f1 h\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00d7\u00d7 \u00f6\u00fd \u00f8\u00f3 \u00f2 \u00f6 \u00f2\u00fd \u00f3 \u00f8 \u00f8\u00f3\u00f1\u00d7\u00ba \u2022 \u00fb \u00f8 \u00f6\u00f9\u00f0 \u00b4 \u00b5 \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00d7\u00f9\u00f1\u00f1 \u00f2 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8 \u00fb \u00f8 w ai \u00b4\u00f6 \u00d7\u00f4\u00ba w bj \u00b5 \u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00d7\u00f9\u00f1\u00f1 \u00f2 \u00d7 \u00f2 \u00f3\u00f2\u00f0\u00fd a i \u00d7 \u00f2 \u00f6 \u00f0 \u00b4\u00f6 \u00d7\u00f4\u00ba b j \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00f6 \u00f0 \u00b5\u00ba \u00ec h \u00f2 \u00f2 \u00f6\u00f6 \u00d7\u00f9 \u00d7\u00f9\u00f1 \u00f3 \u00fb \u00f8\u00d7 \u00d7 \u00f8 \u00f0 \u00d7\u00f8 w\u00ba \u2022 \u00ec \u00f9\u00f0\u00f8 \u00f0 \u00f8 \u00f6 \u00f0\u00d7 \u00f2\u00fa\u00f3\u00f0\u00fa \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00d7\u00f8 \u00f8 \u00f1 \u00f2\u00f8 \u00b4 \u00b5 \u00f8 \u00d7 \u00f6 \u00f8 \u00f3\u00f2\u00b9 \u00d7\u00f8\u00f6 \u00f2\u00f8\u00d7 \u00d7 \u00fd \u00f2 \u00f8 \u00f8 \u00f8 \u00f8\u00f3\u00f1\u00d7 a 1 , ",
        "prob": 0.18333333333333335
    }, {
        "ID": 7362,
        "phrase": " ,c r \u2208 p \u00f2 \u00f8\u00d7 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 \u00f9\u00f2 \u00f6 tr sns \u00d7 \u00fa \u00f2 \u00f2 \u00f2 \u00f8 \u00f3\u00f2 \u00ba \u00ba \u00eb \u00f2 hb v (tr sns (p )) = hb v (p ) \u00fd \u00f2 \u00f8 \u00f3\u00f2 \u00f2 i = i v \u00b8\u00f8 \u00f6\u00f9\u00f0 \u00d7 \u00f2\u00fa\u00f3\u00f0\u00fa \u00f2 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f8\u00f3 p h /i v \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00b4\u00bd \u00b5 \u00d7 \u00f6 \u00f9 \u00f8\u00f3 sat(c i ) \u2190 l \u2032 i \u2264 {} \u00fb \u00f6 l \u2032 i = max(0, l i \u2212 w i ) \u00f3\u00f6 w i = ws iv (a i = w ai , \u223cb i = w bi ) \u00b4\u00bd \u00b5 \u00d7 \u00f6 \u00f9 \u00f8\u00f3 unsat(c i ) \u2190 u \u2032 i \u2264 {} \u00fb \u00f6 u \u2032 i = max(0, (u i + 1) \u2212 w i ) \u00b4\u00bd \u00b5 \u00d7 \u00f6\u00f3\u00f4\u00f4 \u00f0\u00f8\u00f3 \u00f8 \u00f6 \u00d7 (a 0 ) h = \u2205 \u00b4\u00bd \u00b5 \u00f2 \u00b4\u00bd \u00b5 \u00f6 \u00f1 \u00f2 \u00f2\u00f8 \u00f8 \u00f9\u00d7 \u00f8 \u00fd \u00f2\u00fa\u00f3\u00f0\u00fa \u00f3\u00f2\u00f0\u00fd \u00f2 \u00f8\u00f3\u00f1\u00d7 \u00f2 \u00b4\u00bd \u00b5 \u00d7 \u00f6\u00f3\u00f4\u00f4 \u00fd \u00f2 \u00f8 \u00f3\u00f2\u00ba \u00e4 \u00f8 \u00f9\u00d7 \u00f8 \u00f2 \u00fa \u00f6 \u00fd \u00f8 \u00f8 tr sns (p ) h /i v \u00d7 \u00d7\u00f8\u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00ba \u00f8 \u00f6 \u00f2\u00d7\u00f4 \u00f8 \u00f2 \u00f8 \u00ec \u00f3\u00f6\u00fd \u00f2 \u00e8\u00f6 \u00f8 \u00f3 \u00e4\u00f3 \u00e8\u00f6\u00f3 \u00f6 \u00f1\u00f1 \u00f2 \u00be \u00f4 \u00f2 \u00f2 \u00d7 \u00f2 \u00f8 \u00f6 \u00f9 \u00f6\u00f9\u00f0 \u00d7\u00b8\u00fb \u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f2 \u00f8\u00f3\u00f1\u00d7 \u00f2 hb(tr sns (p )) \u00f2 \u00d7\u00d7 \u00f2 \u00f8\u00f3 \u00d7\u00f8\u00f6 \u00f8 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8 \u00f8\u00f3\u00f1\u00d7 sat(c) \u00f2 unsat(c) \u00d7\u00d7\u00f3 \u00f8 \u00fb \u00f8 \u00fb \u00f8 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2\u00f8\u00d7 c \u00f0\u00f3\u00f2 \u00f8\u00f3 \u00d7\u00f8\u00f6 \u00f8\u00f9\u00f1 \u00bc \u00f2 f \u00f0\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00d7\u00f8\u00f6 \u00f8\u00f9\u00f1 1\u00ba \u00ec \u00f9\u00d7 tr sns (p ) \u00d7 \u00d7\u00d7 \u00f2\u00f8 \u00f0\u00f0\u00fd \u00d7\u00f8\u00f6 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00d7 \u00f8 \u00f6 \u00f1 \u00f2 \u00f6\u00d7 \u00f3 \u00fb \u00f8 \u00f6\u00f9\u00f0 \u00d7 \u00f8 \u00d7 \u00f8\u00d7\u00ba \u00ec \u00f2 tr sns (p ) \u00d7 \u00f9\u00f2 \u00f5\u00f9 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0 \u00b4 \u00f4\u00f8 \u00f8 \u00f0\u00ba \u00bd \u00b5\u00ba \u00fd \u00f2\u00fd \u00f2 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00d7 \u00f3 \u00f2 \u00f8\u00f3\u00f1\u00d7 \u00f2 \u00fb \u00f8 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7\u00b8\u00fb \u00f3 \u00f8 \u00f2 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2\u00b9 \u00d7 \u00f1 \u00f8 \u00f3 \u00f3\u00f6 \u00fa \u00f6 \u00fd \u00f2 \u00fb \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f6 \u00f5\u00f9 \u00f6 \u00b9 \u00f1 \u00f2\u00f8 hb v (p ) = hb v (q)\u00b8 \u00ba \u00ba\u00b8hb(p ) = hb(q) \u00f2 \u00f8 \u00d7 \u00d7 \u00b8 \u00f2 \u00d7 \u00f0\u00fd \u00f1 \u00f8 \u00fd \u00fc\u00f8 \u00f2 \u00f2 \u00f8 \u00e0 \u00f6 \u00f6 \u00f2 \u00d7 \u00d7 \u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba \u00f3\u00f6\u00f3\u00f0\u00f0 \u00f6\u00fd \u00ba\u00bd\u00bf \u00e4 \u00f8 p \u00f2 q \u00f8\u00fb\u00f3 \u00fb \u00f8 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00d7\u00f9 \u00f8 \u00f8 hb h (p ) = hb h (q) = \u2205 \u00f2 hb v (p ) = hb v (q)\u00ba \u00ec \u00f2 p \u2261 q \u21d0\u21d2 tr sns (p ) \u2261 v tr sns (q) \u21d0\u21d2 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2\u00d7 eqt(tr sns (p ), tr sns (q)) \u00f2 eqt(tr sns (q), tr sns (p )) \u00fa \u00f2\u00f3 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7\u00ba \u00e1\u00f8 \u00d7 \u00f1\u00d7 \u00f8 \u00f8 \u00f2 \u00f8\u00f3\u00f1\u00d7 \u00f2 \u00f8\u00f3\u00f0 \u00f6 \u00f8 \u00f2 \u00fb \u00f8 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f8\u00f3 \u00d7\u00f3\u00f1 \u00f6 \u00b8 \u00f9\u00f8 \u00fb \u00d7 \u00f4 \u00d7\u00f9 \u00f2 \u00fc\u00f8 \u00f2\u00d7 \u00f3\u00f2 \u00f3 \u00f3\u00f6\u00f3\u00f0\u00f0 \u00f6\u00fd \u00ba\u00bd\u00bf \u00f3\u00f6 \u00d7\u00f4 \u00f6 \u00d7\u00f3\u00f2\u00d7\u00ba ae \u00fa \u00f6\u00f8 \u00f0 \u00d7\u00d7\u00b8\u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7\u00f8 \u00f0 \u00d7 \u00f3\u00fa \u00f2 \u00f0 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00fa \u00f6 \u00f8 \u00f3\u00f2 \u00f3 \u00fb \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00f3\u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f4\u00f6\u00f3 \u00f9 \u00fd \u00f0\u00f4 \u00f6\u00d7 \u00ba \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00ec \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 \u00f9\u00f2\u00f8 \u00f3\u00f2 eqt \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00d7 \u00f2 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f2 \u00f9\u00f2 \u00f6 \u00f8 \u00e4 \u00f2\u00f9\u00fc \u00f3\u00f4 \u00f6 \u00f8 \u00f2 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00ba \u00ec \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8\u00f3\u00f6 \u00fb \u00fb \u00fa \u00f2 \u00f1 \u00f0\u00f4 \u00f5 \u00f8 \u00d7 \u00f8\u00fb\u00f3 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 p \u00f2 q \u00d7 \u00f8\u00d7 \u00f2\u00f4\u00f9\u00f8 \u00f2 \u00f4\u00f6\u00f3 \u00f9 \u00d7 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 eqt(p, q) \u00d7 \u00f8\u00d7 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8\u00ba \u00ec \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00d7\u00d7\u00f9\u00f1 \u00d7 \u00f8 \u00f2\u00f8 \u00f6\u00f2 \u00f0 \u00f0 \u00f3\u00f6\u00f1 \u00f8 \u00f3 \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00fb \u00f2 \u00f0 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f9\u00d7 \u00f8 \u00f6\u00f3\u00f2\u00f8\u00b9 \u00f2 \u00f0\u00f4 \u00f6\u00d7 \u00f3 \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00f2 \u00f3\u00f2 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00f0\u00f4 \u00f5\u00ba 9 \u00e1\u00f8 \u00d7 \u00fd \u00f8 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00f8\u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f0\u00f4 \u00f5 \u00d7 \u00f8 \u00f8 \u00f8 \u00fa \u00d7 \u00f0 \u00e0 \u00f6 \u00f6 \u00f2 \u00d7 \u00d7 \u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f2 \u00f3\u00f1\u00f4 \u00f6 \u00f6 \u00fc \u00f8\u00f0\u00fd \u00f8 \u00d7 \u00f1 \u00d7 \u00f2\u00d7 \u00d7\u00f8 \u00fd \u2261 v \u00ba \u00e1\u00f2 \u00f4\u00f6 \u00f8 \u00b8\u00fa \u00d7 \u00f0 \u00f8\u00f3\u00f1\u00d7 \u00f6 \u00f6 \u00f3 \u00f2 \u00fe \u00d7 \u00f8 \u00f3\u00d7 \u00fa \u00f2 \u00f2 \u00f1 \u00f2 \u00f8 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f8 \u00f0 \u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00ba \u00ec \u00f0 \u00f8 \u00d7\u00f8 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 \u00f0\u00f4 \u00f5 \u00d7 \u00f0\u00d7\u00f3 \u00f4\u00f6 \u00f4 \u00f6 \u00f8\u00f3 \u00f0 \u00fb \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f2\u00fa\u00f3\u00f0\u00fa \u00f2 \u00f2\u00fa \u00d7 \u00f0 \u00f8\u00f3\u00f1\u00d7\u00b8 \u00ba \u00ba\u00b8 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00fd \u00f8 \u00f6\u00f3\u00f2\u00f8\u00b9 \u00f2 \u00f0\u00f4 \u00f6\u00d7 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00ba \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f9 \u00f2 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 eqt(p, q)\u00b8\u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8\u00f3\u00f6 \u00f9\u00d7 \u00d7 \u00ec \u00f6 \u00f2\u00b3\u00d7 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f8\u00f3 \u00f2 \u00d7\u00f8\u00f6\u00f3\u00f2 \u00f0\u00fd \u00f3\u00f2\u00f2 \u00f8 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00f3\u00f6 \u00f8 \u00f4 \u00f2 \u00f2\u00fd \u00f6 \u00f4 \u00f3 q h \u00fb \u00f2 \u00f8\u00d7 \u00d7 \u00f8 \u00f8 q h /i v \u00d7 \u00d7\u00f8\u00f6 \u00f8 \u00f0 \u00f3\u00f6 \u00f0\u00f0 i v \u2286 hb v (q)\u00ba \u00f2 \u00f3\u00fa \u00f6 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f3\u00f2 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00d7 \u00f6 \u00d7\u00f4 \u00f8 \u00f0\u00f0 \u00f4 \u00f2 \u00f2 \u00d7 \u00f3 \u00f2\u00fa \u00d7 \u00f0 \u00f8\u00f3\u00f1\u00d7 \u00f6 \u00f8 \u00f2 \u00f2\u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8 \u00f6 \u00f6 \u00f0 \u00d7\u00d7 \u00f3 i v \u00ba \u00d7\u00f9 \u00d7\u00d7 \u00f9\u00f0 \u00f8 \u00d7\u00f8 \u00f9 \u00f6 \u00f2\u00f8 \u00d7 \u00f8 \u00f8 q \u00d7 \u00f2\u00f3\u00f9 \u00fa \u00d7 \u00f0 \u00f8\u00f3\u00f1\u00d7 \u00d7\u00f3 \u00f8 \u00f8 eqt(p, q) \u00fb\u00f3\u00f6 \u00d7 \u00f3\u00f6\u00f6 \u00f8\u00f0\u00fd\u00ba \u00e7\u00f8 \u00f6\u00fb \u00d7 \u00b8 \u00f2 \u00f6\u00f6\u00f3\u00f6 \u00f1 \u00d7\u00d7 \u00d7 \u00f4\u00f6 \u00f2\u00f8 \u00f3\u00f6 \u00f8 \u00f9\u00d7 \u00f6\u00ba \u00ec \u00f9\u00f6\u00f6 \u00f2\u00f8 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00b4\u00f0\u00f4 \u00f5 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00bd\u00ba\u00bd \u00b5 \u00d7 \u00fa \u00f0 \u00f0 10 \u00f2 \u00f8 \u00ef\u00ef\u00ef\u00ba \u00ec \u00f0 \u00d7 \u00f6 \u00f0 \u00f8 \u00fb \u00f8 \u00f2 \u00f1 \u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00d7 \u00f2 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f6 \u00f4\u00f3\u00f6\u00f8 \u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f6 \u00f0\u00d7\u00f3 \u00f4\u00f6\u00f3\u00fa \u00ba \u00ec\u00f3 \u00d7\u00d7 \u00d7\u00d7 \u00f8 \u00d7 \u00f0 \u00f8\u00fd \u00f3 \u00f0\u00f4 \u00f5 \u00f2 \u00f4\u00f6 \u00f8 \u00fb \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f2\u00f9\u00f1 \u00f6 9 \u00f8 \u00fc\u00f8\u00f9 \u00f0 \u00f9\u00f1 \u00f2\u00b9\u00f6 \u00f0 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f2 \u00f0\u00d7\u00f3 \u00f4\u00f6\u00f3 \u00f9 \u00f3\u00f2 \u00f6 \u00f5\u00f9 \u00d7\u00f8\u00ba 10 \u00e8\u00f0 \u00d7 \u00f3\u00f2\u00d7\u00f9\u00f0\u00f8 \u00f8\u00f8\u00f4 \u00bb\u00bb\u00fb\u00fb\u00fb\u00ba\u00f8\u00d7\u00ba \u00f9\u00f8\u00ba \u00bb\u00eb\u00f3 \u00f8\u00fb \u00f6 \u00bb\u00f0\u00f4 \u00f5\u00bb \u00f3\u00f6 \u00f2 \u00f6 \u00d7 \u00f2 \u00d7\u00f6 \u00f4\u00f8\u00d7 \u00f2\u00fa\u00f3\u00f0\u00fa \u00ba \u00bf\u00bc \u00ec\u00ba \u00e2 \u00f2 \u00f9\u00f2 \u00f2 \u00f2 \u00ba \u00e7 \u00f6 \u00f2 \u00f2 \u00b4 \u00b5 \u00e8\u00f0 \u00f5\u00f9 \u00f2 \u00f3\u00f2 \u00f3\u00f0\u00f9\u00f1\u00f2 \u00f2 \u00f5\u00b4 \u00b8 \u00be\u00b5 \u00b9 \u00f5\u00b4 \u00b8 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00be\u00b5\u00b8 \u00be \u00ba \u00f5\u00b4 \u00b8 \u00b5 \u00b9 \u00f2\u00f3\u00f8 \u00f2 \u00f5\u00b4 \u00b8 \u00b5\u00b8\u00f2\u00f3\u00f8 \u00f5\u00b4 \u00b8 \u00be\u00b5 \u00b4 \u00be\u00b5 \u00be \u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00ba \u00f2 \u00f5\u00b4 \u00b8 \u00b5\u00ba \u00b4 \u00b5 \u00e8\u00f0 \u00f5\u00f9 \u00f2 \u00f3\u00f2 \u00f3\u00f0\u00f9\u00f1\u00f2 \u00f9\u00d7 \u00f2 \u00f3 \u00f6\u00f9\u00f0 \u00bd \u00df \u00f5\u00b4 \u00b8 \u00b5 \u00b4 \u00b5 \u00bd \u00b9 \u00b4 \u00b5\u00ba \u00b4\u00b5 \u00e8\u00f0 \u00f5\u00f9 \u00f2 \u00f3\u00f2 \u00f6\u00f3\u00fb \u00f2 \u00f5\u00b4 \u00be\u00b8 \u00b5 \u00b9 \u00f5\u00b4 \u00b8 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00be\u00b5\u00b8 \u00be \u00ba \u00f5\u00b4 \u00b8 \u00b5 \u00b9 \u00f2\u00f3\u00f8 \u00f2 \u00f5\u00b4 \u00b8 \u00b5\u00b8\u00f2\u00f3\u00f8 \u00f5\u00b4 \u00be\u00b8 \u00b5 \u00b4 \u00be\u00b5 \u00be \u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00ba \u00f2 \u00f5\u00b4 \u00b8 \u00b5\u00ba \u00b4 \u00b5 \u00e5 \u00d7\u00f9\u00f6 \u00f8 \u00f8 \u00f5\u00f9 \u00f2\u00d7 \u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f6 \u00f8 \u00f2 \u00f3\u00f8 \u00f6 \u00b4\u00d7 \u00f1 \u00f6\u00f3\u00fb \u00f3\u00f6 \u00f3\u00f2 \u00f0\u00b5 \u00b9 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00bd\u00b5\u00b8\u00f5\u00b4 \u00b8 \u00b5\u00b8\u00f5\u00b4 \u00bd\u00b8 \u00b5\u00b8 \u00bd \u00ba \u00b9 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00bd\u00b5\u00b8 \u00b4 \u00bd\u00b5\u00b8\u00f5\u00b4 \u00b8 \u00b5\u00b8\u00f5\u00b4 \u00bd\u00b8 \u00bd\u00b5\u00b8 \u00bd\u00b8 \u00bd\u00b8 \u00d7\u00b4 \u00b9 \u00bd\u00b5 \u00d7\u00b4 \u00b9 \u00bd\u00b5\u00ba \u00b4\u00bd\u00ba\u00ba\u00f5\u00f9 \u00f2\u00d7\u00b5\u00ba \u00b4 \u00b5 \u00e5 \u00d7\u00f9\u00f6 \u00f8 \u00f8 \u00f5\u00f9 \u00f2\u00d7 \u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f6 \u00f8 \u00f2 \u00f3\u00f8 \u00f6 \u00b4\u00d7 \u00f1 \u00f3\u00f0\u00f9\u00f1\u00f2 \u00f3\u00f6 \u00f3\u00f2 \u00f0\u00b5 \u00b9 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00bd\u00b5\u00b8\u00f5\u00b4 \u00b8 \u00b5\u00b8\u00f5\u00b4 \u00b8 \u00bd\u00b5\u00b8 \u00bd \u00ba \u00b9 \u00b4 \u00b5\u00b8 \u00b4 \u00b5\u00b8 \u00b4 \u00bd\u00b5\u00b8 \u00b4 \u00bd\u00b5\u00b8\u00f5\u00b4 \u00b8 \u00b5\u00b8\u00f5\u00b4 \u00bd\u00b8 \u00bd\u00b5\u00b8 \u00bd\u00b8 \u00bd\u00b8 \u00d7\u00b4 \u00b9 \u00bd\u00b5 \u00d7\u00b4 \u00b9 \u00bd\u00b5\u00ba \u00b4\u00bd\u00ba\u00ba\u00f5\u00f9 \u00f2\u00d7\u00b5\u00ba \u00ba \u00bf\u00ba \u00f2\u00f3 \u00f2 \u00f8 n\u00b9\u00f5\u00f9 \u00f2\u00d7 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00ba \u00f3 \u00f8 \u00d7\u00f8\u00d7 \u00fb \u00f8 \u00f6 \u00f2\u00f8 \u00f8 \u00d7\u00f8 \u00d7 \u00d7\u00ba \u00ec \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f3 \u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00fb \u00f6 \u00f3\u00f1\u00f4 \u00f6 \u00fb \u00f8 \u00f8 \u00f3\u00d7 \u00f3 \u00f8 \u00f8 \u00f3\u00f9\u00d7 \u00f4\u00f4\u00f6\u00f3 \u00b8 \u00ba \u00ba\u00b8\u00f8 \u00f2 \u00fa \u00f3\u00f2 \u00bd\u00ba \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f3\u00f2 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0 m \u00f3 p \u00f2\u00f3\u00f8 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00d7\u00f3 \u00f6\u00ba \u00be\u00ba \u00fb \u00f8 \u00f6 q \u00d7 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0 n \u00d7\u00f9 \u00f8 \u00f8 m v = n v \u00ba \u00eb\u00f8\u00f3\u00f4 \u00f2\u00f3\u00f8\u00ba \u00bf\u00ba \u00f3\u00f2\u00f8 \u00f2\u00f9 \u00f6\u00f3\u00f1 \u00d7\u00f8 \u00f4 \u00bd \u00f9\u00f2\u00f8 \u00f0 \u00f0\u00f0 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3 p \u00fa \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f8 \u00ba \u00e1\u00f8 \u00d7 \u00f3 \u00fa \u00f3\u00f9\u00d7 \u00f8 \u00f8 \u00d7 \u00f1 \u00f0 \u00f6 \u00d7 \u00f8\u00f3 \u00f6\u00f6 \u00f3\u00f9\u00f8 \u00f2 \u00f8 \u00f3\u00f8 \u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00d7\u00f8 \u00f0 \u00d7 p \u2261 v q \u00f2 \u00f2 \u00f0\u00f3 \u00fd \u00f8\u00f3 \u00f3\u00f6\u00f3\u00f0\u00f0 \u00f6 \u00d7 \u00ba \u00f2 \u00ba\u00bd\u00bf\u00ba \u00ec \u00f6 \u00d7 \u00d7\u00f8 \u00f0\u00f0 \u00f6\u00f3\u00f3\u00f1 \u00f3\u00f6 \u00f3\u00f4\u00f8 \u00f1 \u00fe \u00f8 \u00f3\u00f2 \u00f2 \u00f3\u00f8 \u00f4\u00f4\u00f6\u00f3 \u00d7\u00ba \u00e1 \u00f3\u00f2 \u00f2 \u00d7 \u00f3\u00f9\u00f2\u00f8 \u00f6\u00b9 \u00fc \u00f1\u00f4\u00f0 \u00f2 \u00f3\u00f2 \u00f6 \u00f8 \u00f3\u00f2\u00b8\u00f8 \u00f2 p \u2261 v q \u00d7 \u00f2\u00f3\u00fb\u00f2 \u00f8\u00f3 \u00f3\u00f0 \u00f2 \u00f8 \u00f6 \u00d7 \u00f2\u00f3 \u00f2 \u00f8\u00f3 \u00f3 \u00f8 \u00d7\u00f8 \u00f2 \u00f2 \u00f8 \u00f3\u00f8 \u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00fc \u00f4\u00f8 \u00f3\u00f2 \u00fb \u00d7 \u00d7 \u00f8\u00f3 \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f6\u00f3\u00f9 \u00f2 \u00f0\u00fd\u00d7 \u00d7\u00ba \u00eb \u00f2 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00d7 \u00f1 \u00f8\u00f3 \u00d7 \u00f0 \u00f6 \u00f2\u00f8\u00f0\u00fd \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00fb \u00f3\u00f9\u00f2\u00f8 \u00f0\u00fb \u00fd\u00d7 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f2 \u00f3\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f3\u00f2 \u00d7 \u00f3\u00f9\u00f0 \u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f6 \u00f3\u00f6 \u00f3\u00f9\u00f2\u00f8 \u00f6\u00b9 \u00fc \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f3\u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00d7\u00f8\u00f3\u00f4\u00f4 \u00f1\u00f1 \u00f8 \u00f0\u00fd \u00f8 \u00f6 \u00f2 \u00f2 \u00f3\u00f9\u00f2\u00f8 \u00f6\u00b9 \u00fc \u00f1\u00f4\u00f0 \u00ba \u00eb \u00f2 \u00f8 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f3 \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00f1 \u00fd \u00f0\u00d7\u00f3 \u00f4 \u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f6 \u00f6 \u00f3 \u00f6\u00f9\u00f0 \u00d7 \u00f2 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f2 \u00f0 \u00f8 \u00f6 \u00f0\u00d7 \u00f2 \u00f6\u00f9\u00f0 \u00d7\u00b8\u00fb \u00d7 \u00f9 \u00f8 \u00f1 \u00f6 \u00f2 \u00f3\u00f1\u00f0\u00fd\u00ba \u00e1\u00f2 \u00f3\u00f8 \u00f4\u00f4\u00f6\u00f3 \u00d7\u00b8\u00f8 \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00d7\u00fd\u00d7\u00f8 \u00f1 \u00b4\u00fa \u00f6\u00d7 \u00f3\u00f2 \u00be\u00ba\u00be \u00b5 \u00d7 \u00f6 \u00d7\u00f4\u00f3\u00f2\u00d7 \u00f0 \u00f3\u00f6 \u00f8 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f8 \u00f8 \u00f6 \u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f8 \u00f9\u00d7 \u00f2 \u00f8 \u00f6\u00f3\u00f2\u00f8\u00b9 \u00f2 \u00f0\u00f4 \u00f6\u00d7 \u00b4\u00fa \u00f6\u00d7 \u00f3\u00f2 \u00bd\u00ba\u00bc\u00ba\u00bd\u00bf\u00b5\u00ba \u00e1\u00f2 \u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00b8\u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00f2 \u00f3\u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00f8 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00f2 \u00fd \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 \u00f8\u00f6\u00fd \u00f2 \u00f8\u00f3 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f3\u00f2 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00f9 \u00fd \u00f0\u00f4 \u00f5\u00ba \u00ec \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 \u00f8 \u00f1 \u00d7 \u00f0\u00d7\u00f3 \u00f8 \u00f2 \u00ec \u00f3\u00f6\u00fd \u00f2 \u00e8\u00f6 \u00f8 \u00f3 \u00e4\u00f3 \u00e8\u00f6\u00f3 \u00f6 \u00f1\u00f1 \u00f2 \u00bf\u00bd \u00ec \u00f0 \u00bd\u00ba \u00ea \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3\u00f6 \u00f8\u00fb\u00f3 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00b4n\u00b9\u00f5\u00f9 \u00f2\u00d7\u00b5\u00ba n \u00eb\u00e5 a tavg b tavg \u00ea \u00ea c \u00e8avg d \u00e8avg \u00ea\u00e1 e \u00ea\u00e7 f \u00f0\u00f4 \u00f5 \u00f2 \u00fa \u00f0\u00f4 \u00f5 \u00f2 \u00fa \u00bd \u00bd \u00bc\u00ba\u00bc\u00bc\u00bc \u00bc\u00ba\u00bc \u00bc \u00b9 \u00bc \u00bc \u00be \u00be \u00bc \u00bc\u00ba\u00bc\u00bc\u00bc \u00bc\u00ba\u00bc \u00bd \u00b9 \u00bc \u00bc \u00bf \u00bd\u00bf\u00bc \u00bf \u00bc \u00bc\u00ba\u00bc\u00bc\u00bf \u00bc\u00ba\u00bc \u00bd \u00bd \u00ba\u00bc\u00bc\u00bc \u00bc \u00bc \u00bd\u00be \u00bf \u00be \u00bc\u00ba\u00bc\u00bd \u00bc\u00ba\u00bd\u00be\u00bc \u00ba\u00bf\u00bd \u00bc \u00be \u00bf\u00bc\u00bc \u00bd\u00bc \u00bc\u00ba\u00bc \u00be \u00bc\u00ba \u00bd\u00bc\u00ba \u00bd\u00bc \u00bd \u00bc\u00bc \u00bd \u00bd \u00bc\u00ba\u00bd\u00bf \u00bc\u00ba\u00be \u00bd\u00ba \u00bc \u00bd \u00bd \u00bd\u00bc \u00be \u00bc \u00bc\u00ba \u00bd \u00be\u00ba\u00bf \u00bc \u00ba \u00bf \u00bc \u00bd \u00bc \u00bc \u00be \u00be\u00ba \u00ba \u00be\u00bd \u00be\u00ba\u00be \u00bd \u00bf \u00be \u00bf \u00be \u00bd\u00bc \u00bf \u00be \u00bd \u00ba\u00bf\u00bd \u00bf\u00be\u00ba\u00bc\u00bf\u00be \u00bd\u00ba \u00bc \u00bd \u00bf \u00be\u00bc \u00bd\u00bc\u00bd \u00bd\u00bc \u00be \u00ba \u00bc\u00ba \u00bc\u00ba \u00bc \u00be \u00bd\u00bf \u00bf\u00bd\u00be \u00bd \u00bc \u00bd\u00bf \u00bd\u00bd \u00be \u00bc \u00bd \u00ba \u00bd\u00ba\u00bf\u00bc\u00be \u00bc\u00ba \u00bf\u00bd \u00bd\u00bd \u00bf \u00bd\u00bf \u00be \u00bc \u00bd a ae\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 q x 1 n \u00f2 q x 2 n \u00ba b \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00f2 \u00d7 \u00f3\u00f2 \u00d7\u00ba c \u00ea \u00f8 \u00f3 \u00f3 \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7\u00ba d \u00fa \u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3 \u00f4\u00f3 \u00f2\u00f8\u00d7 \u00f9\u00f6 \u00f2 \u00f8 \u00d7 \u00f6 \u00ba e ae\u00f9\u00f1 \u00f6 \u00f3 \u00f6\u00f9\u00f0 \u00d7 \u00f2 \u00f8 \u00f2\u00f4\u00f9\u00f8 |q x 1 n | + |q x 2 n |\u00ba f ae\u00f9\u00f1 \u00f6 \u00f3 \u00f6\u00f9\u00f0 \u00d7 \u00f2 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 |eqt(q x 1 n , q x 2 n )| + |eqt(q x 2 n , q x 1 n )|\u00ba \u00f2\u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8 \u00f0\u00f8 \u00f3\u00f9 \u00f8 \u00d7 \u00f2 \u00f0 \u00f0 \u00ba \u00ec \u00f2 \u00fa \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00f2 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00d7 \u00d7 \u00f0\u00f0 \u00d7\u00f6 \u00f4\u00f8\u00ba \u00ec \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00f2 \u00f3\u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f2\u00d7 \u00d7\u00f8\u00d7 \u00f3 \u00f8 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00f3 \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 \u00f2 \u00f2 \u00f8 \u00f2 \u00d7\u00d7 \u00f6\u00fd \u00b4 \u00f9\u00f8 \u00f2\u00f3\u00f8 \u00f2 \u00d7\u00d7 \u00f6 \u00f0\u00fd \u00f0\u00f0\u00b5 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3 p \u00f4\u00f0\u00f9\u00d7 \u00f8 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f3 \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 \u00f8 \u00d7\u00f8 \u00f2 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f9\u00f2 \u00f6 \u00f0\u00d7\u00f3 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3 q\u00ba \u00ec \u00d7 \u00f8 \u00d7\u00f8\u00d7 \u00f6 \u00f6 \u00f0 \u00fe \u00f2 \u00f4\u00f6 \u00f8 \u00fd \u00f2 m v \u222a {\u223ca | a \u2208 hb v (q) \\ m v } \u00d7 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00d7\u00f8 \u00f8 \u00f1 \u00f2\u00f8 \u00f8\u00f3 q\u00ba \u00e1\u00f8 \u00d7 \u00fb\u00f3\u00f6\u00f8 \u00f2\u00f3\u00f8 \u00f2 \u00f8 \u00f8 \u00f8 \u00f2 \u00fa \u00f4\u00f4\u00f6\u00f3 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00d7\u00f8 \u00f2 \u00f2\u00fd \u00fb \u00fd \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0 n \u00f3 q \u00fb \u00f8 m v = n v \u00d7 \u00f9\u00f2 \u00f5\u00f9 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00d7 \u00f8 \u00f3 \u00f2 \u00f1 \u00f6 \u00d7 \u00d7 \u00d7 \u00f0 \u00f8 \u00f2 \u00d7\u00f9 \u00fb \u00fd \u00f8 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00fa \u00f2\u00f3\u00f9 \u00fa \u00d7 \u00f0 \u00f8\u00f3\u00f1\u00d7 \u00f2 \u00f8 \u00f3\u00f6\u00f6 \u00f8\u00f2 \u00d7\u00d7 \u00f3 \u00f8 \u00f2 \u00fa \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00f9 \u00f6 \u00f2\u00f8 \u00ba \u00f0\u00f0 \u00f8 \u00f8 \u00d7\u00f8\u00d7 \u00f6 \u00f4\u00f3\u00f6\u00f8 \u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00fb \u00f6 \u00f6\u00f9\u00f2 \u00f9\u00f2 \u00f6 \u00f8 \u00e4 \u00f2\u00f9\u00fc \u00be\u00ba \u00ba \u00f3\u00f4 \u00f6 \u00f8 \u00f2 \u00d7\u00fd\u00d7\u00f8 \u00f1 \u00f3\u00f2 \u00bd\u00ba \u00e0\u00fe \u00e5 \u00f8 \u00f0\u00f3\u00f2 \u00e8 \u00be\u00bc\u00bc\u00bc\u2022 \u00e8\u00ed \u00fb \u00f8 \u00bd \u00f3 \u00f1 \u00f2 \u00f1 \u00f1\u00f3\u00f6\u00fd\u00ba \u00d7 \u00f6 \u00f6 \u00d7 \u00f8 \u00f1 \u00f2 \u00d7 \u00f2 \u00f8 \u00d7\u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7\u00b8\u00fb \u00f6 \u00f4\u00f3\u00f6\u00f8 \u00f8 \u00d7\u00f9\u00f1 \u00f3 \u00f9\u00d7 \u00f6 \u00f2 \u00d7\u00fd\u00d7\u00f8 \u00f1 \u00f8 \u00f1 \u00d7\u00ba \u00ba\u00bd \u00ec n\u00b9\u00e9\u00f9 \u00f2\u00d7 \u00f2 \u00f1 \u00f6 \u00e7\u00f9\u00f6 \u00f6\u00d7\u00f8 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00fb \u00d7 \u00d7 \u00f3\u00f2 \u00f8 n\u00b9\u00f5\u00f9 \u00f2\u00d7 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00ba \u00ef \u00fa \u00f6 \u00f8 \u00fa \u00d7 \u00f0 \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00f3 \u00f8 \u00f6 \u00f6 \u00f2\u00f8 \u00f3\u00f6\u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f6 \u00fa \u00f6 \u00f2\u00f8\u00d7 \u00f3 \u00f3\u00f2 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00fd ae \u00f1 \u00f0 \u00b4\u00bd \u00b8\u00f4\u00ba \u00be \u00bc\u00b5\u00ba \u00ec \u00f2\u00f3 \u00f2 q x1 n \u00f3\u00f2\u00d7 \u00d7\u00f8\u00d7 \u00f3 \u00f4 \u00f6\u00f8\u00d7 \u00b4 \u00b5 \u00f2 \u00b4 \u00b5 \u00fa \u00f2 \u00f2 \u00ba \u00bf \u00f2 \u00d7 \u00d7 \u00f2 \u00d7\u00f3 \u00f8 \u00f8 \u00f5\u00f9 \u00f2\u00d7 \u00f6 \u00f4\u00f0 \u00f3\u00f0\u00f9\u00f1\u00f2\u00b9\u00fb \u00d7 \u00f8\u00f3 \u00f8 \u00f3 \u00f6 \u00ba \u00ec \u00d7 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00f6 \u00f1 q x2 n \u00f3\u00f2\u00d7 \u00d7\u00f8\u00d7 \u00f3 \u00f4 \u00f6\u00f8\u00d7 \u00b4 \u00b5 \u00f2 \u00b4 \u00b5 \u00fa \u00f2 \u00f2 \u00ba \u00bf\u00b8 \u00ba \u00ba\u00b8 \u00f8 \u00d7 \u00fa \u00f6 \u00f2\u00f8 \u00f3 q x1 n \u00fb \u00f6 \u00f8 \u00f3 \u00f8\u00fb \u00f2 \u00f4\u00f0 \u00f2 \u00f3\u00f6 \u00f2\u00f3\u00f8 \u00f4\u00f0 \u00f2 \u00f5\u00f9 \u00f2 \u00f2 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f0\u00f0 \u00f3 \u00f8 \u00d7\u00d7 \u00f3 \u00f6 \u00d7 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8\u00f0\u00fd \u00f3\u00f6\u00f1\u00f9\u00f0 \u00f8 \u00f9\u00d7 \u00f2 \u00f3 \u00f6\u00f9\u00f0 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f4\u00f0 \u00f2 \u00d7 \u00f6\u00f9\u00f0 \u00d7\u00ba \u00ec \u00f8 \u00f6 \u00f4\u00f6\u00f3 \u00f6 \u00f1 q y n \u00b8 \u00ba \u00ba\u00b8\u00f4 \u00f6\u00f8\u00d7 \u00b4\u00b5 \u00f2 \u00b4 \u00b5 \u00fa \u00f2 \u00f2 \u00ba \u00bf\u00b8 \u00d7 \u00f2 \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 q x1 n \u00f2 \u00fb \u00f5\u00f9 \u00f2\u00d7 \u00f6 \u00f4\u00f0 \u00f6\u00f3\u00fb\u00b9\u00fb \u00d7 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f3\u00f0\u00f9\u00f1\u00f2\u00b9\u00fb \u00d7 \u00ba \u00bf\u00be \u00ec\u00ba \u00e2 \u00f2 \u00f9\u00f2 \u00f2 \u00f2 \u00ba \u00e7 \u00f6 \u00f2 \u00f2 \u00f6\u00d7\u00f8 \u00fb \u00fa \u00f6 \u00f8 \u00fa \u00d7 \u00f0 \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00f3 q x1 n \u00f2 q x2 n \u00f2 \u00f8 \u00f2 \u00f8 \u00f8 \u00f3 q x1 n \u00f2 q y n \u00f9\u00d7 \u00f2 \u00f3\u00f8 \u00f8 \u00f0\u00f4 \u00f5 \u00f2 \u00f8 \u00f2 \u00fa \u00f4\u00f4\u00f6\u00f3 \u00d7\u00ba \u00ec \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f5\u00f9 \u00f2\u00d7 n \u00fb \u00d7 \u00fa \u00f6 \u00f6\u00f3\u00f1 \u00bd \u00f8\u00f3 \u00bd\u00bd \u00f2 \u00f8 \u00fa \u00f6 \u00f8 \u00f3\u00f2 \u00f8 \u00d7 \u00fb \u00d7 \u00f6 \u00f4 \u00f8 \u00bd\u00bc\u00bc \u00f8 \u00f1 \u00d7 \u00f3\u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f5\u00f9 \u00f2\u00d7 \u00f2 \u00f6 \u00f8 \u00f2 \u00f8 \u00f1 \u00f2 \u00fb \u00f6 \u00f2 \u00f3\u00f1\u00f0\u00fd \u00d7 \u00f9 \u00fa \u00f6\u00d7 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f2\u00fa\u00f3\u00f0\u00fa \u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3 \u00f8 \u00d7 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f6 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00ec \u00f0 \u00d7 \u00bd \u00f2 \u00be\u00b8\u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd\u00ba \u00e1\u00f8 \u00f4\u00f4 \u00f6\u00d7 \u00f8 \u00f8 \u00f8 \u00f2 \u00fa \u00f4\u00f4\u00f6\u00f3 \u00f3\u00f1 \u00d7 \u00d7\u00f9\u00f4 \u00f6 \u00f3\u00f6 \u00f2 \u00f8 \u00d7 \u00f3 \u00f8\u00fb\u00f3 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00fb \u00f0\u00f0\u00b9\u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f3\u00f2\u00f8 \u00f2 \u00f2 \u00f2 \u00f8\u00f3\u00f1\u00d7 \u00b4\u00f8 \u00f8\u00f3\u00f1\u00d7 \u00f2 \u00f5\u00b4 \u00b8 \u00b5 \u00f6 \u00fc\u00f4\u00f0 \u00f8\u00f0\u00fd \u00f2\u00b5 \u00d7 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f6\u00f3\u00fb \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f2\u00f6 \u00d7 \u00d7\u00ba \u00f3\u00f1\u00f4 \u00f6 \u00f2 \u00f8 \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f6\u00f3\u00f1 \u00ec \u00f0 \u00d7 \u00bd \u00f2 \u00be\u00b8 \u00f8 \u00f2 \u00d7 \u00f2 \u00f8 \u00f8 \u00f8 \u00f6 \u00f2 \u00f2 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00d7 \u00d7\u00f1 \u00f0\u00f0 \u00f6 \u00f2 \u00f8 \u00d7 \u00fb \u00f6 \u00f8 \u00d7 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f3\u00f2\u00f8 \u00f2 \u00f2 \u00f8\u00f3\u00f1\u00d7\u00ba \u00ec \u00d7 \u00f2 \u00d7 \u00f2 \u00d7 \u00f2 \u00f2 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f8 \u00d7 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6\u00f0\u00fd \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2 \u00f4 \u00f6\u00f8 hidden \u2022 (\u2022) \u00f8 \u00f8 \u00f2\u00f6 \u00d7 \u00d7 \u00f8 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00f3 \u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00ba \u00ec\u00f3 \u00f2\u00fa \u00d7\u00f8 \u00f8 \u00f8 \u00d7 \u00f9\u00f6\u00f8 \u00f6\u00b8\u00fb \u00fa \u00f6 \u00f8 \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00f3 q x1 n \u00f2 q y n \u00fb \u00f8 \u00f3\u00f9\u00f8 \u00f0 \u00f6 \u00f2 \u00f8 \u00f8\u00f3\u00f1\u00d7 \u00f2 \u00f5\u00b4 \u00b8 \u00b5 \u00f2\u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3 \u00f8 \u00f2 \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00f6 \u00d7 \u00f1 \u00f0 \u00f3\u00f9\u00f6 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00b4\u00e2 \u00f2 \u00f9\u00f2 \u00f2 \u00f2 \u00e7 \u00f6 \u00f2 \u00f2 \u00be\u00bc\u00bc\u00be\u00b5\u00b8 \u00ba \u00ba\u00b8\u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00f4 \u00f6 \u00f3\u00f6\u00f1\u00d7 \u00d7\u00f3\u00f1 \u00fb \u00f8 \u00f8\u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f2 \u00fa \u00f3\u00f2 \u00ba \u00e5\u00f3\u00f6 \u00f3\u00fa \u00f6\u00f8 \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f3 \u00f2 \u00fa \u00f4\u00f4\u00f6\u00f3 \u00f6 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f0\u00fd \u00f8 \u00d7 \u00f1 \u00d7 \u00fb \u00f8 \u00f2 \u00f8\u00f3\u00f1\u00d7\u00b8 \u00f9\u00f8 \u00f8 \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f3\u00f6 \u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00f6 \u00d7 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00d7\u00f1 \u00f0\u00f0 \u00f6\u00ba \u00ec \u00f6 \u00d7\u00f3\u00f2 \u00fb \u00fd \u00f8 \u00f2 \u00fa \u00f4\u00f4\u00f6\u00f3 \u00f4\u00f4 \u00f6\u00d7 \u00f8\u00f3 \u00f1\u00f1\u00f9\u00f2 \u00f8\u00f3 \u00f2 \u00d7 \u00f2 \u00f8 \u00fa \u00d7 \u00f0 \u00f8\u00fd \u00f3 \u00f8\u00f3\u00f1\u00d7 \u00d7 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00ba \u00e1\u00f2 \u00f3\u00f9\u00f6 \u00f2\u00f3 \u00f2 \u00d7 \u00f3 \u00f8 n\u00b9\u00f5\u00f9 \u00f2\u00d7 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00b8\u00f8 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f2 \u00f8\u00f3\u00f1\u00d7 \u00f2 \u00f6 \u00f8\u00f0\u00fd \u00f8 \u00f6\u00f1 \u00f2 \u00f3\u00f2 \u00f8 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00fa \u00d7 \u00f0 \u00f4 \u00f6\u00f8 \u00d7 \u00f2\u00f3\u00fb\u00f2\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00d7 \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00d7\u00d7 \u00f6 \u00f0\u00fd \u00f8 \u00d7 \u00f2 \u00f2 \u00f6 \u00f0 \u00f2 \u00f2 \u00f2 \u00f8 \u00f9\u00f2 \u00f5\u00f9 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0 \u00f3\u00f6 \u00f8 \u00f2 \u00f4 \u00f6\u00f8 \u00f2 \u00f1\u00f3\u00f6 \u00f0 \u00f3\u00f6 \u00f3\u00f9\u00d7 \u00f2 \u00f8 \u00f1 \u00f3\u00f2\u00d7\u00f9\u00f1 \u00f2 \u00d7 \u00f2 \u00f3\u00f9\u00f6 \u00f0 \u00d7\u00f8 \u00f2 \u00f1 \u00f6 \u00f8\u00f3 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00ba\u00bf\u00ba \u00ef \u00f3\u00d7 \u00f8 \u00f4 \u00f6\u00d7 \u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 (q x1 n , q x2 n ) \u00f2 (q x1 n , q y n ) \u00f3\u00f6 \u00f3\u00f9\u00f6 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f8\u00f3 \u00d7 \u00f8 \u00f8\u00fb\u00f3 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00f6 \u00f2\u00f8\u00f0\u00fd \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00fb \u00f8 \u00f6 \u00f0\u00f3 \u00f0 \u00f2 \u00b4 \u00f3 \u00f6\u00f9\u00f0 \u00d7 \u00f9\u00d7 \u00f2\u00d7\u00f8 \u00f3 \u00d7 \u00f6\u00f9\u00f0 \u00d7\u00b5 \u00f3\u00f6 \u00f0\u00f3 \u00f0 \u00f2 \u00b4 \u00f2 \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00f2\u00f3 \u00f2 \u00d7 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00b5 \u00d7 \u00f1 \u00f2 \u00f8 \u00f2\u00f3 \u00f2 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f3\u00f9\u00f6 \u00f8 \u00d7\u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00d7 \u00f3\u00fb \u00f2\u00f3 \u00f0 \u00f6 \u00f2 \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f6 \u00f6 \u00f8 \u00f3\u00f2\u00ba \u00f9\u00f6\u00f8 \u00f6\u00f1\u00f3\u00f6 \u00b8\u00fb \u00f8\u00f3 \u00f8 \u00d7\u00f8 \u00f2\u00f3\u00f2\u00b9 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f4 \u00f6\u00d7 \u00f3 n\u00b9\u00f5\u00f9 \u00f2\u00d7 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7\u00ba \u00ec\u00f3 \u00f8 \u00d7 \u00f2 \u00b8\u00fb \u00f6\u00f3\u00f4\u00f4 n \u00f6 \u00f2 \u00f3\u00f1 \u00f6\u00f9\u00f0 \u00d7 \u00f6\u00f3\u00f1 q y n \u00b8 \u00f2 \u00fa \u00f6 \u00f8 \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00f3 q x1 n \u00f2 \u00f8 \u00f1\u00f3 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 q y n \u00fd \u00d7 \u00f0 \u00f8 \u00f2 \u00f3\u00f2\u00f0\u00fd \u00f2\u00f3\u00f2\u00b9 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f4 \u00f6\u00d7 \u00b4 \u00f3\u00f8 \u00fb \u00f8 \u00f2 \u00fb \u00f8 \u00f3\u00f9\u00f8 \u00f2 \u00f8\u00f3\u00f1\u00d7\u00b5\u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f8\u00f9\u00f6\u00f2 \u00f3\u00f9\u00f8 \u00f8\u00f3 \u00fa \u00f6\u00fd \u00d7 \u00f1 \u00f0 \u00f6 \u00f8\u00f3 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f8 \u00f8 \u00fb \u00f6 \u00f3 \u00f8 \u00f2 \u00f3\u00f6 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00f4 \u00f6\u00d7\u00ba \u00e1\u00f2 \u00f0\u00f0 \u00f3\u00f9\u00f6 n\u00b9\u00f5\u00f9 \u00f2\u00d7 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3 \u00f4\u00f3 \u00f2\u00f8\u00d7 \u00b4 \u00ba \u00ba\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3 \u00d7 \u00f1 \u00fd \u00d7\u00f1\u00f3 \u00f0\u00d7 \u00fb \u00f0 \u00d7 \u00f6 \u00f2 \u00f3\u00f6 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 \u00f8 \u00f8\u00f6 \u00f2\u00d7\u00f0 \u00f8 \u00f3\u00f2\u00b5 \u00d7 \u00d7\u00f0 \u00f8\u00f0\u00fd \u00d7\u00f1 \u00f0\u00f0 \u00f6 \u00f2 \u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00f8 \u00f2 \u00f2 \u00f8 \u00f2 \u00fa \u00f3\u00f2 \u00ba \u00ec \u00f9\u00d7 \u00f8 \u00d7 \u00f1\u00d7 \u00f8 \u00f8 \u00fa \u00f6 \u00fd \u00f2 \u00f8 \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00f3 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f9\u00d7 \u00f2 \u00f0\u00f4 \u00f5 \u00f0 \u00d7 \u00f8\u00f3 \u00d7\u00f1 \u00f0\u00f0 \u00f6 \u00d7 \u00f6 \u00d7\u00f4 \u00b8 \u00f9\u00f8 \u00f8 \u00fa \u00f2\u00f8\u00f9 \u00f0 \u00f2\u00fd \u00f2 \u00fa \u00f6\u00fd \u00d7 \u00f6 \u00d7 \u00f8 \u00f1 \u00d7 \u00f3\u00f2 \u00f6\u00f2 \u00ba \u00ba\u00be \u00ea \u00f2 \u00f3\u00f1 3\u00b9\u00eb \u00ec \u00f2 \u00f6 \u00f4 \u00e8\u00f6\u00f3 \u00f0 \u00f1\u00d7 \u00ef \u00f0\u00d7\u00f3 \u00f4 \u00f6 \u00f3\u00f6\u00f1 \u00d7\u00f3\u00f1 \u00f8 \u00d7\u00f8\u00d7 \u00fb \u00f8 \u00f6 \u00f2 \u00f3\u00f1\u00f0\u00fd \u00f2 \u00f6 \u00f8 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7\u00ba \u00ef \u00f2\u00b9 \u00f6 \u00f8 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f8 \u00f8 \u00d7\u00f3\u00f0\u00fa \u00f2 \u00f2\u00d7\u00f8 \u00f2 \u00f3 \u00f6 \u00f2 \u00f3\u00f1 \u00bf\u00b9\u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00fb \u00f8 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f0 \u00f9\u00d7 \u00d7 \u00f8\u00f3 \u00fa \u00f6 \u00f0 \u00d7 \u00f6 \u00f8 \u00f3 c/v = 4\u00ba \u00eb\u00f9 \u00f2\u00d7\u00f8 \u00f2 \u00d7 \u00f6 \u00f8\u00fd\u00f4 \u00f0\u00f0\u00fd \u00d7 \u00f8 \u00d7 \u00f0 \u00b8 \u00f9\u00f8 \u00d7\u00f3 \u00f0\u00f3\u00d7 \u00f8\u00f3 \u00f8 \u00f4 \u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f4\u00f3 \u00f2\u00f8 \u00b4 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f0\u00fd \u00ba\u00bf\u00b5 \u00f8 \u00f8 \u00f2 \u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00ec \u00f3\u00f6\u00fd \u00f2 \u00e8\u00f6 \u00f8 \u00f3 \u00e4\u00f3 \u00e8\u00f6\u00f3 \u00f6 \u00f1\u00f1 \u00f2 \u00bf\u00bf \u00ec \u00f0 \u00be\u00ba \u00ea \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3\u00f6 \u00f8\u00fb\u00f3 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f0\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00b4n\u00b9\u00f5\u00f9 \u00f2\u00d7\u00b5\u00ba n \u00eb\u00e5 a tavg b tavg \u00ea \u00ea c \u00e8avg d \u00e8avg \u00ea\u00e1 e \u00ea\u00e7 f \u00f0\u00f4 \u00f5 \u00f2 \u00fa \u00f0\u00f4 \u00f5 \u00f2 \u00fa \u00bd \u00bd \u00bc\u00ba\u00bc\u00bc\u00bc \u00bc\u00ba\u00bc \u00bc \u00b9 \u00bc \u00bc \u00bf\u00bc \u00be \u00bc \u00bc\u00ba\u00bc\u00bc\u00bc \u00bc\u00ba\u00bc \u00bc \u00b9 \u00bc \u00bc \u00bf \u00bd \u00bf \u00bc \u00bc\u00ba\u00bc\u00bc \u00bc\u00ba\u00bc \u00be \u00ba \u00bf \u00bc \u00bc \u00bd\u00bf \u00be \u00bc\u00ba\u00bc\u00be\u00bc \u00bc\u00ba\u00bd\u00be \u00ba\u00be\u00bc \u00bc \u00be \u00bf \u00bd\u00bd \u00bd\u00bc \u00bc\u00ba\u00bc \u00be \u00bc\u00ba \u00bf \u00ba\u00bc \u00bd \u00bc\u00bc \u00be\u00be \u00bc \u00bc\u00ba\u00bd \u00bc\u00ba\u00be \u00bd \u00bd\u00ba \u00bd \u00bd \u00bd\u00be \u00bf \u00bc \u00bc \u00bc\u00ba \u00bd \u00be\u00ba \u00bf \u00bf\u00ba\u00bd \u00bf \u00be\u00bc\u00bd \u00bf \u00be \u00ba \u00ba \u00bf\u00bd \u00bd\u00ba\u00be \u00bd \u00be \u00bf \u00bf\u00bd\u00bd \u00bf \u00be \u00bf \u00ba \u00bc\u00bc \u00bf \u00ba \u00bf \u00bd\u00ba\u00bc\u00bf \u00bc\u00bf \u00bc \u00bd\u00bf \u00be \u00bd\u00bc \u00be \u00be\u00bf \u00ba \u00be \u00bd\u00bd\u00bc\u00ba\u00bd\u00bc \u00bc\u00ba \u00be \u00bf \u00bf\u00be \u00bf \u00bd\u00bc\u00bc \u00bd \u00bf\u00bc \u00bd\u00bd \u00be \u00bc \u00bd \u00be\u00bd\u00ba \u00bf\u00bc \u00ba\u00bc\u00be \u00bc\u00ba\u00bf \u00bd\u00be\u00be\u00bd\u00bc \u00bd\u00bf \u00be \u00bd \u00be \u00bf\u00bd\u00bc a ae\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 q x 1 n \u00f2 q y n \u00ba b \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00f2 \u00d7 \u00f3\u00f2 \u00d7\u00ba c \u00ea \u00f8 \u00f3 \u00f3 \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7\u00ba d \u00fa \u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3 \u00f4\u00f3 \u00f2\u00f8\u00d7 \u00f9\u00f6 \u00f2 \u00f8 \u00d7 \u00f6 \u00ba e ae\u00f9\u00f1 \u00f6 \u00f3 \u00f6\u00f9\u00f0 \u00d7 \u00f2 \u00f8 \u00f2\u00f4\u00f9\u00f8 |q x 1 n | + |q y n |\u00ba f ae\u00f9\u00f1 \u00f6 \u00f3 \u00f6\u00f9\u00f0 \u00d7 \u00f2 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 |eqt(q x 1 n , q y n )| + |eqt(q y n , q x 1 n )|\u00ba \u00d7 \u00f0\u00f6 \u00fd \u00f1 \u00f2 \u00f2 \u00f3\u00f6 \u00eb \u00ec \u00d7\u00f3\u00f0\u00fa \u00f6\u00d7\u00ba \u00ec\u00f3 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00d7\u00f0\u00f3\u00f4\u00f4\u00fd \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00f1 \u00f6 \u00f1 \u00f2 \u00f1 \u00d7\u00f8 \u00d7\u00b8\u00fb \u00f6\u00f3\u00f4\u00f4 \u00f3\u00f2 \u00f6 \u00f2 \u00f3\u00f1 \u00f6\u00f9\u00f0 \u00f6\u00f3\u00f1 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00ba \u00f9 \u00f8\u00f3 \u00f2\u00f3\u00f2\u00b9 \u00fc \u00d7\u00f8 \u00f2 \u00f3 \u00f2 \u00f8\u00f3\u00f1\u00d7\u00b8\u00fb \u00f8 \u00fb \u00f5\u00f9 \u00fa \u00f0 \u00f2 \u00f3 \u00f8 \u00f1\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00f2 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00f8\u00f3 \u00d7 \u00f1 \u00f2 \u00d7\u00f9 \u00f1 \u00d7\u00f8 \u00f8\u00d7 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 \u00f2\u00f3\u00f8\u00ba \u00d7 \u00f3\u00f2\u00d7 \u00f5\u00f9 \u00f2 \u00b8\u00f8 \u00f4 \u00f6\u00d7 \u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f2\u00f0\u00f9 \u00f3\u00f8 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f2 \u00f2\u00f3\u00f2 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00d7 \u00d7\u00ba \u00ef \u00f2 c/v = 4\u00b8 \u00f4\u00f4\u00f6\u00f3\u00fc \u00f1 \u00f8 \u00f0\u00fd \u00bc\u00b1 \u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00f4 \u00f6\u00d7 \u00fb \u00f6 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8\u00ba \u00ec \u00d7 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00d7 \u00f1 \u00f8\u00f3 \u00f4 \u00f2 \u00f1\u00f9 \u00f3\u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00d7 \u00fe \u00b4\u00f1 \u00d7\u00f9\u00f6 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fa \u00f6 \u00f0 \u00d7 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00b5 \u00fb \u00f8 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00d7 \u00fe \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00d7\u00ba \u00ef \u00f8 \u00d7\u00f1 \u00f0\u00f0 \u00f6 \u00fa \u00f0\u00f9 \u00d7 \u00f3 c/v \u00f8 \u00f4 \u00f6 \u00f2\u00f8 \u00f3 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00f4 \u00f6\u00d7 \u00d7 \u00f0\u00f3\u00fb \u00f6 \u00f9\u00f8 \u00f3\u00f6 \u00f0 \u00f6 \u00f6 \u00fa \u00f0\u00f9 \u00d7 \u00f3 c/v \u00f8 \u00f4 \u00f6 \u00f2\u00f8 \u00f6\u00f3\u00fb\u00d7 \u00f9\u00f4 \u00f8\u00f3 \u00bc\u00b1\u00ba \u00e1\u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00fb \u00f8 \u00f6 \u00f2 \u00f3\u00f1 \u00bf\u00b9\u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7\u00b8\u00fb \u00fa \u00f6 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fa \u00f6 \u00f0 \u00d7 v \u00f6\u00f3\u00f1 \u00bd\u00bc \u00f8\u00f3 \u00bc \u00fb \u00f8 \u00d7\u00f8 \u00f4\u00d7 \u00f3 \u00ba \u00f3\u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fa \u00f6 \u00f0 \u00d7 \u00fb \u00f6 \u00f4 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00bd\u00bc\u00bc \u00f8 \u00f1 \u00d7 \u00f2 \u00f2 \u00f6\u00b9 \u00f8 \u00f8 \u00f1 \u00f2 \u00fb \u00f6 \u00f2 \u00f3\u00f1 \u00f2\u00d7\u00f8 \u00f2 \u00ba \u00ec \u00fa \u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8 \u00f1 \u00d7 \u00f2 \u00f8 \u00fa \u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3 \u00f4\u00f3 \u00f2\u00f8\u00d7 \u00f3\u00f6 \u00f3\u00f8 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00f6 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f9\u00f6 \u00ba \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00f8 \u00f8 \u00f8 \u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00d7 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00d7\u00f8 \u00f6 \u00f8 \u00f2 \u00f8 \u00f2 \u00fa \u00f3\u00f2 \u00ba \u00ec \u00f6 \u00f2 \u00f2\u00f6 \u00d7 \u00d7 \u00d7 \u00f4\u00f6\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00f8 \u00f2 \u00d7 \u00f6\u00f3\u00fb\u00ba \u00ec \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3 \u00f4\u00f3 \u00f2\u00f8\u00d7 \u00d7 \u00f0\u00d7\u00f3 \u00f0\u00f3\u00fb \u00f6 \u00f2 \u00f8 \u00f3\u00f6\u00f1 \u00f6 \u00f4\u00f4\u00f6\u00f3 \u00f3\u00f2 \u00f2 \u00fa \u00f6 \u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f3\u00f2 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00fb \u00f8 \u00f6 \u00f2 \u00f3\u00f1 \u00bf\u00b9\u00d7 \u00f8 \u00f2\u00d7\u00f8 \u00f2 \u00d7 \u00fb \u00f2 \u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00d7 \u00f2 \u00f8 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8\u00b8 \u00f9\u00f8 \u00fb \u00f4\u00f8 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fa \u00f6 \u00f0 \u00d7 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8\u00b8v = 40\u00b8 \u00f2 \u00fa \u00f6 \u00f8 \u00f6 \u00f8 \u00f3 c/v \u00f6\u00f3\u00f1 \u00bf\u00ba \u00f8\u00f3 \u00ba \u00fb \u00f8 \u00d7\u00f8 \u00f4\u00d7 \u00f3 \u00bc\u00ba\u00bd\u00be \u00ba \u00f3\u00f6 \u00fa \u00f0\u00f9 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3 c/v\u00b8\u00fb \u00f6 \u00f4 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00bd\u00bc\u00bc \u00f8 \u00f1 \u00d7 \u00f2 \u00f6 \u00f8 \u00f2 \u00f8 \u00f1 \u00f2 \u00fb \u00f6 \u00f2 \u00f3\u00f1 \u00f2\u00d7\u00f8 \u00f2 \u00ba \u00ec \u00f1\u00f3\u00f8 \u00fa \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00d7 \u00fc\u00f4 \u00f6 \u00f1 \u00f2\u00f8 \u00fb \u00d7 \u00f8\u00f3 \u00d7 \u00f3\u00fb \u00f8 \u00f0\u00f4 \u00f5 \u00f4\u00f4\u00f6\u00f3 \u00f4 \u00f6 \u00f3\u00f6\u00f1\u00d7 \u00f3\u00f1\u00f4 \u00f6 \u00f8\u00f3 \u00f8 \u00f2 \u00fa \u00f3\u00f2 \u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f6 \u00f1\u00d7 \u00f2 \u00f6\u00f3\u00f1 \u00f0\u00f1\u00f3\u00d7\u00f8 \u00f0\u00fb \u00fd\u00d7 \u00d7 \u00f8 \u00d7 \u00f0 \u00b4\u00f1 \u00f2\u00fd \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7\u00b5 \u00f8\u00f3 \u00f0\u00f1\u00f3\u00d7\u00f8 \u00f0\u00fb \u00fd\u00d7 \u00f9\u00f2\u00d7 \u00f8 \u00d7 \u00f0 \u00b4\u00f2\u00f3 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0\u00d7\u00b5\u00ba \u00bf \u00ec\u00ba \u00e2 \u00f2 \u00f9\u00f2 \u00f2 \u00f2 \u00ba \u00e7 \u00f6 \u00f2 \u00f2 0",
        "prob": 0.9262500000000002
    }, {
        "ID": 7483,
        "phrase": " the system has to analyse articles such as: 'phe naimahawan, of chiang mai's mae ai district, has been selected (\u2026) to represent thailand in a swimming event (\u2026)",
        "prob": 0.1823529411764706
    }, {
        "ID": 7539,
        "phrase": " then, with probability 1 \u2212 \u03b4, where \u03b4 \u2264 (|q| + 1) \u2022 exp \u22122m \u01eb 2 log 2 (\u03b2/\u03b1) , the algorithm outputs some distribution q ml \u2208 q which has kl(p||q ml ) \u2264 4\u01eb",
        "prob": 0.39230769230769236
    }, {
        "ID": 7791,
        "phrase": " pr m d (e) = pr(\u03b5) [1 + o(1)] + [pr(x)] (l\u22121) pr (m l) (\u03b5) \u2265 [pr(x)] (l\u22121) pr (m l) (\u03b5) \u2265 [pr(x)] (l\u22121) e \u2212n esp(r 1 ) , (19) where the last inequality follows from the sphere-packing lower bound on the ml decoding error probability  [3] ",
        "prob": 0.43913043478260877
    }, {
        "ID": 7870,
        "phrase": " in principle, it recomputes the ml path each time",
        "prob": 0.23333333333333334
    }, {
        "ID": 7958,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.35000000000000003
    }, {
        "ID": 8050,
        "phrase": " n 2 proof of  (7)  since z is a noisy version of *  source signal and its reconstruction respectively, a is a linear, time-invariant operator that is bounded from below, t i is a t seconds interval and \n 2 e 1 ai 21 [x (t)] s = < \u221e and with a power spectraldensity function x (f ),1/ 2 f 1/ 2 \u03c6 \u2264 \u2264 ",
        "prob": 0.2772727272727273
    }, {
        "ID": 9223,
        "phrase": " an axiom, previously created by struct axm, is bound to the ml identifier exp defined",
        "prob": 0.29285714285714287
    }, {
        "ID": 9230,
        "phrase": " \n\t\t\t standard ml uses strict evaluation, but lazy lists can be implemented using closures",
        "prob": 0.22142857142857145
    }, {
        "ID": 9439,
        "phrase": " this maximum value is returned in the ai eld",
        "prob": 0.2625
    }, {
        "ID": 9439,
        "phrase": " the ai eld is initialized to zero at the source",
        "prob": 0.3875
    }, {
        "ID": 9439,
        "phrase": " the network reads only the ocr, laf and ai elds and modi es only the laf and ai elds",
        "prob": 0.5916666666666667
    }, {
        "ID": 9439,
        "phrase": " hence, we initialize tcr in control cell maxftcr, ocrg \n responding to network feedback the source uses the tcr and the modi ed laf and ai elds of the returned control cell to calculate its new rate tcr as follows: new tcr tcr in cell laf in cell if laf 1 and new tcr tcr tcr = new tcr else if laf 1 and new tcr tcr tcr = new tcr when laf 1, the network is asking the source to decrease its tcr",
        "prob": 0.7836363636363636
    }, {
        "ID": 9439,
        "phrase": " the source interval t is set to the maximum of the switch averaging intervals in the path which has been returned in the ai eld of the control cell",
        "prob": 0.5062500000000001
    }, {
        "ID": 9439,
        "phrase": " so, when feedback is given to the sources the ai eld is set to the maximum of the ai eld in the cell and the switch a v eraging interval: ai in cell maxai in cell, switch averaging interval \n achieving e ciency e ciency is achieved as follows: laf in cell maxlaf in cell, z the idea is that if all sources divide their rates by laf, the switch will have z = 1 in the next cycle",
        "prob": 0.6342105263157894
    }, {
        "ID": 9445,
        "phrase": " t o m ai nt a inah i g h s i g n al -t o-no is er a t io ,o n e m u s te it h er i n crease th e s i g n al l evel (m or e power) or u s es p ecial cod i n g m eth ods t o p r o d u ce low er frequ en cy s ig n al s ",
        "prob": 0.2157894736842105
    }, {
        "ID": 9449,
        "phrase": "   fiber d istrib u te d d a t ai n t e r face (fd d i) i s a 1 0 0m e g a b its p e r s e c o n dber o p t iclo c a l a r e a n e t w o r k ( l a n) standard b e in g d e v e lo p e d b y t he a m eric a n n a t io n a l s t a n d a r d i n s t itu te (a n s i)",
        "prob": 0.2818181818181818
    }]
}, {
    "topic_id": 16,
    "top_words": ["learning", "machine", "techniques", "based", "work", "system", "using", "use", "context", "models", "application", "applications", "management", "provide", "applying"],
    "phrases": [{
        "ID": 62,
        "phrase": "the objective of the oscar project is the construction of a general theory of rationality for autonomous agents and its implementation in an ai system",
        "prob": 0.20666666666666667
    }, {
        "ID": 68,
        "phrase": " models are, usually, a convenient abstraction of a system, and qualitative abstractions of real values have emerged in ai as a meaningful and (sometimes) useful abstraction",
        "prob": 0.22777777777777775
    }, {
        "ID": 91,
        "phrase": " the availability of a system supporting such an expressive language in an efficient way is stimulating ai and database people to use logic-based systems for the development of their applications",
        "prob": 0.205
    }, {
        "ID": 242,
        "phrase": " although empirical machine learning methods have proven to be useful in reducing that cost for specific domains  (tou ng et al",
        "prob": 0.41764705882352937
    }, {
        "ID": 267,
        "phrase": " we describe the component taggers and the machine learning method used for the second level learner",
        "prob": 0.2928571428571428
    }, {
        "ID": 330,
        "phrase": " the only previous research resolving bunsetsu identification by machine learning methods, is the work by zhang  (zhang and ozeki, 1998) ",
        "prob": 0.5687500000000001
    }, {
        "ID": 340,
        "phrase": "we present some novel machine learning techniques for the identification of subcategorization information for verbs in czech",
        "prob": 0.22142857142857145
    }, {
        "ID": 360,
        "phrase": " this work reports a comparative study of five ml approaches to wsd, and focuses on studying their portability",
        "prob": 0.20666666666666667
    }, {
        "ID": 423,
        "phrase": " we present the argument for ml 1 = 1 here",
        "prob": 0.3
    }, {
        "ID": 637,
        "phrase": " firstly, we will start by describing previous work in machine learning of language structure and then we will give a description of the abl algorithm",
        "prob": 0.24117647058823527
    }, {
        "ID": 641,
        "phrase": " eas are increasingly important in such areas as function optimization, machine learning, and modeling",
        "prob": 0.46923076923076923
    }, {
        "ID": 660,
        "phrase": " van der dosch and  daelemans (1998)  show that not ignoring the low count instances is often crucial to performance in machine learning systems for natural language",
        "prob": 0.1631578947368421
    }, {
        "ID": 705,
        "phrase": " he stresses that \"[c]hoosing what components to include in the first place, shaping them to extra-documentary objectives, and attending to semantic, strategic, and stylistic entailments among those choices, are where the real expertise-and the ai challenge-lies",
        "prob": 0.23461538461538461
    }, {
        "ID": 725,
        "phrase": " this development has meant that together with new database techniques there is an ever growing need for the use of ai techniques such as those of multi-agent systems, knowledge representation (including in particular ontologies and hierarchies), natural language, resolution of conflict and machine learning",
        "prob": 0.30333333333333334
    }, {
        "ID": 785,
        "phrase": "introduction this paper reports on the still preliminary, but already satisfying results of the learning com-putational grammars (lcg) project, a postdoc network devoted to studying the application of machine learning techniques to grammars suitable for computational use",
        "prob": 0.7033333333333333
    }, {
        "ID": 785,
        "phrase": " after this we will describe the machine learning algorithms applied to this data and conclude with some notes about combining different system results",
        "prob": 0.31875000000000003
    }, {
        "ID": 785,
        "phrase": "this paper reports on the learning computational grammars (lcg) project, a postdoc network devoted to studying the application of machine learning techniques to grammars suitable for computational use",
        "prob": 0.8304347826086956
    }, {
        "ID": 814,
        "phrase": " almost any machine learning problem could potentially use language modeling techniques as a solution, and identifying new areas where language models work well is likely to be as useful as trying to do basic research",
        "prob": 0.5222222222222223
    }, {
        "ID": 814,
        "phrase": " on the other hand, language modeling is useful for many fields beyond speech recognition, and is an interesting test bed for machine learning techniques in general",
        "prob": 0.605
    }, {
        "ID": 846,
        "phrase": " given the subtleties involved in language, translation by artificial intelligence is in its infancy and currently works quite poorly",
        "prob": 0.31875
    }, {
        "ID": 1235,
        "phrase": " this means that further progress on the control of partial deduction will probably not come from ever more refined mathematical techniques such as new wqos, but probably more from heuristics and artificial intelligence techniques such as case-based reasoning or machine learning",
        "prob": 0.35
    }, {
        "ID": 1242,
        "phrase": " it is not claimed that the results of this paper will prove useful to ai practice",
        "prob": 0.31
    }, {
        "ID": 1243,
        "phrase": " it is not claimed that the results of this paper will prove useful to ai practice",
        "prob": 0.21000000000000002
    }, {
        "ID": 1281,
        "phrase": " we shall use a term vector representation, common in machine learning, to represent a research paper",
        "prob": 0.14
    }, {
        "ID": 1282,
        "phrase": " mladeni  [46]  goes some way to achieving this requirement, adopting a machine learning view of interface agents",
        "prob": 0.27333333333333326
    }, {
        "ID": 1282,
        "phrase": " where machine learning techniques are employed, standard tests such as precision and recall provide useful metrics for comparing learning algorithms",
        "prob": 0.33888888888888896
    }, {
        "ID": 1386,
        "phrase": " decentralized scheduler, machine learning, fixed system oriented policy \n apples: a network enabled scheduler the apples  [28]  (application level scheduling) project at the university of california, san diego primarily focuses on developing scheduling agents for individual applications on production computational grids",
        "prob": 0.40285714285714286
    }, {
        "ID": 1386,
        "phrase": "2: taxonomy of grid resource management systems attributes of resource management systems taxonomy 2 grid type (service focus) computational grids, data grids, service grids machine organization flat, cell (flat cells and hierarchical cells), hierarchical resource model schema, object model (fixed or extensible) namespace organization relational, hierarchical, graph qos soft, hard, none resource information store network directory and distributed objects resource discovery query and agents resource info dissemination batch/period (push or pull), online/on-demand scheduler organization centralised, hierarchical, decentralised scheduling policy system-centric, user centric state estimation predictive (heuristics, pricing models, machine learning) and non-predictive rescheduling periodic, event driven \n table 2 ",
        "prob": 0.3840425531914894
    }, {
        "ID": 1387,
        "phrase": " \n related work in this section we will compare our work with that of others that have applied machine learning techniques to the same data sets",
        "prob": 0.25625
    }, {
        "ID": 1398,
        "phrase": " to the best of my knowledge, there is only one large-scale present-day attempt to build an ai system based on logic, namely the cyc system, and this so far has not reported significant success in spite of a massive effort",
        "prob": 0.16399999999999998
    }, {
        "ID": 1398,
        "phrase": " as discussed above, true ai will involve semantic reasoning based on machine \"understanding",
        "prob": 0.25833333333333336
    }, {
        "ID": 1500,
        "phrase": " this was both to ensure that the entries were being correctly delimited, and to add fields to each entry that may assist in future analysis and serve as a gold standard for future machine learning tasks",
        "prob": 0.18636363636363634
    }, {
        "ID": 1727,
        "phrase": " they have used the data for developing a named-entity recognition system that includes a machine learning component",
        "prob": 0.4066666666666666
    }, {
        "ID": 1740,
        "phrase": " for example a smart room or ubiquitous computing environment that implemented the activity-centric view of context, could monitor the agent's performance of an activity, and together with machine learning techniques evolve context' to better represent the context that surrounds the particular class of activities",
        "prob": 0.27575757575757576
    }, {
        "ID": 1803,
        "phrase": " in the machine learning context, a roc graph is a plot of false positives against true positives",
        "prob": 0.36428571428571427
    }, {
        "ID": 1839,
        "phrase": "in this paper we name some of the advantages of virtual laboratories; and propose that a behaviours virtual laboratory should be useful for both biologists and ai researchers, offering a new perspective for understanding adaptive behaviour",
        "prob": 0.33809523809523806
    }, {
        "ID": 1877,
        "phrase": " it appears that their techniques do not involve machine learning",
        "prob": 0.4555555555555555
    }, {
        "ID": 1881,
        "phrase": " in chapter 3 i examine the use of machine learning techniques in natural language processing, and introduce the particular techniques i will be using in this thesis",
        "prob": 0.39444444444444443
    }, {
        "ID": 1881,
        "phrase": " \n literature review since i am trying to cover several different areas of natural language, and applying techniques from machine learning, bioinformatics and computational linguistics, my survey of previous work has necessarily been slightly cursory",
        "prob": 0.262962962962963
    }, {
        "ID": 1881,
        "phrase": " thus, in machine learning terms we must use unsupervised learning",
        "prob": 0.25833333333333336
    }, {
        "ID": 1881,
        "phrase": " there are two main motivations for applying machine learning techniques to natural languages",
        "prob": 0.3153846153846154
    }, {
        "ID": 1881,
        "phrase": " in machine learning of syntax, for example, one might propose as a suitable set of models a set of probabilistic context free grammars (pcfg), and try to find suitable parameters for them",
        "prob": 0.2217391304347826
    }, {
        "ID": 1881,
        "phrase": " i won't discuss this sort of argument any further since it is clear that this sort of a priori argumentation has very little to do with the real behaviour of actual machine learning algorithms",
        "prob": 0.255
    }, {
        "ID": 1881,
        "phrase": " to recapitulate, the aim of this thesis was to examine the validity of the argument from the poverty of the stimulus (aps) by examining the use of unsupervised machine learning algorithms on a corpus that approximates the primary linguistic data (pld) available to an infant child",
        "prob": 0.21785714285714283
    }, {
        "ID": 1881,
        "phrase": " thirdly, the study of machine learning is still in its infancy, and many of the more advanced techniques are still poorly understood: as a result i have restricted myself to fairly basic techniques",
        "prob": 0.5285714285714286
    }, {
        "ID": 1881,
        "phrase": " \n\t\t\t the major difference between these is that mdl techniques first select a class of models, and then select the best model using a ml criterion, whereas mml techniques perform the two operations at the same time",
        "prob": 0.16399999999999998
    }, {
        "ID": 1881,
        "phrase": "in this thesis i present various algorithms for the unsupervised machine learning of aspects of natural languages using a variety of statistical models",
        "prob": 0.33888888888888885
    }, {
        "ID": 1888,
        "phrase": " our work is distinct from this previous work, in that the previous applications of machine learning techniques do not use anything similar to the contextual normalization that cnibl and cnmlr use in phase 1",
        "prob": 0.36818181818181817
    }, {
        "ID": 1894,
        "phrase": "introduction this paper is concerned with the management of context for supervised machine learning from examples",
        "prob": 0.46923076923076923
    }, {
        "ID": 1897,
        "phrase": " engineering the target concept is important, due to our focus on understanding the past, as opposed to the more common focus in machine learning on predicting the future",
        "prob": 0.32105263157894737
    }, {
        "ID": 1984,
        "phrase": " the main reason for this is that the unsupervised learning of a natural language remains one of the biggest challenges for research in machine learning and it seems likely that insights gained in that area will prove useful in other areas",
        "prob": 0.46249999999999997
    }, {
        "ID": 1984,
        "phrase": " compared with all other work on unsupervised learning of grammar-like structures, the most distinctive features of this research are: \u2022 the integration of learning with other areas of ai and computation",
        "prob": 0.5055555555555555
    }, {
        "ID": 1984,
        "phrase": " what is different about the icmaus scheme (as it has been developed for ai applications) is an emphasis on partial matching and on relatively thorough searching of the space of alternative possible matches",
        "prob": 0.2157894736842105
    }, {
        "ID": 2070,
        "phrase": " drawing on conversation analysis  [16] , we enhanced our audio space system with a machine learning component that analyzes participant turn-taking behavior to identify conversational floors as they emerge, noting which participants are in which floor",
        "prob": 0.7346153846153846
    }, {
        "ID": 2288,
        "phrase": " they employed a wide variety of machine learning techniques as well as system combination",
        "prob": 0.3923076923076923
    }, {
        "ID": 2333,
        "phrase": " the ai\u00b5 model is optimal by construction of \u00b5 ai ",
        "prob": 0.15714285714285717
    }, {
        "ID": 2333,
        "phrase": " we also make some personal comments and speculations on the present status and the future of the research fields ai and machine learning themselves",
        "prob": 0.4066666666666666
    }, {
        "ID": 2333,
        "phrase": " as long as there is no convincing evidence against occam's razor, and even more importantly, as long as there is no alternate suggestion of how to define machine learning rigorously, it is worth assuming occam's razor and studying its consequences",
        "prob": 0.42083333333333334
    }, {
        "ID": 2333,
        "phrase": " we expect that in the future, machine learning will, by default, be based on occam's razor",
        "prob": 0.5083333333333333
    }, {
        "ID": 2333,
        "phrase": " without the vague concept of occam's razor, science and, hence, machine learning would probably be not existent at all",
        "prob": 0.31875
    }, {
        "ID": 2363,
        "phrase": " then we iterate the following construction (1 \u2264 i \u2264 n): -m i = w, v i is obtained from m i\u22121 = w, v i\u22121 by applying the construction of lemma 6 on a ai and t(\u03c8 i , \u03b1, \u03b2)",
        "prob": 0.2818181818181818
    }, {
        "ID": 2364,
        "phrase": " then we iterate the following construction (1 \u2264 i \u2264 n): -m i = w, v i is obtained from m i\u22121 = w, v i\u22121 by applying the construction of lemma 5 on a ai and t(\u03c8 i , \u03b1, \u03b2)",
        "prob": 0.2818181818181818
    }, {
        "ID": 2406,
        "phrase": " although our understanding is still very patchy, there is increasing success with ai applications in achieving human-like capabilities such as speech recognition, the ability to play games like chess, go or bridge, the ability to recognise visual patterns and objects in a flexible manner, and others",
        "prob": 0.253125
    }, {
        "ID": 2421,
        "phrase": " \n conclusion this has been a relatively brief outline of the possibilities offered by the icmaus framework in understanding issues in cognitive science, artificial intelligence, and beyond",
        "prob": 0.26842105263157895
    }, {
        "ID": 2480,
        "phrase": " \n interactions and supervised learning the objective of unsupervised machine learning is construction of a model which helps predict the value of any attribute with partial knowledge of other attribute values",
        "prob": 0.5761904761904763
    }, {
        "ID": 2481,
        "phrase": " \u2022 investigation of relevance of interactions in the context of supervised machine learning",
        "prob": 0.6454545454545454
    }, {
        "ID": 2481,
        "phrase": " interactions and supervised learning the objective of unsupervised machine learning is the construction of a model which helps predict the value of any attribute with partial knowledge of other attribute values",
        "prob": 0.5761904761904763
    }, {
        "ID": 2482,
        "phrase": " \u2022 investigation of relevance of interactions in the context of supervised machine learning",
        "prob": 0.5545454545454546
    }, {
        "ID": 2482,
        "phrase": " \n interactions and supervised learning the objective of unsupervised machine learning is the construction of a model which helps predict the value of any attribute with partial knowledge of other attribute values",
        "prob": 0.5761904761904763
    }, {
        "ID": 2506,
        "phrase": " it will be an important resource for the developement of indian language parsers, machine learning of grammars, lakshan charts (discrimination nets for sense disambiguation) and a host of other tools",
        "prob": 0.24285714285714283
    }, {
        "ID": 2615,
        "phrase": " many areas of artificial intelligence are producing components that could be combined with database techniques; for example these components allow us to handle speech, natural language, reasoning with uncertainty, and machine learning",
        "prob": 0.31153846153846154
    }, {
        "ID": 2797,
        "phrase": " the paper illustrates these issues and the conciseness and precision of z by the specification of a working oocp that solves an historical ai problem : parsing a context free grammar",
        "prob": 0.3210526315789474
    }, {
        "ID": 2850,
        "phrase": " \n relationship to other research on unsupervised learning in terms of broad categories of research in machine learning, development of the sp system for learning is more closely related to research on grammar induction using psgs (augmented or otherwise) than it is to research on the learning of finite-state grammars, n-grams or markov models-which are known to be less adequate for representing the structure of natural languages  (chomsky, 1957) ",
        "prob": 0.3431818181818182
    }, {
        "ID": 2850,
        "phrase": " compared with other work on unsupervised learning of grammar-like structures, the most distinctive features of this approach to machine learning are: \u2022 the integration of learning with other areas of artificial intelligence and computation",
        "prob": 0.4136363636363637
    }, {
        "ID": 2873,
        "phrase": " \n adaptive user interfaces hebb's law of learning  [4] , an essential component of many unsupervised methods in machine learning, is the basis of our efforts to generate meaningful and dynamic sets of inter-bucket links",
        "prob": 0.27307692307692305
    }, {
        "ID": 2941,
        "phrase": " this knowledge constitutes non-trivial and potentially useful information that can be obtained in many cases by applying machine learning (ml) techniques",
        "prob": 0.4789473684210526
    }, {
        "ID": 2941,
        "phrase": " in this preliminary report we explore different alternatives for developing applications which combine defeasible argumentation and machine learning techniques",
        "prob": 0.711764705882353
    }, {
        "ID": 2941,
        "phrase": " first, we briefly introduce the components of most argument-based framework and then outline possible directions for the integration of ml techniques and defeasible argumentation",
        "prob": 0.4789473684210527
    }, {
        "ID": 2941,
        "phrase": " \n integrating ml and argument-based frameworks argument-based frameworks [?, ?, ?] provide a sound formalization of defeasible reasoning, and have found a wide acceptance in many areas such as development of legal reasoning applications, multiagent systems, etc",
        "prob": 0.4862068965517241
    }, {
        "ID": 2941,
        "phrase": " next we will outline different approaches that we are currently considering to model the above issues in the context of ml techniques",
        "prob": 0.5399999999999999
    }, {
        "ID": 2941,
        "phrase": " in this context, ml techniques provide sound alternatives for considering numeric attributes or probabilistic values for deciding between conflicting hypotheses [?]",
        "prob": 0.6166666666666667
    }, {
        "ID": 2941,
        "phrase": " as explained in the previous section, we feel that the integration of defeasible argumentation and ml can tackle many of the problems described above, thus enhancing existing algorithms for text mining",
        "prob": 0.32272727272727275
    }, {
        "ID": 2941,
        "phrase": " we think that integrating ml techniques with argumentation frameworks would be highly desirable, as it would provide a combination of both analytical and inductive ml methods capable of tackling the pitfalls of each separately yet conserving their advantages, making them more attractive and suitable for other research and application areas",
        "prob": 0.396969696969697
    }, {
        "ID": 2941,
        "phrase": " in this paper we outline different alternatives for combining defeasible argumentation and machine learning techniques",
        "prob": 0.65
    }, {
        "ID": 2942,
        "phrase": " this knowledge constitutes non-trivial and potentially useful information that can be obtained in many cases by applying machine learning (ml) techniques",
        "prob": 0.3736842105263158
    }, {
        "ID": 2942,
        "phrase": " in this preliminary report we explore different alternatives for developing applications which combine defeasible argumentation and machine learning techniques",
        "prob": 0.711764705882353
    }, {
        "ID": 2942,
        "phrase": " first, we briefly introduce the components of most argument-based framework and then outline possible directions for the integration of ml techniques and defeasible argumentation",
        "prob": 0.4789473684210526
    }, {
        "ID": 2942,
        "phrase": " \n integrating ml and argument-based frameworks argument-based frameworks [sl92, cml00, pv99] provide a sound formalization of defeasible reasoning, and have found a wide acceptance in many areas such as development of legal reasoning applications, multiagent systems, etc",
        "prob": 0.409375
    }, {
        "ID": 2942,
        "phrase": " next we will outline different approaches that we are currently considering to model the above issues in the context of ml techniques",
        "prob": 0.47333333333333333
    }, {
        "ID": 2942,
        "phrase": " in this context, ml techniques provide sound alternatives for considering numeric attributes or probabilistic values for deciding between conflicting hypotheses  [mit97] ",
        "prob": 0.6166666666666667
    }, {
        "ID": 2942,
        "phrase": " as explained in the previous section, we feel that the integration of defeasible argumentation and ml can tackle many of the problems described above, thus enhancing existing algorithms for text mining",
        "prob": 0.2772727272727273
    }, {
        "ID": 2942,
        "phrase": " we think that integrating ml techniques with argumentation frameworks would be highly desirable, as it would provide a combination of both analytical and inductive ml methods capable of tackling the pitfalls of each separately yet conserving their advantages, making them more attractive and suitable for other research and application areas",
        "prob": 0.36666666666666664
    }, {
        "ID": 2942,
        "phrase": " in this paper we outline different alternatives for combining defeasible argumentation and machine learning techniques",
        "prob": 0.7214285714285715
    }, {
        "ID": 2980,
        "phrase": " two major approaches to feature selection are commonly used in machine learning  [jkp94] : filter and wrapper models",
        "prob": 0.24117647058823527
    }, {
        "ID": 3147,
        "phrase": "   \n conclusions and discussions in this paper, we have presented different soft computing and machine learning paradigms for developing a tactical air combat decision support system",
        "prob": 0.3857142857142858
    }, {
        "ID": 3208,
        "phrase": " my future work will continue to study on demarcation information and its applications in data mining and machine learning",
        "prob": 0.47333333333333333
    }, {
        "ID": 3210,
        "phrase": " \n conclusions and related work defeasible argumentation is a relatively new field in artificial intelligence",
        "prob": 0.3642857142857143
    }, {
        "ID": 3210,
        "phrase": " theoretical results have been combined with development of practical applications in ai & law, case-based reasoning and various knowledge-based systems",
        "prob": 0.22777777777777775
    }, {
        "ID": 3212,
        "phrase": " we then describe our current research, which focuses on the use of machine learning to assess the progress of conversational engagement",
        "prob": 0.4066666666666666
    }, {
        "ID": 3212,
        "phrase": " we are applying machine learning techniques to the recognition of various forms of conversational engagement, using voice activity detection and prosodic cues rather than speech recognition",
        "prob": 0.3227272727272727
    }, {
        "ID": 3212,
        "phrase": " we briefly describe our current research on applying machine learning to infer degrees of conversational engagement from observed conversational behavior",
        "prob": 0.33888888888888885
    }, {
        "ID": 3213,
        "phrase": " our audio space system includes a machine learning component that analyzes participant turn-taking behavior to identify conversational floors as they emerge, noting which participants are in which floor",
        "prob": 0.7434782608695651
    }, {
        "ID": 3306,
        "phrase": " improved machine learning methods will also be critical",
        "prob": 0.34444444444444444
    }, {
        "ID": 3441,
        "phrase": " there are several issues we have to address during our research activities in the coming years: \u2022 enable service specification, creation and composition via business process descriptions using a business modelling language \u2022 dynamic, automatic service composition by using self-organisation, evolution, and applying artificial intelligence \u2022 describe software components analogously to dna \u2022 add replication rate dependence on usage feedback \u2022 create a software services ecosystem capable of supporting the evolution of populations of service supply chains: a system that is generic enough to be available to all smes, but also able to highly specialise and tailor solutions to the individuals smes",
        "prob": 0.2043478260869565
    }, {
        "ID": 3474,
        "phrase": " methods the various sections of our system can be broadly classified as the data gathering module (composed of the gps and the pda), the machine learning module (performed on the pc) and the alerting module (the pda)",
        "prob": 0.5041666666666667
    }, {
        "ID": 3474,
        "phrase": " the machine learning module of the system is contained in the user's pc",
        "prob": 0.3727272727272727
    }, {
        "ID": 3474,
        "phrase": " the pda software uses the tables generated by the machine learning routines to alert the user if he/she will be late for an appointment",
        "prob": 0.30000000000000004
    }, {
        "ID": 3474,
        "phrase": " the user's movements through space and time (gps data) are fed into our machine learning (ml) filter",
        "prob": 0.2733333333333333
    }, {
        "ID": 3474,
        "phrase": " the ml filter uses clustering techniques to find the user's significant places (where he/she spends time)",
        "prob": 0.50625
    }, {
        "ID": 3474,
        "phrase": " the pc system used to process the gps data and run the machine learning algorithms is a compaq evo n800v with 256mb ram running at 2ghz",
        "prob": 0.24285714285714283
    }, {
        "ID": 3600,
        "phrase": " in this paper, we describe the machine learning component of one such adaptive communication system",
        "prob": 0.425
    }, {
        "ID": 3632,
        "phrase": " even the most sophisticated machine learning methods are unlikely to remove the \"curse of dimensionality\" that limits the possibilities of unsupervised learning in high-dimensional spaces",
        "prob": 0.255
    }, {
        "ID": 3959,
        "phrase": "24 \n [ charniak93][daelemans02] [manning99], often extended by artificial intelligence and information theoretic techniques [rathnaparkhi98]",
        "prob": 0.22142857142857145
    }, {
        "ID": 4230,
        "phrase": " similarly, there also exist other techniques, which involve graphical classification of the concepts and then semantic matching based on set theory and ai concepts  [32] ",
        "prob": 0.3
    }, {
        "ID": 4333,
        "phrase": "  nevertheless, zhang, otterbacher, and radev (2003)  and  zhang and radev (2004)  continue this work using machine learning algorithms to identify the cross-document relations",
        "prob": 0.45499999999999996
    }, {
        "ID": 4544,
        "phrase": " such findings should be of relevance in the deployment of machine learning methods in different problem domains",
        "prob": 0.5461538461538461
    }, {
        "ID": 4552,
        "phrase": " however, this attitude does not deny the machine learning research works",
        "prob": 0.4636363636363636
    }, {
        "ID": 4552,
        "phrase": " the \"machine learning\" design of the model then contributes to help the participants to approach a commonly agreed solution  [3] ",
        "prob": 0.20666666666666667
    }, {
        "ID": 4693,
        "phrase": " in previous work we saw how the application of machine learning models was limitless on the known signal pulse detection problem using wavelets",
        "prob": 0.42631578947368426
    }, {
        "ID": 4694,
        "phrase": " in this application we have confirmed the easy of use of svms as a machine learning tool regarding its capability to provide different weights for both classes, allowing the training system to comply with the otherwise difficult probability of false alarm rates",
        "prob": 0.325
    }, {
        "ID": 4776,
        "phrase": " ( 12 ) static mdl is omnipresent in machine learning and applications, see also section 8",
        "prob": 0.2583333333333333
    }, {
        "ID": 4988,
        "phrase": " this work does not consider gaze because it has been studied more recently in ai models for turn taking  (thorisson (1997) ;  cassell et al",
        "prob": 0.22142857142857145
    }, {
        "ID": 5153,
        "phrase": " 03 ) and (zhang & radev 04) continue the work with some experiments, during which they use machine learning techniques to identify the cross-document relations",
        "prob": 0.41764705882352937
    }, {
        "ID": 5327,
        "phrase": " a first trend was to directly apply machine learning methods to replace ie components",
        "prob": 0.22142857142857145
    }, {
        "ID": 5469,
        "phrase": " and this opens up the possibility for huge improvements in areas such as machine learning (e",
        "prob": 0.19090909090909092
    }, {
        "ID": 5568,
        "phrase": "introduction probabilistic models of application domains are central to pattern recognition, machine learning, and scientific modeling in various fields",
        "prob": 0.5055555555555555
    }, {
        "ID": 5672,
        "phrase": " finally, we are going to explore further the properties of tsallis entropy into optimization methods in artificial intelligence applications",
        "prob": 0.20666666666666667
    }, {
        "ID": 5714,
        "phrase": " this thread of work on machine learning, spawned yet more work in the unsupervised domain, but trying to perform dynamic clustering ( where the patterns in the input date move over time)",
        "prob": 0.41363636363636364
    }, {
        "ID": 5744,
        "phrase": " potentially, there are several machine learning approaches to the numerical part of the project including hidden markov models (hmms) and kalman filters, markov networks and ising models (or even cellular automata)",
        "prob": 0.27307692307692305
    }, {
        "ID": 5843,
        "phrase": " the huge search complexities are tackled by a combination of indexing techniques, isomorphism abstraction, machine learning and knowledge reuse through references",
        "prob": 0.2833333333333333
    }, {
        "ID": 5930,
        "phrase": " therefore, instead of trying to find an analytical model for rssi, we used a machine learning approach in our investigation",
        "prob": 0.38125000000000003
    }, {
        "ID": 6308,
        "phrase": " the only remaining components of \u03c8 \u03b8 consist of at most \u03c8 k \u03b8 and one more component \u03c8 l \u03b8 which takes the value of \u03b8k if \u03b8k is not the maximal ml component of \u03b8",
        "prob": 0.23846153846153847
    }, {
        "ID": 6430,
        "phrase": " \n identifying false positives pietraszek  [15]  tackles the problem of reducing false positives by introducing an alert classifier system (alac, adaptive learner for alert classification) based on machine learning techniques",
        "prob": 0.5423076923076924
    }, {
        "ID": 6430,
        "phrase": " pietraszek and tanner  [39]  further expand the previous work using alert post-processing based on data mining and machine learning techniques",
        "prob": 0.3736842105263158
    }, {
        "ID": 6676,
        "phrase": " although the present results are based on ml encoding/decoding, the sparsity and graphical structure of our constructions render them suitable candidates for practical message-passing schemes, which remains to be investigated in future work",
        "prob": 0.284
    }, {
        "ID": 6784,
        "phrase": " this project raises a number of interesting ai research issues, including imagination process management for coordinating visual object interactivity, natural language understanding and autonomous agents (objects, landscapes and their interactions) in the context of story",
        "prob": 0.6464285714285715
    }, {
        "ID": 6785,
        "phrase": " this project raises a number of interesting ai research issues, including imagination process management for coordinating visual object interactivity, natural language understanding, and autonomous agents (objects, landscapes and their interactions) in the context of a story",
        "prob": 0.6107142857142858
    }, {
        "ID": 6948,
        "phrase": "  [11]  report on machine learning techniques for combining aspect mining analyses",
        "prob": 0.25833333333333336
    }, {
        "ID": 7000,
        "phrase": " yet both hard ai and the more recent \"soft\" specializations of ai have been a seminal source of all sorts of interesting and useful pattern models",
        "prob": 0.19375
    }, {
        "ID": 7175,
        "phrase": " up till now, the automation of knowledge acquisition using machine learning methods is still an active area of research  [4] ,  [16] , the main objective of a learning model is to have models capable of thinking and acting rationally; a rational system should acquire knowledge and respond rationally at right times",
        "prob": 0.346875
    }, {
        "ID": 7333,
        "phrase": " in most of these applications, then, a key concern (albeit one usually left for future work) is the development of machine learning models to recognize \"who is talking to whom\"that is, which participant is party to which conversation",
        "prob": 0.6863636363636364
    }, {
        "ID": 7333,
        "phrase": " the system works by  (1)  applying machine learning models to identify the participants of the conversation(s) and (2) increasing intelligibility within each conversation by providing a customized audio mix to each participant",
        "prob": 0.7772727272727272
    }, {
        "ID": 7333,
        "phrase": " \n tools for qualitative analysis a system attempting to model conversational behavior using supervised machine learning techniques (our own  [2] , or others mentioned in the introduction, e",
        "prob": 0.405
    }, {
        "ID": 7334,
        "phrase": " in most of these applications, then, a key concern (albeit one usually left for future work) is the development of machine learning models to recognize \"who is talking to whom\"that is, which participant is party to which conversation",
        "prob": 0.5954545454545455
    }, {
        "ID": 7334,
        "phrase": " the system works by  (1)  applying machine learning models to identify the participants of the conversation(s) and (2) increasing intelligibility within each conversation by providing a customized audio mix to each participant",
        "prob": 0.7318181818181818
    }, {
        "ID": 7334,
        "phrase": " \n tools for qualitative analysis a system attempting to model conversational behavior using supervised machine learning techniques (our own  [2] , or others mentioned in the introduction, e",
        "prob": 0.555
    }, {
        "ID": 7593,
        "phrase": " two major issues are the development of a specific annotation editor for domain specialists and a set of machine learning and linguistic processing tools tuned for the biomedical domain",
        "prob": 0.3227272727272727
    }, {
        "ID": 7595,
        "phrase": " \n information extraction for ontology design acquisition of ontological knowledge is a well-known bottleneck for many ai applications and a large amount of work has been devoted to knowledge acquisition from text",
        "prob": 0.30869565217391304
    }, {
        "ID": 8166,
        "phrase": "introduction several machine learning concepts have been tested in game domains, since strategic games offer ample opportunities to automatically explore, develop and test winning strategies",
        "prob": 0.29583333333333334
    }, {
        "ID": 8167,
        "phrase": "introduction several machine learning concepts have been tested in game domains, since strategic games offer ample opportunities to automatically explore, develop and test winning strategies",
        "prob": 0.25416666666666665
    }, {
        "ID": 8208,
        "phrase": " using google with the keyword \"generic design\" mainly leads to references in the domains of ai and knowledge-acquisition (e",
        "prob": 0.2733333333333333
    }, {
        "ID": 8300,
        "phrase": " introduction in machine learning pure applications of mdl are rare, partially because of the difficulties one encounters trying to define an adequate model code and data-to-model code, and partially because of the operational difficulties that are poorly understood",
        "prob": 0.4321428571428572
    }, {
        "ID": 8301,
        "phrase": " introduction in machine learning pure applications of mdl are rare, partially because of the difficulties one encounters trying to define an adequate model code and data-to-model code, and partially because of the operational difficulties that are poorly understood",
        "prob": 0.3964285714285714
    }, {
        "ID": 9077,
        "phrase": " we are also currently researching the feasibility of applying machine learning algorithms and statistical models to identification and ranking of desired paths in the structure of the sources",
        "prob": 0.42631578947368426
    }, {
        "ID": 9078,
        "phrase": "  \n conclusions we achieved our objective to provide an audio portal interface to rss feeds for the visual impaired users and audio browser for mobile telephonic interfaces further work can be invested into more complex dialog management features, including machine learning techniques for using the dialog context and previous dialog paths in predicting the future user's behavior in browsing",
        "prob": 0.907142857142857
    }, {
        "ID": 9079,
        "phrase": "  \n conclusions we achieved our objective to provide an audio portal interface to rss feeds for the visual impaired users and audio browser for mobile telephonic interfaces further work can be invested into more complex dialog management features, including machine learning techniques for using the dialog context and previous dialog paths in predicting the future user's behavior in browsing",
        "prob": 0.8833333333333332
    }, {
        "ID": 9080,
        "phrase": " machine learning techniques can be employed in ranking algorithms for complex dialog management features for using the dialog context and previous dialog paths in predicting the future user's behavior in browsing",
        "prob": 0.644
    }, {
        "ID": 9083,
        "phrase": " machine learning techniques can be employed to rank and personalize dialog paths",
        "prob": 0.425
    }, {
        "ID": 9084,
        "phrase": " more advanced dialog management techniques use ai planning techniques for controlling the conversation in planning domains (e",
        "prob": 0.6066666666666667
    }, {
        "ID": 9085,
        "phrase": " more advanced dialog management techniques use ai planning techniques for controlling the conversation in planning domains (e",
        "prob": 0.6066666666666667
    }, {
        "ID": 9086,
        "phrase": " more advanced dialog management techniques use ai planning techniques for controlling the conversation in planning domains (e",
        "prob": 0.6066666666666667
    }, {
        "ID": 9190,
        "phrase": " related work the application of machine learning techniques to the domain of telecommunications is a rapidly growing area",
        "prob": 0.33999999999999997
    }, {
        "ID": 9240,
        "phrase": " more generally, we are interested in the construction of program development tools based on machine learning techniques",
        "prob": 0.22142857142857145
    }, {
        "ID": 9241,
        "phrase": " a machine learning component characterizes the syntax and semantics of the user's information",
        "prob": 0.3416666666666666
    }, {
        "ID": 9256,
        "phrase": " encouraged by the success of this one trainable component, an architecture for corpus-driven system development was proposed which uses machine learning techniques to address a number of natural language processing problems  (lehnert et al",
        "prob": 0.204
    }, {
        "ID": 9266,
        "phrase": " much work in management science and in distributed ai adopts a somewhat complementary view",
        "prob": 0.23846153846153847
    }, {
        "ID": 9266,
        "phrase": " last but not least, our work is related to work applying organization theory and management techniques to the eld of distributed ai  (fox, 1981; malone, 1987; durfee, lesser, & corkill, 1987) ",
        "prob": 0.305
    }, {
        "ID": 9270,
        "phrase": " finally, we plan to use machine learning techniques on flecs's choice points to gain a possibly automated understanding of the mapping between e cient planning methods and planning domains and problems",
        "prob": 0.3375
    }, {
        "ID": 9277,
        "phrase": " alternatively, machine learning techniques can be used to derive descriptions from example objects",
        "prob": 0.3923076923076923
    }, {
        "ID": 9277,
        "phrase": " a function-based object recognition system is an example of a cv system for which machine learning techniques can be useful in the development of object descriptions",
        "prob": 0.4789473684210526
    }, {
        "ID": 9277,
        "phrase": " the omlet system is an example of using machine learning techniques to aid in the development of a computer vision system",
        "prob": 0.31875
    }, {
        "ID": 9281,
        "phrase": " the development of these and other pruning rules may prove important as machine learning tackles ever more complex search spaces",
        "prob": 0.3588235294117647
    }, {
        "ID": 9298,
        "phrase": " in practice, the common use of occam's razor in machine learning seeks to minimize surface syntactic complexity",
        "prob": 0.25625
    }, {
        "ID": 9298,
        "phrase": " \n other theoretical objections to the occam thesis most machine learning systems explicitly or implicitly employ occam's razor",
        "prob": 0.44375
    }, {
        "ID": 9298,
        "phrase": " in addition to its almost universal use in machine learning, the principle of occam's razor is widely accepted in general scienti c practice",
        "prob": 0.5055555555555555
    }, {
        "ID": 9298,
        "phrase": " several attempts have been made to provide theoretical support for the occam thesis in the machine learning context  (blumer et al",
        "prob": 0.25625
    }, {
        "ID": 9298,
        "phrase": " \n new experimental evidence against the occam thesis the theoretical and experimental objections to the occam thesis do not appear to have greatly diminished the machine learning community's use of occam's razor",
        "prob": 0.5695652173913043
    }, {
        "ID": 9298,
        "phrase": " the version of occam's razor examined in this research has been used widely in machine learning with apparent success",
        "prob": 0.47333333333333333
    }, {
        "ID": 9298,
        "phrase": " if this thesis is accepted then one of the key challenges facing machine learning is to understand these deeper qualities and to employ that understanding to place machine learning on a sounder theoretical footing",
        "prob": 0.6409090909090909
    }, {
        "ID": 9301,
        "phrase": " by automatically adapting this scheduling system to the distribution of scheduling problems, the adaptive approach resulted in a significant improvement in scheduling performance over an expert strategy: the best adaptation found by machine learning exhibited a seventy percent improvement in scheduling performance (the average learned strategy resulted in a fifty percent improvement)",
        "prob": 0.2657894736842105
    }, {
        "ID": 9301,
        "phrase": " this paper has described the application of adaptive problem solving, using the lr-26 scheduling system and the composer machine learning system, to automatically learn effective scheduling heuristics for deep space network communications scheduling",
        "prob": 0.575
    }, {
        "ID": 9306,
        "phrase": " while most ai work in visual reasoning has focused on diagrams and their role in controlling search, in recent years we have seen the development of a class of problem solvers that are imagistic, i",
        "prob": 0.30500000000000005
    }, {
        "ID": 9343,
        "phrase": "caching su cient statistics computational e ciency is an important concern for machine learning algorithms, especially when applied to large datasets  (fayyad, mannila, & piatetsky-shapiro, 1997; fayyad & uthurusamy, 1996)  or in real-time scenarios",
        "prob": 0.22592592592592592
    }, {
        "ID": 9345,
        "phrase": " \n related work windowing techniques are related to several other research areas in the eld of machine learning, including sub-sampling, active learning, and techniques for complexity reduction such as feature subset selection",
        "prob": 0.27307692307692305
    }, {
        "ID": 9345,
        "phrase": " according to the term's original de nition (within the eld of machine learning), active learning includes \\any form of learning in which the learning program has some control over the inputs it trains on",
        "prob": 0.2318181818181818
    }, {
        "ID": 9377,
        "phrase": " for segmentation, applying machine learning techniques  (beeferman et al",
        "prob": 0.51
    }, {
        "ID": 9551,
        "phrase": "introduction the notion of using a neural network, or other machine learning system, to implement components in a text-tospeech system is an attractive one",
        "prob": 0.33888888888888885
    }, {
        "ID": 9564,
        "phrase": " although these works are usually either theoretical, or not based on machine learning, they can serve as a good basis for practical machine learning sosages",
        "prob": 0.4263157894736842
    }, {
        "ID": 9599,
        "phrase": " finally, we believe that methods and ideas developed in machine learning research  [22]  are particularly useful for contentbased recommending, filtering, and categorization, as well as for integrating with collaborative approaches  [5, 4] ",
        "prob": 0.2318181818181818
    }, {
        "ID": 9599,
        "phrase": " given the future potential importance of such services to digital libraries, we look forward to an increasing application of machine learning techniques to these challenging problems",
        "prob": 0.40499999999999997
    }, {
        "ID": 9670,
        "phrase": " combining has also been studied in other fields such as econometrics, under the name \"forecast combining\"  [28] , or machine learning where it is called \"evidence combination\"  [4, 23] ",
        "prob": 0.6066666666666667
    }, {
        "ID": 9704,
        "phrase": " if we look back at the hmc systems of the seventies we see a clear division of approach that persists to this day: on the one hand there were theoreticallymotivated models in the artificial intelligence tradition that emphasized reasoning and a deep understanding of language based on knowledge of the world about which the conversation took place",
        "prob": 0.190625
    }, {
        "ID": 9704,
        "phrase": " the next key step in empirical linguistics, one not yet achieved anywhere, will be such a robust model of english dialogue structure, probably using machine learning methods, a task so far only attempted for speech interfaces in very narrow domains",
        "prob": 0.4862068965517241
    }, {
        "ID": 9779,
        "phrase": " such tasks should instead be addressed by model-independent machine learning techniques",
        "prob": 0.3416666666666666
    }, {
        "ID": 9780,
        "phrase": " for instance, it will be possible to develop specialized agents whose goal is to identify emerging perspectives, using heuristic knowledge and machine learning techniques",
        "prob": 0.255
    }, {
        "ID": 9853,
        "phrase": " this is particularly true since many domains of interest in ai (and other application areas) are finite; any version of cox's theorem that uses par5 is simply not applicable in these domains",
        "prob": 0.305
    }, {
        "ID": 9871,
        "phrase": " we also describe several other applications or potential applications of the same subroutine, to tsp heuristics, greedy matching, machine learning, gr\u00f6bner basis computation, and local optimization methods",
        "prob": 0.5045454545454545
    }, {
        "ID": 9871,
        "phrase": " \n constructive induction a second potential application arises in machine learning",
        "prob": 0.5083333333333333
    }, {
        "ID": 9871,
        "phrase": " we apply these data structures to hierarchical clustering, greedy matching, and tsp heuristics, and discuss other potential applications in machine learning, gr\u00f6bner bases, and local improvement algorithms for partition and placement problems",
        "prob": 0.27307692307692305
    }]
}, {
    "topic_id": 17,
    "top_words": ["qy", "vq", "qa", "bw", "br", "gq", "gr", "sy", "xr", "xy", "gw", "bt", "xa", "ty", "py"],
    "phrases": [{
        "ID": 4552,
        "phrase": " \n \u00a2\u00a1 \u00a4\u00a3 \u00a6\u00a5 \u00a8 \u00a7 \u00a9 \u00a4 \u00a9 \"! \u00a4# $ %# '& (# \u00a3 \u00a1 0) 1\u00a3 2 \u00a4! 3 \u00a7 4\u00a9 \u00a25 6\u00a3 87 9 \u00a3 \u00a1 a@ \u00a9 b7 c$ %d e& f# \u00a3 \u00a1 \u00a4d \u00a7 g h \u00a9 \u00a1 i& ($ p rq ts vu xw `y ba 8c dq te vf 6g vh pi qa 4r sy bt tu wv \u00a6r ax 8q ty bt yf g u q ts v ba 8 bq t \" s y tg b q tu `a 4a 3x 8q s yr qs p s d e gf ih w k j ml n po %q r ph ws r p s dr qt uq vr ph ws r 4 u dr qt uw x sh yj wf zr p{ | dr qt } t 4 s 6 q t % 6 6 t 6 4 t t t t t m p ( m 4 p s | e gf ih w k j ml n po v pe g qn px sj i r p{ |e h t y tl s s se gl 6t tw \u00a1x uh yj wf zr p{ | dr qt } \u00a2 4 t v \u00a3 t 6 p t 6\u00a2 p \u00a4 u \u00a3 % m p p ( m p \u00a5 \u00a6 s 4 t 6 q 6 t y 4 ( m p \u00a7 v\u00a9 \u00aa \u00ab \u00ac \u00ae p\u00aa \u00afq c se 8o n 6\u00b0x sh \u00b1n po rj wf zr p s k j i |n ur p{ c\u00b0n p t e gf ih ir 4j i |n p \u00aer p{ cr p\u00b2 e g tj ih \u00b3 |h \u00b5\u015b{ dr p\u00b0e ' \u00b6n p ur 4j ix sf zr 4{ \u2022{ xr 4 u\u00b2 px \u00aer p\u00b2 pe \"\u015bf in 6\u00b0ge h wh w | u\u00b2 r 4 \u00ae dx u \u00ae qe gf ih yj zr p u s | u\u00b2 2j i se a ue ge ' sh en 4o pj i se ax uh we f 'q c se h we r p\u00b2 e g tj ih \u00b5r 4f ie 8j l s\u015b |\u00b0'r p{ |{ k l \u00b6 |s 8\u00fa{ |e s 8e g tj ie \u00b9o `n pf \u00b5h w\u00fde \u00b0 k \u00ba \u00ae\u00b0 sn ps r p | uh \u00a6h wx s\u00b0 \u00a4j i ur 4j qn s r p | 8\u00bb t un ' \u2022{ |e ' q\u00b2 e r p \u00ae e\u00b0gn t e gf ih ir j i dn p uh fr 4f ie \u00a1\u00bc ux u |{ k j (s r p tx \u00aer 4{ d{ k l 6p\u00bd bn s r 4 | 8\u00bb q sn ' \u2022{ |\u00be e ' q\u00b2 e bn 4o vj i ue gh we br p\u00b2 pe 6j ih \u2022r 4f ie e s\u00b0n t se ir 4h r\u00b0n t e gf ih ir j i |n \u00aer 4{ \u00b0gn 6j ie 6j c \u2022 u |\u00b0z a\u00b0'r 4x uh we h r \u00b6\u00fdn 6n 4f \"h we \u00far 4f zr 4j i |n p \u00bf\u00bc ye gj m fe e j i ue \"j cn d q dh yj i | s\u00b0gj ij l q\u00fde h n po \u00a6\u00bb t un ' \u2022{ |e ' s\u00b2 pe \u2022q c s dh qf in \u00bc u{ |e s \u00e0 |h %s r p\u00b2 s k \u00ba \u00aee ' \u00b1\u00bc 6l \u00b3j i ue r{ dr p\u00b0z\u00bb \u00b1n 4o v\u00bb q sn ' \u2022{ de s\u00b2 e \u00a1r 4\u00b0'\u00e1 6x u |h w k j i dn p ej in 6n { |h cr 4 \u00ae bt 6r ph (r f ie h wx s{ k j 't r 4\u00b2 e 6j ih \u00ba \u00ae u \u00b5 k j % s k \u00e2 8\u00b0x s{ k j %j in pr sr p\u015bj j in p s k \u00e3 be gf ie 6j % sn ps r p | uh r 4 \u00ae \u00b5j in x ub sr 4j ie e g\u00e4 q |h yj i | u\u00b2 e\u00bb t sn \u2022{ |e ' q\u00b2 e \u00a6\u00bc \u00aer 4h we h q c se eo `f zr ps 8e cn pf i\u00bb \u00b9qf in \u00fdn h we \u00a4 | 3j i u |h \u00far p\u00fde gf \u00b3r 4 ds 8h bj in f ie \u00b0gj i k o `l \u00e5j i u |h qf in \u00bc u{ |e s \u00bc 6l \u00bc sx u |{ d s | u\u00b2 r s 8n t sx u{ |e fj in p \u00aer p u s{ |e c\u00bb t un ' \u2022{ |e ' q\u00b2 e \u00a1r p\u00b0'\u00e1 6x s dh w k j i |n vq c se rs 8n t sx s{ de cr p\u00b0'\u00e1 6x u k f ie h \u00bb t un ' \u2022{ |e ' q\u00b2 e pj i qf in x u\u00b2 p r \u00b3\u00b0'r 4h we g\u00be \u00bc \u00aer 4h we ' is 8e gj i sn t sn p{ dn p\u00b2 pl \u00b0'r 4{ |{ de ae \u00a1 |\u00fa\u00fa{ |e \u00bd bn ' \u2022 iae \u00a1x u{ |e h \u00e7 ae \u00a1\u00bd bae p\u00e8 \u00e9 6r bj ie \u00b0z u u d\u00e1 6x ue cj i ur 4j f \u00aer ph (\u00bc ye e 8e s 8\u015b{ |n l e ' \u00b1h wx u\u00b0g\u00b0e h wh yo x s{ |{ |l r 4\u00b0gf in h wh cr \u00a6 sn h yj fn po e g\u00e4 q\u00fde gf wj \u2022h yl qh yj ie s \"\u0229 \u00eb \u00ec r\u00ed b\u00ee b\u00ef \u2022\u00f0 v\u00f1 \u00a1\u00f2 \u00b3\u00f3 \u00b5\u00f4 \u00f5 wy s ga 4u `u xw `t qa py u \u00e5\u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu q tt sa 4y u g \"\u00f9 q \u00d7 qa \u00b6\u00fa a pa 4y \u00f9 va ds bu x w ` \"q t a t sr sq tu bw `y \u00fb \u00f9 ba \u00f8 ga pq qu x \u00fcr t\u00fd \u00f9 us v \"q qy \u00fe\u00f6 4r q \"\u00df bs y ga 4\u00f8 ew `y s ga 4\u00f8 q q\u00f6 w `r qy v p\u00e0 \u00e1 b\u00f9 vw ` e\u00f9 vq s \u00b1 ar q w `\u00d7 6q 6 a \u00e2q 3u q t\u00f8 gt qa y \u00aes b i\u00fa a p\u00f8 8r t\u00fd bq tt qa py u g \u00b5r t\u00fd \u00d7 q q\u00f8 i \u00aew `y bt \u00b5\u00f6 4r q \"\u00df bu `a \u00e3 yw x ii e r e zs b\u00f8 \u00fd q q\u00f6 4a w `y a\u00f8 a \u00f6 a 4y u ci qa q t\u00f8 \u2022\u00e4 |\u00e5 ae y\u00e0 t\u00e7 \u00b5y va pr q\u00fd b \u00f9 va pa q t\u00f8 gu xw `a p z pg q ty \u00df a 4\u00f8 g\u00f9 vq t\u00df ar u i p\u00e8 a pu xu e \u00aey br 6\u00e8 y g ua \u00e3 bq t \"\u00df bu `a \u00b3r q\u00fd % zs \u00f6 \u00f9 \u00e5q tt sa 4y u g \u00a1w ` p\u00e9 \u2022u `w x\u00ea q \u00b9\u00e4 `\u00eb \u00ec ae y\u00e0 \u00ae\u00e9 \u2022u `w x\u00ea q a 4y vt sq tt sa p q \u00f6 r sy \u00ae\u00d7 qa 4\u00f8 gq 6u w `r qy a \u00f9 b\u00f8 gr qs vt q\u00f9 \" zw ` \"\u00df bu xa \u00a6 g\u00f6 \u00f8 gw `\u00df y g f g\u00f9 vq 6 \u2022\u00df b\u00f8 gr q \"\u00df y r g\u00f9 ba \u00a6 \u00df a q te qa p\u00f8 c\u00e8 w d g\u00f9 \"\u00ed us ba i gw xr sy v r ya p\u00f8 w `\u00d7 qa \u00fd \u00a4\u00f8 gr q \u00f9 ba eu q 6 a i s y a p\u00f8 gq qy v\u00f6 a s\u00e0 u \u00ee\u00f9 vw xu `a e \u00f9 bw q t\u00df v\u00df b\u00f8 r uq q\u00f6 \u00f9 \u00e5q qu xu `r 6\u00e8 \u00a6 r qy ba \u00b1 r 2\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g a \u00a6\u00e8 w x \u00f9 \u00b6\u00e9 \u2022u `w x\u00ea q bg \u00ae \u00f9 va \u00f8 a zs bu x w `y bt \u00e5 bw `q qu xr st qs ba 8\u00fa a p\u00f6 4r q \"a p \u00b5q \u00b9 za p\u00f8 w `a p \u00a6r t\u00fd \u2022\u00f8 ga 4\u00df a w x w `r qs \u00b3\u00ed us ba p z w `r qy 4\u00e0 \u00ef br q\u00f8 \u00b1q ty dq qt qa 4y u gr \u00e5\u00fa a r t\u00fd \u2022q ty \u00aei \u00a4s v za sg vw x \u00b5 \u00f9 br qs bu \u00b6\u00fa a iq t\u00fa vu xa 8 gr \u00b9\u00df b\u00f8 gr 6\u00d7 \u00aew ` ya r q \"a e \u00aew `y v \u00b6r t\u00fd \u2022 a 4\u00f8 g\u00d7 \u00aew `\u00f6 4a qg v s v\u00f6 \u00f9 dq q \u00b3t qw `\u00d7 \u00aew xy bt \u00b9q qy a \u00e3 y\u00df a p\u00f8 z \u00a1q s y\u00d7 \u00aew `\u00f6 4a bw xy \"q \u00b1\u00f0 va 4u ir t\u00fd z\u00df a p\u00f6 4w `q qu xw q t w `r qy \u00e0 t\u00e1 b\u00f9 vw ` cw c \u00f9 va b ii u\u00df a br t\u00fd q tt sa 4y u c \u00f9 vq t r \u00f9 bw c\u00df vq t\u00df a 4\u00f8 \u00e8 w xu `u \u00fd \u00a4r y\u00f6 s v br sy q ty v 3w xy \u00b6\u00df vq q\u00f8 z gw `\u00f6 4s bu q t\u00f8 g s g\u00f9 ba \u00f6 s i gr q \"w ` gq 6 gw xr sy 3r q\u00fd f s v\u00f6 \u00f9 \u00b6q tt qa py u g p\u00e0 r qy u a p a\u00df r q\u00f8 q t\u00f8 gi \u00b3\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy vq tu tq qt qa 4y u u `r ur se \u00b3 gr \u00a6 g\u00f9 ba \u2022\u00f0 va pu ` v %r q\u00fd bu xw `y bt qs vw ` z w \u00f6 4 (q ty v 8 \"a p iu r q\u00f8 gi d\u00fd \u00a4r q\u00f8 ar s\u00f8 a 2\u00f8 ga pq qu xw z w \u00f6 \" ar y ya pu ` r t\u00fd \u00a6q tt sa 4y u g 2\u00e4 \u00f1 6ae y\u00e0 (\u00ef v\u00f8 r s \u00f2 \u00f9 vw ` pg % 2q ty \u00aei yw x\u00f3 a p\u00f8 a py s 8 ii \u00ae\u00df a p r t\u00fd \u00df vq t\u00f8 za p\u00f8 \u00b3q ty z\u00df a 4a \u00f6 \u00f9 t qa 4y va 4\u00f8 q 6 w `r qy \u00b6 i \u00ae z a p 2 \u00b3q t\u00f8 ga 8\u00fa bs bw `u x p\u00e0 v\u00ef br q\u00f8 \u00b5w xy i q ty v\u00f6 4a qg b g\u00f9 ba p \u2022\u00f9 vw xu `u xw `\u00df v \u00b3 \u00f8 q tw `y zi y z a 4 \u00f4\u00e4 `\u00eb ae w q i\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy vq tu q tt qa py u g\u00f9 vq 6 w p\u00f6 4r qy by va p\u00f6 ' ga p \u00b9 r 2q \u00df vs b\u00fa bu `w `\u00f6 \u00b5 a pu xa p\u00df b\u00f9 br sy ba \u00b5y va zu \u00e8 r s\u00f8 e \u00a6\u00e8 \u00f9 vw `\u00f6 \u00f9 \u00f6 pq ty 8\u00df b\u00f8 gr 6\u00d7 \u00aew ` ya f g\u00f8 gq qw xy e gw x \"a q t\u00fa bu `w `y bt \u00a6w `y y\u00fd \u00a4r q\u00f8 g 2q 6 w `r qy \u00b1 g\u00f9 b\u00f8 r ss bt q\u00f9 8\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy \u00e0 '\u00e1 b\u00f9 bw ` q tt qa py u ea a 4y u gw `q qu xu `i \u00b6 \u00f8 ga pq t g \u00b1 \u00f9 va 2s v za p\u00f8 8w xy v\u00df bs y iq s 8q \u00a4\u00ed us ba p\u00f8 i \u00f5w xy u r \u00a4 g\u00f9 ba \" w ` \"a gq q\u00fa bu `a \u00b9 bq 6 q t\u00fa vq s za s\u00e0 \u00f6 w ` aw `u q t\u00f8 b zi y z a 4 \u00f7\u00fa ui 3\u00f8 va 4u `u xa eq ty v 3c r \u00aer qy ba pi \u00e4 x\u00eb \u00f9 ae \u00f6 4q qy \u00e5u `a pq t\u00f8 gy \u00b9 gr g\u00f8 gq qy v u `q t a e za py s ga 4y v\u00f6 4a p w xy u gr \u00ed ss va 4\u00f8 gw xa \u00fd \u00a4r s\u00f8 r q\u00fa b gq tw `y bw `y bt \u00f5t sa 4r st q\u00f8 q t\u00df b\u00f9 bw \u00f6 4q qu \u2022w `y y\u00fd \u00a4r q\u00f8 g 2q 6 w `r qy \u00faq t\u00fa r qs y i \u00f9 ba \u00b6\u00fb \u00a6y bw x a \u00fa u q 6 ga p p\u00e0 fh pr t g\u00f9 r t\u00fd \u00b1 \u00f9 ba za i \u00ae z a p \u00fc\u00f9 vq \u00d7 sa \u00a4q \u00fe\u00df b\u00f8 ga p ba \u00f0 vy ba \u00fb bq 6 q t\u00fa vq s za 3 \u00f9 vq t \u00e5 i gr q\u00f8 ga p a g\u00f9 ba e \u00aey br 6\u00e8 u xa yt qa \u00a4r t\u00fd \u00b1 \u00f9 va q tt qa py u p\u00e0 \u00ee\u00f9 bw `u xa \" g\u00f9 bw 8w ` et sr \u00aer \u00ae \u00f5\u00fd \u00a4r q\u00f8 i zi y z a 4 2 e\u00e8 \u00f9 ba p\u00f8 a \" \"r s z e\u00fd q q\u00f6 g q q\u00f8 a \"q 6 gr q \"w `\u00f6 qg \u00f9 vw ` ew 8y br q zs bw x gq q\u00fa bu `a e\u00fd \u00a4r q\u00f8 \u00b3 z r s\u00f8 w `y bt aa \u00e3 y\u00df a p\u00f8 z \u00a6e \u00aey br 6\u00e8 u `a p bt qa q\u00e0 b\u00e1 b\u00f9 vw ` \u00df v\u00f8 r s\u00fa bu xa p \u00fc r qu `\u00d7 \u00aew xy bt \"e \u00aey br 6\u00e8 u `a p yt sa ew ` \u00fa q q a p r qy \u00a4\u00f9 ba 4s b\u00f8 gw i gw `\u00f6 p b\u00e8 \u00f9 bw `\u00f6 \u00f9 \u00f6 pq ty by br q \u00fa a s bw x gq t\u00fa vu xi \u00b9a 4\u00e3 y\u00df b\u00f8 a a p 3w `y \u00a4q a\u00fd q t \u00a6 bq 6 q t\u00fa vq s za s\u00e0 \u00e1 b\u00f9 ba 4\u00f8 ga q t\u00f8 ga a 4\u00d7 sa 4y \"r q\u00f8 ga q t i\u00fa bw x w `r qs v \u00b5q tt qa py u g b g\u00f9 vq 6 e yr \u00b9y br q \u00b5r qy vu xi \u00a4w xy \u00f6 r q\u00f8 g\u00df r q\u00f8 q 6 a 8 \u00df a pa p\u00f6 \u00f9 g \u00fa bs y \u00b3q tu r i\u00fa r y yi \u00e5u q ty bt ss vq tt sa qg y s v\u00f6 \u00f9 \u00a4q s ba 4 \"r t gw xr sy v bq ty v \u00b6 \u00df vq 6 gw `q qu q \u00e8 pq q\u00f8 a py ba p g 4g \u00aeq q ba 4\u00e3 ya 4 \"\u00df bu `w d\u00f0 va \u00fa ui 2\u00fe a q 2\u00e4 \u00f9 6ae q ty v \u00b9c \u00f5q 6\u00e3 \u00b6\u00e4 \u00ff tae m\u00e0 \u00ae\u00e1 b\u00f9 ba p a \u00b5q qt qa py s \u2022q t\u00f8 ga \u00b3q q\u00fa bu xa \u00b3 r a\u00f6 r qy \u00ae\u00d7 sa 4i i s b\u00fa y gu xa 4 w `a p b s v\u00f6 \u00f9 \u00b9q q \u00a1\u00fd q q\u00f6 4w `q qu a \u00e3 y\u00df b\u00f8 ga p g zw `r qy v \u00b1\u00e8 \u00f9 bw \u00f6 \u00f9 \u00bfq t\u00f8 ga 2w x \"\u00df r q\u00f8 gq qy s 8y br sy yu y\u00d7 qa 4\u00f8 g\u00fa vq qu c\u00f6 4s ba p 8\u00fd \u00a4r q\u00f8 a 4\u00e3 \u00ae\u00df v\u00f8 a w xy vt 3 g\u00f9 ba \u00b9\u00f6 r sy u a \u00e3 \u00ae w `y \u00e8 \u00f9 bw `\u00f6 \u00f9 \u00df r se qa py \u00e5w `y y\u00fd \u00a4r q\u00f8 g 2q 6 w `r qy \u00a4w t qw `\u00d7 qa py \u00e0 \u00fe a p\u00f6 4a 4y u \u00b3 ya 4\u00d7 sa 4u `r q\u00df b \"a py s bw xy \u00a4 g\u00f9 ba a i y\u00f6 e\u00df b\u00f8 gr \u00a1 ia p\u00f6 \u00a6q tu `u xr 6\u00e8 \u00a6 ba 4\u00e3 \u00ae\u00df a 4\u00f8 r 2s v\u00df bq t a 8 g\u00f9 ba 8e \u00aey br 6\u00e8 u xu a p yt sa 3\u00fa vq s za \u00e5 \u00f9 b\u00f8 gr qs vt q\u00f9 q \u00e2\u00e8 a p\u00fa yu y\u00fa vq q a p gq q\u00df b\u00df bu `w `\u00f6 pq 6 gw xr sy \u00e0\u00e4 \u00ec 6ae m\u00e0 r\u00e1 b\u00f9 ba \u00b6 i \u00ae z a p \u00f9 vq q r \u00aer su ` \" s v\u00f6 \u00f9 \u00faq s yw `\u00f6 w `r qy vq q\u00f8 w `a p \u00b3q ty v dq qy vq tu `r qt sw xa p r \u00b9w `y u \u00f8 gr y ys v\u00f6 a y ba 4\u00e8 \u00fd q s\u00f6 ' g \u00b3w xy u gr 2 \u00f9 ba ie \u00aey br 6\u00e8 u xa yt qa 8\u00fa q q a q\u00e0 \u00e1 b\u00f9 va zi y z a 4 \u00fcw ` q qu ` r 2 zs \u00a3\u00a2 2\u00f6 4w xa py u u `i \u00e5w `y s ga 4u `u xw `t qa py u r \"t qa py ba 4\u00f8 q 6 ga \u00b1\u00f8 ga 4u q 6 ga p \u00e5\u00fd q q\u00f6 g \u00e8 \u00f9 bw \u00f6 \u00f9 q t\u00f8 ga \u00b5w ` \"\u00df bu `w xa \u00fa ui \u00f9 ba s v a 4\u00f8 rw `y b\u00df bs b p\u00e0 t \u00ee\u00f9 bw `u `a b \u00f9 bw r zi y z a p \u00df b\u00f8 gr 6\u00d7 uw ya (r sy ba br t\u00fd \u00f9 ba \"r s z rw xy vy br 6\u00d7 6q 6 w `\u00d7 qa b \"a g\u00f9 br y r t\u00fd e \u00aey br 6\u00e8 u `a p yt sa \u00e2q s\u00f6 4\u00ed us bw zw x w `r qy g pw x \u00b6r sy bu `i \u00e0q t\u00df b\u00df bu `w `a p 3 r \u00fbq q b bw xy bt \u00fd q q\u00f6 g \u00a4w xy q \u00f6 r q \" \"r qy bu y a 4y v a e uy vr 6\u00e8 u xa yt qa \u00b1\u00fa vq q a q\u00e0 y \u00ee\u00f9 vw xu `a e \u00f9 bw \u00f6 4q qy 3\u00df v\u00f8 r 6\u00d7 \u00aew ya \u00b1q \" r qu `w ` 3\u00fa vq s\u00f6 e su ya 4y \u00b9\u00fd \u00a4r s\u00f8 pt sa 4y ba p\u00f8 gq qu ve uy vr 6\u00e8 u xa yt qa sg \u00f9 ba q q\u00f8 g\u00f6 \u00f9 bw x a \u00f6 ' gs b\u00f8 a \u00b1w y br t \u00a6 s bw x gq t\u00fa vu xa e\u00fd \u00a4r s\u00f8 \u00f8 a 4 gq tw `y bw `y bt \" z\u00df a p\u00f6 4w d\u00f0 \u00f6 8 br q 2q tw `y 3e \u00aey br 6\u00e8 u `a p bt qa q\u00e0 \u00f5 wy g zs b \" 2q t\u00f8 gi qg f\u00f6 r sy s ga 4 \"\u00df r q\u00f8 q t\u00f8 gi \u00f5\u00f6 r sy u\u00d7 sa 4\u00f8 q t w `r qy vq qu rq tt qa py u g q q\u00f8 a 2\u00fd \u00a4r y\u00f6 4s v za r qy g\u00f9 ba \u00e5\u00df b\u00f8 gr q\u00fa bu u xa p r t\u00fd \u00df b\u00f8 gr 6\u00d7 \u00aew ` yw `y bt q y vq 6 gs b\u00f8 q tu eq ty v \u00e0q s bq t\u00df b w `\u00d7 qa d\u00e8 bq i gr \u00faw `y u a p\u00f8 gq s\u00f6 ' \u00e5\u00e8 w x \u00f9 \u00f9 ba \u00fea 4y v s v a 4\u00f8 \u00e0 \u00a4 w x z u `a \u00e5\u00f9 q q \u00fa a 4a py yr sy ba \u00b9r qy g w ` a\u00df vu xw x\u00fd \u00a4i \u00aew xy bt d \u00f9 ba 3\u00df b\u00f8 r y\u00f6 4a p g 8r t\u00fd \u00a6s b\u00df v bq t w `y bt \u00f9 va \u00e5e \u00aey br 6\u00e8 u `a p yt sa 2r t\u00fd \u00f9 ba 8q tt sa 4y u g p\u00e0 y\u00e1 b\u00f9 bw b\u00df vq t\u00df a 4\u00f8 b\u00df b\u00f8 gr q\u00df r s a p bq ie uy vr 6\u00e8 u xa yt qa eq q\u00f6 p\u00ed ss vw ` w d gw xr sy \u00e5 \"r y ys bu `a \u00b1 \u00f9 vq t b\u00e8 w `u `u q tu `u xr 6\u00e8 \u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu vq qt qa py s gr \u00b9u xa q t\u00f8 gy yr q 2q tw `y d \u00df a \u00f6 w x\u00f0 \u00f6 e \u00aey br 6\u00e8 u `a p yt sa qg y g\u00f9 \u00aes v 4g \u00f6 \u00f8 ga pq t w `y bt \u00b9q \"\u00fd va 4\u00e3 uu w x\u00fa bu `a 8\u00fd \u00a4\u00f8 q t \"a 4\u00e8 pr q\u00f8 ge 2\u00fd \u00a4r s\u00f8 \u00b5\u00f6 s i gr q \"w ` w `y bt \u00b9 z\u00df a p\u00f6 4w `q qu xw a p q tt sa 4y u g p\u00e0 v\u00e1 b\u00f9 ba i zs b\u00fa za \u00ed ss va 4y u \u00b3 za \u00f6 ' gw xr sy v \u00a6\u00e8 w `u xu ya 4 \"r qy i g\u00f8 gq t a e\u00f9 br 6\u00e8 \u00e0 g\u00f9 bw i g\u00f8 s v\u00f6 s b\u00f8 ga e\u00e8 r s\u00f8 e y p\u00e0 \u00a5 \u00a6 \u00f0 v\u00ec \u00a8 \u00a7 \u00a9 \u00f1 \u2022\u00f0 b\u00ee \u00e1 b\u00f9 ba \u2022 \"r y ys bu `a \u00a1\u00fa bs bw `u b r sy q ty 8a \u00e3 yw i gw xy vt \u00b3\u00f6 r sy u\u00d7 sa 4\u00f8 q t w `r qy vq qu 6q tt qa py u (q ty v ee \u00aey br 6\u00e8 u `a p bt qa \u2022q q\u00f6 p\u00ed us bw ` w x w `r qy aa 4 \u00f9 br y yr su xr st qi s\u00e0 \u00f6 z\u00df a p\u00f6 4w `q qu p vq 6 gq \u00e2 i g\u00f8 s \u00f6 ' s v\u00f8 a 3e uy vr 6\u00e8 y q q i\u00fd \u00a4\u00f8 q t \"a \u00e5w \u00fd \u00a4s vy v bq t \"a py s q tu p r \u00e2 \u00f9 va ya 4\u00d7 sa 4u `r q\u00df b \"a 4y u fr t\u00fd y \u00f9 va \"r y ys bu `a q\u00e0 6\u00e1 b\u00f9 ba \u00a1\u00fd \u00a4r qu `u xr 6\u00e8 w `y bt \u00b3 a p\u00f6 w `r qy v f z\u00f9 q tu `u sw `y u \u00f8 gr \u00ae bs v\u00f6 a \u00a1 \u00f9 ba za a 4u `a 4 \"a 4y u g \u00fa b\u00f8 w `a \u00fd i q\u00e0 ! #\" %$ '& )( 10 32 14 5 % 60 \u00a37 98 a@ !$ b #2 \u00e1 b\u00f9 ba i \"r y ys bu `a \u00fd \u00a4r s\u00f8 \u00b5e \u00aey br 6\u00e8 u `a p bt qa iq s\u00f6 4\u00ed us bw zw x w `r qy w \u00b1\u00fa bs bw `u d er qy \u00f5a \u00e3 yw ` z w `y bt \u00a4\u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu %q tt sa 4y u a p\u00f6 \u00f9 vy br qu `r qt sw xa 4\u00e0 \u2022\u00ef fw `\u00f8 g z 3q ty \u00fd \u00a4r q\u00f8 ga 4 \"r s z pg r g\u00f9 ba \u00f5\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy vq tu q tt sa 4y u 2 \u00f9 q 6 \u00e5w \u00e5q qs bt q \"a 4y u ga p \u00e8 w d g\u00f9 \u00ee \u00f9 ba \u00f5 ar y ys vu xa \u00e2w ` \u00e5p \u2022\u00f8 r s\u00fa r q p\u00e0 \u00f5 y \u00e5w ` \u00a4q ty \u00fba 4\u00e3 u ga 4y v w `r qy \u00fb r g \u00f9 ba \u00e2\u00df b\u00f8 r st q\u00f8 q t \" \"w xy vt \u00feu q ty vt qs vq qt qa w xp \u2022\u00f8 gr qu `r qt g yq ty \u00b6a 4y b\u00f9 q ty v\u00f6 4a p 3\u00d7 qa 4\u00f8 w xr sy \u00e5r t\u00fd c i q ty v vq t\u00f8 \u00e5p \u2022\u00f8 gr qu `r qt \u00a4\u00e4 `\u00eb dc ae y\u00e0 p \u2022\u00f8 r s\u00fa r q 8w ` q \u00a4 gs b\u00f8 gy yu m\u00fa q q a p \u00fe\u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu fq qt qa 4y u g \u00e8 \u00f9 ba 4\u00f8 ga \" \u00f9 ba 2s za p\u00f8 q ty v \u00e2 g\u00f9 ba \u00b9q tt sa 4y u q tu x a 4\u00f8 gy vq t a i \u00df a pq te \u00aew `y bt v\u00e0 v\u00e1 b\u00f9 ba p\u00f8 a iw ` \u00b1y br 3y vq 6 gs b\u00f8 gq qu (u q ty vt qs vq qt qa \u00df b\u00f8 gr y\u00f6 a w xy vt \u00e5w `y \u00f5p \u2022\u00f8 gr q\u00fa r t g w `y v z a pq s s v za p\u00f8 \u00a1w `y b\u00df bs y pw ` \u00a1 2q 6 g\u00f6 \u00f9 va p 2q tt uq tw `y v z \u2022\u00df vq 6 a 4\u00f8 gy v ya \u00f0 vy va p 2w `y \"\u00f0 vu `a p \u2022e \u00aey br 6\u00e8 y \u00b9q s \u00a1 g\u00f6 \u00f8 gw x\u00df b g p\u00e0 u r qy u a 4\u00e3 \u00ae r t\u00fd \u2022 g\u00f9 ba p a i\u00df q 6 z ga 4\u00f8 gy v \u00b1q t\u00f8 ga i a 4\u00df vq q\u00f8 gq t a p \u00f9 b\u00f8 gr qs bt s\u00f9 \u00f9 va is v a ar t\u00fd \u2022 gr q\u00df bw \u00f6 4 de \u00f9 bw eq tu `u xr 6\u00e8 \u00a6 \u00a6 \u00f9 ba 2 gq t \"a \u00df vq 6 a 4\u00f8 gy v \u00b5\u00e8 w d g\u00f9 \u00f5\u00d7 6q t\u00f8 gi \u00aew xy vt \u00e5 \"a pq qy bw xy vt s gr \u00a4\u00f6 4r \u00aea \u00e3 yw ` z \u00b5\u00e8 w x \u00f9 vw xy \u00f5 \u00f9 ba \"q tt sa 4y u \u00b5\u00e8 w x \u00f9 br ss y 8q t \u00fa vw xt ss bw d ii \u00e4 x\u00eb s\u00eb 'ae m\u00e0 u\u00f5 y w \u00df r u w x\u00fa vu xa gr i ya 4\u00f0 vy ba \u00b5 s bu x w `\u00df bu `a \u00a6 r s\u00df bw \u00f6 4 \u00a1\u00fd \u00a4r q\u00f8 \u2022 g\u00f9 ba \u00b5q qt qa py s g q\u00f9 br 6\u00e8 pa 4\u00d7 sa 4\u00f8 g \u00f9 ba eq tt sa 4y u \u00a1\u00f6 4q qy r qy bu `i \u00b9\u00f9 vq qy v yu `a 8r qy ba \u00b1 r s\u00df bw \u00f6 \u00b1q t \u00b3q i w ` aa s\u00e0 f g h& i0 \u00a3p q$ '( \u00ef b\u00f8 q t \"a p pq t\u00f8 ga \u00b5 z \u00f8 gs v\u00f6 ' gs b\u00f8 ga p sr \u00f0 v\u00f8 i b\u00df b\u00f8 gr q\u00df r s a p 2\u00fa \u00aei 2c dq q\u00f8 \u00d7 \u00aew `y \u00e5c w `y v ze \u00aei \u00e4 t ae vu \u00a1s za 2\u00fd \u00a4r q\u00f8 b ya \u00f6 4\u00f8 w `\u00fa bw `y bt q ii \u00ae\u00df bw `\u00f6 pq tu \u00b1 zw x s vq t w `r qy g p zs \u00f6 \u00f9 \u00e0q q 2a py s ga 4\u00f8 gw xy vt q \u00bf\u00f8 gr ur s \u00b6\u00e0 \u2022\u00e9 \u00a1q q\u00f6 \u00f9 \u00e0q s z\u00df a p\u00f6 \u00e5r t\u00fd e g\u00f9 ba \u00e2 w d gs vq 6 gw xr sy \u00eew ` \u00f8 a p\u00df b\u00f8 a za py u a p \u00fe\u00fa \u00aei \u00e2q \u00f5 zu `r t \u00e0 %c w `y v ze \u00aei \u00fe\u00fa a pu xw `a 4\u00d7 sa p e g\u00f9 vq 6 ir qy ba \u00b9s vy v ya 4\u00f8 z gq ty b yw q tu `r qt ss ba \" \u00f9 b\u00f8 gr qs vt q\u00f9 \u00f0 vy v yw `y bt \u00fe\u00fd \u00a4\u00f8 gq q \"a p i \u00f9 vq t \u00b9 ya p g\u00f6 \u00f8 gw x\u00fa a \u00a4 \u00f9 ba \u00f6 4r qy u a py s 2 \"r s z 2q t\u00df b\u00df b\u00f8 gr q\u00df v\u00f8 w q 6 ga 4u `i q\u00e0 rv \u00a6a q tu r \u00f5\u00fa a 4u `w xa p\u00d7 qa p \u00f9 vq t a g\u00f9 ba 4\u00f8 ga \u00b6w ` \"q \u00e2\u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 ui r q\u00fd \u00b3\u00fd \u00a4\u00f8 q t \"a p pg c\u00e8 \u00f9 ba 4\u00f8 ga 3a q q\u00f6 \u00f9 zs b\u00fa za \u00ed ss va 4y u au `a 4\u00d7 sa 4u bw `y g\u00f9 ba d\u00f6 \u00f9 vq tw `y r t\u00fd cw xy b\u00f9 va 4\u00f8 gw d q ty v\u00f6 4a \u00f6 r qy u q tw `y v w `y v\u00f6 \u00f8 ga pq s zw `y bt \"q t \"r qs by u \u00a6r q\u00fd r ba gq qw xu \u00a6q q\u00fa r ss y \u00f9 ba r q\u00df vw `\u00f6 er q\u00fd fw `y u a 4\u00f8 ga p z pg s v\u00f6 \u00f9 \u00bfu `w xe sa 3 s b\u00fa v\u00f6 u q q g za 8w xy g \u00f9 ba 3r q\u00fa 3 ia \u00f6 ' r s\u00f8 w `a 4y u a \u00df vq t\u00f8 q q bw xt s \u00a4\u00e0 \u00f6 \u00fd \u00a4\u00f8 q t \"a \u00b9w q tu r \u00f5q t\u00fa bu `a 2 gr \"q qw xy u q tw `y \u00a4q au `w ` z \u00a6r t\u00fd r\u00ed us ba p z w `r qy v p g\u00f9 vq 6 \u00a6\u00f6 pq ty \u00b6\u00fa a q s ze sa p \u00e5\u00e8 \u00f9 ba 4y \u00f6 a p\u00f8 z q tw `y 3\u00d7 6q qu xs ba q t\u00f8 ga \u00b5y va 4a p ba p \u00e0 \u00e1 b\u00f9 ba 4\u00f8 ga \u00a4q q\u00f8 a 3 i\u00e8 pr \u00f5 ii \u00ae\u00df a p ar t\u00fd \u00b1e uy vr 6\u00e8 u xa yt qa 3 \u00f9 vq t 2r q\u00df a 4\u00f8 q 6 a \u00a4w `y q \u00fe\u00f6 r sy u\u00d7 sa 4\u00f8 q t w `r qy vq qu q qt qa 4y u \u00e0 \u00e7 \u00b5y ba \"w ` 8\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy de \u00aey br 6\u00e8 u xa yt qa \"q ty d g\u00f9 ba 2r t g\u00f9 ba 4\u00f8 g yr q 2q qw xy \u00fee \u00aey br 6\u00e8 u xa yt qa s\u00e0 \u00e1 b\u00f9 ba p a a ii u\u00df a p r t\u00fd be uy vr 6\u00e8 u xa yt qa 2q t\u00f8 ga \" \"r \u00ae bs bu `q q\u00f8 pg (q ty v \u00fes v a \u00b9q \u00b6 zw `y bt qu `a \u00b9 bq t gq z \u00f8 gs v\u00f6 ' gs b\u00f8 a \"e \u00aey br 6\u00e8 y \u00bfq q 8q \u00a4\u00fd \u00a4\u00f8 q t \"a \u00f9 br ss bt q\u00f9 3 \u00f9 ba za q q\u00f8 a \u00b1 2q tw `y u gq tw `y ba \u00e5 g\u00f9 b\u00f8 gr qs bt s\u00f9 3 a 4\u00df vq q\u00f8 gq t a \u00b1\u00df b\u00f8 r y\u00f6 4a p ys b\u00f8 ga p p\u00e0 \u00ef b\u00f8 q t \"a p (\u00f6 4q ty iq tu zr \u00a6\u00f8 ga pq s\u00f6 ' ( r \u00b3a p\u00d7 qa py s g\u00f9 b\u00f8 gr qs bt s\u00f9 e \u00f9 ba ps v a \u00a1r t\u00fd bq ta p ar sy v p\u00e0 p\u00e1 b\u00f9 ba za pq t\u00f8 ga w x \"w `u `q q\u00f8 r \u00f5a p\u00d7 qa py s i\u00f9 vq ty v bu xa p\u00f8 g 8w `y gu q ty bt ss vq tt sa p s v\u00f6 \u00f9 gq s xw uq \u00d7 q v\u00e0 w `p \u2022\u00f8 r su xr st d\u00f9 vq s ya 4\u00f0 vy ba p q y \u00aes b \u00fa a 4\u00f8 ir t\u00fd bq ta p ar sy v p \u00f9 q 6 \u00b3q t\u00f8 ga 8\u00f6 4q qu xu `a p 3\u00e8 \u00f9 ba 4y q a\u00d7 6q t\u00f8 gw xa 4 ii \u00b9r t\u00fd fa 4\u00d7 sa 4y u g pg b zs \u00f6 \u00f9 \u00b6q s p \u00f9 ba 8w `y v z gq qy s gw `q t w `r qy \u00a4r t\u00fd cq \u00fd \u00a4\u00f8 gq q aa sg yr y\u00f6 4\u00f6 s v\u00f8 g p\u00e0 \u00ef b\u00f8 q t \"a p \u00a6q q\u00f8 a 8w ya q tu ( vq 6 gq 2 z \u00f8 gs v\u00f6 s b\u00f8 ga p b\u00fd \u00a4r s\u00f8 \u00a6 g\u00f9 ba e \u00aey br 6\u00e8 u `a p yt sa q q\u00f6 4\u00ed us bw w d gw xr sy \u00a4 \"r y ys bu `a q s \u00a6w x zs b\u00df v\u00df r s\u00f8 z \u00fd va 4\u00e3 \u00aew `\u00fa bu `a i bq t gq 3 i gr q\u00f8 q tt qa q s \u00a6\u00e8 pa 4u `u fq s \u00b3\u00f6 4r qy u gq qw xy bw `y bt \u00b9a pu xa p \"a 4y u g \u00b5r t\u00fd \u2022\u00f6 r sy \u00ae\u00d7 qa 4\u00f8 gq 6 w `r qy \u00b6w `y q i \"r y ys bu q t\u00f8 2q qy by ba 4\u00f8 \u00e0 `y a b c bd e7 $ bf 6@ %$ b8 eg ih p c4 5( 14 v2 d4 ! \u00e1 b\u00f9 ba \"e uy vr 6\u00e8 u xa yt qa \"q q\u00f6 p\u00ed ss vw ` w d gw xr sy \u00f5 \"a g\u00f9 br y yr qu `r qt si dq q yr s\u00df y a d\u00fd \u00a4r s\u00f8 \u00b1 \u00f9 bw 8\u00df b\u00f8 gr \u00a1 ia \u00f6 ' ew ` \u00b1 g\u00f9 ba \u00b9\u00fe w `\u00df b\u00df bu `a q \u00b3r 6\u00e8 y \u00e0\u00fe s vu xa qr \u00fe rq \u00b1\u00fe su \u00b9q q\u00df b\u00df b\u00f8 gr sq q\u00f6 \u00f9 %\u00e0 r\u00f5 y \u00e5\u00e8 pq s \"\u00f0 v\u00f8 i \u00a4 ya 4\u00d7 \u00aew za \u00fa\u00fa \u00aei p rq ts bu 8 r q \"\u00df y r sy \u00e4 t ae \u00b1q q \u00e5q \u00f6 r qy zw i ga 4y u \u00a6q t\u00df b\u00df v\u00f8 r uq q\u00f6 \u00f9 \u00b9 gr \"s b\u00df vq 6 w `y bt 2u q t\u00f8 gt qa \u00b1e \u00aey br 6\u00e8 u xa yt qa \u00b1\u00fa vq s za e\u00e4 u ae y\u00e0 \u00e1 b\u00f9 ba \u00b3\u00f6 r s\u00f8 a \u00a6q s s b \"\u00df y gw xr sy ar q\u00fd v \u00f9 bw \u00a1 \"a 4 \u00f9 br y yr su xr st qi w r g\u00f9 vq 6 a \u00e3 y\u00df a p\u00f8 z \u2022 2q te sa \u00a8 is v yt s aa py u g \u2022r sy q 2\u00f6 4q q a 8\u00fa \u00aei 3 r q \"a 8w ` a\u00df vu xw \u00f6 w x \u00b3\u00f8 ga pq q r qy vw xy bt \u00e0 \u00a3q \u00b3w x\u00f3 va 4\u00f8 ga 4y u \u00b5\u00f6 r sy v\u00f6 u `s v w xr sy v q t\u00f8 ga 8t qw `\u00d7 qa py q q \u00a6q \"\u00f8 ga p s bu x \u00a6r t\u00fd \u00d7 q q\u00f8 w q 6 gw xr sy v cw `y i g\u00f9 ba p a \u00b3\u00f6 pq q a p p\u00e0 6\u00e9 r\u00e3 y\u00df a p\u00f8 z \u2022q t\u00f8 ga b\u00fa a 4 z a p\u00f8 q t \u2022w ` ya py u w x\u00fd \u00a4i uw `y bt e g\u00f9 ba \u00a6\u00d7 6q t\u00f8 gw `q t w `r qy v cw `y 2\u00f6 4q s za \u00f9 vq t \u00b3 yw ` z w `y bt ss bw ` \u00f9 ba br qy ba \u00b1\u00fd \u00a4\u00f8 gr q \u00f7q qy br t g\u00f9 ba 4\u00f8 \u00e0 x ey br 6\u00e8 u xa yt qa iw ` i gr q\u00f8 ga p d\u00e8 w x \u00f9 vw xy \u00bfq \u00a4\u00f8 s vu xa \" g\u00f8 a pa qg \u00e8 \u00f9 ba p\u00f8 a \"a pq s\u00f6 \u00f9 \u00f5y br y ya 2w 8q \u00b6\u00f6 r sy v\u00f6 u `s v w xr sy \u00feq s \u00e8 a pu xu bq q iq d za 4 ir q\u00fd \u00b3\u00f6 r qy yw d gw xr sy v 8 g\u00f9 vq 6 aw d a s v z a gq 6 gw ` z\u00fd \u00a4i q\u00e0 \u00f6 aq dy ba p\u00e8 \u00f6 4q q a \u00b9w t sw x\u00d7 sa 4y gr d \u00f9 va e uy vr 6\u00e8 u xa yt qa \u00a4\u00fa vq q a qg rw x \u00b9\u00e8 w `u xu \u00a6\u00fa a \u00a4 a i ga p \u00fbq tt uq tw `y v i \"\u00f8 gs bu xa \"\u00e8 w d g\u00f9 bw `y \u00fa g\u00f9 ba \u00b6 \u00f8 ga 4a s\u00e0 p r qy \u00f6 u `s v zw `r qy \u00faw ` t qw `\u00d7 qa 4y 3\u00fa \u00aei 2 \u00f9 ba 8u q q z y br y ya \u00b1 \u00f9 vq t \u00f9 ba \u00f6 pq q a \u00b1\u00f6 4r q \"\u00df bu `a ga 4u `i \u00e5 q t w i\u00f0 a p p\u00e0 u\u00f5 y\u00fd f \u00f9 va 8a \u00e3 y\u00df a p\u00f8 z \u00a6 yw gq tt q\u00f8 ga 4a \u00e8 w d g\u00f9 g \u00f9 va \u00a4\u00f6 4r qy v\u00f6 4u xs v w `r qy g fy ba 4\u00e8 \u00f7\u00f8 s bu `a p a\u00f6 4q qy g\u00fa a 3\u00e8 \u00f8 gw d a py g r \u00fe\u00f6 r s\u00f8 \u00f8 ga p\u00f6 \u00f9 ba \u00a4e \u00aey br 6\u00e8 u `a p yt sa \u00e5\u00fa vq s za s\u00e0 v \u00a6a 4\u00e8 \u00f8 gs bu xa e\u00fa b\u00f8 q ty v\u00f6 \u00f9 ba \u00b5\u00fd \u00a4\u00f8 r s \u00f4 \u00f9 ba 2u q q z \u00f6 r s\u00f8 \u00f8 ga p\u00f6 \u00b1y br y ya sg v \u00f9 vq t w ` pg v \u00f9 va 2y br y ya \" \u00f9 vq t 8\u00f9 vq q \u00e2 \u00f9 va w xy v\u00f6 4r q\u00f8 g\u00f8 a \u00f6 ' 8\u00f6 r sy v\u00f6 u `s v w xr sy \u00e0 \u00f6 e g\u00f9 ba \"\u00f8 a i 8r t\u00fd \u00f9 ba \" g\u00f8 a pa iw ey br q q 6\u00f3 va p\u00f6 ' 8\u00fa \u00aei g\u00f9 bw ` 8\u00f6 \u00f9 q ty bt sa qg \u00fe rq \u00b1\u00fe t qw `\u00d7 qa p bq 2\u00f6 4r qy v w ` z a py u q q\u00df b\u00df b\u00f8 gr sq s\u00f6 \u00f9 2 r 2w `y v\u00f6 \u00f8 ga 4 \"a py s q tu vu `a pq t\u00f8 gy bw `y bt v\u00e0 \u00fb \u00a6\u00df v bq 6 ga p \u00a1q q\u00f8 a \u00b3r qy bu `i \u00f8 ga p\u00ed us bw `\u00f8 a \"\u00e8 \u00f9 ba 4y \" g\u00f9 ba \u00b3a 4\u00e3 y\u00df a p\u00f8 z bw ` gq tt s\u00f8 a pa p r\u00e8 w x \u00f9 2 g\u00f9 ba \u00b3\u00f6 4r qy v\u00f6 4u xs v w `r qy \" \u00f9 va e uy vr 6\u00e8 u xa yt qa 2\u00fa vq s za 2\u00f9 q q b\u00f8 gq \u00e8 y \u00e0 %\u00f5 wy g\u00df b\u00f8 q q\u00f6 ' gw `\u00f6 4a qg a q q\u00f6 \u00f9 s b\u00df v bq 6 ga \u00e5\u00f8 ga p\u00ed us bw `\u00f8 a e \u00f9 va \u00e5 z\u00df a p\u00f6 4w d\u00f0 \u00f6 4q 6 gw xr sy r t\u00fd \u00b5q \u00fe\u00f6 4q s za sg cq \u00fe a \"r t\u00fd \u00b5\u00f8 gs bu `a p i \u00f9 q 6 \"w ` ya py u w x\u00f0 va p a g\u00f9 ba \u00f6 4q q a 3q qy v q \u00e2y ba p\u00e8 \u00fc\u00f6 r sy v\u00f6 u `s v w xr sy \u00bf \u00f9 q 6 2w ` yw d\u00f3 va 4\u00f8 ga 4y u \u00a6\u00fd \u00a4\u00f8 gr q \u00fc \u00f9 va i\u00f6 r sy v\u00f6 u `s v w xr sy \u00b6t qa 4y va 4\u00f8 q 6 a \u00a4\u00fa ui 3 \u00f9 va e \u00aey br 6\u00e8 u xa yt qa 8\u00fa q q a q\u00e0 v\u00e1 b\u00f9 ba za a 4u `a 4 \"a 4y u g \u00e8 w xu `u v\u00fd \u00a4r s\u00f8 \u00df vq q\u00f8 z \u2022r q\u00fd g\u00f9 ba e\u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy i \u00f9 vq t \u00a1 \u00f9 va \u00b5q tt sa 4y u \u00a1 is v i ps by v ya p\u00f8 z q te sa \u00fd \u00a4r q\u00f8 a \u00e3 \u00ae \u00f8 q q\u00f6 w `y bt e uy vr 6\u00e8 u xa yt qa \u00b5\u00fd \u00a4\u00f8 r s \u00f9 va 8a \u00e3 y\u00df a p\u00f8 z \u00e0 w x \u00f1 \u00f4 \u00b5\u00f2 sy \u00a9 \u00e1 b\u00f9 ba 8 \"r \u00ae bs bu xa ew \u00a6\u00f6 r sy v w ` z a \u00e5r q\u00fd % i\u00e8 pr ae \u00aey br 6\u00e8 u `a p bt qa eq q\u00f6 4\u00ed us bw w d gw xr sy \u00a4\u00f6 4r q \"\u00df r sy ba 4y u e b yr s 2q tw `y \u00a4q qy v \u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu re uy vr 6\u00e8 u xa yt qa s\u00e0 (h pr t g\u00f9 \u00bfs v za g\u00f9 ba \u00b9\u00fd \u00a4\u00f8 q t \"a 3\u00f9 bw xa p\u00f8 gq q\u00f8 g\u00f6 \u00f9 \u00aei \u00f5 r \u00e2 z r s\u00f8 a \u00e5w xy y\u00fd \u00a4r s\u00f8 2q t w `r qy \u00f8 a \u00ed ss vw x\u00f8 ga p \u00f5\u00fa ui \u00b6 g\u00f9 ba \"e \u00aey br 6\u00e8 u xa yt qa aq q\u00f6 p\u00ed ss vw ` w d gw xr sy \u00f5\u00df b\u00f8 gr y\u00f6 a \u00b1q ty v \u00f5 \u00f9 va \" ba gq qw xu \u00b1r t\u00fd \u00a1\u00e8 \u00f9 vw `\u00f6 \u00f9 \u00fe\u00e8 w xu `u r\u00fa a a \u00e3 bq t \"w `y ba p 3w xy ya 4 gq qw xu `a p \u00a4w `y \u00e5 g\u00f9 ba e\u00fd \u00a4r qu `u xr 6\u00e8 w `y bt 2 a p\u00f6 ' gw xr sy v p\u00e0 y h a b c bd e7 $ bf 6@ %$ b8 eg ih p c4 5( 14 v2 d4 ! g & )0 p $ b b4 5$ '& i0 3& ig ) # \u00e1 b\u00f9 ba e \u00aey br 6\u00e8 u xa yt qa q s\u00f6 4\u00ed us bw zw x w `r qy \u00fd \u00a4\u00f8 q t \"a r x \u00f6 \u00fd \u00a4\u00f8 q t \"a 1u aw \u00b9s za \u00fd \u00a4r s\u00f8 \u00e5 z r q\u00f8 gw `y bt w xy y\u00fd \u00a4r s\u00f8 2q t w `r qy \u00f8 a \u00ed ss vw x\u00f8 ga p d\u00fd \u00a4r q\u00f8 q \u00b6 zw `y bt su xa \"s b\u00df v bq 6 ga q\u00e0 %\u00e1 b\u00f9 va 4\u00f8 ga aq q\u00f8 a 2q \u00a4y \u00aes b \u00fa a 4\u00f8 8r q\u00fd \u00a1\u00f0 b\u00e3 ya p \u00e2a 4u `a 4 \"a py s e \u00f9 q 6 q \u00b6x \u00f6 \u00fd \u00a4\u00f8 gq q aa eq q b yw \u00f6 ' q 6 ga p 3\u00fa ui 3\u00fe rq \u00b5\u00fe q ty \u00b9w yw ` g\u00f6 s a p \u00e5\u00df b\u00f8 a p\u00d7 \u00aew xr ss v zu `i \"w xy \u00aea \u00f6 ' w `r qy \u00ec y\u00e0 \u00f9 b\u00e0 yx \u00f6 \u00fd \u00a4\u00f8 gq q \"a z\u00f9 br ss bu \u00fe\u00f6 4r qy u gq qw xy \u00e2 \u00f9 v\u00f8 a pa \u00b9 zu `r t 4g \u00e8 \u00f9 ba p\u00f8 a \"a q q\u00f6 \u00f9 w d ga 4 \u00a2w ` 8\u00f8 ga 4\u00df v\u00f8 a za py s ga p \u00e2\u00fa \u00aei \u00f5q \u00a4\u00fd \u00a4\u00f8 gq q \"a \"q qy v q t\u00f8 ga a p g za py s gw `q qu xu `i s b\u00fa y\u00fd \u00a4\u00f8 q t \"a p p\u00e0 \u00f6 \u2022q \u00b1\u00f8 ga p s bu x pg tq 8x \u00f6 \u00fd \u00a4\u00f8 gq q \"a p\u00e8 w `u `u b\u00f9 vq \u00d7 qa \u00f9 va b\u00fd \u00a4r qu `u xr 6\u00e8 w `y bt 8 zs v\u00fa y\u00fd \u00a4\u00f8 gq q \"a p d \u00f6 4q q a \u00a4\u00fd \u00a4\u00f8 gq q \"a qg \u2022\u00f6 r sy v\u00f6 u `s v w xr sy \u00fd \u00a4\u00f8 q t \"a q ty \u00fa\u00f6 4r qy v yw x w `r qy \u00fd \u00a4\u00f8 q t \"a qg \u2022q s \"w xu `u `s v i g\u00f8 gq t a w `y \u00ee\u00ef (w `t qs v\u00f8 a \u00eb q\u00e0 \u00ae\u00f9 vq q ba p \u00a4\u00fa r \u00e3 ya w `y v yw \u00f6 4q t a b \u00f9 vq t b \u00f9 ba e\u00fd \u00a4\u00f8 q t \"a ew ` \u00b3 yr q 2q tw `y \u00b6 ya 4\u00df a 4y v ba 4y u p\u00e0 \u012b \u00ae\u00a3 w sf zr 4s 8e \u00e1 b\u00f9 ba \u00b9\u00f6 4q s za \"\u00fd \u00a4\u00f8 q t \"a \u00b9 ya \u00f6 4\u00f8 w `\u00fa a \u00b1\u00fd \u00a4a pq t s b\u00f8 ga p 8r q\u00fd bq w x s vq t w `r qy \u00fd \u00a4\u00f8 gr q \u00e8 \u00f9 vw `\u00f6 \u00f9 \u00bfq ty a 4\u00e3 \u00ae\u00df a 4\u00f8 \u00f6 4q qy y\u00f8 gq \u00e8 \u00e0q a\u00f6 r sy v\u00f6 u `s v w xr sy g y zs \u00f6 \u00f9 3q q b i \u00ae a\u00df b r q 2 pr t\u00fd fq \u00df vq t w `a 4y u p\u00e0 y\u00e1 b\u00f9 bw p\u00fd \u00a4\u00f8 q t \"a \u00b5w b yr q 2q qw xy \u00a4 ya 4\u00df a 4y yu ya 4y u pg vq ty \u00b6 s v z \u00b5\u00fa a \u00f8 ga 4 \"r y ya 4u `a p \u00a4\u00fd \u00a4r s\u00f8 \u00a6a 4\u00d7 sa 4\u00f8 gi 3e \u00aey br 6\u00e8 u `a p bt qa 8\u00fa vq s za 8 g\u00f9 ba q qt qa 4y u \u00b3w \u00a6w `y u \u00f8 gr y ys v\u00f6 a r v\u00e0 b\u00e1 b\u00f9 vw ` p q q e \u00b9w ` p g\u00f9 ba e\u00f8 a z\u00df r qy zw `\u00fa bw `u xw x ii \u00b9r t\u00fd ( \u00f9 ba 8 ya p\u00d7 qa pu xr s\u00df a p\u00f8 g\u00f9 vq 6 \u00a6w q q vq t\u00df y gw xy bt i \u00f9 va q tt qa py u gr \u00f9 ba 8y ba p\u00e8 br q 2q tw `y g yr t\u00fd c\u00f6 r ss b\u00f8 g a qg y\u00e8 w x \u00f9 s 3\u00a2 \u00b9\u00f6 w `a 4y u \u00a6\u00f6 r sy v zs vu d q 6 w `r qy \u00a4\u00e8 w x \u00f9 \u00a4 \u00f9 ba 8a 4\u00e3 y\u00df a p\u00f8 z 4\u00e0 \u00e1 b\u00f9 ba d\u00f6 4q s za \u00a4\u00fd \u00a4\u00f8 q t \"a dq tu zr \u00f9 br ss v a p a \u00f9 va \u00f5 yr q 2q qw xy \u00fbe \u00aey br 6\u00e8 u `a p yt sa \u00a4\u00fa q q a q\u00e0 \u2022\u00e1 b\u00f9 bw 2w \u00e5q \u00feu xr st qw \u00f6 4q qu \u00f6 \u00f9 br qw \u00f6 a \u00b1q q \u00f9 ba ee \u00aey br 6\u00e8 u `a p yt sa \u00a6\u00fa vq s za \u00b1 s v z b\u00f9 vq \u00d7 qa \u00b1q q\u00f6 4\u00f6 4a p g \u2022 gr g\u00f9 ba \u00b1\u00fd \u00a4a pq t s b\u00f8 ga p pr t\u00fd fq i\u00f6 pq q a \u00b3w `y \u00e5r q\u00f8 ya p\u00f8 r y\u00f8 q \u00e8 \u00fa\u00f6 4r qy v\u00f6 4u xs v w `r qy v (\u00fd \u00a4\u00f8 gr q w x p\u00e0 q \u00b3s ba b gr bq ta p \"r qy aw xy b\u00f9 va 4\u00f8 gw d q ty v\u00f6 4a qg 6 g\u00f9 ba e \u00aey br 6\u00e8 u xa yt qa b\u00fa vq s za b\u00e8 w `u xu r qy bu `i \u00f5y ba pa p \u00e2 r \u00f5\u00fa a \u00b9 ya 4\u00f0 vy ba w xy g\u00f9 ba 2t qa py ba 4\u00f8 gw `\u00f6 2\u00f6 pq q a a\u00fd \u00a4\u00f8 gq q aa \u00b9q qy v q tu `u \u2022w `y v i q ty v\u00f6 4a \"\u00fd \u00a4\u00f8 gq q \"a p 8\u00e8 w `u xu \u00f9 vq \u00d7 qa \u00b1q q\u00f6 4\u00f6 4a p g \u2022 gr iw x p\u00e0 y\u00e1 b\u00f9 ba p\u00f8 a 4\u00fd \u00a4r q\u00f8 ga qg \u00aeq ty \u00aei 2y ba p\u00e8 \u00f6 4q s za \u00f6 4\u00f8 a q 6 a 2\u00e8 w `u xu q tu r s v a \u00b3 g\u00f9 ba e \"r s z p\u00f8 ga p\u00f6 4a 4y u \u00d7 qa 4\u00f8 w xr sy \u00bfr t\u00fd \u00a6 g\u00f9 ba 3e \u00aey br 6\u00e8 u `a p bt qa \u00e5\u00fa q q a q\u00e0 c\u00e1 b\u00f9 bw ` iw `y b\u00f9 ba 4\u00f8 gw x gq ty \u00f6 a \u00b6 i g\u00f8 s v\u00f6 s b\u00f8 ga 3\u00f6 4r q \"\u00df bu `a 4 \"a 4y u i\u00fe rq \u00b1\u00fe de \u00f6 r qy zw i ga 4y v\u00f6 4i q tu `u `r 6\u00e8 \u00a6 2q tu `u \u00a6a \u00e3 yw i gw xy bt \u00bfq qy v \u00fa\u00fd \u00a4s y s b\u00f8 ga \u00f5\u00f6 pq q a p a r g \u00f9 vq q\u00f8 a 3 \u00f9 ba \u00e2 q q aa \u00b6e \u00aey br 6\u00e8 u `a p yt sa \u00fa vq q a e\u00e8 w d g\u00f9 br qs y g\u00f9 ba 8y ba pa p 3 r \"\u00f8 ga p z \u00f8 gs v\u00f6 ' gs b\u00f8 a s\u00e0 r qy v\u00f6 4u xs v w `r qy v iq t\u00f8 ga \u00b9\u00df r u w `\u00fa bu xa \u00a4\u00f6 u q q g zw x\u00f0 \u00f6 pq 6 w `r qy 8 \u00f9 q 6 aq qy ga \u00e3 y\u00df a 4\u00f8 a 2q i \u00fet qw `\u00d7 qa \u00e5 r \u00e2q \u00e2\u00f6 4q s za s\u00e0 \u00e1 b\u00f9 bw ` i za 4 r t\u00fd \u00d7 6q tu `s ba \u00f6 4q qy \u00fa a \u00a4 i gr q\u00f8 ga p q q e\u00fd q 6 \u00d7 6q tu `s ba 4g (\u00f9 br 6\u00e8 a p\u00d7 qa p\u00f8 8w xy g r q \"a \u00b9\u00f6 4q s za 4g %w d a \"q i \u00fa a 3\u00f8 a p\u00df b\u00f8 a za py u a p \u00e2 \"r q\u00f8 ga \u00e5q q ba p\u00ed us vq 6 ga 4u `i \u00f5\u00fa \u00aei \u00e2\u00fd \u00a4\u00f8 gq q aa 4\u00e0 (\u00ef br q\u00f8 ia \u00e3 bq t \"\u00df bu `a qg % \u00f9 ba 3q tt qa py u \"q i \u00feu `a pq t\u00f8 gy \u00f9 br 6\u00e8 r a 4u `a p\u00f6 \u00f6 4q q\u00f8 g f\u00fd \u00a4r s\u00f8 q 8t sw x\u00d7 sa 4y 2\u00f6 s v z r s \"a 4\u00f8 \u00e0 u r qy v\u00f6 4u xs zw `r qy v \u2022w xy 2 g\u00f9 bw \u00a1\u00f6 4q s za \u00e8 pr qs vu ` \"\u00fa a \u00b3\u00fa a a 4\u00f8 \u00f8 a p\u00df b\u00f8 a za py u a p 3\u00fa \u00aei 3q 2\u00f6 pq t\u00f8 b\u00fd \u00a4\u00f8 q t \"a 8\u00f8 gq t \u00f9 ba p\u00f8 b \u00f9 vq qy e is v i \u00b3 \u00f9 ba \"r y ya pu r t\u00fd f \u00f9 ba i\u00f6 4q t\u00f8 \u00e0 b\u00e1 b\u00f9 bw b\u00fd \u00a4\u00f8 q t \"a 8w ` yr q 2q tw `y \u00e2q qy v \u00e2w x \"\u00df bu `a 4 \"a 4y u q 6 w `r qy \u00few `y v ya 4\u00df a 4y ya 4y u pg (q ty v \u00f5 s v z 8\u00fa a \"\u00f8 ga p\u00f6 \u00f8 ga pq t a \u00fd \u00a4r q\u00f8 ea q q\u00f6 \u00f9 \u00f5y va 4\u00e8 e uy vr 6\u00e8 u xa yt qa \u00b1\u00fa vq q a q\u00e0 r qy v yw x w `r qy \u00a6q t\u00f8 ga 8\u00f8 a z\u00df r qy zw `\u00fa bu `a e\u00fd \u00a4r q\u00f8 \u00a6\u00f9 br su ` bw xy bt \u00e5\u00f8 s bu `a p \u00a6\u00f8 a pu `q t a p \u00a4w `y y\u00fd \u00a4r q\u00f8 g 2q 6 gw xr sy \u00a4\u00e8 \u00f9 va 4\u00f8 ga \u00f8 s vu xa z\u00df a p\u00f6 4w d\u00fd \u00a4i \u00b6 yw i gw xy bt ss bw z\u00f9 bw `y bt 2\u00df b\u00f8 gr q\u00df a 4\u00f8 w `a p br q\u00fd \u2022q 2\u00f6 4q q a q\u00e0 b\u00e1 b\u00f9 va p a 8\u00df b\u00f8 r s\u00df a p\u00f8 z gw xa \u00a6q t\u00f8 ga e\u00df b\u00f8 ga p yw \u00f6 4q t a p \u00f9 vq t \u00e8 w xu `u a pw d g\u00f9 ba 4\u00f8 pa 4\u00d7 6q qu xs vq t a \u00b3 r g\u00f8 s va \u00b3r q\u00f8 \u00a1\u00fd q tu za s\u00e0 'q \u00b5s ba \u00b3 r g\u00f9 ba \u00b5\u00fd \u00a4\u00f8 gq q aa \u00b5 i g\u00f8 s v\u00f6 s b\u00f8 ga qg s \u00f9 va p a \u00b3\u00df b\u00f8 ga p yw \u00f6 4q t a q t\u00f8 ga \u00f8 ga p\u00ed us bw `\u00f8 a \u00b6 r \u00a4e \u00aey br 6\u00e8 \u00e8 \u00f9 bw \u00f6 \u00f9 \u00f5 zu `r t ew `y d \u00f9 va a\u00f6 pq q a \u00fd \u00a4\u00f8 q t \"a iw \u00b5 r 3\u00fa a a a i ga p \u00e0 \u00e1 b\u00f9 ba p\u00f8 a 4\u00fd \u00a4r q\u00f8 ga qg q \u00f6 r qy yw d gw xr sy \u00fd \u00a4\u00f8 q t \"a y ba pa p b \u00b3 r \u00a4\u00f9 vq \u00d7 sa 8 \u00f9 b\u00f8 ga 4a a zu `r t v u xr q \u00b5y vq q aa sg r s\u00df a p\u00f8 gq t r s\u00f8 \u00b5q ty d\u00f6 r s a\u00df q t\u00f8 gw ` r qy \u00d7 q qu xs va q\u00e0 u\u00f5 wy 2 \u00f9 ba e w x \"\u00df bu `a p z p\u00f6 pq q a qg sq i zu `r t \u00e8 w xu `u v\u00fa a \u00b5\u00d7 qa 4\u00f8 gw x\u00fd \u00a4i i\u00e8 \u00f9 ba 4 \u00f9 ba p\u00f8 w x b\u00f9 br qu b \u00a1q i z\u00df a p\u00f6 4w d\u00f0 \u00f6 \u00a6\u00d7 6q tu `s ba q\u00e0 v \u00a6r 6\u00e8 pa 4\u00d7 qa p\u00f8 pg u g\u00f9 ba 4\u00f8 ga 8q t\u00f8 ga \u00b5r q \u00f9 ba p\u00f8 \u00a6 bq 6 q ii \u00ae\u00df a p p g\u00f9 vq 6 \u00a6\u00f8 ga p\u00ed us bw `\u00f8 a p ar s\u00f8 a \u00b1 g\u00f9 vq ty is v z \u00a6a p\u00ed us vq tu `w x ii qg b s v\u00f6 \u00f9 q q 3y us v aa p\u00f8 w \u00f6 \u00f5q qy v \u00e0 bq t a \u00fe\u00f6 r q \"\u00df vq q\u00f8 w r qy v p\u00e0 \u2022\u00f5 y \u00b6w ` 3\u00df r u w `\u00fa bu xa \u00f5 r \u00f6 \u00f8 ga pq 6 ga dy ba p\u00e8 ya \u00f0 y bw d gw xr sy v 3r t\u00fd \u00f6 r q \"\u00df vq q\u00f8 w r qy \u00b1\u00fd \u00a4\u00f8 gq q \"a p w x\u00fd y \u00f9 va p a \u00a1y ba p\u00e8 \u00fd \u00a4\u00f8 gq q aa %\u00f6 4r qy u gq qw xy e g\u00f9 ba \u2022 g\u00f9 b\u00f8 a pa \u00a1 u xr q fr u `r t %y vq q \"a qg r q\u00df a 4\u00f8 q 6 r s\u00f8 q ty v \u00a4\u00f6 r s a\u00df q t\u00f8 gw ` r qy 3\u00d7 q qu xs va q\u00e0 gu \u00f5 y ew 8\u00df r s g zw `\u00fa bu `a a\u00fd \u00a4r q\u00f8 8q ty \u00fea \u00e3 y\u00df a 4\u00f8 8 r ya \u00f0 y ba 2 s bu x w `\u00df bu `a \"\u00f8 s bu `a p \u00b1\u00fd \u00a4r s\u00f8 e \u00f9 ba \u00b9 gq t \"a 2\u00f6 4q s za s\u00e0 \u00e1 b\u00f9 bw ` w ` \"q s ya 2\u00df r s g zw `\u00fa bu `a 2\u00fa ui q tu `u `r 6\u00e8 w xy bt \u00a4 g\u00f9 ba \u00e5x \u00f6 \u00fd \u00a4\u00f8 q t \"a \" r q te sa \u00b9q \u00b6u xw i ir t\u00fd \u00f6 r qy yw d gw xr sy \u00fd \u00a4\u00f8 gq q \"a p p\u00e0 \u00ee\u00f9 ba 4y dq s b ya p \u00a4 gr 2 \u00f9 va e \u00aey br 6\u00e8 u xa yt qa 8\u00fa q q a qg y g\u00f9 ba u `w ` z \u00b3\u00e8 w `u xu (\u00fa a a\u00f6 r sq qu xa \u00f6 4a p 3\u00e8 w d g\u00f9 \u00b6 \u00f9 ba i\u00fa r \u00aer su xa q ty \u00fd \u00a4s by v\u00f6 ' gw xr sy \u00f6 v sq i\u00e0 \u00e7 \u00b5y v\u00f6 a aq tu `u c \u00f9 ba \" bq 6 q \u00e5w e\u00f6 r su xu `a p\u00f6 a p g e \u00aey br 6\u00e8 u `a p bt qa i\u00f6 pq ty \u00e2\u00fa a \"s b\u00df v bq 6 ga p \u00e2w xy \u00e2 \u00f9 va ie \u00aey br 6\u00e8 u `a p yt sa \u00fa vq q a \u00b3\u00fa \u00aei 2\u00f6 4q qu xu `w xy vt q \u00df b\u00f8 ga p ba \u00f0 vy ba 2\u00fd \u00a4s by \u00f6 ' w `r qy ih ij j k l mj il '\u00e0 y\u00e1 b\u00f9 bw \u00e8 w xu `u q q b \" g\u00f9 ba \u00b1y ba 4\u00e8 \u00ee\u00f8 gs bu `a \u00b5q 6 p \u00f9 va q t\u00df b\u00df b\u00f8 gr q\u00df v\u00f8 w q 6 ga \u00b5u `r y\u00f6 4q 6 gw xr sy 3w `y 3 \u00f9 ba \u00fe rq \u00b1\u00fe \u00f8 ga 4a s\u00e0 \u00e1 b\u00f9 bw ` \u00a6\u00f9 bw xa p\u00f8 gq q\u00f8 g\u00f6 \u00f9 \u00aei \u00e5\u00f6 4r 6\u00d7 qa p\u00f8 g \u00f9 va \u00fa vq q w \u00f6 4 b\u00fd \u00a4r s\u00f8 \u00a6e \u00aey br 6\u00e8 u xa yt qa 8q s\u00f6 4\u00ed us bw zw x w `r qy g v\u00f9 br 6\u00e8 a p\u00d7 qa p\u00f8 pg b\u00f6 4r qy v w ` yu a 4\u00f8 q 6 w `r qy a z\u00f9 vr qs bu \u00fa a t qw `\u00d7 qa py gr \u00b1s vy v ya 4\u00f8 z gq ty yw xy vt \u00b1a 4\u00e3 y\u00df a p\u00f8 z c a p\u00f8 \"w `y br qu `r qt si \u00b1\u00fd \u00a4r q\u00f8 \u2022 \u00df a \u00f6 w x\u00fd \u00a4i uw `y bt \u00b1 \u00f9 va p a \u00f8 s bu `a p pq ty \u00e5\u00f6 4q s za 4\u00e0 \u00ae\u00e1 b\u00f9 ba \u00b1y ba \u00e3 \u00ae za \u00f6 ' gw xr sy \u00e5 z\u00f9 q tu `u a 4\u00e3 y\u00df bu `q qw xy \u00e5w xy \u00b6 ya q tw `u \u00f9 vr 6\u00e8 \u00ee \u00f9 ba za \u00b5 a p\u00f8 \"w `y br qu `r qt sw xa \u00f6 4q ty \u00a4\u00fa a 8r q\u00fa y q tw `y ba p 3\u00fa \u00aei \u00b9 \u00f9 va q tt qa py u bq qy v \u00a4\u00f9 br 6\u00e8 \u00e0 g\u00f9 ba p a \u00b1 i\u00e8 r \"\u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 bw `a p b\u00f6 r \u00aer q\u00df a 4\u00f8 q 6 ga q\u00e0 y h f ! #\" %$ '& )( 10 32 14 5 % n8 eg ih p c4 5( 14 v2 d4 ! g & )0 p $ b b4 5$ '& i0 3& ig ) # \u00e1 b\u00f9 ba \u00f6 r sy u\u00d7 sa 4\u00f8 q t w `r qy \u00a4q q\u00f6 4\u00ed us bw w d gw xr sy \u00e5\u00fd \u00a4\u00f8 q t \"a 8\u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 \u00aei \u00b9q tu `u xr 6\u00e8 \u00a6 q qy \u00b6q qt qa py s b gr \" \u00f8 q ty v u `q t a e\u00e8 \u00f9 vq t q ty \u00f5a 4\u00e3 y\u00df a p\u00f8 z 8\u00f9 vq s \u00b1 gq tw dw `y u r \u00b6q ty \u00e2w xy u a p\u00f8 y q tu c\u00f8 a p\u00df b\u00f8 ga p a 4y u gq t w `r qy \u00e0 p \u2022\u00f8 ga 4\u00d7 \u00aew xr ss v u xi w `y \u00e2p \u00a1\u00f8 r s\u00fa r q pg vs v a 4\u00f8 \u00f9 vq q \u00f5 r \u00b6\u00f6 \u00f8 ga pq t a \" \u00f6 4\u00f8 w `\u00df y g \u00b5\u00fd \u00a4r s\u00f8 8\u00f8 a \u00f6 r qt sy bw zw `y bt \u00b9\u00df vq t z ga 4\u00f8 gy v ew xy \u00df a pa p\u00f6 \u00f9 \u00e0 \u00e1 b\u00f9 bw e\u00e8 pq s eq 3 w x \"\u00df bu `a \"i qa 4 \u00fd \u00a4s by v\u00f6 ' gw xr sy vq tu q t\u00df b\u00df b\u00f8 gr sq s\u00f6 \u00f9 \u00e0 \u00fb \u00a6y b\u00fd \u00a4r q\u00f8 s by vq t a pu xi sg a pq s\u00f6 \u00f9 \u00fe u xr q w ` w xy u a p\u00f8 \u00df v\u00f8 a 4 a p yw x\u00f3 va 4\u00f8 ga 4y u u `i \u00e2q qy v \u00fe\u00f8 a 4u \u00ed ss vw x\u00f8 ga p 8q 3y ba 4\u00e8 a 8r t\u00fd p\u00df vq 6 a 4\u00f8 gy v p\u00e0 \u00f6 \u00b1\u00fd \u00a4\u00f8 q t \"a p 8q q\u00f8 a a\u00df r q\u00df bs bu q 6 ga p \u00fe\u00e8 w x \u00f9 \u00fe ar s\u00f8 a 2 u xr q g pg \u00f6 4\u00f8 w `\u00df y \u00f9 vq \u00d7 qa \u00b1 r \u00e5\u00fa a \u00e8 \u00f8 gw x z a py \u00b6\u00fd \u00a4r q\u00f8 \u00a6a q q\u00f6 \u00f9 \u00b6y ba p\u00e8 u `r t de v\u00f8 a zs bu x w `y bt 2w `y dq \"\u00df b\u00f8 gr qu `w d\u00fd \u00a4a p\u00f8 gq t w `r qy \u00a4r t\u00fd \u2022 \u00f6 4\u00f8 w `\u00df y 4\u00e0 v\u00e1 b\u00f9 va \u00f9 bw xa p\u00f8 gq q\u00f8 g\u00f6 \u00f9 \u00aei \u00df v\u00f8 r s\u00df r u za \"\u00f9 ba 4\u00f8 ga \u00a6w \u00a1q w x \"\u00df bu `a \u00b5 r qu `s y gw xr sy \"\u00fd \u00a4r q\u00f8 r qu `\u00d7 \u00aew xy vt e \u00f9 bw \u00a1\u00df v\u00f8 r s\u00fa bu xa p \u00fa \u00aei a \"a 4\u00f8 gt qw `y bt \u00f6 4\u00f8 w `\u00df y g q qy v 3w xy u a p\u00f8 y q tu bq t gq a\u00f8 a p\u00df b\u00f8 ga p a 4y u gq t w `r qy v pw `y s gr a \u00f9 ba e\u00fd \u00a4\u00f8 q t \"a 8 i g\u00f8 s \u00f6 ' s v\u00f8 a s\u00e0 x ey br 6\u00e8 u xa yt qa \u00a6q s\u00f6 4\u00ed us bw zw x w `r qy \u00e5w xy \u00e5 \u00f9 bw p ar y ys vu xa \u00b5s v za \u00fe sq \u00b5\u00fe \u00e0\u00fd \u00a4r q\u00f8 b i gr q\u00f8 gw xy bt i\u00df vq 6 a p\u00f8 y v \u00a1 \u00f9 q 6 pq qy q tt qa py u \u00b5 2q i 3y va 4a p d r 3\u00f8 a \u00f6 r qt sy bw za q qy v w x \u00b1w e zw ` \"w xu q t\u00f8 \u00b3 r 3 \u00f9 ba i\u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 ui \u00b6 ya \u00f6 4\u00f8 w `\u00fa a w `y d \u00f9 va \u00df b\u00f8 a p\u00d7 \u00aew xr ss v \u00b3 a p\u00f6 w `r qy \u00e0 vv \u00a6r 6\u00e8 pa 4\u00d7 sa 4\u00f8 g y \u00f9 bw \u00b1w ` \u00b5\u00f8 ga p z \u00f8 gw `\u00f6 a p \u00a4 gr 3\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy vq tu e \u00aey br 6\u00e8 u `a p yt sa \u00e8 \u00f9 bw \u00f6 \u00f9 t qw `\u00d7 qa p bt s\u00f8 a q 6 ga 4\u00f8 \u00a6\u00f6 r sy u \u00f8 gr qu r 6\u00d7 sa 4\u00f8 b\u00f9 br 6\u00e8 \u00f9 ba e \u00aey br 6\u00e8 u `a p bt qa 8w \u00a6 i gr q\u00f8 ga p \u00b6q ty \u00b6 \"q qy bw `\u00df bs bu q 6 a \u00b6q ty v q s q \u00f8 ga p s bu d ar s\u00f8 a \u00a6\u00f0 b\u00e3 ya p 2a pu xa p aa py u g p\u00f6 4q ty \u00e5\u00fa a \u00b1 ya \u00f0 vy va p \u00e0 \u00f6 b \u00df a \u00f6 w x\u00f0 va p 2\u00fa \u00aei i \u00f9 ba e\u00fe rq \u00b1\u00fe \u00ee\u00df vq q\u00f8 gq s yw xt s \u00b6g \u00f9 ba \u00e5\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy vq tu fe \u00aey br 6\u00e8 u `a p yt sa \"q s\u00f6 4\u00ed us bw zw x w `r qy \u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 \u00aei d z\u00f9 vr qs bu \u00f6 r qy u q tw `y q \u00f6 pq q a qg \u00f8 gs bu `a q ty v \u00ee\u00f6 4r qy v\u00f6 4u xs v w `r qy \u00e0 \u00f6 y \u00aei \u00fbs y z ga 4\u00f8 q ty v\u00f6 4a \u00fd \u00a4\u00f8 r s \u00fc g\u00f9 ba \u00f5s za p\u00f8 \u00e5w 2 \u00f8 ga pq t a \u00e0q q 3q g\u00f6 4q s za s\u00e0 \u00a1\u00fe s bu `a p \u00a4q t\u00f8 ga \u00df vq 6 a 4\u00f8 gy v \u00b3 \u00f9 vq t e\u00f6 pq ty \u00e2\u00fa a a 2q 6 g\u00f6 \u00f9 va p r 6\u00d7 sa 4\u00f8 \u00a6 g\u00f9 ba \"\u00f6 4q q a q\u00e0 v\u00ef fw xy q tu `u xi d\u00f6 4r qy v\u00f6 4u xs v w `r qy v \u00b5q t\u00f8 ga \u00f8 q ty zu q 6 ga p \u00d7 q qu xs va p p\u00fd \u00a4r q\u00f8 \u00a6 u `r t g bw `y \u00a4 \u00f9 ba e\u00fd \u00a4\u00f8 q t \"a s\u00e0 \u00f6 y \u00aei u xr q 2 \u00f9 vq t \"\u00f8 ga p\u00ed us bw `\u00f8 ga p \"s v a 4\u00f8 \u00b9 \u00df a pa p\u00f6 \u00f9 w xy v\u00df bs y \u00e5y ba pa p b a gr \u00bf\u00f9 vq \u00d7 qa 3 \u00f9 va w xy y\u00fd \u00a4\u00f8 q q z \u00f8 gs v\u00f6 s b\u00f8 ga \u00fd \u00a4r q\u00f8 q q\u00f6 p\u00f6 a w xy vt 3s y a p\u00f8 gq qy v\u00f6 a \u00b1\u00fd \u00a4\u00f8 r s \u00f4 \u00f9 ba 2s za p\u00f8 eq s e\u00e8 a pu xu \u2022q s 8q \u00a4u xr y\u00f6 4q t w `r qy \u00e2 r z r q\u00f8 ga \"\u00f8 s vu xa \u00b1 \u00f9 vq t q t\u00f8 ga \u00a4q q\u00df b\u00df bu `w xa g gr \u00e2 g\u00f9 ba \u00b6w xy v\u00df bs y p\u00e0 \u00f6 y \u00fbq q b yw x w `r qy q tu \u00a6 u xr q aw 2q q b ba p r \u00fe \u00f9 ba \u00a4\u00fd \u00a4\u00f8 q t \"a i g\u00f8 s \u00f6 ' s v\u00f8 a sg o 3p p rq l sh it %u q g \u00e8 \u00f9 bw \u00f6 \u00f9 i gr q\u00f8 ga p s za p\u00f8 w xy v\u00df bs y fq qy v \u00b1w ` %s b\u00df v bq 6 ga p 8\u00e8 w x \u00f9 8a p\u00d7 qa 4\u00f8 gi \u00b3s b z a p\u00f8 gq qy v\u00f6 a s\u00e0 p \u2022\u00f8 ga p a 4y u u `i qg \u00f9 ba o 3p vp wq l mh \u00a1t %u q zu `r t p\u00fd \u00a4r q\u00f8 ba 4\u00d7 sa 4\u00f8 gi \"\u00fd \u00a4\u00f8 gq q \"a \u00b5 g\u00f9 b\u00f8 gr qs bt s\u00f9 br qs y p \u00f9 va 8\u00f9 bw xa p\u00f8 gq q\u00f8 g\u00f6 \u00f9 \u00aei \"\u00e8 w `u xu \u00f9 vq \u00d7 sa \u00b3 g\u00f9 ba gq t \"a za py s ga 4y v\u00f6 4a \u00b1 r 2w `y s ga 4\u00f8 g\u00df b\u00f8 ga p\u00e0 yv \u00b3r 6\u00e8 a p\u00d7 qa 4\u00f8 g \u00aew d \u00a6w b\u00df r s g zw `\u00fa bu `a \u00b5 gr 2w xy \u00f6 u `s v ya r q \"a \u00b1 a \u00e3 \u00ae 2q ty bw `\u00df bs bu q 6 gw xr sy q q 2 g\u00f9 ba \u00f5w `y b\u00df bs b 3w \u00b9w `y s ga 4\u00f8 g\u00df b\u00f8 ga a \u00fb\u00fa \u00aei g\u00f9 ba d\u00fd \u00a4\u00f8 q t \"a 4\u00e8 pr q\u00f8 ge q qy v \u00fb\u00e8 w xu `u \u00b1\u00fa a \u00feq ty \u00e0q t\u00f8 ga pq \u00fe\u00fd \u00a4r s\u00f8 \u00b9\u00fd \u00a4s y gs b\u00f8 ga a \u00e3 y\u00df bu `r q\u00f8 q 6 w `r qy %\u00e0 \u00a1\u00e1 b\u00f9 ba \u00f5e \u00aey br 6\u00e8 u `a p bt qa \u00fa vq s za \u00e2w ` 3 i gr q\u00f8 ga p \u00fbw `y q ty br q \u00f9 ba p\u00f8 \u00b9\u00f0 b\u00e3 ya \u00e0 zu `r t g sx ft p wq l vy %l q p w `y \u00e8 \u00f9 bw `\u00f6 \u00f9 %g y \u00f9 ba 8\u00f8 gs bu `a p \u00fd \u00a4r q\u00f8 \u00b3w xy u a p\u00f8 \u00df v\u00f8 a 4 gq 6 gw xr sy 3q q\u00f8 a 8 z r q\u00f8 ga p \u00e5\u00f9 ba 4\u00f8 ga q\u00e0 \u00e1 b\u00f9 ba bw xy y\u00fd \u00a4\u00f8 q q z \u00f8 gs v\u00f6 s b\u00f8 ga pq qu xr sy ba bw ` cy vr t \u2022a 4y vr qs bt s\u00f9 \u00fd \u00a4r s\u00f8 \u2022 z\u00df a p\u00f6 4w d\u00fd \u00a4i \u00aew `y bt \u00b1 \u00f9 ba \u00f8 gs bu `a p de \u00f9 ba p\u00f8 a by ba pa p b f gr \u00fa a \u00b3q \u00e8 pq i r \u00ed us vq qu xw x\u00fd \u00a4i g\u00f9 ba \u00b3\u00df vq t z ga 4\u00f8 gy v 4\u00e0 \u00f6 y ba p\u00e8 \u00fa\u00fd \u00a4s vy v\u00f6 ' gw xr sy g o k z {h p u s| yg qw \u00a1 ya 4\u00f0 vy ba p \"w `y 2w `p \u2022\u00f8 r su xr st \u00f9 vq t \u00b5\u00e8 w `u xu cq tu `u xr 6\u00e8 g\u00f9 ba \u00fd \u00a4r su xu `r 6\u00e8 w xy vt 2 ii \u00ae\u00df a ir t\u00fd \u2022\u00df vq t z a p\u00f8 y \u00a6 gr \u00b9\u00fa a a 2q 6 \u00f6 \u00f9 ba p g \u00fa vq q a p dr qy dq \u00b9u `w i \u00b1r t\u00fd t qw `\u00d7 qa 4y \u00a4\u00e8 pr q\u00f8 b 4g hh tg y r 2 2q 6 \u00f6 \u00f9 \u00a4q qt sq qw xy v z d } h ifr v \u00f9 ba 8s y a p\u00f8 gq qy v\u00f6 a e s i \u00f9 vq \u00d7 sa \u00b1a p\u00d7 qa p\u00f8 i 2\u00e8 pr q\u00f8 \u00b9w `y \u00a4 \u00f9 ba 8u `w ` z h 6\u00e0 } h it ! b g\u00f9 ba 8s y a 4\u00f8 q ty \u00f6 a e s v z \u00a6\u00f6 r sy s q tw `y \u00a4q t \u00a6u xa q q z r qy ba e\u00e8 pr q\u00f8 2 \u00f9 q 6 \u00a6w w xy 3 \u00f9 va 8u xw i h t\u00e0 } | \u00a3h i k ry | bl mh i q \u00f9 ba 8s b z a p\u00f8 gq qy v\u00f6 a e is v i \u00a6\u00f6 4r qy u gq qw xy 3 \u00f9 ba 8\u00df v\u00f9 b\u00f8 gq s za h t\u00e0 \u00e1 b\u00f9 bw ` w ` y br t iw xy u a py v ya \u00fe r d\u00fa a \u00e5q d\u00f6 4r q \"\u00df b\u00f8 ga 4\u00f9 ba py v zw `\u00d7 qa \"u `w ` z ir q\u00fd pr s\u00df a p\u00f8 gq t w `r qy \u00fe \u00f9 q 6 a\u00f6 pq ty \u00fa a \u00b9\u00df a p\u00f8 zu \u00fd \u00a4r q\u00f8 g aa \u00b9r sy \u00e5 z\u00df a 4a \u00f6 \u00f9 \u00b9 ga \u00e3 \u00ae pg \u00ae g\u00f9 br qs bt s\u00f9 2 \u00f9 va 4i \u00e5q q\u00f8 a \u00b1q q\u00f6 4\u00f6 4a 4\u00df y q t\u00fa bu `a \u00a6\u00fd \u00a4r s\u00f8 \"r u i \u00f6 w `\u00f8 g\u00f6 4s b 2 i q ty v\u00f6 4a p pg s\u00df q t\u00f8 u w \u00f6 s bu q t\u00f8 gu xi aw `y \u00b9e qa pi u\u00e8 pr q\u00f8 i \"q t g\u00f6 \u00f9 bw `y bt \u00e0 s\u00ef bs v\u00f8 z g\u00f9 ba 4\u00f8 pr q\u00df a 4\u00f8 q 6 gw xr sy v \u2022\u00f6 4q qy 2\u00fa a \u00b1q q b ba p a r \u00f9 bw \u00a1\u00fd \u00a4s by v\u00f6 ' gw xr sy \u00fa ui 3q q b yw `y bt \"y ba p\u00e8 ya 4\u00f0 vy bw x w `r qy v r o k z eh p u | \u00a4w `y \u00a4w `p \u2022\u00f8 gr qu `r qt \u00e0 \u00e1 b\u00f9 ba 2q q\u00f6 4\u00ed us bw w d gw xr sy \u00e2r q\u00fd g\u00f9 ba p a \"\u00df vq 6 a 4\u00f8 gy v 8w 8 yr sy ba 2 2q ty \u00aes vq tu `u `i qg \u00fa \u00aei d\u00e8 \u00f9 bw \u00f6 \u00f9 g g\u00f9 ba 2s v a 4\u00f8 8\u00f9 vq s r a 4\u00e3 \u00ae\u00df vu xw \u00f6 w x u `i iw `y bw x w q 6 ga \u00a6 \u00f9 va \u00b3\u00df b\u00f8 gr y\u00f6 a p g p\u00e0 qv \u00a6r 6\u00e8 pa 4\u00d7 sa 4\u00f8 g 6u xr st qw \u00f6 4q tu `u `i w d b z\u00f9 vr qs bu 2q tu zr 8\u00fa a \u00b3\u00df r s g w x\u00fa bu `a \u00fd \u00a4r s\u00f8 \u00f9 ba \u00b5\u00df b\u00f8 r y\u00f6 4a p g r r i\u00fa a \u00b5w xy i q ty u w q 6 ga p 2\u00e8 \u00f9 ba py 2 \u00f9 va \u00b5 i \u00ae z a p \u00f0 vy v b \u00a1 \u00f9 vq t y br sy ba \u00b3r q\u00fd w d \u2022\u00fd \u00a4\u00f8 q t \"a \u00a1\u00f6 4q qy w xy u a p\u00f8 \u00df v\u00f8 a 4 p g\u00f9 ba 8s v a 4\u00f8 w `y b\u00df bs y \u00e0 p cq q\u00f8 z fr t\u00fd \u00f9 ba p\u00d7 \u00aew ` w xr sy r q\u00fd \u00f6 \u00f8 ga pq t w `y bt \u00a6 g\u00f9 bw ` c \"r y ys bu `a pw ` ( r eq tu `u `r 6\u00e8 \u00fd \u00a4\u00f8 gq q aa ( r \u00b1\u00fa a b\u00f8 ga 4s v gq t\u00fa bu `a q\u00e0 \u00f6 a pq q\u00f6 \u00f9 \u00fd \u00a4\u00f8 gq q \"a pw f\u00f8 a z\u00df r qy zw `\u00fa bu `a \u00a1\u00fd \u00a4r s\u00f8 rw xy u a p\u00f8 \u00df v\u00f8 a 4 w `y bt \u00b1 vq 6 gq \u00b3\u00fd \u00a4r q\u00f8 rw x g a 4u x\u00fd ig 6w x cw c\u00df r s g zw `\u00fa bu `a gr \u00b5\u00f8 ga 4s za p \u00f9 va q q aa 3\u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu fe \u00aey br 6\u00e8 u `a p bt qa \"\u00fa vq q a q\u00e0 f\u00ef br s\u00f8 a \u00e3 bq t \"\u00df bu `a qg (t qa py v ya 4\u00f8 \"q i \u00e2\u00fa a \u00a4q d s b\u00fa y\u00fd \u00a4\u00f8 q t \"a r t\u00fd rq ty br q \u00f9 ba p\u00f8 b\u00fd \u00a4\u00f8 gq q aa sg b zs \u00f6 \u00f9 \u00b6q s b\u00df a p\u00f8 g r qy %\u00e0 v\u00e1 b\u00f9 ba q tt sa 4y u b \u00f9 ba py \u00b6u xa q t\u00f8 gy v zr s \"a \u00b1\u00f8 gs bu `a p b\u00fd \u00a4r s\u00f8 \u00a6 ya \u00f0 y bw xy vt \u00f9 ba 8t sa 4y v ya p\u00f8 br t\u00fd rq i\u00df a 4\u00f8 r qy \u00e0 b\u00e1 b\u00f9 ba 8q qt qa 4y u 2q i 2y ba 4a 3 r \"\u00fa a q s bq t\u00df b a p \u00e5 r 2r q \u00f9 ba p\u00f8 yr q 2q tw `y v q t zr s aa \u00b5\u00df r sw xy u bu `q t a p\u00f8 pg u\u00e8 \u00f9 bw \u00f6 \u00f9 \u00b9\u00f8 a \u00ed us bw x\u00f8 ga p \u00a1w xy b\u00fd \u00a4r q\u00f8 g \"q t w `r qy \u00b9r sy \u00e5w `y u a 4\u00f8 g\u00df b\u00f8 ga gw xy bt \u00f9 ba \u00b1t qa py v ya 4\u00f8 g \u00ae q i sg q\u00fd \u00a4r s\u00f8 q ty bw ` 2q tu 4\u00e0 6\u00e1 b\u00f9 ba p\u00f8 a pq t\u00f8 ga p\u00f6 4r q \" \"r qy vq qu xw x w `a p (w xy \u00f9 ba bu q ty bt ss vq tt sa \u00a1s v a p \u00fa a 4 i\u00e8 a pa 4y \u00f9 ba yr s \"q qw xy (q qy v w d ew ` \u00b1\u00f9 ba p\u00f8 a \u00f9 vq t \u00b5 \"r y ys bu q t\u00f8 gw d ii \u00b6r q\u00fd \u2022 \u00f9 ba a\u00df b\u00f8 gr q\u00df r s a p \u00b6\u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 \u00aei 3w \u00b5e qa 4i s\u00e0 \u00fe \u00a6s bu xa \u00b1u xa q t\u00f8 gy ba p \u00a4\u00fd \u00a4\u00f8 gr q \u00f9 ba 3\u00df b\u00f8 a p\u00d7 \u00aew xr ss v yr s \"q qw xy g\u00f6 pq ty \u00bf\u00fa a \u00e5q t\u00df v\u00df bu xw `a p \u00bf r g\u00f9 ba \u00e5y ba p\u00e8 yr q 2q tw `y \u00e0 r\u00e7 \u00b3\u00fd \u00f6 4r qs b\u00f8 a qg y ba p\u00e8 \u00f8 s vu xa \u00f9 vq \u00d7 qa \u00e5 r \u00fa a \u00f6 4\u00f8 a q 6 a \u00bf\u00fd \u00a4r s\u00f8 \" br q 2q tw `y \u00fa \u00df a \u00f6 w x\u00f0 \u00f6 3 a p\u00f8 \"w `y br qu `r qt sw xa 4g fw xy q q b bw d gw xr sy gr \u00e2w `y v\u00f6 r s\u00f8 \u00f8 ga p\u00f6 \u00f6 r qy \u00f6 u `s v zw `r qy q q p\u00fd \u00a4\u00f8 q t \"a p \u00a6q q\u00f8 a es v a p \u00a4w `y yw d\u00f3 va 4\u00f8 ga 4y u \u00b5\u00f6 4r qy u a 4\u00e3 \u00ae g p\u00e0 b\u00fe rq \u00b5\u00fe a 4\u00e3 b\u00f6 a 4u bw `y w xy v\u00f6 4\u00f8 a p \"a 4y u gq qu e uy vr 6\u00e8 u xa yt qa eq q\u00f6 p\u00ed ss vw ` w d gw xr sy g y\u00e8 \u00f9 bw \u00f6 \u00f9 \u00b6\u00f8 a pw xy y\u00fd \u00a4r s\u00f8 g\u00f6 4a p pw x g by ba \u00f6 a p g w d ii \u00b9w `y \u00a4 \u00f9 bw \"r y ys bu `a q\u00e0 n z\u00ec y i\u00f1 \u2022\u00ef \u00a1\u00f2 s\u00a9 \u00fe\u00f1 \u00a1\u00f3 \u00ae\u00f0 v\u00f1 y \u00e1 b\u00f9 ba \u2022t qr uq tu 6r q\u00fd s g\u00f9 ba \u00a1 yw q tu `r qt ss ba \u2022\u00f6 r sy s g\u00f8 r su t\u00f6 r s a\u00df r qy va 4y u w ` r 2q te sa ra \u00e3 y\u00df a 4\u00f8 zu wq tt qa py u \u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy v y vq 6 gs b\u00f8 gq qu \u00e0 \u00aec r u i b\u00f6 s v z r s aa p\u00f8 w `y v\u00ed us bw `\u00f8 i \"\u00df b\u00f9 vr qy ba \u00b1u xw `y ba \u00a1\u00f8 ga p\u00ed us bw `\u00f8 a \u00b5s v a 4\u00f8 r r \" gq i ir s\u00f8 a py s ga 4\u00f8 b z\u00df a p\u00f6 4w d\u00f0 \u00f6 q ty v \u00e8 a p\u00f8 g \u00e8 \u00f9 ba 4y \u00df b\u00f8 r s \"r t a \u00bf\u00e8 w x \u00f9 \u00faq d\u00f0 b\u00e3 ya p \u00fa za 4 ir t\u00fd \u00b3\u00ed us ba i gw xr sy v pg (\u00e8 \u00f9 bw \u00f6 \u00f9 u `a pq s b r \u00e2q \u00f5 \"a 4y \u00aes y\u00f8 w `\u00d7 qa py \u00a4 bw `q qu xr st qs ba \u00b1\u00f8 gq t \u00f9 ba p\u00f8 b \u00f9 vq qy \u00a4q 2\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy \u00e0 \u00f5 y \u00e5w ` 3w ` a\u00df r q\u00f8 gq qy u \u00b9 r \u00bf\u00f0 \u00f8 g z \u00e5a \u00e3 bq q aw `y ba d\u00e8 \u00f9 q 6 3e \u00aew `y v \u00eer q\u00fd ew `y u a p\u00f8 gq s\u00f6 ' w `r qy \u00fb g\u00f9 ba \u00f5q qt qa 4y u \u00e5 is v z a 4y bt uq tt qa 2w `y \u00fd \u00a4r q\u00f8 ie \u00aey br 6\u00e8 u xa yt qa \u00b9q s\u00f6 4\u00ed us bw zw x w `r qy %\u00e0 \u00f5 y iw a a 4y u w q tu `u `i \u00e2q \u00b6 q q e \u00f5\u00fd \u00a4r s\u00f8 \u00f0 vu `u xw `y bt dw `y g bq t gq bg \u00e8 \u00f9 bw `\u00f6 \u00f9 %g \u00e8 \u00f9 ba 4y \u00bf\u00f6 4r q \"\u00df bu `a a g g\u00f9 ba \u00e5q tt sa 4y u 8w ` q t\u00fa bu `a \" r s b\u00df v bq t a \" \u00f9 va 2e uy vr 6\u00e8 u xa yt qa \"\u00fa vq s za \"\u00e8 w x \u00f9 \u00e0 \u00f6 e ya p g\u00f6 \u00f8 gw `\u00fa a w xy \u00e2\u00df b\u00f8 ga 4\u00d7 \u00aew xr ss v \u00b1 za \u00f6 ' w `r qy 4g \u00f9 ba \"q tt sa 4y u \u00b5y va 4a p v \u00b5q \u00b9\u00f0 b\u00e3 ya p dy \u00aes b i\u00fa a p\u00f8 er t\u00fd \u2022a 4u `a 4 \"a py s 4\u00e0 v \u00a6r 6\u00e8 pa 4\u00d7 qa p\u00f8 pg cw x \u00b9w ` \"y vr t \u00b9y ba \u00f6 a p g gq t\u00f8 gi \u00fd \u00a4r q\u00f8 \" \u00f9 va s v za p\u00f8 g a gr t qw `\u00d7 qa q tu `u r t\u00fd \u00b1 \u00f9 ba w `y y\u00fd \u00a4r s\u00f8 2q 6 gw xr sy \u00faw `y \u00fbq \u00f0 b\u00e3 ya p \u00far q\u00f8 ya 4\u00f8 \u00e0 (p \u00a1\u00f8 r s\u00fa r q as v a p \" g\u00f6 \u00f8 gw x\u00df b g i r \u00f6 r sy s g\u00f8 r su \u00a1 g\u00f9 ba yw `\u00f8 a \u00f6 ' w `r qy q ty v g \u00f9 ba \u00f6 4r qy u a py s \"r t\u00fd \u00b1q \u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy \u00e0 q\u00e1 b\u00f9 vw ` w ` y br q p\u00d7 sa 4\u00f8 gi i\u00df b\u00f8 q q\u00f6 w \u00f6 4q qu vw x\u00fd \u00fd va \u00e3 yw `\u00fa bw `u xw x ii \"w ` pq \u00f8 ga p\u00ed us bw `\u00f8 a p \"a 4y u pg uq q w d bw ` y br q \u00df r u w x\u00fa vu xa r gr \u00b5q qy s gw `\u00f6 4w x\u00df q 6 a q tu `u u\u00f6 4r q \u00fa vw xy vq t w `r qy v %r t\u00fd y\u00e8 \u00f9 bw \u00f6 \u00f9 r q\u00f8 ya p\u00f8 %q \u00a6s v a 4\u00f8 ( 2q i \u00b1 \u00df a \u00f6 w x\u00fd \u00a4i \u00b1\u00fd q q\u00f6 ' 4\u00e0 \u00f6 q \"\u00f8 a zs bu x pg v\u00df b\u00f8 a p\u00d7 \u00aew xr ss v w ` a\u00df vu xa p aa py u gq 6 gw xr sy v r q\u00fd f g\u00f9 ba 8e \u00aey br 6\u00e8 u `a p yt sa q q\u00f6 4\u00ed us bw w d gw xr sy 3 \"r y ys bu `a 8\u00fd \u00a4r qu `u `r 6\u00e8 \u00a6 \u00f9 ba 8 \"a 4y \u00aes y\u00f8 gw x\u00d7 sa 4y \u00a4 yw `q qu xr st qs ba e \"r y ya 4u m\u00e0 \u00f6 \"r s\u00f8 a eq q bq q\u00df y w `\u00d7 qa eq t\u00df v\u00df b\u00f8 r uq q\u00f6 \u00f9 \u00b9w p r 2q qu xu `r 6\u00e8 \u00e0s v a 4\u00f8 r 2 z\u00df a p\u00f6 4w d\u00fd \u00a4i 3 zu `r t b\u00d7 6q tu `s ba p bw `y 3y vr i\u00f0 v\u00e3 \u00aea r q\u00f8 ya 4\u00f8 \u00e0 b\u00f5 y \u00b5w \u00b5w x \"\u00df a 4\u00f8 q 6 w `\u00d7 qa \u00fd \u00a4r q\u00f8 \u00a6 g\u00f9 ba r su ` d g\u00f6 \u00f8 gw `\u00df y \u00b5 i \u00ae z a p \u00f7 gr 3\u00f6 \u00f9 vq qy bt qa s\u00e0 \u00f6 \u00b3 \u00f9 va i\u00f6 r sy \u00ae\u00d7 qa 4\u00f8 gq 6 w `r qy w ` 3\u00f6 a 4y u ga 4\u00f8 ga p \u00fbq t\u00f8 gr qs by \u00faa 4\u00e3 \u00ae \u00f8 q q\u00f6 ' gw xy vt \u00bfw xy y\u00fd \u00a4r s\u00f8 2q t w `r qy \u00fb\u00fd \u00a4\u00f8 gr q g\u00f9 ba \u00f5s za p\u00f8 2 r \u00bf\u00f0 u xu \u00b1w xy \u00fb g\u00f9 ba \u00fd \u00a4\u00f8 q t \"a qg q d\u00fd \u00a4\u00f8 q t \"a \u00b6w ` ay br 6\u00e8 \u00f7\u00fa r ss by v ya g gr q \u00fe g\u00f6 \u00f8 gw x\u00df y \u00e0 \u2022\u00e1 b\u00f9 ba \u00a4\u00df bs b\u00f8 g\u00df r u za \u00b6r t\u00fd \u00b1q \u00fe g\u00f6 \u00f8 gw `\u00df y aw a r yw `\u00f8 a \u00f6 ' \" \u00f9 va r 6\u00d7 qa 4\u00f8 q tu `u \u00f6 r sy u\u00d7 sa 4\u00f8 q t w `r qy g \u00ae s v\u00f6 \u00f9 q q pg y\u00f9 br 6\u00e8 g\u00f9 ba q tt sa 4y u \u00a6 z\u00f9 vr qs bu \u00a4\u00f8 a q q\u00f6 ' r sy v\u00f6 a q qu xu v g\u00f9 ba y ba \u00f6 a p g gq t\u00f8 gi w xy y\u00fd \u00a4r s\u00f8 2q t w `r qy dw \u00b3t sw x\u00d7 sa 4y g \u00e8 \u00f9 ba 4\u00f8 ga pq s \u00fd \u00a4\u00f8 q t \"a p \u00b5y br 6\u00e8 \u00f9 vq qy v yu `a \u00f9 va g\u00f8 gq qy v zu q 6 gw xr sy r t\u00fd \u00a1 yw q tu `r qt ss ba 8 gr zr s aa 3w xy u ga 4\u00f8 gy vq tu pe \u00aey br 6\u00e8 u xa yt qa \u00e5\u00f8 a p\u00df b\u00f8 a za py u gq 6 gw xr sy \u00e0 (\u00e1 b\u00f9 va \u00e5 gr q\u00df yu y \"r s z \u00fd \u00a4\u00f8 q t \"a \u00e5r q\u00fd \u00a6 \u00f9 ba \u00a4\u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 \u00aei \u00e8 w xu `u v\u00fa a 8q q g r \u00ae\u00f6 4w `q t a 2\u00e8 w d g\u00f9 \u00b9 g\u00f9 ba 8 \u00f6 4\u00f8 w `\u00df y p\u00e0 b \u00aew `y v\u00f6 4a \u00b1 r q \"a \u00b1w xy y\u00fd \u00a4r s\u00f8 2q t w `r qy \u00b9 2q i 2\u00fa a \u00b1 z r s\u00f8 a 2\u00e8 w d g\u00f9 bw `y zs b\u00fa b\u00fd \u00a4\u00f8 gq q aa 4g pw x \u00a4w \u00a4y ba p\u00f6 4a p g q q\u00f8 i \u00fa r \u00fa\u00df vq q g \u00e5w `y y\u00fd \u00a4r s\u00f8 2q 6 gw xr sy yr 6\u00e8 y \u00ee g\u00f9 ba i g\u00f8 s v\u00f6 s b\u00f8 ga \u00e2 s v\u00f6 \u00f9 \u00f9 vq t zs b\u00fa b\u00fd \u00a4\u00f8 gq q aa i\u00f6 pq ty q qu ` r \u00f5w `y u a p\u00f8 \u00df b\u00f8 ga i \u00f9 ba \u00a4s v a 4\u00f8 aw xy v\u00df bs y a\u00fd \u00a4r q\u00f8 a\u00d7 q qu xs va p p\u00e0 f\u00f5 wy r q\u00f8 ya 4\u00f8 i r \u00fe yr \u00fe r vg ( \u00f9 va \u00fd \u00a4\u00f8 gq q aa 2 is v z e \u00aey br 6\u00e8 \u00e8 \u00f9 bw \u00f6 \u00f9 \u00bf zu `r t q t\u00f8 ga \u00b9 s b\u00fa y\u00fd \u00a4\u00f8 q t \"a p p\u00e0 \u00e1 b\u00f9 bw u `a pq q v e r \u00b6 g\u00f9 ba \u00b9w `y v\u00f6 u `s v w xr sy \u00fer q\u00fd bq qy q q b yw x w `r qy q tu \u00b3 u xr q 3\u00f6 4q qu xu `a p o l mh iz q \u00e2\u00e8 \u00f9 ba 4\u00f8 ga \u00b6 \u00f9 ba \u00e2 zu `r t \u00e5y q t \"a dq ty v g\u00f9 ba \u00f5 s b\u00fa y\u00fd \u00a4\u00f8 q t \"a ii \u00ae\u00df a w ` 2\u00df q tw `\u00f8 a \u00e0 r\u00f5 wy \u00f9 ba \u00fd \u00a4s b s b\u00f8 ga qg \u00a1 u `r t g a g\u00f9 vq 6 \u00b9s za \"\u00fd \u00a4\u00f8 gq q \"a \u00a4\u00e8 w `u `u \u00b5q ts b r q 2q t w \u00f6 4q tu `u `i gq tt st qa \u00faq s 2q zs b\u00fa b\u00fd \u00a4\u00f8 gq q aa \u00b6q ty \u00bf\u00e8 w xu `u a 4u `w ` aw `y vq t a 3 \u00f9 ba \u00a4y ba 4a \u00bf\u00fd \u00a4r s\u00f8 i g\u00f9 ba \u00a4a \u00e3 \u00ae \u00f8 q \u00f5 u xr q p\u00e0 \u2022 y\u00f6 4\u00f8 w `\u00df y g \"\u00f6 pq ty g g\u00f9 ba 4y \u00fas v a \u00f9 bw w `y y\u00fd \u00a4r q\u00f8 g 2q 6 w `r qy \u00e5 r \u00b9\u00f6 4\u00f8 a q 6 a e s b\u00fa y r s\u00df bw \u00f6 4 p\u00e0 v \u00aes b\u00fa y gr q\u00df bw \u00f6 4 u `w `y be 3q \" s b\u00fa y\u00fd \u00a4\u00f8 q t \"a \u00b1 r a \u00f9 ba e gr q\u00df yu y \"r s z \u00fd \u00a4\u00f8 gq q aa sg \u2022q ty v \u00f9 \u00aes v pg \u2022\u00df b\u00f8 gr 6\u00d7 \u00aew ` ba \u00a4q \u00f6 \u00f9 vq qy by ba 4u r q\u00fd \u00b1\u00f6 4r q \" s by vw `\u00f6 pq 6 w `r qy \u00fd \u00a4r q\u00f8 2\u00df vq s w `y bt \u00e2s za p\u00f8 2w xy b\u00df vs y p\u00e0 \u00e9 \u2022\u00d7 qa p\u00f8 i \u00bfw `y b\u00df bs y 2w i\u00f0 vu d ga 4\u00f8 ga p g \u00f9 b\u00f8 gr qs bt s\u00f9 g g\u00f9 ba \u00e5\u00fd \u00a4\u00f8 q t \"a \u00a4\u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 ui s\u00e0 \u00f6 \"a pq q\u00f6 \u00f9 g\u00fd \u00a4\u00f8 gq q aa \u00a4w aq q\u00fa bu `a \u00e5 gr \u00df b\u00f8 r y\u00f6 4a p g s za p\u00f8 w xy b\u00df vs y pg zu `r t \u00f6 4q ty \u00a4\u00fa a e\u00f0 vu xu `a p \u00a4w `y q ty \u00aei 2r q\u00f8 ya 4\u00f8 \u00e0 y\u00f6 \u00f8 gw x\u00df b g ( s v z f\u00fa a q t\u00fa bu `a \u2022 gr \u00b5\u00d7 sa 4\u00f8 gw d\u00fd \u00a4i \u00b1 g\u00f9 vq 6 rq ty ia 4y u w `\u00f8 a \u00a1\u00fd \u00a4\u00f8 gq q \"a \u00f9 vq s %\u00fa a 4a py \u00f0 vu `u `a p s v\u00f6 p\u00f6 a p g z\u00fd \u00a4s bu xu `i q\u00e0 \u00e1 b\u00f9 ba 4\u00f8 ga \u00b5 2q i 2\u00fa a ea 4u `a 4 \"a 4y u g bw `y 3\u00fd \u00a4\u00f8 gq q aa \u00f9 vq t q q\u00f8 a \u00b1r q\u00df b w `r qy vq qu vq qy v \u00b9w x w ` p g\u00f9 ba 4\u00f8 ga \u00fd \u00a4r s\u00f8 a \u00b1y ba \u00f6 a p g gq t\u00f8 gi r i \u00df a p\u00f6 w x\u00fd \u00a4i \"\u00e8 \u00f9 bw \u00f6 \u00f9 3 u xr q \u00a1w ` pq \u00f8 ga p\u00ed us bw w d ga q\u00e0 \u00f6 y ba p\u00e8 \u00e0 bq ta p ar sy g %l q o x fl q j tg sw \u00a1w `y u \u00f8 gr y ys v\u00f6 a 2\u00e8 \u00f9 bw \u00f6 \u00f9 s v za \"q ty \u00aei \u00bfw xp \u00a1\u00f8 r su xr st \u00f5\u00df b\u00f8 ga p yw \u00f6 4q t a 3 r \u00f6 \u00f9 ba p\u00f6 e \u00bf\u00e8 \u00f9 va \u00f9 va 4\u00f8 2q \u00f5\u00d7 6q qu xs ba \u00a4\u00f9 vq s \u00fd \u00a4s vu d\u00f0 vu `u `a p \u00fa \u00f9 ba \u00a4\u00f8 ga p\u00ed us bw `\u00f8 a 4u aa py u g p\u00e0 \u00e1 b\u00f9 bw ` \u00b1\u00e8 pr q\u00f8 ge y \u00b3w `y \u00fe\u00f6 4r qy i is vy v\u00f6 ' gw xr sy \u00e2\u00e8 w x \u00f9 q \u00e5y va 4\u00e8 \u00fd \u00a4s vy v\u00f6 ' gw xr sy g 6| \u00a3h i k l q g \u00e8 \u00f9 bw \u00f6 \u00f9 \u00e2q t\u00df v\u00df bu xw `a p \u00f9 ba \u00df b\u00f8 a yw \u00f6 4q 6 ga \u2022 ya \u00f0 y ba p 8w `y {l q o x fl q j \u00b5 r \u00b3 ya 4 a p\u00f8 \"w `y ba \u2022\u00e8 \u00f9 ba 4 \u00f9 ba p\u00f8 (q b\u00fd \u00a4\u00f8 q t \"a rw %\u00f6 r s \"\u00df bu xa 4 a s\u00e0 p \u00ee\u00f9 ba py q t\u00df b\u00df bu `w `a p a r i zs b\u00fa b\u00fd \u00a4\u00f8 gq q aa 4g q \u00f9 bw \u2022\u00e8 w `u `u q tu `u `r 6\u00e8 g\u00f9 ba \u00b3a py s gw x\u00f8 ga \u00f9 bw `a 4\u00f8 q t\u00f8 \u00f6 \u00f9 \u00aei r \u00fa a \u00b3\u00f6 \u00f9 va p\u00f6 e qa \u00e0 t\u00f5 wy \" ga 4\u00f8 g \" r t\u00fd ce uy vr 6\u00e8 u xa yt qa eq q\u00f6 p\u00ed ss vw ` w d gw xr sy g u \u00f9 bw \u00e8 w `u xu %t qs vq q\u00f8 gq qy s ga 4a \u00b5 \u00f9 vq t b \u00f9 ba 8s v a 4\u00f8 \u00f9 q q b\u00df b\u00f8 gr 6\u00d7 \u00aew ` ya \u00e5a py br qs vt q\u00f9 w xy y\u00fd \u00a4r s\u00f8 2q t w `r qy \u00a4\u00fd \u00a4r q\u00f8 \u00b3 \u00f9 ba e \u00aey br 6\u00e8 u `a p bt qa e\u00fa vq q a 8 gr 2\u00fa a is b\u00df vq 6 a \u00e0 \u00e1 b\u00f9 vw ` \u00a6\u00fd \u00a4r q\u00f8 g \" \u00f9 ba u q q z \u00b3a pu xa p aa py u y ba 4a ya p 3\u00fd \u00a4r q\u00f8 b\u00fd a \u00e3 yw x\u00fa vu xa 8\u00f6 r sy \u00ae\u00d7 qa 4\u00f8 gq 6 w `r qy %\u00e0 \u00e2\u00f1 \u00f3 \u00b3\u00ed y z\u00f2 b i\u00f1 \u00a1\u00f3 s b\u00f8 \u00f8 ga 4y u 2\u00f6 r sy u\u00d7 sa 4\u00f8 q t w `r qy vq qu \u00a1q tt sa 4y u g aq t\u00f8 ga \u00e5\u00df v\u00f8 w ` 2q t\u00f8 gw xu `i \u00fd \u00a4r y\u00f6 s v a p r qy \u00f8 ga pq qu xw z w \u00f6 \u00e5 w x is bu `q t w `r qy \u00far t\u00fd \u00f9 us v \"q qy gw `y s ga 4\u00f8 q q\u00f6 w `r qy v pg f s v\u00f6 \u00f9 q s g\u00f9 ba \u00e5s za \u00a4r t\u00fd \u00a6\u00fa r y yi \u00bfu `q qy bt qs q tt qa 3q ty v \u00bf\u00fa a 4\u00f9 q \u00d7 uw `r qs v\u00f8 \"r y ya 4u 4\u00e0 v \u00a6r 6\u00e8 pa 4\u00d7 qa p\u00f8 pg \u00ae ya p\u00d7 qa 4u `r q\u00df v aa py u pw `y u r \"q tt qa py u b\u00f6 4s v i gr q \"w q t w `r qy \u00e5\u00f9 q q p\u00fa a pa 4y \u00b6y ba pt qu `w xt sw x\u00fa bu `a q\u00e0 y\u00e1 b\u00f9 bw p\u00df vq t\u00df a 4\u00f8 \u00f9 vq q \u00b1 ya 4 \"r sy v i g\u00f8 gq t a q 2\u00fd \u00a4\u00f8 q t \"a 4\u00e8 pr q\u00f8 ge \u00b9 g\u00f9 vq 6 ew ` \u00b1q \u00e5 z \u00f8 gs v\u00f6 s b\u00f8 ga p \"a 4 \u00f9 br y \u00fd \u00a4r s\u00f8 \u00b1q qt qa py s gr \u00e5u `a pq t\u00f8 gy yr q 2q tw `y \u00b6q ty v \u00b6\u00f6 r sy \u00ae\u00d7 qa 4\u00f8 gq 6 w `r qy q tu ve \u00aey br 6\u00e8 u `a p bt qa q\u00e0 \u00f5 y 3w \u00e5 2q q ba \u00f5\u00df r s g zw `\u00fa bu `a d \u00f9 v\u00f8 r ss bt q\u00f9 \u00fb g\u00f9 ba \u00fe a 4\u00df q t\u00f8 q 6 w `r qy \u00fbr q\u00fd \u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu \u00a6q ty v \u00e0 br q 2q tw `y e uy vr 6\u00e8 u xa yt qa 8 gr \u00e5\u00df b\u00f8 gr 6\u00d7 \u00aew ` ba q \u00b9\u00f6 r sy v w ` z a py s eq t\u00df b\u00df v\u00f8 r uq q\u00f6 \u00f9 \u00a4\u00fd \u00a4r q\u00f8 \u00b1\u00f6 s v z r s aw w xy bt \u00a4q ty dq qt qa 4y u \u00e0 r s a\u00df vu xa 4u aa py u w `y bt \u00b9 g\u00f9 bw ` eq q\u00f8 g\u00f6 \u00f9 bw x a \u00f6 ' gs b\u00f8 a w ` \u00b5 \u00f9 va is v a r q\u00fd \u00fe rq \u00b1\u00fe 8\u00e0 \u00e1 b\u00f9 ba \"a 4 \u00f9 br y yr su xr st qi zs v\u00df b\u00df r s\u00f8 z \u00b3w `y v\u00f6 4\u00f8 a 4u aa py u gq tu yu `a pq q\u00f8 y vw xy bt \u00b5w xy 2q \u00b1\u00f6 r sy v zw z a 4y u c 2q ty by ba p\u00f8 p\u00e0 t\u00e1 b\u00f9 vw ` cw c zw `t qy bw x\u00f0 \u00f6 pq ty u cq s f \u00f9 ba i y i ga 4 w rq tw ` aa r \"\u00fa a q s bq t\u00df b w `\u00d7 qa 8q ty v \u00a4\u00f6 4q qy \u00b6t sq tw `y \u00e5e \u00aey br 6\u00e8 u `a p bt qa e\u00e8 \u00f9 bw `u xa ew `y \u00a4s za s\u00e0 \u00f6 \u00f6 \u00f8 gs v\u00f6 w q tu y\u00df vq q\u00f8 z rr q\u00fd g\u00f9 ba \"r \u00ae bs bu xa w c g\u00f9 ba s v a pr q\u00fd \u00fd \u00a4\u00f8 q t \"a 4\u00e0 t\u00e1 b\u00f9 bw \u2022 z \u00f8 gs v\u00f6 ' gs b\u00f8 ga pa py v\u00f6 4q q\u00df v s bu `q t a bq 6 q 3w `y \u00bfq \u00a4 \"q qy by ba p\u00f8 8 \u00f9 vq t q tu `u xr 6\u00e8 \u00a6 \u00b1e \u00aey br 6\u00e8 u `a p yt sa gr \u00fa a 2\u00f8 ga 4s q q\u00fa bu xa s\u00e0 \u00e1 b\u00f9 ba \u00b9\u00f6 r u i e r dq s bq t\u00df b 8q qy q tt qa py u i gr \u00feq \u00fe zw ` \"w xu q t\u00f8 2 yr s 2q tw `y \u00e8 w `u xu b\u00fa a \u00a4\u00f8 ga p bs v\u00f6 a \u00e0 \u2022\u00ef b\u00f8 q t \"a p aq tu r \u00fe\u00f6 4r qy u \u00f8 gw x\u00fa vs y a 3 r \u00e2\u00fd va \u00e3 yw `\u00fa bu `a \u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy 2\u00fd vr 6\u00e8 8g y\u00e8 \u00f9 vw `\u00f6 \u00f9 \u00a4\u00e8 r ss bu 3r q \u00f9 ba p\u00f8 \u00e8 w a \u00b5\u00fa a p\u00f6 4r q \"a q a aa py \u00aes \u00a4 y\u00f8 gw `\u00d7 qa 4y \u00b6 yw q tu `r qt ss ba q\u00e0 \u00f5 wy \u00f5 zs v a 2q q\u00f8 i sg v g\u00f9 ba i \"r y ys bu `a \" ya q tw `u xa w xy \u00f5 \u00f9 bw \u00b1\u00df vq t\u00df a 4\u00f8 \u00b1w \u00b1q \u00e5y br 6\u00d7 qa pu (q q\u00df b\u00df b\u00f8 gr sq q\u00f6 \u00f9 \u00b6 gr 3 r qu `\u00d7 uu w xy bt \u00a4 g\u00f9 ba \"\u00df b\u00f8 r s\u00fa bu `a 4 \u00f2r q\u00fd p\u00f6 s i gr q \"w ` w `y bt \u00a4\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy vq tu fq tt sa 4y u g p\u00e0 v\u00f5 y w ` 8\u00f6 pq t\u00df vq q\u00fa bu xa ar t\u00fd pu xa q t\u00f8 gy bw `y bt \u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu q qy v 3 br q 2q tw `y 3e \u00aey br 6\u00e8 u `a p bt qa \u00b1w xy q i\u00fd va \u00e3 yw `\u00fa bu `a q ty v 3\u00f8 a ps v gq t\u00fa bu `a e \"q qy by ba p\u00f8 p\u00e0 \u00a6 \u00a6\u00f2 r b\u00f2 \u00a6\u00f0 \u00a3\u00a9 \u00f1 \u00a1\u00f0 b\u00ee \u00e1 b\u00f9 bw ` \u00a1\u00fd \u00a4\u00f8 q t \"a 4\u00e8 pr q\u00f8 ge \u00f9 vq s \u00a1q qu xu \u00f9 ba \u00b5a 4u `a 4 \"a 4y u \u00a1\u00f8 ga p\u00ed us bw `\u00f8 a a\u00fd \u00a4r q\u00f8 e uy vr 6\u00e8 u xa yt qa \u00b3q s\u00f6 4\u00ed us bw zw x w `r qy \"\u00fd \u00a4r s\u00f8 \u00fa r t g\u00f9 yr q 2q tw `y \u00b6q ty v 3\u00f6 r qy \u00ae\u00d7 sa 4\u00f8 q t w `r qy vq qu ve \u00aey br 6\u00e8 u `a p yt sa qg u \u00f9 br ss bt q\u00f9 %g \u00ae \u00f9 ba e\u00e8 pr q\u00f8 ge \" \u00f9 \u00aes v p\u00fd q t\u00f8 bw br t\u00fd cq \u00df b\u00f8 ga 4u `w ` iu w xy vq q\u00f8 i \u00e5y vq 6 gs b\u00f8 a s\u00e0 q ts bt sw xy bt i \u00f9 va zs \u00f6 4\u00f6 a pr q\u00fd cq 2\u00f6 4r qy \u00ae\u00d7 qa p\u00f8 g gq 6 gw xr sy vq tu q tt qa py u bw \u00a6q \" yw \u00a2 \u00b9\u00f6 s bu x \u00b3 2q ty by va 4\u00f8 g bq q p \u00f9 va 4\u00f8 ga q t\u00f8 ga 2y br \u00e2 z gq qy v bq t\u00f8 \u00fe \"a \u00f8 gw \u00f6 4 8\u00fd \u00a4r s\u00f8 \"a pq s zs v\u00f8 w `y bt \u00b6 \u00f9 va \u00e5\u00df a 4\u00f8 \u00fd \u00a4r q\u00f8 g \"q qy v\u00f6 a s\u00e0 \u00f6 a\u00fe rq \u00b1\u00fe \u00f9 vq s q tu `\u00f8 ga pq q bi \u00df b\u00f8 r 6\u00d7 sa 4y r \u00fa a q s v\u00f6 4\u00f6 4a p g i\u00fd \u00a4s bu \"a 4 \u00f9 br y yr su xr st qi \u00fd \u00a4r q\u00f8 \"e \u00aey br 6\u00e8 u `a p yt sa \u00a4q s\u00f6 4\u00ed us bw zw x w `r qy %g ( g\u00f9 ba 4\u00f8 ga \u00b6w ` \"y vr y ba 4a r \u00e5 a i e\u00e8 \u00f9 ba g\u00f9 ba 4\u00f8 \u00b1 g\u00f9 ba i \"r y ys bu `a \"\u00f6 4q ty \u00e2q q\u00f6 4\u00ed us bw `\u00f8 ga e \u00aey br 6\u00e8 u `a p yt sa q\u00e0 v\u00f5 wy i ga pq q g \u00fd \u00a4s v\u00f8 z g\u00f9 ba 4\u00f8 \u00b1\u00e8 r s\u00f8 e y ba 4a b c r \u00fa a \u00b3 br qy ba r sy i ga p z w `y bt \u00f9 br 6\u00e8 \u00fa \u00f9 va a 4y u w `\u00f8 a \u00a6\u00fd \u00a4\u00f8 gq q aa p\u00e8 r s\u00f8 e \u00f6 4r \u00aer q\u00df a 4\u00f8 q 6 a c\u00e8 \u00f9 ba 4y \u00b9q s bq t\u00df b w `y bt r \u00e5q \u00b9 \u00df a p\u00f6 w x\u00f0 \u00f6 br q 2q tw `y \u00e0 \u00f6 zw ya \u00fd \u00a4\u00f8 gr q \u00f7 a i gw xy bt \u00e5r qy r qy va yr q 2q qw xy g v \u00f9 ba p\u00f8 a 8w \u00b3q qu ` r \u00b9q 2y ba pa p \u00a4 gr q q bq q\u00df y c \u00f9 ba q tt sa 4y u f r e s bu x w `\u00df bu `a \u00a6 yr q 2q qw xy v (u g\u00f9 bw ` c\u00e8 bq i qg g\u00f9 ba \u00f8 a 4u ms q q\u00fa bw xu `w x ii 8r t\u00fd v g\u00f9 ba p\u00fd \u00a4\u00f8 gq q \"a 4\u00e8 pr q\u00f8 ge \u00f6 4q ty \u00a4\u00fa a 8\u00f8 a p\u00d7 qa pq qu xa \u00e0 \u00ed b\u00ee \u00f3 \u00b3\u00f1 y \u00a9 %\u00f4 \u00a6\u00ef \u00a7 \u00a9 (\u00f3 \u00a3 \u00e1 b\u00f9 bw ` \u00a6\u00f8 a za q t\u00f8 \u00f6 \u00f9 \u00e5\u00f9 vq s \u00fa a pa 4y \u00b6\u00fd \u00a4s by ya p \u00b6\u00fa \u00aei \u00b9 g\u00f9 ba \u00ae 2q t\u00f8 \u00a6\u00f5 wy u a p\u00f8 y ba 4 \u00b3\u00e1 %a \u00f6 \u00f9 by br su xr st qi \u00a4 p\u00fe \u00a6 q ty v 3 \u00f9 va q ts y g\u00f9 br q\u00f8 \u00e8 pr qs bu u `w xe sa \u00b9 r \u00e2a \u00e3 y\u00df b\u00f8 ga p g 8 g\u00f9 vq ty be y \u00fd \u00a4r q\u00f8 i \u00f9 ba \u00a4 zs b\u00df v\u00df r s\u00f8 z a\u00f8 a \u00f6 a 4w `\u00d7 qa \u00fe \u00f9 b\u00f8 gr qs vt q\u00f9 br ss y \u00f9 va \u00df b\u00f8 r y ys \u00f6 ' w `r qy r t\u00fd \u00b5 \u00f9 bw \"\u00df vq q\u00df a p\u00f8 p\u00e0 \u00f6 u ` r vg c g\u00f9 vq ty be y a gr \u00f6 vq t \u00fch pa 4\u00f8 g\u00f8 gi \u00fd \u00a4r q\u00f8 \"\u00df b\u00f8 gr ur q\u00fd \u00b5\u00f8 ga pq s yw xy vt \u00f5 g\u00f9 bw ` \u00df vq t\u00df a 4\u00f8 \u00e0  the size of available documents to be handled has grown rapidly since the internet was introduced",
        "prob": 0.97913688840022
    }, {
        "ID": 4552,
        "phrase": " algorithm for selecting classifiers \n pe gf z se f 't f\u00b8 qe d se pt \u00a1r p \u00ae \u00a4 \u00b5\u2022 tj ie | t\u00bc u |h wh \u00b8q c ue 3\u00fa s d{ | |\u00fah \"r px sj in ps r 4j i |\u00b03j wf zr 4 | j i |s 8e gj zr 4\u00bc u{ |e \u00b3 d qo n 4f is r 4j i |n \u00e5h yl qh yj ie s \"\u00a1\u00a5 m b\u00a6 d \u00a7 r\u00a9 \u00aa \u00ac\u00ab d\u00ae \u00ae s\u00a1\u00b0'\u00b1 v\u00a9 \u00b2 d\u00b3 f\u00b1 f d\u00b0ut b n p{ |x us 8e \u00b4t v\u00far p\u00b2 e gh r\u00b5 \u00b6 1\u2022 \u03bc \u00b9 )\u00b5 6\u00b8 \u2022 d\u2022 )\u00ba 6\u03bc t\u00bd br t d i\u00bb cr \u00e4 tj ie gf 't \u00bc n \u00bd fx qf wj i dh t c\u00bd r ' e 3 q\u00b0z u ue g x qe gf 't cae \u00a1n \u00bc ye f wj r 4 u{ |e gf wj 't \u00be |e gf i{ |x u |\u00b2 s\u00a2 a k f zr p\u00b2 p{ | xr tt \u00be ve j ie gf r r 4\u00b2 ue f 't r j i tl x\u00be r 4 6j in t b\u00bf br ' t d e\u00a2 \"r 4j wj i se g \u2022h t \u00aer 4 \u00ae iw s r p u ur r\u00a4 p \u00e1\u00e0 e ' qn s \"w \u00a1 i | 6j ie gf w\u00be r 4\u00b0gj i | e \u00a1 s dr p{ |n p\u00b2 x ue \u00a1h yl qh yj ie s \u00eeo n 4f c\u00bb t un ' \u2022{ |e ' s\u00b2 pe \u00a1r p\u00b0'\u00e1 6x u |h w k j i |n | 8\u00b0gl q\u00b03\u00a5 x\u00e2 m\u00e3 b\u00ab %\u00e4 \u00e2 m\u00e5 vae d\u00e7 \u00e9\u00e8 s \u00ea \u00eb \u00ec w\u00aa m \u00a7 \u00e9 \u00b0\u00ed {\u00b1 \u00ef\u00ee ir\u00f0 s\u00e2 \u00b0\u00b1 `\u00b3 f\u00b1 v\u00b2 d\u00b3 f\u00b1 \u00f1 d9\u00e2 \u00b0'\u00b3 s\u00f2 \u00f2 \u00b1 \u00ef\u00f3 im\u00b0'\u00b3 \u00a6 '\u00f4 \u00ec \u00b3 m\u00ae s\u00ec it y\u00aer 4\u00b2 e h \u00f5 1\u00f6 \u00b8 \u00b6 )\u00ba tt !\u00b5 d\u00d7 d\u00d7 \u00f5 \u00f5 \u0157\u00bc q\u1e11\u00bd cr ph wh we { |{ t q p\u1e11\u00bb f |\u00b0z\u00bb ts 8\u00bb n pf ie t \u00a2 31\u00bb ( d{ |{ | | u\u00b2 p qx qf ih yj 't d\u00f8 %\u1e11\u00bd cr ps 8\u015b\u00bc ye { |{ t \u1e11\u00bd f \u00aer p s\u00b2 st \u00b3\u00a4 p |{ | d\u00f9 wr 4{ |s 8h wh wn t r 4 \u00ae d \u00b5i\u00fa fr p v#\u00fb s \u00b1\u00bc yn t q |s 8e 6j ( | \u00b0n t e f ih ir 4j i |n ur p{ b | tj ie f wo r p\u00b0ge h \u00fc uae \u00a1e 'r t%\u00a5 \u00fd\u00ab %\u00fe \u00e2 s\u00df )\u00df pt t\u00far p\u00b2 e gh \u00ba 1\u00b5 \u00d7 o d\u00b5 \u00b4t \u2022 d\u2022 1\u2022 t \u00b6 s\u0157\u00bc q\u00bd cr ph wh we g{ d{ \u00a6r 4 \u00ae \u00a2 3\u0157 tj in se \u0146\u00f8 v d t | u\u00b2 ur p u \u00e2j in s 8n x qj i !\u00fc c\u00be %h yl q\u00b0z un { |n p\u00b2 |\u00b0'r p{ bj i se n pf i |e h ar p\u00bc yn px sj h w\u00fde ge \u00b0 \u00b6r p \u00ae 3\u00b2 e h yj ix qf ie | | 6j ie gf zr p\u00b0j i d e i q dr p{ |n \u00b2 px ue h yl qh yj ie s 8h \u0229\u00a5 \u00fd\u00e0 \u00a8\u00ea w \u00e1\u00a9 r\u00f0 d\u00b1 \u00b0\u00a1\u00f3 d\u00ec w\u00e2 d\u00b3 \u00aa '\u00e3\u00e4 \u00e4 \u00e4 \u00e2 \u00e4 \u00df )\u00df )\u00df s\u00e5 %\u00b2 1\u00f2 `\u00f2 3\u00a6 \u00f4 d\u00ae \u00a7 i d\u00ec \u00b1 `\u00a1\u00ae ae d\u00b0e\u00e0 \u00a8\u00ec \u00f4 1\u00a9 \u00aa 1\u00f2 \u00e1 \u00f3 d\u00b1 v\u00a9 \u00b2 1\u00f2 3\u00ed a \u00e1\u00f0 is\u00f2 \u00ec 9 w\u00e2 \u00e3\u00ab d\u00ae s\u00ae \u012b\u00b0\u00b1 v\u00a9 \u00b2 d\u00b3 f\u00b1 v d\u00b0{\u00b1 \u00b0\u00e7\u00ab 1\u00f2 `\u00f2 \u00e1\u00b2 )\u00e8 d\u00ea w\u00b2 d\u00b3 f\u00b1 `\u00f1 d\u00a6 \u00f4 d\u00ec \u00b3 m\u00ae \u00ec zt u\u00aer 4\u00b2 e h \u00f5 \u00b6 i \u00b6 i\u00b5 6t \u2022 1\u2022 1\u2022 to t\u0157\u00be v)\u00bd fn s 8qj in er 4 \u00ae \u00b3ae \u00b31\u00bc r p sh we \u00aew \u00e2\u015b u |{ |n h wn \u015b u |\u00b0'r 4{ \u00ae\u00bc \u00aer 4h w dh o `n pf (\u00bb q sn ' \u2022{ de s\u00b2 e \u00a1r 4\u00b0'\u00e1 6x u |h w k j i dn p '\u00a5 m e\u00e7 d\u00ea r\u00f0 \u00e9 c\u00a1\u00ea r m \u00a7 r\u00b2 d\u00b0\u00eb\u00ea r\u00b03 \u00ec \u00f2 \u00ef\u00f0 \u00f3 id\u00e4 \u00a9 \u00ed s\u00a1\u00b1 `\u00ec \u00b1 `\u00b3 f\u00b1 v d\u00b0e\u00e2 d\u00ea s\u00ea \u00a1\u00b03 d\u00ec \u00f2 \u00efr\u00f0 \u00e1\u00f3 is\u00e5 `\u00ee \u00b2 d\u00ec sr\u00f0 \u00ef\u00a6 '\u00f4 \u00ec \u00b3 m\u00ae s\u00ec \u00eb\u00e8 d\u00ea \u00eb \u00ec w\u00aa \u00a7 \u00aet \u00aer 4\u00b2 e h \u00b4\u00ba \u00e1i\u2022 \u00f6 t \u2022 \u00f6 \u2022 q1 q3 y\u00b8 n p\u00favt \u00a1\u00bb i\u00bc x s u\u00b2 st t \u00b3\u00a1\u00f8 e gh wh ws r p u vt qr p u \u00f0\u00a5 z r 4\u00b0 sh ws \u00b1x qj i !\u00a2 \"r 4\u00e4 8\u00be r \u00a6s \u00b5x u{ k j i |s 8n t ur 4{ yr ph wh w |h yj zr p 6j | i q k f wj ix ur p{ bf ie 'r p{ | k j ml i\u00b0n sh yj wf ix u\u00b0gj i |n p \u00b8\u00ea 9\u00e2 m\u00e5 `\u00ea r\u00a1\u00b0b\u00f2 \u00b0'\u00ec \u00b3 v\u00f2 \u00b1 v\u00a9 \u00aa 9\u00e2 \u00b0'\u00b3 s\u00f2 \u00f2 \u00b1 \u00ef\u00f3 im\u00b0\u00a1\u00f1 gt \u00b6 \u00fc 1 \u00b8 \u00b4t \u00b5 d\u00d7 d\u00d7 \u00f5 \u015f\u00a2 3!\u00a2 a\u00b0q e 'r 4f '\u00b1 t\u00fdn \u00bb e \u00e5 q xr 4{ |n \u00b2 x se \u00b1j ie \u00b0z u sn { |n \u00b2 4l \u00fc !\u00fb \u00aer 4\u00bc u{ | | u\u00b2 j i ue \u00b3\u00b0n t e gf ih ir j i |n \u00aer 4{ (x sh we gf b | 6j ie gf w\u00be o r p\u00b0e p\u00e4 s \n \u00b0ut b\u00b0z \u00aer pqj ie gf w n sf zr 4s 8e g cn 4f i\u00bb ao n 4f \u00a6ae e g\u015b\u00be f ie gh we 6j i d s\u00b2 un ' \u2022{ |e ' q\u00b2 e \u00e7\u00a2 e\u00a5 yq \u00be f ie h wh t \u2022 \u00f6 \u00a1 \u2022q\u0157\u00be v\u00be f ie h yj in vt \u00bf \u00b5!\u00fb % q cr 4f z sh t r 4 \u00ae \u00e9\u00be %\u00bd fn ps 8\u015bj in v\u03bcw \u00f5\u00b5 d\u00d7 d\u00d7 1\u00d7 if ix s{ |e \u00b1e g\u00e4 q\u00fde gf wj h yl qh yj ie s \u2022 |j i sn x qj \u00b3r \u00bb t sn \u2022{ |e ' q\u00b2 e e u\u00b2 p | ue e gf 'a\u00a5 m \u00ac\u00e0 c\u00ea r \u00e1\u00a9 r\u00f0 d\u00b1 `\u00b0i\u00f3 d\u00ec e w\u00e2 d\u00b3 \u00aa '\u00eb\u00f6 1\u00b3 \u00aa \u00ef\u00e4 \u00e4 \u00e4 \u00e2 m\u00e5 v\u00a6 1 \u00a7 i \u00b0'\u00ec m d\u00ea r\u00f0 \u00e9\u00ee \u00b2 v\u00f7 \u00ea \u00a1\u00b03 d\u00ec \u00f2 \u00efr\u00f0 \u00e1\u00f3 i\u00e4 \u00a9 \u00ed s\u012b\u00b1 \u00ec \u00b1 \u00b3 f\u00b1 v d\u00b0\u00e2 d\u00ea \u00ea \u00a1\u00b03 d\u00ec \u00f2 \u00efr\u00f0 \u00e1\u00f3 is\u00e5 `\u00ee \u00b2 ir\u00f0 \u00a6 \u00f4 d\u00ec \u00b3 m\u00ae s\u00ec {\u00e8 d\u00ea r\u00eb \u00ec w\u00aa m \u00a7 \u00aet \u2022 d\u2022 d \u00b6 s \u00d7 q\u015f\u00bd \u00b8 sr ps 8s \u00b5x sj '\u00b8 dqf in { |n \u00b2 \u015bf in p\u00b2 pf zr 4s 8s 8e gf \u00e1\u00f8 h s r 4 tx \u00aer p{ 6j wj i\u00fc \u00f9 d\u00f9 r r \u00b0h we x s uh y \u0229 ' sx v\u0157 px 3\u00f9 e\u00b0{ dr 4x \u00ae se \u00e1\u00f9 j ie 'r 4\u00b0 s d s\u00b2 i\u00f9 4w \u00a5 r\u00f9 un 4j ie h \u00f9 4qf in { |n \u00b2 )\u00f9 4 | \u00ae qe g\u00e4 b 6j is 8{ d \u015f\u00bd b sr ps 8s \u00b5x sj 'f\u00e9 \u00a8\u00f2 \u00efr\u00a9 s\u00b3 f\u00ea r d\u00b0\u00b1 v\u00a9 e\u00f3 '\u00ea r\u00b2 \u00b0'\u00ec m\u00b2 )\u00a9 s\u00b3 f\u00b1 v d\u00b0\u00ec d d\u00b0\u00e4 \u00ea m\u00b3 f\u00b1 \u00fa c\u00a9 s\u00b1 v\u00b2 1\u00f2 \u00a3\u00e2 \u00b0'\u00b3 s\u00f2 `\u00f2 \u00b1 \u00ef\u00f3 im\u00b0b\u00a9 t b\u00b0 ur p\u015bj ie f \u00a1\u00a2 \"r 4 \u00aer p\u00b2 p | u\u00b2 \u00bd fn p 6j ie g\u00e4 tj \u2022 d \"r d\u00bd fn t e gf ih ir j i |n \u00aer 4{ vw \u00a1\u00b2 e 6j '\u00f8 | s\u00bb n \u015b d s\u00b2 \u00b1 u | e gf ih w k j ml x\u00fb { |e \u00b0gj wf in p u |\u00b0s\u00be f ie h wh t 3\u00b5 d\u00d7 d\u00d7 \u00b5 t\u0157\u00bc q \u00b6e \u00e1\u00e0 e t\u00bc ur px us \"a\u00fb { | \u00ef\u00e0 r \u00e5\u00be \u00a6r 2\u00b0n ps 8\u00fax sj ie f e\u015bf in p\u00b2 pf zr 4s \u00fco n 4f ej i ue h yj ix \u00ae tl \u00b6n 4o p ur 4j ix sf zr 4{ r{ dr p u\u00b2 px \u00aer 4\u00b2 e \u00b0gn s 8s \u00b1x s u |\u00b0'r j i dn p 3\u00bc ye j m ce ge \u00b6s r p \u00a4r p u \u00a4s r p\u00b0z u | ue p\u00fd\u00ab \u00ae s\u00ae s\u00a1\u00b0\u00b1 v\u00a9 \u00b2 d\u00b3 f\u00b1 v d\u00b0\u00ec \u00f0 w\u00e2 \u00e3\u00b3 \u00aa '\u00e3\u00e4 s\u00ab %\u00ed 2t #\u2022 \u00e7 \u00f5 \u00b9 4\u00be \u00b6 )\u00ba \u00e8 t \u2022 d\u00b9 1\u00b9 q \u00f5 \u0157\u00bc q3\u00a2 3b\u00fb be g{ d{ |e \u00a6r 4 \u00ae iae \u00a6\u00bc s\u00a3\u00a2 an 6n p ue gl 6\u00f8 ve 'r 4f i s | u\u00b2 \u00b1j in e\u00far 4f ih we sr 4j zr 4\u00bc \u00aer ph we \u00b3\u00e1 6x ue f i de gh rx uh w | u\u00b2 e | u sx u\u00b0j i d e { |n p\u00b2 |\u00b08\u015bf in p\u00b2 pf zr ps 8s 8 | s\u00b2 s\u00a5 m \u00e7\u00e0 \u00a8\u00ea w \u00e1\u00a9 mr\u00f0 d\u00b1 `\u00b0i\u00f3 d\u00ec x w\u00e2 s\u00b3 \u00aa '\u00a8\u00e4 s\u00fc \u00b3 \u00aa \u00e9\u00fd r\u00b2 \u00b3 f\u00b1 v d\u00b03\u00b2 d\u00f2 \u00ab \u00b0\u00e1\u00e2 \u00e1m\u00ea rm\u00b03\u00a9 d\u00b0\u00ef\u00e4 \u00ea \u00b3 f\u00b1 \u00fa 6\u00a9 s\u00b1 v\u00b2 1\u00f2 \u00e2 \u00b0\u00b3 s\u00f2 `\u00f2 \u00b1 \u00ef\u00f3 im\u00b0b\u00a9 mt s\u00aer 4\u00b2 e h \u00d7 )\u00ba d\u00d7 \u00e1\u00b8 \u00d7 )\u00ba 1\u00ba 6w pw pw \u00a5 c\u00be f ie h wh \u00f9 d\u00a2 e\u00a5 yq q\u00be f ie h wh t \u2022 d\u2022 1\u00b9 q6 1 introduction \n fig",
        "prob": 0.6617088607594936
    }, {
        "ID": 5345,
        "phrase": " then, 1/\u03c6 r = ai b(a i )) = b(r), 1/\u03c6 r c = b(r c ), g r = a i n (ai) a i b(ai) = n (r)/b(r), g r c = n (r c )/b(r c ), and g = n (r)+n (r c ) b(r)+b(r c ) ",
        "prob": 0.3727272727272727
    }, {
        "ID": 6862,
        "phrase": " the probability distribution on the joint ensemble space w 0 \u00d7w 1 \u00d7x n a \u00d7x n b \u00d7x n 1a \u00d7x n 1b \u00d7y n 1a \u00d7y n 1b \u00d7y n 2a \u00d7y n 2b is given by p(w 0 , w 1 , x n a , x n b , x n 1a , x n 1b , y n 1a , y n 1b , y n 2a , y n 2b ) = p(w 0 )p(w 1 )p(x n a , x n b |w 0 , w 1 ) \u2022 n i=1 f ai (x 1ai |y i\u22121 1a , y i\u22121 1b )f bi (x 1bi |y i\u22121 1a , y i\u22121 1b )p(y 1ai , y 2ai |x ai , x 1ai )p(y 1bi , y 2bi |x bi , x 1bi ) ",
        "prob": 0.3812500000000001
    }, {
        "ID": 6952,
        "phrase": " for each child a i of a in topological order do (a) x := move as (a i , x, \u03b1) (b) if \u03c6 ai \u2208 x[a i ] then x[a] := insert a (x[a], \u03c6 ai ) 3",
        "prob": 0.25833333333333336
    }, {
        "ID": 6952,
        "phrase": " for each child a i of a in topological order do (a) if \u03b8 ai \u2208 x[a] then x[a i ] := insert ai (x[a i ], \u03b8 ai ) (b) x := close as (a i , x) (c) if \u03c6 ai \u2208 x[a i ] then x[a] := insert a (x[a], \u03c6 ai ) (d) x[a] := close a (x[a]) 3",
        "prob": 0.4263157894736842
    }, {
        "ID": 7362,
        "phrase": " , r}w s i (a i = w ai , \u223cb i = w bi ) \u2264 u i \u00ba \u00e1\u00f8 \u00d7 \u00f3\u00f9\u00f0 \u00f4\u00f3 \u00f2\u00f8 \u00f3\u00f9\u00f8 \u00f8 \u00f8 p i \u00f3\u00f2\u00d7 \u00d7\u00f8\u00d7 \u00f3 \u00e0\u00f3\u00f6\u00f2 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2\u00f8 \u00f6\u00f9\u00f0 \u00d7 \u00f3 \u00f8 \u00f3\u00f6\u00f1 h \u2190 c 1 , ",
        "prob": 0.22000000000000003
    }, {
        "ID": 8659,
        "phrase": " , b lk ) ml zlj fig",
        "prob": 0.2625
    }, {
        "ID": 8938,
        "phrase": " then there is a 1 \u2264 l \u2264 \u03ba such that ml is a substring of u \u2032 ",
        "prob": 0.18333333333333335
    }, {
        "ID": 9448,
        "phrase": " for exam pl e , e xhaus t i ve s e r vi c e i s unf ai r ",
        "prob": 0.2625
    }]
}, {
    "topic_id": 18,
    "top_words": ["artificial", "intelligence", "research", "introduction", "years", "knowledge", "reasoning", "related", "interest", "community", "field", "recent", "last", "science", "developed"],
    "phrases": [{
        "ID": 30,
        "phrase": " then we discuss the ties between computational mechanics and several approaches to machine learning",
        "prob": 0.425
    }, {
        "ID": 105,
        "phrase": " in the ai & law field this arises as a consequence of the fact that current non-monotonic or defeasible formalisms treat conditional obligation as a normal default (see e",
        "prob": 0.305
    }, {
        "ID": 141,
        "phrase": "introduction artificial intelligence: the science of artificial intelligence (ai) might be defined as the construction of intelligent systems and their analysis",
        "prob": 0.38125
    }, {
        "ID": 141,
        "phrase": " short codes q contribute mostly to \u03be ai (y 1 x 1 ",
        "prob": 0.2625
    }, {
        "ID": 161,
        "phrase": " in computer science, the journal of artificial intelligence research (http://www",
        "prob": 0.2818181818181818
    }, {
        "ID": 180,
        "phrase": " the framework of this paper is based on the extensive research work by  vapnik [1982 , vapnik [1995 , vapnik [1998  and that of  vapnik and chervonenkis [1968 , vapnik and chervonenkis [1981 , vapnik and chervonenkis [1991  in the area of mathematical statistics and its applications to computational machine learning theory",
        "prob": 0.5222222222222223
    }, {
        "ID": 195,
        "phrase": " the case of decision problems is even more spectacular: in a paper that proved very influential in the artificial intelligence community  [3] , cheeseman, kanefsky and taylor conjectured that roughly the difference between tractable and intractable problems, specifically between problems in p and np-complete problems is that: 1",
        "prob": 0.38275862068965516
    }, {
        "ID": 195,
        "phrase": " the connection between computational complexity and the existence of phase transitions has been addressed in statistical mechanics [2] and artificial intelligence [3], but not studied rigorously",
        "prob": 0.41764705882352937
    }, {
        "ID": 279,
        "phrase": " this simple observation, that motivated the development of simulated annealing  [19] , a simple general-purpose heuristic for combinatorial optimization, lies behind the recent birth of a new field at the crossroads of statistical mechanics, theoretical computer science and artificial intelligence, that studies phase transitions in combinatorial problems (see  [14]  for a readable introduction)",
        "prob": 0.5026315789473684
    }, {
        "ID": 306,
        "phrase": "introduction over the last ten years, following the seminal paper of cheeseman, kanefsky and taylor  [6]  , one of the most exciting areas in artificial intelligence and computer science has been the study of phase transition behaviour in hard combinatorial problems",
        "prob": 0.6703703703703703
    }, {
        "ID": 377,
        "phrase": "introduction rule-based systems  1  have had a long history in ai and powerful implementations have been developed",
        "prob": 0.3153846153846154
    }, {
        "ID": 381,
        "phrase": " intelligent agents are an active field of study in artificial intelligence (ai) at present",
        "prob": 0.5083333333333333
    }, {
        "ID": 396,
        "phrase": "introduction knowledge acquisition is a long-standing problem in both artificial intelligence and computational linguistics",
        "prob": 0.5071428571428571
    }, {
        "ID": 449,
        "phrase": " topic detection and tracking (tdt) is also a promising research area for ir and machine learning communities that raises, among others, temporal issue in the data",
        "prob": 0.33809523809523806
    }, {
        "ID": 682,
        "phrase": " the cf model is a calculus of uncertainty mangement and has been used to approximate standard probability theory  [1]  in artificial intelligence",
        "prob": 0.13125
    }, {
        "ID": 683,
        "phrase": " the carsim planner is much more straightforward, because the planning process is not as complex as a lot of traditional ai planning problems, see also  (norvig and russell, 1995) ",
        "prob": 0.22777777777777775
    }, {
        "ID": 704,
        "phrase": "introduction over the last twenty years or so a growing body of research in artificial intelligence has focussed on the representation of legislation and regulations (for a comprehensive discussion see  (sergot, 1991) )",
        "prob": 0.6714285714285714
    }, {
        "ID": 704,
        "phrase": " this is the kind of representation task that accounts for the much of artificial intelligence and law research over the past 20 years",
        "prob": 0.6066666666666667
    }, {
        "ID": 706,
        "phrase": " \n rst analysis of contractual text legislation and legal contracts have, in recent years, been the focus of much research mainly in the artificial intelligence community",
        "prob": 0.40499999999999997
    }, {
        "ID": 713,
        "phrase": " another part was represented only as a collections of transparencies which he used during his regular reports at the monthly seminar \"artificial intelligence\" in moscow house for scientific and technical knowledge propagation which existed more than a decade",
        "prob": 0.25416666666666665
    }, {
        "ID": 713,
        "phrase": " they were among the founders of the georgian national school of artificial intelligence",
        "prob": 0.6454545454545454
    }, {
        "ID": 713,
        "phrase": " according the agreement, he got the duties of the principal coordinator for the main artificial intelligence stream, knowledge representation and intelligent data banks",
        "prob": 0.4789473684210526
    }, {
        "ID": 713,
        "phrase": " the participants were attracted by kuzin, his vision of the ai trends when he estimated and analyzed the topics",
        "prob": 0.17500000000000002
    }, {
        "ID": 713,
        "phrase": " this was a joint forum where the georgian school in artificial intelligence was widely presented",
        "prob": 0.425
    }, {
        "ID": 713,
        "phrase": " this was a great advance in the sphere of artificial intelligence in the ussr which strongly influenced the research activity in the country",
        "prob": 0.27333333333333326
    }, {
        "ID": 722,
        "phrase": " first, please see the journal of artificial intelligence research (jair; www",
        "prob": 0.3153846153846154
    }, {
        "ID": 722,
        "phrase": " in seven years this fsp journal became a highly visible journal in the ai community, indexed by inspec, science citation index, and math-scinet",
        "prob": 0.255
    }, {
        "ID": 725,
        "phrase": " to the extent that computational logic belongs (also) to ai (see the recent book on \"logic-based artificial intelligence\" published after a meeting held in washington in june 1999  [149] ) we can see that logic will also have a role to play in this new research area",
        "prob": 0.5222222222222223
    }, {
        "ID": 785,
        "phrase": " we were impressed by early experiments applying learning to natural language, but dissatisfied with the concentration on a few techniques from the very rich area of machine learning",
        "prob": 0.22777777777777775
    }, {
        "ID": 870,
        "phrase": "introduction knowledge acquisition is a long-standing problem in both artificial intelligence and computational linguistics",
        "prob": 0.65
    }, {
        "ID": 871,
        "phrase": "introduction knowledge acquisition is a long-standing problem in both artificial intelligence and computational linguistics",
        "prob": 0.65
    }, {
        "ID": 894,
        "phrase": "\" according to roberts, the pioneers of artificial intelligence at mit and stanford, marvin minsky and john mccarthy, initially hated the fact that somebody else might use their computer",
        "prob": 0.45909090909090905
    }, {
        "ID": 894,
        "phrase": " roberts, \"expanding ai research and founding arpanet,\" in bartee, ed",
        "prob": 0.51
    }, {
        "ID": 895,
        "phrase": "\" according to roberts, the pioneers of artificial intelligence at mit and stanford, marvin minsky and john mccarthy, initially hated the fact that somebody else might use their computer",
        "prob": 0.5045454545454545
    }, {
        "ID": 895,
        "phrase": " roberts, \"expanding ai research and founding arpanet,\" in bartee, ed",
        "prob": 0.51
    }, {
        "ID": 1034,
        "phrase": " since the early '90s, the ml approach to tc has gained popularity and has eventually become the dominant one, at least in the research community (see  [mitchell 1996 ] for a comprehensive introduction to ml)",
        "prob": 0.4136363636363637
    }, {
        "ID": 1034,
        "phrase": " one of the reasons why from the early '90s the effectiveness of text classifiers has dramatically improved, is the arrival in the tc arena of ml methods that are backed by strong theoretical motivations",
        "prob": 0.205
    }, {
        "ID": 1034,
        "phrase": " in turn, this probably means that the active involvement of the ml community in tc is bound to grow",
        "prob": 0.36428571428571427
    }, {
        "ID": 1158,
        "phrase": "introduction since intelligent agents must have planning capabilities, planning has been an important problem in ai since its very beginning, and numerous approaches and methods have been developed in extensive work over the last decades",
        "prob": 0.29583333333333334
    }, {
        "ID": 1208,
        "phrase": " this kind of logic has attracted much attention of researchers from diverse fields such as artificial intelligence(ai), economics, linguistics, and theoretical computer science",
        "prob": 0.4789473684210526
    }, {
        "ID": 1208,
        "phrase": " among them, the ai researchers and computer scientist have elaborated some technically sophisticated formalisms and applied them to the analysis of distributed and multi-agent systems  [31, 54] ",
        "prob": 0.33888888888888885
    }, {
        "ID": 1209,
        "phrase": " reinforcement learning has been used extensively in artificial intelligence (ai)",
        "prob": 0.20999999999999996
    }, {
        "ID": 1225,
        "phrase": " \n qualitative modeling of bio-economic systems strategies to avoid the analytical and methodological difficulties mentioned above are opened by smart qualitative techniques which are developed in artificial intelligence research and to an increasing extent applied for sustainability issues (e",
        "prob": 0.575
    }, {
        "ID": 1226,
        "phrase": " \n qualitative modeling of bio-economic systems strategies to avoid the analytical and methodological difficulties mentioned above are opened by smart qualitative techniques which are developed in artificial intelligence research and to an increasing extent applied for sustainability issues  (petschel-held and l\u00fcdeke, 2001; guerrin and dumas, 2001; bene et al",
        "prob": 0.5911764705882353
    }, {
        "ID": 1230,
        "phrase": " such models are utilised in machine learning and computer science but also in models of economic behaviour  [young et al, 2000] ",
        "prob": 0.22142857142857145
    }, {
        "ID": 1242,
        "phrase": " it builds on the insights, motivations and techniques developed by researchers in knowledge representation and artificial intelligence, but its purpose is to present the topic of (ai-type) nonmonotonic deduction (or induction) to logicians",
        "prob": 0.6565217391304348
    }, {
        "ID": 1243,
        "phrase": " it builds on the insights, motivations and techniques developed by researchers in knowledge representation and artificial intelligence, but its purpose is to present the topic of (ai-type) nonmonotonic deduction (or induction) to logicians",
        "prob": 0.7
    }, {
        "ID": 1254,
        "phrase": " a large number of researchers in ai have been attracted by and have developed this approach further: both in the abstract and by devising revision procedures that satisfy the agm rationality postulates",
        "prob": 0.39444444444444443
    }, {
        "ID": 1282,
        "phrase": " many researchers are currently active in this vibrant area, drawing from more traditional research within the artificial intelligence (ai) and human computer interaction (hci) communities",
        "prob": 0.4809523809523809
    }, {
        "ID": 1282,
        "phrase": " it is the turing test that inspired the birth of the artificial intelligence community",
        "prob": 0.3727272727272727
    }, {
        "ID": 1291,
        "phrase": "introduction researchers in computer music have chosen to use techniques from artificial intelligence (ai) to explore complex musical tasks at the cognitive level",
        "prob": 0.32105263157894737
    }, {
        "ID": 1332,
        "phrase": "  [22, 38, 39] ), artificial intelligence (e",
        "prob": 0.18333333333333335
    }, {
        "ID": 1333,
        "phrase": "  [24, 40, 41] ), artificial intelligence (e",
        "prob": 0.35000000000000003
    }, {
        "ID": 1398,
        "phrase": " to stress the last word in the last sentence, i mean that a true artificial intelligence system should be able to take the meaning of statements into account, or at least act as if it takes the meaning into account",
        "prob": 0.3521739130434782
    }, {
        "ID": 1398,
        "phrase": " there will be limited but significant success in artificial intelligence by 2050 \u00b130 years",
        "prob": 0.31
    }, {
        "ID": 1488,
        "phrase": " ai work on this topic has focused on novel knowledge representations which, in certain settings, can drastically speed up equilibrium finding (e",
        "prob": 0.31875
    }, {
        "ID": 1568,
        "phrase": "introduction argumentation is a form of reasoning that has recently captured the interest of many researchers in the artificial intelligence community, among others",
        "prob": 0.6166666666666667
    }, {
        "ID": 1613,
        "phrase": " ideas of gold and putnam gave birth to a direction that is called inductive inference  (gasarch and smith, 1997 ) and is a fruitful direction in machine learning and artificial intelligence",
        "prob": 0.29047619047619044
    }, {
        "ID": 1614,
        "phrase": " this and its possible link to qualitative reasoning in ai is an interesting problem for future study",
        "prob": 0.25833333333333336
    }, {
        "ID": 1636,
        "phrase": "introduction in the recent decades, probabilistic reasoning has become an important research topic in artificial intelligence",
        "prob": 0.6733333333333333
    }, {
        "ID": 1667,
        "phrase": " other primitives may include various traditional ai path planners  (russell and norvig, 1994) , artificial neural networks  (werbos, 1974 , rumelhart et al",
        "prob": 0.22777777777777775
    }, {
        "ID": 1667,
        "phrase": ") traditional ai planning procedures-compare chapter v by  russell and norvig (1994)  and  koehler et al",
        "prob": 0.25833333333333336
    }, {
        "ID": 1691,
        "phrase": " algorithms: foil and focl \n overview a variety of relational machine learning systems have been developed in recent years  [mitchell, 1997] ",
        "prob": 0.3
    }, {
        "ID": 1736,
        "phrase": " q bn ) def = n i=1 \u03b4(q ai , \u03c3, q bi )",
        "prob": 0.18333333333333335
    }, {
        "ID": 1737,
        "phrase": " q bn ) def = n i=1 \u03b4(q ai , \u03c3, q bi )",
        "prob": 0.18333333333333335
    }, {
        "ID": 1804,
        "phrase": "\u2022 3 \n a sokoban encodings 60 \u2022 1 \n introduction the need for representing and manipulating complex knowledge arising in artificial intelligence and in other emerging areas, like knowledge management and information integration (see also section 8), has renewed the interest in advanced logic-based formalisms for knowledge representation and reasoning (kr&r), which started in the early 1980s",
        "prob": 0.6416666666666667
    }, {
        "ID": 1805,
        "phrase": "\u2022 1 \n introduction the need for representing and manipulating complex knowledge arising in artificial intelligence and in other emerging areas, like knowledge management and information integration (see also section 8), has renewed the interest in advanced logic-based formalisms for knowledge representation and reasoning (kr&r), which started in the early 1980s",
        "prob": 0.6205882352941177
    }, {
        "ID": 1806,
        "phrase": "\u2022 1 \n introduction the need for representing and manipulating complex knowledge arising in artificial intelligence and in other emerging areas, like knowledge management and information integration (see also section 8), has renewed the interest in advanced logic-based formalisms for knowledge representation and reasoning (kr&r), which started in the early 1980s",
        "prob": 0.6794117647058823
    }, {
        "ID": 1846,
        "phrase": "introduction originally grounded in research work in artificial intelligence (ai) and, more specifically in ai in medicine and production systems  [13] , nexpert object became a commercial success in the late eighties and nineties",
        "prob": 0.43913043478260866
    }, {
        "ID": 1846,
        "phrase": " this basic tenet of the whole artificial intelligence theoretical field has been comprehensively captured by newell's knowledge level hypothesis [10], and if the distinction between behaviour and beliefs is well established, the nature of behaviour as computation is still much debated",
        "prob": 0.18214285714285713
    }, {
        "ID": 1964,
        "phrase": "introduction over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence",
        "prob": 0.7833333333333333
    }, {
        "ID": 1965,
        "phrase": "introduction over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence",
        "prob": 0.7833333333333333
    }, {
        "ID": 1965,
        "phrase": " in recent years, a remarkable progress in artificial intelligence has been the development of incomplete algorithms for various kinds of problems",
        "prob": 0.6937500000000001
    }, {
        "ID": 1966,
        "phrase": "introduction over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence",
        "prob": 0.7833333333333333
    }, {
        "ID": 1966,
        "phrase": " in recent years, a remarkable progress in artificial intelligence has been the development of incomplete algorithms for various kinds of problems",
        "prob": 0.63125
    }, {
        "ID": 1967,
        "phrase": "introduction over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence",
        "prob": 0.7833333333333333
    }, {
        "ID": 1967,
        "phrase": " in recent years, a remarkable progress in artificial intelligence has been the development of incomplete algorithms for various kinds of problems",
        "prob": 0.6937500000000001
    }, {
        "ID": 1968,
        "phrase": "introduction over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence",
        "prob": 0.7277777777777777
    }, {
        "ID": 1968,
        "phrase": " in recent years, a remarkable progress in artificial intelligence has been the development of incomplete algorithms for various kinds of problems",
        "prob": 0.6937500000000001
    }, {
        "ID": 1980,
        "phrase": "most traditional artificial intelligence (ai) systems of the past 50 years are either very limited, or based on heuristics, or both",
        "prob": 0.36428571428571427
    }, {
        "ID": 1987,
        "phrase": " guidebeam works based on a principle called \"rational monotonicity\", which emerged from artificial intelligence research in the early nineties",
        "prob": 0.3588235294117647
    }, {
        "ID": 2100,
        "phrase": " indeed, it is often said that nlp is \"ai-complete\" (a pun on np-completeness; see [other chapter]), meaning that the most difficult problems in artificial intelligence manifest themselves in human language phenomena",
        "prob": 0.2652173913043478
    }, {
        "ID": 2197,
        "phrase": "2 see [15]  for a gentle introduction to imprecise probabilities with emphasis on artificial intelligence",
        "prob": 0.425
    }, {
        "ID": 2198,
        "phrase": ", to select certain values of a class variable given evidence  2  see also  [39]  for a gentle and less dense introduction to imprecise probabilities with emphasis on artificial intelligence",
        "prob": 0.1952380952380952
    }, {
        "ID": 2333,
        "phrase": " the artificial intelligence book  [rn95]  by russell and norvig gives a comprehensive overview over ai approaches in general",
        "prob": 0.54
    }, {
        "ID": 2333,
        "phrase": " short codes q contribute most to \u03be ai (y 1 x 1 ",
        "prob": 0.3
    }, {
        "ID": 2407,
        "phrase": " \n parsing as information compression research on parsing and related topics within computational linguistics and ai does not normally consider these topics in terms of information compression (ic) (but see, for example,  [berger et al",
        "prob": 0.5041666666666667
    }, {
        "ID": 2447,
        "phrase": " the amai notification letter (as received on 31 august 2004) dear amar, we are sorry to inform you that the paper you submitted to the special volume of the annals of mathematics and artificial intelligence dedicated to the 2004 ai+math symposium, \"integrating cardinal direction relations in qsr\", has not been accepted for publication",
        "prob": 0.16451612903225804
    }, {
        "ID": 2449,
        "phrase": " the huge interest, the last couple of years, in applications such as robot navigation, illustrated by active and promising robocup soccer meetings at the main ai conferences (ijcai, aaai: see, for instance,  [54]  for robocup'99), had and still have as a consequence that relative orientation, and, more generally, relative position, considered as expressing more specific knowledge, are gaining increasing interest from the qsr community",
        "prob": 0.36829268292682926
    }, {
        "ID": 2504,
        "phrase": " this is the major problem, which the discipline of artificial intelligence is addressing, but with only limited success",
        "prob": 0.3416666666666666
    }, {
        "ID": 2621,
        "phrase": " participation in the robocup world cup 99 and the sixteenth international joint conferences on artificial intelligence was a good milestone towards the end of the project",
        "prob": 0.33888888888888885
    }, {
        "ID": 2725,
        "phrase": "introduction argumentation has attracted much interest in the area of artificial intelligence",
        "prob": 0.5916666666666667
    }, {
        "ID": 2819,
        "phrase": " the search for such a representation substantially influenced ai research during the last twenty years",
        "prob": 0.5916666666666667
    }, {
        "ID": 2850,
        "phrase": " the book describes ways in which information compression can illuminate concepts and issues in artificial intelligence and human cognition and, indeed, the nature of 'computing' itself",
        "prob": 0.26842105263157895
    }, {
        "ID": 2850,
        "phrase": " artificial intelligence-which is an important topic throughout this book-is something of a half-way house",
        "prob": 0.38125
    }, {
        "ID": 2850,
        "phrase": " of course, many researchers in artificial intelligence borrow extensively from psychology and vice versa",
        "prob": 0.2928571428571428
    }, {
        "ID": 2850,
        "phrase": " \n parsing as information compression research on parsing and related topics within computational linguistics and ai does not normally consider these topics in terms of information compression (but see, for example,  berger et al",
        "prob": 0.4826086956521739
    }, {
        "ID": 2850,
        "phrase": "1 introduction although 'planning' and 'problem solving' are often linked in artificial intelligence, it is not entirely obvious that they are any more closely related than several other pairs of artificial intelligence topics",
        "prob": 0.36818181818181817
    }, {
        "ID": 2850,
        "phrase": " until relatively recently, the focus has been on the development of a framework that could integrate aspects of artificial intelligence other than learning, bearing in mind that learning should eventually form part of the picture",
        "prob": 0.18636363636363634
    }, {
        "ID": 2850,
        "phrase": " it should not be forgotten that many of the topics in artificial intelligenceincluding those that have been considered in previous chapters-are founded on everyday observations of what people can and cannot do",
        "prob": 0.1823529411764706
    }, {
        "ID": 2980,
        "phrase": " this index has gained a growing popularity, especially in the artificial intelligence community",
        "prob": 0.5083333333333333
    }, {
        "ID": 3090,
        "phrase": "  (maney, 1998)   \n artificial intelligence it has been mentioned that quantum computers will be much faster and consequently will perform a large amount of operations in a very short period of time",
        "prob": 0.40499999999999997
    }, {
        "ID": 3210,
        "phrase": "defeasible argumentation has experienced a considerable growth in ai in the last decade",
        "prob": 0.2818181818181818
    }, {
        "ID": 3211,
        "phrase": "in the last years, there has been an increasing demand of a variety of logical systems, prompted mostly by applications of logic in ai and other related areas",
        "prob": 0.35882352941176476
    }, {
        "ID": 3437,
        "phrase": "introduction one of the most challenging and promising goals of artificial intelligence research is the design of autonomous agents, including robots, that explore partially known environments and that are able to act sensibly under incomplete information",
        "prob": 0.244
    }, {
        "ID": 3443,
        "phrase": " this allows machine learning programs to compete to become reviewers",
        "prob": 0.19090909090909092
    }, {
        "ID": 3473,
        "phrase": " we believe that this relationship deserves much more attention in order to understand the theoretical underpinnings of nonmonotonic reasoning and other artificial intelligence paradigms",
        "prob": 0.5611111111111111
    }, {
        "ID": 3621,
        "phrase": " (artificial intelligence: uncertainty, fuzzy/neutrosophic and probabilistic reasoning) \n introduction",
        "prob": 0.3727272727272727
    }, {
        "ID": 3663,
        "phrase": " it was funded and overseen by swisscom; the partners were three swiss institutions, namely lia (artificial intelligence laboratory) and lith (theoretical computer science laboratory) at epfl (swiss federal institute of technology), issco (``dalle molle'' institute for semantic and cognitive studies) and idiap (``dalle molle'' institute for perceptual artificial intelligence)",
        "prob": 0.7131578947368421
    }, {
        "ID": 3708,
        "phrase": " furthermore, the project fosters education in ai and robotics related topics, because so many issues must be solved to handle the overall problem",
        "prob": 0.22777777777777775
    }, {
        "ID": 3713,
        "phrase": " in recent years, robocup simulation as a kind of typical mas, is the hotspot in ai and dai",
        "prob": 0.3727272727272727
    }, {
        "ID": 3841,
        "phrase": " it is in active research in both artificial intelligence and machine learning communities",
        "prob": 0.4636363636363636
    }, {
        "ID": 3856,
        "phrase": " \n ontologies since the early 1990s, ontologies have been used within several artificial intelligence research projects to facilitate the sharing and reuse of knowledge",
        "prob": 0.4789473684210526
    }, {
        "ID": 3878,
        "phrase": " brooks and his students at mit artificial intelligence laboratory in as the cornerstone of their \"nouvelle ai\" philosophy",
        "prob": 0.425
    }, {
        "ID": 3905,
        "phrase": " the so-called nouvelle artificial intelligence (ai) and alife are each concerned with the application of computers to the study of complex, natural phenomena",
        "prob": 0.3588235294117647
    }, {
        "ID": 3907,
        "phrase": " artificial intelligence (ai) and alife are each concerned with the application of computers to the study of complex, natural phenomena",
        "prob": 0.43571428571428567
    }, {
        "ID": 3962,
        "phrase": " \n\t\t\t artificial intelligence laboratory",
        "prob": 0.4428571428571429
    }, {
        "ID": 4016,
        "phrase": " later, it turned out that the same principle is fundamental in an area of artificial intelligence concerned with using logic for knowledge representation -non-monotonic reasoning 1 ",
        "prob": 0.3736842105263158
    }, {
        "ID": 4128,
        "phrase": " it has become popular in recent years, and has served as a useful platform for both game-theoretic study and ai games research",
        "prob": 0.31875
    }, {
        "ID": 4293,
        "phrase": " key aspects like selforganization and artificial intelligence become increasingly important",
        "prob": 0.3153846153846154
    }, {
        "ID": 4362,
        "phrase": "introduction artificial intelligence (a",
        "prob": 0.4428571428571429
    }, {
        "ID": 4363,
        "phrase": "introduction artificial intelligence (a",
        "prob": 0.4428571428571429
    }, {
        "ID": 4542,
        "phrase": " background: during the last decade, documents summarization got increasing attention by the ai research community",
        "prob": 0.5071428571428571
    }, {
        "ID": 4650,
        "phrase": " basically ann is a part of artificial intelligence (ai)",
        "prob": 0.23333333333333334
    }, {
        "ID": 4683,
        "phrase": " qualitative spatial reasoning (qsr) is an important subfield of ai which is concerned with the qualitative aspects of representing and reasoning about spatial entities",
        "prob": 0.4176470588235295
    }, {
        "ID": 5198,
        "phrase": " most of the research in ai planning has been focused on methodologies and issues related to the development of efficient planners",
        "prob": 0.3923076923076923
    }, {
        "ID": 5252,
        "phrase": "introduction over the past ten years, the study of phase transition phenomena has been one of the most exciting areas in computer science and artificial intelligence",
        "prob": 0.7833333333333333
    }, {
        "ID": 5252,
        "phrase": " another remarkable progress in artificial intelligence has been the development of incomplete algorithms for various kinds of problems",
        "prob": 0.6066666666666667
    }, {
        "ID": 5488,
        "phrase": " \n qualitative models the development of qualitative models of physical systems is currently attracting much interest from the artificial intelligence research community",
        "prob": 0.7947368421052632
    }, {
        "ID": 5520,
        "phrase": " \n learning versus reasoning ultimately, our goal should be to produce an effective ai system with added reasoning and learning capabilities, as recently pointed out by valiant  [valiant, 2003]  as a key challenge for computer science",
        "prob": 0.25416666666666665
    }, {
        "ID": 5520,
        "phrase": " within the following decades, however, the topic did not receive much attention as research in artificial intelligence initially focused on purely symbolic approaches",
        "prob": 0.505
    }, {
        "ID": 5568,
        "phrase": " both for artificial intelligence and computational science, future work will be required to determine whether the prospects outlined above are both realizable and compelling",
        "prob": 0.41764705882352937
    }, {
        "ID": 5597,
        "phrase": " this bottom-up approach, based on artificial intelligence (ai)-oriented models of economic agents, replaces experiments by computational simulations",
        "prob": 0.26842105263157895
    }, {
        "ID": 5854,
        "phrase": " the recent success of several teams in meeting the $2 million darpa grand challenge 2005 of designing an autonomous car that finishes a designated route of 175 mile over desert terrain featuring natural and man-made obstacles within 10 hours  [1]  raises the question if ai might be poised for another period of high support and increased expectations",
        "prob": 0.25897435897435894
    }, {
        "ID": 5854,
        "phrase": " the quest for ai is also the subtext to debates outside of the field of computer science",
        "prob": 0.2818181818181818
    }, {
        "ID": 5854,
        "phrase": " this fresh look has been prompted by the setbacks suffered by the various artificial intelligence projects and also by new analysis and experimental findings",
        "prob": 0.24117647058823527
    }, {
        "ID": 6449,
        "phrase": " the constraint solvers which make up the unicalc system have been used by russian research institute of artificial intelligence to efficiently solve design and modeling problems in various areas of industry and science",
        "prob": 0.29583333333333334
    }, {
        "ID": 6449,
        "phrase": " we thank russian research institute of artificial intelligence and ershov institute of informatics systems of russian academy of science for supporting this research financially",
        "prob": 0.605
    }, {
        "ID": 6603,
        "phrase": " topics are picked according to a zipf law to account for some topics being much more popular than others (again consider basketball versus machine learning)",
        "prob": 0.3736842105263158
    }, {
        "ID": 6604,
        "phrase": "introduction the problem of learning to rank using relevance judgments has recently received significant attention within the machine learning community (for example  (cohen, shapire, & singer 1999; chu & keerthi 2005; yu, yu, & tresp 2005; radlinski & joachims 2005) )",
        "prob": 0.2033333333333333
    }, {
        "ID": 6720,
        "phrase": " the former is essentially of the development of design grammars -a traditional and quite well established research area in the fields of cad and ai (see  [3] )",
        "prob": 0.33888888888888885
    }, {
        "ID": 6742,
        "phrase": " for a long time, knowledge representation as a field of ai has been mainly concerned with the study and development of various formalisms and artificial languages",
        "prob": 0.5352941176470588
    }, {
        "ID": 7000,
        "phrase": " this is the antithesis of artificial intelligence",
        "prob": 0.3
    }, {
        "ID": 7058,
        "phrase": " this can be attributed to the shift in the conference topics; it moved from issues related to the common ground of artificial intelligence and databases, to topics closer to database theory, thus losing some popularity",
        "prob": 0.2652173913043478
    }, {
        "ID": 7082,
        "phrase": " as a matter of fact, knowing what will normally happen next is so important, that representing norms and reasoning on them have been identified as central issues rather early in the history of artificial intelligence (ai)",
        "prob": 0.3227272727272727
    }, {
        "ID": 7085,
        "phrase": " as the notion of norm is used in several contexts, we should make clear that we mean here norms that rule commonsense reasoning, but not norms used for legal reasoning, which are also a subject of growing interest in ai  [2, 4, 6] ",
        "prob": 0.30869565217391304
    }, {
        "ID": 7087,
        "phrase": " it allows representing and solving various problems in artificial intelligence",
        "prob": 0.4636363636363636
    }, {
        "ID": 7175,
        "phrase": " specifically, in this research, we deal with the problems of common sense reasoning that could contribute significantly to the solution of real world problems in robotics, computer vision, machine learning and speech recognition",
        "prob": 0.244
    }, {
        "ID": 7195,
        "phrase": "introduction since fifteen years qualitative methods for reasoning under uncertainty developed in artificial intelligence are attracting more and more people of information fusion community, specially those working in the development of modern multi-source 1 systems for defense",
        "prob": 0.4678571428571428
    }, {
        "ID": 7196,
        "phrase": "introduction since fifteen years qualitative methods for reasoning under uncertainty developed in artificial intelligence are attracting more and more people of information fusion community, specially those working in the development of modern multi-source 1 systems for defense",
        "prob": 0.5035714285714284
    }, {
        "ID": 7409,
        "phrase": " the last one implies commutation of \u2704 ai and \u2192 h ",
        "prob": 0.15714285714285717
    }, {
        "ID": 7498,
        "phrase": "  marjorie & hainebach 1996) , more recent efforts such as the one by  montejo-r\u00e1ez (2002)  tend to exploit the power of ml approaches",
        "prob": 0.20666666666666667
    }, {
        "ID": 7564,
        "phrase": "  \u271b \u03b4 g r * (c \u2032 ,\u03b4 g ) \u03c6 * (c,\u03c3 i ) \u03b4 =\u22a5,\u03c3 i \u2208ext(\u03b4) \u03c3 i \u2732 \u2744 \u273b \u03c6 * (c,\u03c3 i )\u2286ext(\u03b4 g ) \n related work waldinger  [25]  is probably the first to discuss regression in artificial intelligence",
        "prob": 0.5399999999999999
    }, {
        "ID": 7565,
        "phrase": " g r * (c \u2032 ,\u03b4 g ) \u03c6 * (c,\u03c3 i ) \u03b4 =\u22a5,\u03c3 i \u2208ext(\u03b4) \n related work waldinger  [25]  is probably the first to discuss regression in artificial intelligence",
        "prob": 0.65
    }, {
        "ID": 7591,
        "phrase": " the experiments reported here have been performed on three different corpora, mainly focused on linguistics (li), artificial intelligence (ai) and knowledge acquisition (ka) and the results are presented on table  1 ",
        "prob": 0.29047619047619044
    }, {
        "ID": 7907,
        "phrase": " dsmt although not sufficiently known in the information fusion and artificial intelligence communities as any new emerging theory has however been successfully applied in different fields of applications like multitarget tracking and classification or remote sensing application",
        "prob": 0.2103448275862069
    }, {
        "ID": 8079,
        "phrase": " introduction the modelling and reasoning with uncertainty and imprecision is an important research topic in the artificial intelligence community",
        "prob": 0.54
    }, {
        "ID": 8080,
        "phrase": "introduction the modelling and reasoning with uncertainty and imprecision is an important research topic in the artificial intelligence community",
        "prob": 0.6066666666666667
    }, {
        "ID": 8147,
        "phrase": "), cognition and communication at work, cambridge university press, cambridge, 1996 \n figure 1 figure 2 12 figure 1 selection of a meaning for a discipline-independent-constraint key * meaning according design office field 1 ** meaning according design office field 2 \n\t\t\t simon, h the structure of ill-structured problems, artificial intelligence, 4",
        "prob": 0.5162162162162163
    }, {
        "ID": 8149,
        "phrase": " their characteristics are as following: 3 simon h the structure of ill-structured problems artificial intelligence vol 4",
        "prob": 0.36428571428571427
    }, {
        "ID": 8247,
        "phrase": " given our overall experience with ai design, we can however see that real time learning can become progressively difficult in nature like environments",
        "prob": 0.2157894736842105
    }, {
        "ID": 8263,
        "phrase": " such problems appear in numerous areas of computer science, and constraint satisfaction problems attracted considerable attention in artificial intelligence",
        "prob": 0.39444444444444443
    }, {
        "ID": 8264,
        "phrase": " such problems appear in numerous areas of computer science, and constraint satisfaction problems attracted considerable attention in artificial intelligence",
        "prob": 0.3944444444444445
    }, {
        "ID": 8497,
        "phrase": " the renewed interest toward artificiality originates in new approaches of artificial intelligence and in the success of the highly innovative related fields of artificial life  (langton, 1989)  and artificial societies  (gilbert & conte, 1995; epstein & axtell, 1996) ",
        "prob": 0.8185185185185184
    }, {
        "ID": 8497,
        "phrase": " in the fields of artificial intelligence and artificial life, luc steels termed it the synthetic method (see figure  4 )  (steels & brook, 1994) ",
        "prob": 0.6166666666666667
    }, {
        "ID": 8498,
        "phrase": " the renewed interest toward artificiality originates in new approaches of artificial intelligence and in the success of the highly innovative related fields of artificial life  (langton, 1989)  and artificial societies  (gilbert & conte, 1995; epstein & axtell, 1996) ",
        "prob": 0.8185185185185184
    }, {
        "ID": 8498,
        "phrase": " in the fields of artificial intelligence and artificial life, luc steels termed it the synthetic method (see figure  4 )  (steels & brook, 1994) ",
        "prob": 0.5611111111111111
    }, {
        "ID": 8555,
        "phrase": " short codes q contribute most to \u03be ai (y 1 x 1 ",
        "prob": 0.3
    }, {
        "ID": 8555,
        "phrase": " the artificial intelligence book  [rn03]  by russell and norvig gives a comprehensive overview over ai approaches in general",
        "prob": 0.47333333333333333
    }, {
        "ID": 8634,
        "phrase": " the number of nouns found in the artificial intelligence text was 231",
        "prob": 0.31
    }, {
        "ID": 8634,
        "phrase": " among the isosceles triangles in the artificial intelligence text, we find the following relationships",
        "prob": 0.3153846153846154
    }, {
        "ID": 8667,
        "phrase": " code reuse is a topic related to case-based reasoning in artificial intelligence  (riesbeck & schank, 1989)  and analogous reasoning in cognitive psychology  (holyoak, 1985; vosniodou & ortony, 1989) ",
        "prob": 0.45909090909090916
    }, {
        "ID": 8670,
        "phrase": " this theory has been developed in artificial intelligence  (abelson, 1981; minsky, 1975; schank and abelson, 1977)  and in psychological studies on text understanding  (bower et al",
        "prob": 0.4764705882352941
    }, {
        "ID": 8687,
        "phrase": " significant recent interest has focused on postprocessing algorithms that use the ml-certificate property of lp decoding to achieve near ml performance (see  [8] ,  [4] ) and also  [9] ,  [26] )",
        "prob": 0.1952380952380952
    }, {
        "ID": 8724,
        "phrase": " o'reilly are with the computer science and artificial intelligence laboratory, massachusetts institute of technology, cambridge, ma 02139, usa ({varun ag@, unamay@csail",
        "prob": 0.6166666666666667
    }, {
        "ID": 8949,
        "phrase": " an extensive body of basic research in ai  (putnam, 1967; searle, 1980; fodor, 1980; jackson, 1985; minsky, 1988; haugeland, 1989; boden, 1990; feigenbaum & feldman, 1995; chalmers, 1997; nilsson, 1998; minsky, 2007; carter, 2007; jones, 2008; floreano & mattiussi, 2008; fodor, 2008; johnson, 2008; munakata, 2008; russel & norvig, 2009)  and alife  (levy, 1993; brooks & maes, 1994; boden, 1996; langton, 1997; adami, 1999; langton et al",
        "prob": 0.5162162162162162
    }, {
        "ID": 9122,
        "phrase": " recently, these topics have become the focus of attention in various areas of computer science as well, such as artificial intelligence (especially with regard to distributed ai in multiagent settings), systems (e",
        "prob": 0.45909090909090905
    }, {
        "ID": 9252,
        "phrase": " recently, this type of reasoning has been applied to problems in an ai context by  paris and vencovska (1989)  and  shastri (1989) ",
        "prob": 0.23846153846153845
    }, {
        "ID": 9255,
        "phrase": " this approach was at rst made explicit in the ai literature, by the seminal paper of  mccarthy and hayes (mccarthy & hayes, 1969)  where it is referred to as the missouri program",
        "prob": 0.33888888888888885
    }, {
        "ID": 9267,
        "phrase": " the 1989 aaai symposium on ai and limited rationality  (fehling & russell, 1989 ) contains an interesting variety of work on the topic",
        "prob": 0.4066666666666666
    }, {
        "ID": 9272,
        "phrase": " according to this requirement we share the general view from machine learning that the use of this kind of experience is the most promising way to cope with highly intractable problems",
        "prob": 0.255
    }, {
        "ID": 9278,
        "phrase": " \n related work although there has not been extensive research on agents that learn from tutorial instruction per se, learning from instruction-like input has been a long-time goal in ai  (    michalski, & mitchell, 1983; mccarthy, 1968; rychener, 1983) ",
        "prob": 0.33749999999999997
    }, {
        "ID": 9281,
        "phrase": " this paper offers two distinct contributions to the fields of computing, artificial intelligence and machine learning",
        "prob": 0.20666666666666664
    }, {
        "ID": 9283,
        "phrase": " recently there has been a rising interest in clausal representation of knowledge in machine learning",
        "prob": 0.3416666666666666
    }, {
        "ID": 9285,
        "phrase": "introduction the traditional form of representing knowledge in ai is through logical formulas  (mccarthy, 1958; mccarthy & hayes, 1969) , where all the logical conclusions of a given formula are assumed to be accessible to an agent",
        "prob": 0.33809523809523806
    }, {
        "ID": 9290,
        "phrase": " one of the main goals of massively parallel ai research is to produce networks that perform real-time inference over large knowledge-bases very e ciently (i",
        "prob": 0.2157894736842105
    }, {
        "ID": 9300,
        "phrase": " in the last ve to ten years, it has attracted rapidly increasing interest in the machine learning and arti cial intelligence communities",
        "prob": 0.4764705882352941
    }, {
        "ID": 9300,
        "phrase": " it is written to be accessible to researchers familiar with machine learning",
        "prob": 0.21000000000000002
    }, {
        "ID": 9311,
        "phrase": " among the ai work is that of smith's contract net  (smith, 1978 (smith, , 1980 sandholm, 1993 ), malone's enterprise system  (malone et al",
        "prob": 0.20666666666666667
    }, {
        "ID": 9314,
        "phrase": "introduction reasoning with uncertain knowledge and beliefs has long been recognized as an important research issue in ai  (shortliffe & buchanan, 1975; duda et al",
        "prob": 0.24117647058823527
    }, {
        "ID": 9315,
        "phrase": " a functional dependency is related to the artificial intelligence idea of a determination  (russell, 1989) ",
        "prob": 0.425
    }, {
        "ID": 9336,
        "phrase": " the second point, initially of interest to artificial intelligence, is also relevant to the \"proofs as programs\" school of program verification",
        "prob": 0.25625
    }, {
        "ID": 9345,
        "phrase": " nevertheless, windowing has not played a major role in machine learning research",
        "prob": 0.25833333333333336
    }, {
        "ID": 9347,
        "phrase": " the 8-puzzle and the 15-puzzle problems have long been popular among mathematicians  (johnson & story, 1879; kraitchik, 1953; tait, 1880)  and ai researchers",
        "prob": 0.44375
    }, {
        "ID": 9447,
        "phrase": " d urin g t h i s s h ort period, t h e r e s o u rces of neighbori ng ro u t e r sa r eu se dtosu st ai n t he o v erl oad",
        "prob": 0.20666666666666667
    }, {
        "ID": 9524,
        "phrase": " \n\t\t\t copyright c 1998, american association for artificial intelligence (www",
        "prob": 0.41
    }, {
        "ID": 9679,
        "phrase": " \n introduction the study of computational models of learning from past experience, machine learning, is currently a vibrant field of research",
        "prob": 0.4764705882352942
    }, {
        "ID": 9679,
        "phrase": " in its short history, machine learning presented various theoretical accounts, referred to as paradigms, of various ways of learning from past experience, e",
        "prob": 0.531578947368421
    }, {
        "ID": 9680,
        "phrase": " \n introduction the study of computational models of learning from past experience, machine learning, is currently a vibrant field of research",
        "prob": 0.4764705882352941
    }, {
        "ID": 9680,
        "phrase": " in its short history, machine learning presented various theoretical accounts, referred to as paradigms, of various ways of learning from past experience, e",
        "prob": 0.5842105263157895
    }, {
        "ID": 9704,
        "phrase": "introduction practical and theoretical investigations into the nature and structure of human dialogue have been a topic of research in artificial intelligence and the more human areas of linguistics for decades: there has been much interesting work but no definitive or uncontroversial findings",
        "prob": 0.35
    }, {
        "ID": 9704,
        "phrase": " \n the current state of play one could argue that human machine conversation (hmc) is now in a position like that of machine translation fifteen years ago: it is a real technology, coming into being in spite of scepticism, but with a huge gulf between busy practitioners getting on with the job, often within companies, and, on the other side, the researchers, in linguistics, artificial intelligence (ai) or whatever, whose papers fill the conferences",
        "prob": 0.32045454545454544
    }, {
        "ID": 9779,
        "phrase": " of the approaches we discuss, at present it is probably the ones in artificial intelligence and machine learning that are most directly applicable to coin design",
        "prob": 0.24117647058823527
    }, {
        "ID": 9779,
        "phrase": " although work on rl dates back to samuel's checker player  [226] , relatively recent theoretical  [272]  and empirical results  [60, 263]  have made rl one of the most active areas in machine learning",
        "prob": 0.2217391304347826
    }, {
        "ID": 9779,
        "phrase": " \n distributed artificial intelligence the field of distributed artificial intelligence (dai) has arisen as more and more traditional artificial intelligence (ai) tasks have migrated toward parallel implementation",
        "prob": 0.305
    }, {
        "ID": 9780,
        "phrase": " the artificial intelligence community has appropriated the term to mean the construction of knowledge models  [18] ,  [32]  which specify concepts or objects, their attributes, and inter-relationships",
        "prob": 0.2157894736842105
    }, {
        "ID": 9790,
        "phrase": "com/locate/artint : founded in 1970, as the first specialized journal for artificial intelligence research, it became the top ranked journal in the field long before the electronic enhancements",
        "prob": 0.305
    }, {
        "ID": 9857,
        "phrase": " the empirical observation from  [ckt91] , that for a number of np-complete problems the \"hardest on the average\" instances are located near such threshold points has attracted considerable interest in such threshold phenomena from several communities, such as theory of computing, artificial intelligence and statistical mechanics",
        "prob": 0.26129032258064516
    }]
}, {
    "topic_id": 19,
    "top_words": ["intelligence", "artificial", "new", "rules", "systems", "better", "could", "computing", "example", "journal", "game", "good", "traditional", "concepts", "field"],
    "phrases": [{
        "ID": 161,
        "phrase": ") as a result of negotiations with the editorial board of artificial intelligence, elsevier is allowing final versions of papers that appear in that journal to appear on corr",
        "prob": 0.531578947368421
    }, {
        "ID": 161,
        "phrase": " for example, there has been little usage of the comment facility provided by the journal of artificial intelligence research; the comment facility at the electronic transactions on artificial intelligence (http://www",
        "prob": 0.8142857142857142
    }, {
        "ID": 162,
        "phrase": " there is a smaller journal, the journal of ai research, that has agreed to post all its papers on corr",
        "prob": 0.5083333333333333
    }, {
        "ID": 261,
        "phrase": " such a reflexive architecture could be connected to works in artificial intelligence dealing with auto-observation  (pitrat, 1993) ",
        "prob": 0.33999999999999997
    }, {
        "ID": 449,
        "phrase": " vaithyanathan  [118]  gives an overview of the papers in the special issue of artificial intelligence review on data mining on the internet",
        "prob": 0.25625
    }, {
        "ID": 449,
        "phrase": " there are many opportunities for (existing or new) machine learning algorithms that could work with this representation or that could take advantage of the available structures on the web",
        "prob": 0.3210526315789474
    }, {
        "ID": 660,
        "phrase": " we could also have a hybrid system where the person writes rules with the help of machine learning",
        "prob": 0.3153846153846154
    }, {
        "ID": 706,
        "phrase": " there is ongoing research in the artificial intelligence and law community exploring the potential for providing electronic support to contract negotiators, focusing on long-term, complex engineering agreements (see for example  daskalopulu & sergot 1997) ",
        "prob": 0.4111111111111111
    }, {
        "ID": 1134,
        "phrase": " the relation was already investigated in the early days of artificial intelligence by kowalski and kuehner [kk71, page 250]",
        "prob": 0.2733333333333333
    }, {
        "ID": 1220,
        "phrase": " for instance, to model ai planning, preconditions can simply be expressed by rules, choice can be used to select among applicable actions, and frame axioms can be expressed by xy-stratified rules that describe changes from the old state to the new state  (brogi et al",
        "prob": 0.2700000000000001
    }, {
        "ID": 1282,
        "phrase": " hybrids of traditional and nouvelle ai started to appear as new approaches were sought",
        "prob": 0.3416666666666666
    }, {
        "ID": 1613,
        "phrase": " the new paradigm gives a better insight into the functioning of the mind opening new perspectives for artificial intelligence",
        "prob": 0.44375
    }, {
        "ID": 1617,
        "phrase": " the named entity tagger returns a number that compactly represents the presence/absence of named entity types in a i (all t ai are or-ed together)",
        "prob": 0.2833333333333333
    }, {
        "ID": 1632,
        "phrase": " definition 2 definition 3 23 let \u03c1 : nlp a1 \u2192 nlp a2 be a function such that a 1 \u2286 a 2 , and let int ai be the class of all htinterpretations over a i (i = 1, 2)",
        "prob": 0.2928571428571428
    }, {
        "ID": 1635,
        "phrase": " the change in approach has reinvigorated this field, breaking the inertia that gripped it in the '80s, and restoring our optimism in the promises that ai was making when originally founded",
        "prob": 0.41764705882352937
    }, {
        "ID": 1823,
        "phrase": " , an}, a1, r), where r contains the rules ai \u2192 ai+1, for 1 \u2264 i \u2264 n \u2212 1, an \u2192 a1, and ai \u2192 ai ai and ai \u2192 ai, for 1 \u2264 i \u2264 n",
        "prob": 0.18333333333333335
    }, {
        "ID": 1829,
        "phrase": " definition 30 (ga) ga has the following rules: axioms (id) a \u22a2 a (\u03bb) \u22a2 structural rules (ew ) g|\u03b3 \u22a2 \u2206 g|\u03b3 \u22a2 \u2206|\u03b3 \u2032 \u22a2 \u2206 \u2032 (ec) g|\u03b3 \u22a2 \u2206|\u03b3 \u22a2 \u2206 g|\u03b3 \u22a2 \u2206 (s) g|\u03b31, \u03b32 \u22a2 \u22061, \u22062 g|\u03b31 \u22a2 \u22062|\u03b32 \u22a2 \u22062 (m ) g|\u03b31 \u22a2 \u22061 g|\u03b32 \u22a2 \u22062 g|\u03b31, \u03b32 \u22a2 \u22061, \u22062 logical rules (t, l) g|\u03b3 \u22a2 \u2206 g|\u03b3, t \u22a2 \u2206 (t, r) g|\u03b3 \u22a2 \u2206 g|\u03b3 \u22a2 t, \u2206 (\u00ac, l) g|\u03b3 \u22a2 a, \u2206 g|\u03b3, \u00aca \u22a2 \u2206 (\u00ac, r) g|\u03b3, a \u22a2 \u2206 g|\u03b3 \u22a2 \u00aca, \u2206 (\u2192, l) g|\u03b3, b \u22a2 a, \u2206 g|\u03b3, a \u2192 b \u22a2 \u2206 (\u2192, r) g|\u03b3, a \u22a2 b, \u2206 g|\u03b3 \u22a2 a \u2192 b, \u2206 (+, l) g|\u03b3, a, b \u22a2 \u2206 g|\u03b3, a + b \u22a2 \u2206 (+, r) g|\u03b3 \u22a2 a, b, \u2206 g|\u03b3 \u22a2 a + b, \u2206 (\u2227, l) g|\u03b3, a \u22a2 \u2206|\u03b3, b \u22a2 \u2206 g|\u03b3, a \u2227 b \u22a2 \u2206 (\u2227, r) g|\u03b3 \u22a2 a, \u2206 g|\u03b3 \u22a2 b, \u2206 g|\u03b3 \u22a2 a \u2227 b, \u2206 (\u2228, l) g|\u03b3, a \u22a2 \u2206 g|\u03b3, b \u22a2 \u2206 g|\u03b3, a \u2228 b \u22a2 \u2206 (\u2228, r) g|\u03b3 \u22a2 a, \u2206|\u03b3 \u22a2 b, \u2206 g|\u03b3 \u22a2 a \u2228 b, \u2206 alternative (non-invertible) rules to replace (\u2227, l) and (\u2228, r) without losing completeness are: (\u2227 \u2032 i , l) g|\u03b3, ai \u22a2 \u2206 g|\u03b3, a1 \u2227 a2 \u22a2 \u2206 i = 1, 2 (\u2228 \u2032 i , r) g|\u03b3 \u22a2 ai, \u2206 g|\u03b3 \u22a2 a1 \u2228 a2 \u22a2 \u2206 i = 1, 2 we could also replace the rules (m ), (ew ) and the axioms (id), (\u03bb), (t, l), (t, r) with the single axiom: (ax) g|\u03b3, t, ",
        "prob": 0.315625
    }, {
        "ID": 1839,
        "phrase": " for artificial intelligence researchers, a virtual lab would help design and test systems and mechanisms of robots or animats",
        "prob": 0.4764705882352941
    }, {
        "ID": 1869,
        "phrase": " in this example, the document collection is around 100 articles from the journal of artificial intelligence research",
        "prob": 0.3923076923076923
    }, {
        "ID": 1869,
        "phrase": " figure  4  shows a search engine (developed at nrc) for searching for journal articles in the journal of artificial intelligence research",
        "prob": 0.3588235294117647
    }, {
        "ID": 1886,
        "phrase": " \n y \n point was made by an anonymous referee of the journal of experimental and theoretical artificial intelligence",
        "prob": 0.3153846153846154
    }, {
        "ID": 1907,
        "phrase": " \n r-game: z-game: ai = a \u2032 i + fi bi := b \u2032 i + fi a r b r a z b z spoiler: ai \u2208 r duplicator: bi \u2208 r virtual spoiler: a \u2032 i := \u230aai\u230b virtual duplicator: b \u2032 i \u2208 z figure  6 : the duplicator's strategy in the i-th round of the r-game",
        "prob": 0.2833333333333333
    }, {
        "ID": 2001,
        "phrase": " observe that a marked dialectical tree t * a, a , like the one in figure  11  (left), resembles the minimax tree used in artificial intelligence for game trees",
        "prob": 0.2157894736842105
    }, {
        "ID": 2333,
        "phrase": " \n turing test the turing test  [tur50]  was designed to decide whether an ai system is intelligent",
        "prob": 0.2928571428571428
    }, {
        "ID": 2333,
        "phrase": "21) for one game to \u00b5 ai \u1e8b\u2032 1 ",
        "prob": 0.22000000000000003
    }, {
        "ID": 2371,
        "phrase": " similarly, for the query \"neural network\", the first trail shows the course \"artificial intelligence & neural networks\" linked to the home page of chris christodoulou who teaches the course",
        "prob": 0.26521739130434785
    }, {
        "ID": 2406,
        "phrase": " however, notwithstanding turing's own vision of the possibility of artificial intelligence  [turing 50 ], the utm and the pcs and equivalent models of computing operate in a rigid 'clockwork' manner which appears far removed from the fluidity of human intelligence",
        "prob": 0.5592592592592592
    }, {
        "ID": 2749,
        "phrase": " readers are referred to  wolff (2003b)  and other cited sources for more detail about artificial intelligence capabilities of the system outlined here: \u2022 representation of knowledge",
        "prob": 0.24117647058823527
    }, {
        "ID": 2763,
        "phrase": " with this new orientation, the system provides an interpretation for concepts in computing, mathematics and logic and it has a range of ai capabilities described in  [28]  and earlier papers cited there",
        "prob": 0.42631578947368426
    }, {
        "ID": 2844,
        "phrase": " however, if you should choose the red pill, these robots, bound for mars, will have on-board, scientific, astrobiological artificial intelligence",
        "prob": 0.711764705882353
    }, {
        "ID": 2844,
        "phrase": " pause there is a technique (answered more seriously, and without intentional symbolism from the lecturer) in artificial intelligence programming that could be used for this application, called \"modular neural networks\" (cf",
        "prob": 0.43913043478260866
    }, {
        "ID": 2845,
        "phrase": " however, if you should choose the red pill, these robots, bound for mars, will have on-board, scientific, astrobiological artificial intelligence",
        "prob": 0.711764705882353
    }, {
        "ID": 2845,
        "phrase": " pause there is a technique (answered more seriously, and without intentional symbolism from the lecturer) in artificial intelligence programming that could be used for this application, called \"modular neural networks\" (cf",
        "prob": 0.43913043478260866
    }, {
        "ID": 2850,
        "phrase": " a subsidiary aim has been to develop a new kind of computing system, based on the theory, with potential advantages over the current generation of computers, especially in artificial intelligence",
        "prob": 0.4333333333333333
    }, {
        "ID": 2850,
        "phrase": " in this chapter i will show that the operation of a post canonical systemand, consequently, the operation of a universal turing machine-may be interpreted within the sp system, and i will argue that the sp theory is not merely another variant on ideas that were developed 60 or more years ago but that it provides new insights into the nature of computing and artificial intelligence, and new opportunities for rationalisation and integration in the design of computing systems",
        "prob": 0.3431818181818182
    }, {
        "ID": 2850,
        "phrase": " notwithstanding alan turing's own vision of the possibility of artificial intelligence  (turing, 1950) , a 'raw' universal turing machine, without any software, can do very little",
        "prob": 0.3736842105263158
    }, {
        "ID": 2850,
        "phrase": " this is because artificial intelligence applications are intrinsically 'hungry' for computer power and because the sp theory offers opportunities to by-pass the 'busy bee' style of conventional computing to achieve good results in a reasonable time by the application of parallel processing",
        "prob": 0.47000000000000003
    }, {
        "ID": 2913,
        "phrase": " this framework can be successfully applied to the investigation of the performance of artificial intelligence (ai) inference and cognitive systems",
        "prob": 0.22142857142857145
    }, {
        "ID": 2943,
        "phrase": " in the late sixties and early seventies the artificial intelligence group at edinburgh was among the best in europe",
        "prob": 0.2733333333333333
    }, {
        "ID": 2980,
        "phrase": " this is a good classification model-despite its simplifying assumptions [dp97]-, which often competes successfully with much more complex classifiers from the machine learning field, such as c4",
        "prob": 0.255
    }, {
        "ID": 3039,
        "phrase": " cl and especially extensions of its present version with certain new game operators, such as sequential versions of conjunction/disjunction, quantifiers and recurrence operators, 5 might have good potential as a new logical paradigm for ai planning systems",
        "prob": 0.8555555555555555
    }, {
        "ID": 3040,
        "phrase": " cl and especially extensions of its present version with certain new game operators, such as sequential versions of conjunction/disjunction, quantifiers and recurrence operators, 5 might have good potential as a new logical paradigm for ai planning systems",
        "prob": 0.8555555555555555
    }, {
        "ID": 3041,
        "phrase": " cl and especially extensions of its present version with certain new game operators, such as sequential versions of conjunction/disjunction, quantifiers and recurrence operators, 5 might have good potential as a new logical paradigm for ai planning systems",
        "prob": 0.8555555555555555
    }, {
        "ID": 3097,
        "phrase": " in contrast with conventional artificial intelligence techniques which only deal with precision, certainty and rigor, the guiding principle of soft computing is to exploit the tolerance for imprecision, uncertainty, low solution cost, robustness, partial truth to achieve tractability, and better rapport with reality  [108] ",
        "prob": 0.878125
    }, {
        "ID": 3101,
        "phrase": " in contrast with conventional artificial intelligence techniques which only deal with precision, certainty and rigor the guiding principle of hybrid systems is to exploit the tolerance for imprecision, uncertainty, low solution cost, robustness, partial truth to achieve tractability, and better rapport with reality",
        "prob": 0.878125
    }, {
        "ID": 3116,
        "phrase": " in contrast with conventional ai techniques which only deal with precision, certainty and rigor the guiding principle of soft computing is to exploit the tolerance for imprecision, uncertainty, low solution cost, robustness, partial truth to achieve tractability and better rapport with reality",
        "prob": 0.87
    }, {
        "ID": 3141,
        "phrase": " in contrast with conventional artificial intelligence techniques which only deal with precision, certainty and rigor the guiding principle of soft computing is to exploit the tolerance for imprecision, uncertainty, low solution cost, robustness, partial truth to achieve tractability and better rapport with reality  [15] ",
        "prob": 0.8468749999999998
    }, {
        "ID": 3192,
        "phrase": " a version (also called a world, using the ai terminology) is a virtual copy of the state of the objects",
        "prob": 0.23846153846153845
    }, {
        "ID": 3601,
        "phrase": " at the end, only one copy survives, which shows that the example has a unique ml solution",
        "prob": 0.5545454545454546
    }, {
        "ID": 3602,
        "phrase": " at the end, only one copy survives, which shows that the example has a unique ml solution",
        "prob": 0.5545454545454546
    }, {
        "ID": 3708,
        "phrase": " however, the way the functional architecture was conceptualized allows the implementation of these operators and the switching among them using different approaches, as for example ai production systems",
        "prob": 0.205
    }, {
        "ID": 3905,
        "phrase": " apart from traditional and symbolic hard-specific top-down ai in the sixties and seventies, both are nowadays concerned with generating complex behaviour, in a bottom-up manner, turning their attention from the mechanics of phenomena to the logic of it",
        "prob": 0.6192307692307693
    }, {
        "ID": 3905,
        "phrase": " [ ] vitorino ramos, luis ribeiro, exploring temporal rule-relations in water quality time series with swarm intelligence , ais\u00b42002 -artificial intelligence, simulation and planning in high autonomy systems, lisbon, portugal, april 7-10, 2002",
        "prob": 0.3137931034482759
    }, {
        "ID": 3907,
        "phrase": " apart from traditional and symbolic top-down ai in the sixties and seventies, both are nowadays concerned with generating complex behaviour, in a bottom-up manner, turning their attention from the mechanics of phenomena to the logic of it",
        "prob": 0.5875
    }, {
        "ID": 4130,
        "phrase": " born in the late fifties with lisp in a context of artificial intelligence, the functional paradigm really took off in the eighties thanks to novel design techniques such as graph rewriting  [26] ",
        "prob": 0.2772727272727273
    }, {
        "ID": 4555,
        "phrase": " mids could, in principle, also supply new interpretation rules in ai applications when inferences won't succeed because the state of the lexico-conceptual system has changed",
        "prob": 0.255
    }, {
        "ID": 4575,
        "phrase": " we give evidence of elementary learning of the semantics of concepts, in contrast to most prior approaches (outside of knowledge representation research) that have neither the appearance nor the aim of dealing with ideas, instead using abstract symbols that remain permanently ungrounded throughout the machine learning application",
        "prob": 0.4575757575757576
    }, {
        "ID": 4576,
        "phrase": " we give evidence of elementary learning of the semantics of concepts, in contrast to most prior approaches (outside of knowledge representation research) that have neither the appearance nor the aim of dealing with ideas, instead using abstract symbols that remain permanently ungrounded throughout the machine learning application",
        "prob": 0.42727272727272725
    }, {
        "ID": 5520,
        "phrase": " \n standard versus non/standard network architecture even though neural networks are a widely accepted paradigm in ai it is hard to make out a standard architecture",
        "prob": 0.255
    }, {
        "ID": 5520,
        "phrase": " nevertheless, these are both standard approaches to artificial intelligence and it would be very desirable to combine the robustness of neural networks with the expressivity of symbolic knowledge representation",
        "prob": 0.2157894736842105
    }, {
        "ID": 5714,
        "phrase": " this field of research, artificial immune systems (ais) has seen the application of immune inspired algorithms to problems such as robotic control  [71] , network intrusion detection  [33, 65] , fault tolerance  [22, 7] , bioinformatics  [85]  and machine learning  [67, 128] , to name a few",
        "prob": 0.2730769230769231
    }, {
        "ID": 5714,
        "phrase": " evolvable hardware is a new field that brings together reconfigurable hardware, artificial intelligence, fault tolerance and autonomous systems",
        "prob": 0.7833333333333333
    }, {
        "ID": 5714,
        "phrase": " evolved hardware is a new field that brings together reconfigurable hardware, artificial intelligence, fault tolerance and autonomous systems",
        "prob": 0.7833333333333333
    }, {
        "ID": 5969,
        "phrase": " m does not implement l ai \u2264 p lni-t a i ",
        "prob": 0.18333333333333335
    }, {
        "ID": 6386,
        "phrase": " unfortunately the turing test is too hard for now, one cannot even use partial successes in ai to estimate the size of a computer required to pass the test  [2] ",
        "prob": 0.22777777777777775
    }, {
        "ID": 6386,
        "phrase": " in contrast, for the traditional turing test the ai algorithms are less mature and non interactive ai has not been achieved",
        "prob": 0.3923076923076923
    }, {
        "ID": 6526,
        "phrase": " in order to fully exploit the above sketched hardware structures, we will need advanced software tools which should be able to operate with a high degree of autonomy: in other word, we need to develop that experimental branch of learning that falls under the category of artificial intelligence",
        "prob": 0.3482758620689655
    }, {
        "ID": 6876,
        "phrase": " however, the assumption that \u03c4 > 4 v 2 implies that y \u2212 he 2 < y \u2212 h\u015d 2 for any \u015d \u2208 b m , \u015d = e, and it follows that the ml solution is unique",
        "prob": 0.19090909090909092
    }, {
        "ID": 7083,
        "phrase": " these models admit a canonical representation which offers good opportunities from a machine learning point of view",
        "prob": 0.4066666666666667
    }, {
        "ID": 7084,
        "phrase": " these models admit a canonical representation which offers good opportunities from a machine learning point of view",
        "prob": 0.47333333333333333
    }, {
        "ID": 7175,
        "phrase": " obviously human brain is not another version of universal turing machine (utm), cognitivism and 'good old fashion artificial intelligence' gofai have assumed that cognition is a form of computation  [9] ",
        "prob": 0.3375
    }, {
        "ID": 7175,
        "phrase": " the reason why the tm computation approach was dominating in the era of good old fashioned artificial intelligence (gofai) is that it provides a notation of mechanism in terms of computation notations; the computation in the form of tm machines provides a mechanism capable of processing symbols",
        "prob": 0.26999999999999996
    }, {
        "ID": 7175,
        "phrase": " the soft computing approach provides another means to model perception or cognition, the favors of classical hard computing approach to artificial intelligence, are that they are precise, certain, and rigorous  [27] , however, one obstacle that faces symbolic computation is that it is not dynamical; symbols do not have derivatives, only smooth functions have  [1] ",
        "prob": 0.5181818181818182
    }, {
        "ID": 7505,
        "phrase": " these modules would be suited to projects in an artificial intelligence class, providing opportunities to implement a variety of concepts from game theory",
        "prob": 0.5055555555555555
    }, {
        "ID": 7505,
        "phrase": " \n artificial intelligence the monster that roams the maze in the game is an autonomous entity, controlled solely by the game program",
        "prob": 0.6937500000000001
    }, {
        "ID": 7505,
        "phrase": " a class could learn and experiment with artificial intelligence by replacing the modules that deal with the monster's movement",
        "prob": 0.6733333333333333
    }, {
        "ID": 7506,
        "phrase": " these modules would be suited to projects in an artificial intelligence class, providing opportunities to implement a variety of concepts from game theory",
        "prob": 0.5611111111111111
    }, {
        "ID": 7506,
        "phrase": " \n artificial intelligence the monster that roams the maze in the game is an autonomous entity, controlled solely by the game program",
        "prob": 0.7562500000000001
    }, {
        "ID": 7506,
        "phrase": " a class could learn and experiment with artificial intelligence by replacing the modules that deal with the monster's movement",
        "prob": 0.7400000000000001
    }, {
        "ID": 7593,
        "phrase": " the choice of ml and nlp methods differs but their aim is similar to our: normalizing text with predicate-arguments structures for learning better patterns",
        "prob": 0.3736842105263158
    }, {
        "ID": 7853,
        "phrase": " accordingly the artificial intelligence (ai) is usually treated how property of computing systems to execute separate functions of human intelligence, for example, to choose and make optimum decisions on the basis of earlier received experience -of the knowledge base and the rational analysis of external action",
        "prob": 0.21515151515151515
    }, {
        "ID": 7897,
        "phrase": " \n production rule systems and update rule programs the treatment of active rules in active databases is to some extend similar to the forward-chaining production rules system paradigm in artificial intelligence (ai) research  [24] ",
        "prob": 0.5038461538461539
    }, {
        "ID": 7898,
        "phrase": " \n production rule systems and update rule programs the treatment of active rules in active databases is to some extend similar to the forward-chaining production rules system paradigm in artificial intelligence (ai) research  [24] ",
        "prob": 0.5038461538461539
    }, {
        "ID": 7974,
        "phrase": " \n production rule systems and update rule programs the treatment of active rules in active databases is to some extend similar to the forward-chaining production rules system paradigm in artificial intelligence (ai) research  [20] ",
        "prob": 0.6192307692307693
    }, {
        "ID": 7995,
        "phrase": " these fragments together make the set ai of disjoint augmentations",
        "prob": 0.21000000000000002
    }, {
        "ID": 8247,
        "phrase": " even without going into a detailed discussion of intentional environment ahead proactive behavior, we can see that the very possibility of such environment prediction and environment management by an intelligent entity tends to turn our general perception of the objectives of environment based ai learning systems on its head",
        "prob": 0.159375
    }, {
        "ID": 8248,
        "phrase": " the grand aim of ai has always been to make an entity that can think",
        "prob": 0.31
    }, {
        "ID": 8248,
        "phrase": " however we know that symbol based discrete processing has inherent advantages that can help turn our artificial intelligence systems into better, faster and more relentless learners than humans, which is good reason to be wary of them",
        "prob": 0.284
    }, {
        "ID": 8248,
        "phrase": " turing also tacitly assumes that the ai entity in the room is as autonomous as a human is, which we have seen is possible only for conscious, intentional, intelligence systems",
        "prob": 0.5352941176470588
    }, {
        "ID": 8497,
        "phrase": " in the field of artificial intelligence, the excessive ambitions of the sixties were considerably lowered in the seventies, before knowing a new wave of optimism in the mid eighties",
        "prob": 0.7947368421052632
    }, {
        "ID": 8497,
        "phrase": " the emergence of dai is directly linked to the limits of the traditional symbolic ai (gofai) which tries to embed intelligence in a unique entity",
        "prob": 0.6937500000000001
    }, {
        "ID": 8498,
        "phrase": " in the field of artificial intelligence, the excessive ambitions of the sixties were considerably lowered in the seventies, before knowing a new wave of optimism in the mid eighties",
        "prob": 0.7421052631578947
    }, {
        "ID": 8498,
        "phrase": " the emergence of dai is directly linked to the limits of the traditional symbolic ai (gofai) which tries to embed intelligence in a unique entity",
        "prob": 0.6937500000000001
    }, {
        "ID": 8573,
        "phrase": "\" it still sounds a bit complicated, but i think what you mean is that (1) mixed multi-author papers (ml, with m = more productive authors, l = less productive authors) are more likely to be cited than unmixed multiauthor (ll) papers with the same number of authors, and that (2) such ml papers are also more likely to be self-archived",
        "prob": 0.315625
    }, {
        "ID": 8634,
        "phrase": " we have 231 unique nouns in the artificial intelligence text",
        "prob": 0.34444444444444444
    }, {
        "ID": 9228,
        "phrase": " since ml allows us to take theorems apart, we can extract the new term u from the theorem |-t==u",
        "prob": 0.20666666666666667
    }, {
        "ID": 9228,
        "phrase": " it is vital to recognize that the fp style of programming differs fundamentally from the ml style",
        "prob": 0.3153846153846154
    }, {
        "ID": 9252,
        "phrase": " maximum entropy has been gaining prominence as a means of dealing with uncertainty both in ai and other areas",
        "prob": 0.25833333333333336
    }, {
        "ID": 9256,
        "phrase": " wrap-up uses machine learning techniques to avoid months of manual knowledge engineering otherwise required to develop a speci c ie application",
        "prob": 0.29047619047619044
    }, {
        "ID": 9281,
        "phrase": " machine learning systems have employed opus o in this manner to develop rules for inclusion both in sets of decision rules  (webb, 1993)  and in decision lists  (webb, 1994b) ",
        "prob": 0.305
    }, {
        "ID": 9281,
        "phrase": " opus also has potential for application in other areas of artificial intelligence, notably, truth maintenance",
        "prob": 0.3923076923076923
    }, {
        "ID": 9310,
        "phrase": " experiment set 4 investigates whether machine learning can explicitly recognize the new class unknown",
        "prob": 0.20666666666666667
    }, {
        "ID": 9367,
        "phrase": " one 1969 report for the naval supply command  (bernstein, 1969)  n terabit memories at a price of 1 million dollars may be possible by 1982 n card readers will peak at 1500 cards per minute by 1974 and then their use will decline n computer architecture will have parallel processing by 1975 raj reddy and one of us (gb) have two near term (2003) bets: ai has had as significant effect on society as the transistor, and a production model car will be available that drives itself",
        "prob": 0.38863636363636367
    }, {
        "ID": 9447,
        "phrase": " \n old myt hs an o v ervi e w o f t h e c o n gest i on pro b l e m and t h efa c t o r st h at aect i t s de s i g n a l o n g w as pre se n t e d i n j ai n  [ 1]  ",
        "prob": 0.22142857142857145
    }, {
        "ID": 9483,
        "phrase": " their use in computing goes back to the 1960's in ai (if not earlier), and is also found in eg",
        "prob": 0.21000000000000002
    }, {
        "ID": 9570,
        "phrase": " for example, there has been little usage of the comment facility provided by the journal of artificial intelligence research 25 ; the comment facility at the electronic transactions on artificial intelligence 26 has seen more usage",
        "prob": 0.7772727272727272
    }, {
        "ID": 9595,
        "phrase": " the difference between the bottom two lines represents how much better the machine learning scheme could conceivably do in finding the authors' keyphrases from among the candidates",
        "prob": 0.14761904761904762
    }, {
        "ID": 9616,
        "phrase": " i assume the latter has done a great deal of good to nlp/cl: it has freed us from toy systems and fatuous example mongering, and shown that more could be done with superficial knowledge-free methods than the whole ai knowledge-based-nlp tradition ever conceded: the tradition in which every example, every sentence, had in principle to be subjected to the deepest methods",
        "prob": 0.2951219512195122
    }, {
        "ID": 9616,
        "phrase": ", 1988)  among others? none of this is a surprise to those with ai memories more than a few weeks long: in our field people read little outside their own notational clique, and constantly \"rediscover\" old work with a new notation",
        "prob": 0.3375
    }, {
        "ID": 9630,
        "phrase": " the electronic transactions on artificial intelligence (etai) was designed to function primarily as an electronic journal",
        "prob": 0.5785714285714286
    }, {
        "ID": 9637,
        "phrase": " \n planning under uncertainty another fruitful analogy can be drawn with results from ai planning systems, that are intended to work acceptably under conditions of uncertainty",
        "prob": 0.2833333333333333
    }, {
        "ID": 9672,
        "phrase": "introduction a central goal of artificial intelligence is to develop techniques for constructing robust, autonomous agents that are able to achieve good performance in complex, real-world environments",
        "prob": 0.2217391304347826
    }, {
        "ID": 9704,
        "phrase": " \n local ai theories of discourse, usually without models of individuals or domains, but with a taxonomy of speech/dialogue acts and inference rules applied bottom-up to utterances (charniak  [16] , bunt  [17] , carletta  [18] )",
        "prob": 0.2125
    }, {
        "ID": 9790,
        "phrase": "\" in contrast, the editors and organizers of the electronic transactions on artificial intelligence(etai) sought to make the review process of articles more open for authors and readers (http://www",
        "prob": 0.705
    }, {
        "ID": 9790,
        "phrase": ") the etai is an interesting contrast with another hybrid paper-electronic journal for artificial intelligence , the journal of artificial intelligence research (jair)",
        "prob": 0.6894736842105263
    }, {
        "ID": 9790,
        "phrase": " each of these artificial intelligence e-journals values peer review, and public discussion, but also structures them a bit differently",
        "prob": 0.6066666666666667
    }, {
        "ID": 9790,
        "phrase": " a project at the mit artificial intelligence lab designed an information space for searching jair articles arranged on a 3-d plane",
        "prob": 0.31875
    }, {
        "ID": 9790,
        "phrase": " artificial intelligence is one of the enhanced paper-and-electronic journals published by elsevier",
        "prob": 0.3923076923076923
    }, {
        "ID": 9790,
        "phrase": " electronic transactions on artificial intelligence (etai) http://www",
        "prob": 0.61
    }, {
        "ID": 9790,
        "phrase": " the free electronic versions of the articles are already formatted and paginated as they would appear in a traditional printed journal \n\t\t\t etai is not necessarily a better journal for ai researchers than jair",
        "prob": 0.5954545454545455
    }, {
        "ID": 9791,
        "phrase": "\" in contrast, the editors and organizers of the electronic transactions on artificial intelligence(etai) sought to make the review process of articles more open for authors and readers (http://www",
        "prob": 0.755
    }, {
        "ID": 9791,
        "phrase": ") the etai is an interesting contrast with another hybrid paper-electronic journal for artificial intelligence , the journal of artificial intelligence research (jair)",
        "prob": 0.5842105263157894
    }, {
        "ID": 9791,
        "phrase": " each of these artificial intelligence e-journals values peer review, and public discussion, but also structures them a bit differently",
        "prob": 0.6066666666666667
    }, {
        "ID": 9791,
        "phrase": " from an information-processing perspective -a perspective that 4 etai is not necessarily a better journal for ai researchers than jair",
        "prob": 0.36428571428571427
    }, {
        "ID": 9826,
        "phrase": " end while; \n \u03c7 : [ai 1 , ai 2 ], \u2297 if and only if o |= red 2 (\u03c7 : [ai 1 , ai 2 ], \u2297 )",
        "prob": 0.22000000000000003
    }]
}, {
    "topic_id": 20,
    "top_words": ["continuous", "state", "finite", "proof", "sequence", "function", "different", "discrete", "types", "represented", "values", "may", "include", "following", "states"],
    "phrases": [{
        "ID": 141,
        "phrase": " one simply has to look in nature, starting with, for instance, inanimate crystals, then come amino-acids, then some rna fragments, then viruses, bacteria, plants, animals, apes, followed by the truly intelligent homo sapiens, and possibly continued by ai systems or et's",
        "prob": 0.7620689655172413
    }, {
        "ID": 141,
        "phrase": " we have derived a finite bound for e ai n\u03be , but unfortunately, a rather weak one as compared to  (22) ",
        "prob": 0.19090909090909092
    }, {
        "ID": 141,
        "phrase": " \n using the ai models for function mininimization: the ai model can be used for function minimization in the following way",
        "prob": 0.36428571428571427
    }, {
        "ID": 280,
        "phrase": " an execution fragment of a is a finite or infinite alternating sequence, s 0 a 1 s 1 a 2 s 2 \u2022 \u2022 \u2022, of states and actions of a, beginning with a state, and if it is finite also ending with a state, such that for all i > 0, s i\u22121 ai \u2212\u2192 s i ",
        "prob": 0.7705882352941176
    }, {
        "ID": 281,
        "phrase": " an execution fragment of a is a finite or infinite alternating sequence, s 0 a 1 s 1 a 2 s 2 \u2022 \u2022 \u2022, of states and actions of a, beginning with a state, and if it is finite also ending with a state, such that for all i > 0, s i\u22121 ai \u2212\u2192 s i ",
        "prob": 0.7705882352941176
    }, {
        "ID": 1143,
        "phrase": " p(a|x) = c(a|x) ai c(a i |x) = e ax \u03c8 x (n ) l x \u03c8 x (n ) where, as before, c(a|x) is the count function that gives the frequency of phoneme a in x",
        "prob": 0.3923076923076923
    }, {
        "ID": 1235,
        "phrase": " then the global control, exhibited by the function revise(a \u2032 i ) is responsible for adapting the set of atoms in such a way that all atoms in a \u2032 i (and thus s as well as all the leaves) are a i+1 -closed and that, eventually,  initialise: i = 0, a0 = s; repeat for each a k \u2208 ai do let \u03c4 k := unfold(p, a k ); let a \u2032 i := ai\u222a {b|b \u2208 leaves (\u03c4 k )}; let ai+1 := revise(a \u2032 i ); let i := i + 1 until ai = ai\u22121; let a := ai; let p \u2032 := a k \u2208a resultants (\u03c4 k ) fig",
        "prob": 0.3558823529411765
    }, {
        "ID": 1283,
        "phrase": " if a = \u2228 (a), then ai\u2208a \u227a ai + is a's in- duced belief state",
        "prob": 0.3875
    }, {
        "ID": 1466,
        "phrase": ", correlating user ratings [bs97, kmm + 97]), machine learning (e",
        "prob": 0.2818181818181818
    }, {
        "ID": 1499,
        "phrase": "mutual information is widely used in artificial intelligence, in a descriptive way, to measure the stochastic dependence of discrete random variables",
        "prob": 0.22777777777777775
    }, {
        "ID": 1564,
        "phrase": " \u2022 l ai , l w and l aw for the propositional languages built up from these atoms in the usual way, and variables x, y, ",
        "prob": 0.25833333333333336
    }, {
        "ID": 2053,
        "phrase": " at round i, the mbf proof computation stage takes as input the nonce ni (we explain how we build this nonce below) and the proof parameters ei and li, returning the proof si and the output value ai (see section a",
        "prob": 0.1782608695652174
    }, {
        "ID": 2333,
        "phrase": " one simply has to look in nature, starting with, for instance, inanimate crystals, then come amino-acids, then some rna fragments, then viruses, bacteria, plants, animals, apes, followed by the truly intelligent homo sapiens, and possibly continued by ai systems or ets",
        "prob": 0.7275862068965517
    }, {
        "ID": 2333,
        "phrase": " \n value bounds and separability concepts \n introduction the values v km associated with the ai systems correspond roughly to the negative error measure \u2212e \u03c1 n of the sp systems",
        "prob": 0.305
    }, {
        "ID": 2333,
        "phrase": " we have derived a finite bound for e ai n\u03be , but unfortunately, a rather weak one as compared to (6",
        "prob": 0.19090909090909092
    }, {
        "ID": 2333,
        "phrase": " \n using the ai models for function mininimization the ai\u00b5 model can be used for function minimization in the following way",
        "prob": 0.36428571428571427
    }, {
        "ID": 2333,
        "phrase": " \n comparison to other approaches a different way to measure the achievements of this work is to compare aixi(tl) to other ai approaches",
        "prob": 0.2928571428571428
    }, {
        "ID": 2438,
        "phrase": " \n discussion 2: continuous spatial change i open the section with my answer to the question of whether ai should reconsider, or revise its challenges: \"ai to the servive of the earth as the humanity's global, continuous environment: the role of continuous (spatial) change in building a lasting global, locally plausible democracy: (cognitive) ai, which is guided by cognitively plausible assumptions on the physical world, such as, e",
        "prob": 0.33589743589743587
    }, {
        "ID": 2621,
        "phrase": " 23 actions are distributed among multiple agents: let \u03b1 be the finite collection of n agents with each agent having at its disposal a finite set ai of actions",
        "prob": 0.39444444444444443
    }, {
        "ID": 3002,
        "phrase": " we have directly \u2308rec \u211c\u00d7\u2118 (s)\u2309 = \u2228{(i a \u00d7 i b )(q a0 , q b0 ) \u2227 (t a \u00d7 t b )(q ak , q bk ) \u2227 \u2227 k\u22121 i=0 \u03b4 a\u00d7b ((q ai , q bi ), \u03c3 i+1 , (q a(i+1) , q b(i+1) )) : q a0 , q a1 , ",
        "prob": 0.3444444444444444
    }, {
        "ID": 3002,
        "phrase": ", q bk \u2208 q b } = \u2228{i a (q a0 ) \u2227 i b (q b0 ) \u2227 t a (q ak ) \u2227 t b (q bk ) \u2227 \u2227 k\u22121 i=0 \u03b4 a (q ai , \u03c3 i+1 , q a(i+1) )\u2227 \u2227 k\u22121 i=0 \u03b4 b (q bi , \u03c3 i+1 , q b(i+1 ) ) : q a0 , q a1 , ",
        "prob": 0.4428571428571429
    }, {
        "ID": 3031,
        "phrase": " three of these are interpreter based, built using prolog  (miller and nadathur 1988) , lisp  (elliott and pfenning 1989 ) and standard ml  (elliott and pfenning 1991; wickline and miller 1997) ",
        "prob": 0.3857142857142857
    }, {
        "ID": 3141,
        "phrase": " variable name variable type variable label 1 duration continuous a 2 protocol_type discrete b 3 service discrete c 4 flag discrete d 5 src_bytes continuous e 6 dst_bytes continuous f 7 land discrete g 8 wrong_fragment continuous h 9 urgent continuous i 10 hot continuous j 11 num_failed_logins continuous k 12 logged_in discrete l 13 num_compromised continuous m 14 root_shell continuous n 15 su_attempted continuous o 16 num_root continuous p 17 num_file_creations continuous q 18 num_shells continuous r 19 num_access_files continuous s 20 num_outbound_cmds continuous t 21 is_host_login discrete u 22 is_guest_login discrete v 23 count continuous w 24 srv_count continuous x 25 serror_rate continuous y 26 srv_serror_rate continuous x 27 rerror_rate continuous aa 28 srv_rerror_rate continuous ab 29 same_srv_rate continuous ac 30 diff_srv_rate continuous ad 31 srv_diff_host_rate continuous ae 32 dst_host_count continuous af 33 dst_host_srv_count continuous ag 34 dst_host_same_srv_rate continuous ah 35 dst_host_diff_srv_rate continuous ai 36 dst_host_same_src_port_rate continuous aj 37 dst_host_srv_diff_host_rate continuous ak 38 dst_host_serror_rate continuous al 39 dst_host_srv_serror_rate continuous am 40 dst_host_rerror_rate continuous an 41 dst_host_srv_rerror_rate continuous ao \n table 1 ",
        "prob": 0.921
    }, {
        "ID": 3550,
        "phrase": "introduction we start with our answer to the question of whether artificial intelligence (ai) should reconsider, or revise its challenges: \"ai to the service of the earth as the humanity's global, continuous environment: the role of continuous (spatial) change in building a lasting global, locally plausible democracy: (cognitive) ai, which is guided by cognitively plausible assumptions on the physical world, such as, e",
        "prob": 0.35405405405405405
    }, {
        "ID": 3896,
        "phrase": " variable name variable type variable label 1 duration continuous a 2 protocol_type discrete b 3 service discrete c 4 flag discrete d 5 src_bytes continuous e 6 dst_bytes continuous f 7 land discrete g 8 wrong_fragment continuous h 9 urgent continuous i 10 hot continuous j 11 num_failed_logins continuous k 12 logged_in discrete l 13 num_compromised continuous m 14 root_shell continuous n 15 su_attempted continuous o 16 num_root continuous p 17 num_file_creations continuous q 18 num_shells continuous r 19 num_access_files continuous s 20 num_outbound_cmds continuous t 21 is_host_login discrete u 22 is_guest_login discrete v 23 count continuous w 24 srv_count continuous x 25 serror_rate continuous y 26 srv_serror_rate continuous x 27 rerror_rate continuous aa 28 srv_rerror_rate continuous ab 29 same_srv_rate continuous ac 30 diff_srv_rate continuous ad 31 srv_diff_host_rate continuous ae 32 dst_host_count continuous af 33 dst_host_srv_count continuous ag 34 dst_host_same_srv_rate continuous ah 35 dst_host_diff_srv_rate continuous ai 36 dst_host_same_src_port_rate continuous aj 37 dst_host_srv_diff_host_rate continuous ak 38 dst_host_serror_rate continuous al 39 dst_host_srv_serror_rate continuous am 40 dst_host_rerror_rate continuous an 41 dst_host_srv_rerror_rate continuous ao \n table 2 ",
        "prob": 0.921
    }, {
        "ID": 4299,
        "phrase": " two optional integer arguments ml and mu are returned with the number of non-zero sub-diagonals and/or super-diagonals, respectively",
        "prob": 0.26842105263157895
    }, {
        "ID": 4339,
        "phrase": " so we prove inequality: vector x can also be represented as x = ai \u2297 gi and we can repeat above proof for this representation",
        "prob": 0.2583333333333333
    }, {
        "ID": 4390,
        "phrase": "q \u2208 q m \u2203 and that c is eventually accepting; c \u2208 ai for even i means that c",
        "prob": 0.1375
    }, {
        "ID": 5116,
        "phrase": " an infinite sequence {ai} \u221e i=1 , ai i\u2192\u221e \u2212\u2192 +\u221e, ai \u2208 r, is called a dense sequence of values if a1 \u2264 100 and ai+1 \u2212ai = o(ai) (for i \u2192 \u221e)",
        "prob": 0.4636363636363636
    }, {
        "ID": 5135,
        "phrase": " ak 2 ak 1 > where each of the ai j is binary for all i and j",
        "prob": 0.3
    }, {
        "ID": 5244,
        "phrase": " ml-art adds several extensions to ml to implement objects: records with polymorphic access and extension, projective records, recursive types, implicit existential and universal types",
        "prob": 0.29583333333333334
    }, {
        "ID": 5498,
        "phrase": " freshml  [65, 75, 76]  is an extension of the ml programming language that provides built-in support for nominal abstract syntax",
        "prob": 0.38125
    }, {
        "ID": 5527,
        "phrase": " (10) let f 2 n be the finite field with 2 n elements, and n = ml for integers m and l",
        "prob": 0.31
    }, {
        "ID": 5574,
        "phrase": " here we describe the identification of critical residues that mediate protein-protein and protein-rna interactions in rev, using machine learning approaches that rely on the primary amino acid sequence of rev, but do not require any information regarding its structure or the sequence or structure of its interaction partners",
        "prob": 0.24545454545454545
    }, {
        "ID": 5574,
        "phrase": " we have developed machine learning approaches for predicting which amino acids of a protein participate in its interactions with other proteins and/or nucleic acids, using only the protein sequence as input",
        "prob": 0.41363636363636364
    }, {
        "ID": 5697,
        "phrase": " both java and ml have been extended with reactive primitives, respectively in rejo  [1]  and reactiveml  [21] ",
        "prob": 0.17500000000000002
    }, {
        "ID": 5812,
        "phrase": " formalisms to describe such data structure definitions include apigen  [12] , xml schema, ml types, and asdl  [14] ",
        "prob": 0.5062500000000001
    }, {
        "ID": 5813,
        "phrase": " formalisms to describe such data structure definitions include apigen  [13] , xml schema, ml types, and asdl  [15] ",
        "prob": 0.5687500000000001
    }, {
        "ID": 5829,
        "phrase": "introduction artificial intelligence planning is a form of general problem solving task which focuses on problems that map into state models that can be defined by a state space s, an initial state s 0 \u2286 s, a set of goal states s g \u2286 s, a set of actions a(s) applicable in each state s, and a transition function f (a, s) = s \u2032 with a \u2208 a(s), and s, s \u2032 \u2208 s",
        "prob": 0.315625
    }, {
        "ID": 5925,
        "phrase": " graphplan representations in planning), and discrete ai structures such as finite state automaton",
        "prob": 0.425
    }, {
        "ID": 5926,
        "phrase": " graphplan representations in planning), and discrete ai structures such as finite state automaton",
        "prob": 0.425
    }, {
        "ID": 6122,
        "phrase": "3 (execution) an execution of a transition system s 0 , s, act, \u2192, l is an infinite alternating sequence \u03c3 def = s 0 a0 \u2192 s 1 a1 \u2192 s 2 \u2022 \u2022 \u2022 s i ai \u2192 s i+1 \u2022 \u2022 \u2022 of states and actions such that s 0 \u2208 s 0 and for every i \u2265 0, we have s i ai \u2192 s i+1 \u2208\u2192 [klm + 02]",
        "prob": 0.6529411764705882
    }, {
        "ID": 6122,
        "phrase": " \n we extend a finite fragment \u03c3 \u2032 def = s i ai \u2192 s i+1 \u2022 \u2022 \u2022 s k\u22121 a k\u22121 \u2192 s k to an execution \u03c3 def = s i ai \u2192 s i+1 \u2022 \u2022 \u2022 s k\u22121 a k\u22121 \u2192 s k skip \u2192 s k skip \u2192 s k \u2022 \u2022 \u2022 and we call it an extension",
        "prob": 0.5785714285714286
    }, {
        "ID": 6122,
        "phrase": " that is, \u2022 inf s (\u03c3) def = {s | \u03c3 = s 0 a0 \u2192 s 1 \u2022 \u2022 \u2022 s i ai \u2192 s i+1 \u2022 \u2022 \u2022 \u2227 s = s i for infinitely many i}, \u2022 inf t (\u03c3) def = { t | \u03c3 = s 0 a0 \u2192 s 1 \u2022 \u2022 \u2022 s i ai \u2192 s i+1 \u2022 \u2022 \u2022 \u2227 t = s i ai \u2192 s i+1 for infinitely many i}, \u2022 in(t ) def = {s | s a \u2192 s \u2032 \u2208 t }",
        "prob": 0.43571428571428567
    }, {
        "ID": 6122,
        "phrase": "19 (execution acceptance) an execution \u03c3 = s 0 a0 \u2192 s 1 \u2022 \u2022 \u2022 s i ai \u2192 s i+1 \u2022 \u2022 \u2022 \u2208 \u03c3 t s is accepted by a run \u03c0 = q 0 p0 \u2192 q 1 \u2022 \u2022 \u2022 q i pi \u2192 q i+1 \u2022 \u2022 \u2022 \u2208 \u03c3 b if i) \u03c0 is a run of b on \u03c3: \u2200i \u2022 ((0 \u2264 i \u2227 q i pi \u2192 q i+1 \u2208\u2192 b ) \u21d2 s i |= p i ), ii) the run is accepting: inf s (\u03c0) \u2229 a = \u2205",
        "prob": 0.5399999999999999
    }, {
        "ID": 6122,
        "phrase": " as the fair refinement is a \u03c4 -simulation of \u03c4 -f t s 2 by f t s 1 , each computation \u03c3 of \u03c4 -f t s 2 is such that \u03c3 = s 0 \u03c4 * \u2192 s i1\u22121 ai 1 \u2192 s i1 \u03c4 * \u2192 s i2\u22121 ai 2 \u2192 s i2 \u03c4 * \u2192 s i3\u22121 ai 3 \u2192 s i3 ",
        "prob": 0.2625
    }, {
        "ID": 6122,
        "phrase": ", where c \u2208 act 1 \u222a {\u03c4 } and s ij c * \u2192 s c is a finite sequence of fair transitions and states s c are not source states of a fair transition -here \u03c3 \u2032 refines a suffix of a computation of a global system in the abstract level which run around a cycle infinitely many times -, or \u2022 \u03c3 \u2032\u2032 = s ij\u22121 \u03c4 * \u2192 s ij \u22121 ai j \u2192 s ij c * \u2192 s c skip \u2192 s c skip \u2192 s c ",
        "prob": 0.5029411764705882
    }, {
        "ID": 6502,
        "phrase": " (1) by conventional demodulation  [4]  we may retrieve the original input as a k-dimensional output \u00f8 performing the following operation: ( ) 1/ 2 1 n n \u2212 \u2212 = = + \u2212 + + \u00f8 s m ai ss i ai, (2) where + s is the hermitian conjugate of s , and i is the unit matrix",
        "prob": 0.205
    }, {
        "ID": 6573,
        "phrase": " proof: m i=1 (a ai (l) + a bi (l)) = 0, 1 \u2264 l \u2264 n \u2212 1",
        "prob": 0.22000000000000003
    }, {
        "ID": 6782,
        "phrase": " for instance, the reactive ml language  [15]  includes a large fragment of the caml language plus primitives to generate signals and synchronise on them",
        "prob": 0.5611111111111111
    }, {
        "ID": 6782,
        "phrase": " for instance, in the reactive ml language we have already quoted, signals carry values and the emission of two distinct values on the same signal may produce a non-deterministic behaviour",
        "prob": 0.6130434782608696
    }, {
        "ID": 6783,
        "phrase": " for instance, the reactive ml language  [21]  includes a large fragment of the caml language plus primitives to generate signals and synchronise on them",
        "prob": 0.5611111111111111
    }, {
        "ID": 6783,
        "phrase": " for instance, in the reactive ml language we have already quoted, signals carry values and the emission of two distinct values on the same signal may produce a non-deterministic behaviour",
        "prob": 0.6565217391304348
    }, {
        "ID": 6881,
        "phrase": " \n classical random walks an execution path, or a trace in an alt s, is a finite or infinite sequence \u03c3 = (si, ai, si+1) of transitions satisfying: for all i \u2265 0, there exists ai \u2208 act such that (si, ai, si+1) \u2208 t ",
        "prob": 0.3
    }, {
        "ID": 6881,
        "phrase": " each of the mi's can be represented in a straightforward way by a finite-state automaton ai = xi, qi, q 0 i , fi, \u2206i where \u2022 each state of qi corresponds to a state of mi, \u2022 any two different transitions are labelled by two different letters of xi (hence the cardinality of xi equals the numbers of transitions in ai), 2 \u2022 all states are final states (hence fi = qi)",
        "prob": 0.43142857142857144
    }, {
        "ID": 6881,
        "phrase": " each one is represented by a finite state automaton ai = xi, qi, q 0 i , fi, \u2206i ",
        "prob": 0.41
    }, {
        "ID": 6881,
        "phrase": " given that each automaton ai contains a unique transition labeled by \u03b1 (the synchronised transition), let qi,1 and qi,2 be the states just before and juste after this transition, respectively",
        "prob": 0.3736842105263158
    }, {
        "ID": 6935,
        "phrase": " (ii) is clearly equivalent to the following statement: let p l + 1 = 2 a s i=1 p ai i , where p i are prime numbers and a i are non-negative numbers",
        "prob": 0.5071428571428571
    }, {
        "ID": 6936,
        "phrase": " (ii) is clearly equivalent to the following statement: let p l + 1 = 2 a s i=1 p ai i , where p i are prime numbers and a i are non-negative numbers",
        "prob": 0.5785714285714286
    }, {
        "ID": 6952,
        "phrase": " in a, child tnfa a i is represented by its start and accepting state \u03b8 ai and \u03c6 ai and a pseudo-transition labeled \u03b2 connecting them",
        "prob": 0.43571428571428567
    }, {
        "ID": 6952,
        "phrase": " any incoming transition to a state \u03b8 ai or outgoing transition from a state \u03c6 ai is an \u01eb-transition by thompson's construction",
        "prob": 0.3923076923076923
    }, {
        "ID": 7495,
        "phrase": " miller also proposed a functional language extending standard ml to include an intensional function type \u03c4 \u21d2 \u03c4 \u2032 populated by \"functions that can be analyzed at run-time\", that is, higher-order patterns  [miller 1990 ]",
        "prob": 0.37916666666666665
    }, {
        "ID": 7495,
        "phrase": " 2003; shinwell and pitts 2005 ] is a variant of ml (or objective caml) that provides built-in primitives for names and binding based on nominal abstract syntax",
        "prob": 0.655
    }, {
        "ID": 7496,
        "phrase": "  miller [1990]  also proposed a functional language extending standard ml to include an intensional function type \u03c4 \u21d2 \u03c4 \u2032 populated by \"functions that can be analyzed at run-time\", that is, higher-order patterns",
        "prob": 0.43913043478260866
    }, {
        "ID": 7496,
        "phrase": " 2003; shinwell and pitts 2005; pitts and shinwell 2007; pottier 2007 ] is a variant of ml (or objective caml) that provides built-in primitives for names and binding based on nominal abstract syntax",
        "prob": 0.7
    }, {
        "ID": 7776,
        "phrase": " let ai be the sequence of actions \u03b11, ",
        "prob": 0.3
    }, {
        "ID": 7776,
        "phrase": ", b3,a2,b1 is valid: after finishing a sequence of actions ai or bi, the variable vi is in its goal state (0 if i is even, 1 if i is odd)",
        "prob": 0.43571428571428567
    }, {
        "ID": 7939,
        "phrase": " the above formulation shows ml decoding to be equivalent to the minimization of a linear function over a finite set c \u2282 {0, 1} n ",
        "prob": 0.43571428571428567
    }, {
        "ID": 7940,
        "phrase": " the above formulation shows ml decoding to be equivalent to the minimization of a linear function over a finite set c \u2282 {0, 1} n ",
        "prob": 0.5071428571428571
    }, {
        "ID": 8555,
        "phrase": " the values v km associated with the ai systems correspond roughly to the negative loss \u2212l \u03bb n of the sp systems",
        "prob": 0.2928571428571428
    }, {
        "ID": 8555,
        "phrase": " using the ai models for function mininimization",
        "prob": 0.2625
    }, {
        "ID": 8555,
        "phrase": " the ai models can be used for function minimization in the following way",
        "prob": 0.41
    }, {
        "ID": 8766,
        "phrase": " thus, w g and w g * ai are locally equivalent",
        "prob": 0.4428571428571429
    }, {
        "ID": 8766,
        "phrase": " \n proof: for any r \u2208 f q , we have \u03c8(\u03c6 1 , r\u03c8 + \u03c6 2 ) = ai = 0",
        "prob": 0.22000000000000003
    }, {
        "ID": 8766,
        "phrase": " proof: for the only if part, it is sufficient to show that the systems w g , w g * ai , and also the systems w g , w g\u2022 b i are locally equivalent",
        "prob": 0.25833333333333336
    }, {
        "ID": 8783,
        "phrase": " finally, rexp are expressions that may include the value associated with a signal s at the end of the instant (which is written !s, following the ml notation for dereferenciation)",
        "prob": 0.2833333333333333
    }, {
        "ID": 9142,
        "phrase": " we first note that for the more complicated ones are: z a z b \u2208 z 2 \u2297z 2 with a \u227b b, there is an \u03b1 a,b \u2208 p 2 , such that \u03b1 a,b = z a z b + i a i z ai z bi with a i \u227b b i ",
        "prob": 0.20999999999999996
    }, {
        "ID": 9224,
        "phrase": " terms and formulas are values in ml: they have an explicit tree structure and can be decomposed and built up by ml functions",
        "prob": 0.20666666666666667
    }, {
        "ID": 9225,
        "phrase": " , a k /x k ] new proof state: object-level rule proof state new proof state \n\t\t\t sometimes called arities, following martin-l\u00f6f, to avoid confusion with ml types or object-level types",
        "prob": 0.5035714285714286
    }, {
        "ID": 9230,
        "phrase": " we will start to look at ml code including type definitions and substitution functions",
        "prob": 0.3153846153846154
    }, {
        "ID": 9241,
        "phrase": " the finite-state machine learning method presented here is incapable of generalizing over transitions from a particular state, and, as a consequence, the current system has the problem of displaying a very lengthy button-box interface list",
        "prob": 0.204
    }, {
        "ID": 9279,
        "phrase": " recently i have written an ml package to automate recursive definitions in isabelle zf  [24] ",
        "prob": 0.23846153846153847
    }, {
        "ID": 9285,
        "phrase": " examples in ai include computing abductive diagnoses  (reiter, 1987) , enumerating prime implicants in atms  (reiter & de kleer, 1987) , and horn approximations  (kavvadias et al",
        "prob": 0.5315789473684212
    }, {
        "ID": 9300,
        "phrase": " ai search algorithms generate a satisfactory trajectory through a graph of states",
        "prob": 0.19090909090909092
    }, {
        "ID": 9310,
        "phrase": " the following examples (taken from a spoken language corpus that will be described in section 2) illustrate sample discourse and sentential usages of the cue phrases \\say\" and \\further\": discourse \\: : : we might have the concept of say a researcher who has worked for fteen years on a certain project : : : \" \\further, and this is crucial in ai and probably for expert databases as well : : : \" sentential \\: : : let me just say that it bears a strong resemblance to much of the work that's done in semantic nets and even frames",
        "prob": 0.14489795918367346
    }, {
        "ID": 9311,
        "phrase": " what does it mean to achieve a goal? in state oriented domains, it is the classic ai notion of goal achievement: it means to carry out a sequence of actions (a plan) that results in the transformation of the environment to a state where the goal is satis ed",
        "prob": 0.284
    }, {
        "ID": 9315,
        "phrase": " unlike names++, the calculations themselves were constructed at run-time using a machine learning method",
        "prob": 0.22142857142857145
    }, {
        "ID": 9336,
        "phrase": " they wrote ml code to automate parts of the proof, but still the proof script contains long chains of lowlevel inferences",
        "prob": 0.17222222222222222
    }, {
        "ID": 9449,
        "phrase": "li t t l e t o n , ma01460 net wor k a ddr e s s :j ai n@er la n g",
        "prob": 0.2625
    }, {
        "ID": 9449,
        "phrase": "t h u s,e v enthough, t h e p ro b abi l i t y o f u n d etectederrors due t o f a l s e e n d i n g d e l i m i t e r d ecreasesconsid erabl y , t h e n et undetectederrorraterem ai ns c l o s e t o t h at due t o f al se fcs o r d u e t o a f a l s e s t a r t i n g d e l i m i t e r a n d d oes not change",
        "prob": 0.24117647058823527
    }, {
        "ID": 9517,
        "phrase": " + l k ) = l and each li can not be sup-represented: li = ai + bi for ai = li, bi = li",
        "prob": 0.18333333333333335
    }, {
        "ID": 9663,
        "phrase": " however, both the agents reward functions and the overall system structure are automatically set and then updated in a machine learning-like fashion, so as to facilitate the achievement of the global objective",
        "prob": 0.2318181818181818
    }]
}, {
    "topic_id": 21,
    "top_words": ["ml", "codeword", "algorithm", "likelihood", "given", "path", "maximum", "estimates", "estimate", "decision", "node", "number", "cost", "signal", "output"],
    "phrases": [{
        "ID": 141,
        "phrase": " (  56 ) is a special case of a factorizable \u00b5 (15) with identical factors \u00b5 r = \u00b5 ai 1 for all r and equal episode lengths n r+1 \u2212n r = n",
        "prob": 0.3416666666666666
    }, {
        "ID": 415,
        "phrase": " , b ml , b 1r , ",
        "prob": 0.22000000000000003
    }, {
        "ID": 777,
        "phrase": " therefore, for all restrictions of b, t ai depends on only a single bit obtained from i, namely z |b (i)",
        "prob": 0.2818181818181818
    }, {
        "ID": 1374,
        "phrase": " foundations of maximum likelihood the algorithm based on ml principle is similar to the algorithm of the previous example",
        "prob": 0.33999999999999997
    }, {
        "ID": 1464,
        "phrase": " \n method 2: sequential segmentation and ml cost \n model cost using ml in this case, we use as cost function the likelihood of the data, i",
        "prob": 0.26842105263157895
    }, {
        "ID": 1464,
        "phrase": " (in the cost function their cost would be infinite, due to ml probability estimates)",
        "prob": 0.3153846153846154
    }, {
        "ID": 1538,
        "phrase": " \n the segmentation algorithm the ml segmentation t can be obtained from the ml state sequence z = ( z 1 , z 2 , ",
        "prob": 0.3416666666666666
    }, {
        "ID": 1881,
        "phrase": " the estimate made by calculating the mi of the ml estimate tends to overstate the mi -  (li, 1990) ; there are more sophisticated techniques available  (wolf & wolpert, 1992  sometimes there are clusters that are a combination of two or more rather different subclusters",
        "prob": 0.1782608695652174
    }, {
        "ID": 2333,
        "phrase": "1) with identical factors \u00b5 r = \u00b5 ai 1 for all r and equal episode lengths n r+1 \u2212n r = n",
        "prob": 0.4555555555555555
    }, {
        "ID": 3298,
        "phrase": " let e \u2032 be the expression obtained from e by replacing a i by x ai ",
        "prob": 0.3875
    }, {
        "ID": 3335,
        "phrase": " apply the back-off smoothing to integrate the revised ml estimates p \u2032 ml(n) (w i |w i\u22121 i\u2212n+1 )(1 \u2264 n \u2264 n )",
        "prob": 0.46923076923076923
    }, {
        "ID": 3335,
        "phrase": " for each value of n(1 \u2264 n \u2264 n ), the maximum likelihood estimates p ml(n) (w i |w i\u22121 i\u2212n+1 ) of n-gram probability p obtained from the background corpus are revised to p \u2032 ml by the following procedure",
        "prob": 0.5055555555555555
    }, {
        "ID": 3335,
        "phrase": " if the postfix w i\u2212k+1 \u2022 \u2022 \u2022 w i (1 \u2264 k < n) of the word sequence w i\u2212n+1 \u2022 \u2022 \u2022 w i is equal to the prefix \u0175p \u2022 \u2022 \u2022 \u0175p+k\u22121 of one of the fixed phrases \u0175p \u2022 \u2022 \u2022 \u0175q then emphasize the p ml as follows: p \u2032 ml(n) ( \u0175p+k\u22121 |w p\u22121 p\u2212n+k \u0175p+k\u22122 p ) = \u03b2 n (w p\u22121 p\u2212n+k \u0175p+k\u22122 p ) \u2022 \u03b3p ml(n) ( \u0175p+k\u22121 |w p\u22121 p\u2212n+k \u0175p+k\u22122 p ) otherwise, go to step (2)",
        "prob": 0.575
    }, {
        "ID": 3601,
        "phrase": " this unique point determines the ml threshold",
        "prob": 0.5666666666666667
    }, {
        "ID": 3602,
        "phrase": " this unique point determines the ml threshold",
        "prob": 0.5666666666666667
    }, {
        "ID": 3630,
        "phrase": " so when the noise at each receive antenna is the additive white gaussian, to implement ml decoding we search for the ideal received signal point closest to the actual received signal point",
        "prob": 0.26521739130434785
    }, {
        "ID": 3630,
        "phrase": " the second part computes the ml estimate of transmitted signal from the received signal and qr factorization",
        "prob": 0.4066666666666666
    }, {
        "ID": 3630,
        "phrase": " (  1 ), we must compute the ml transmit signal \u00e2 = (\u00e2 1 , \u2022 \u2022 \u2022 , \u00e2t ) t equal to argmin \u00e2\u2208s t x \u2212 m \u00e2 ",
        "prob": 0.3727272727272727
    }, {
        "ID": 3630,
        "phrase": " sd can obtain p that is the ml estimate of p, and one can get the ml estimate of the original channel (1) from p by the inverse permutation \u03c3 \u22121 ",
        "prob": 0.2733333333333333
    }, {
        "ID": 3630,
        "phrase": " the ml estimate of \u00e2 can be obtained by the inverse permutation",
        "prob": 0.4555555555555555
    }, {
        "ID": 3630,
        "phrase": " if we use dijkstra's algorithm to find the shortest path from the root to one of nodes at the bottom level, we can get the node with the minimum d 0 = x\u2212m \u00e2 2 among all nodes at the bottom level and it corresponds to the ml estimate",
        "prob": 0.524
    }, {
        "ID": 3630,
        "phrase": " dijkstra's algorithm searches for only the nodes whose distance is smaller than the minimum distance of nodes at the bottom level, but sd searches for the node whose distance is smaller than c and c must be greater than the minimum distance of nodes at the bottom level in order for ml detection succeed",
        "prob": 0.5181818181818182
    }, {
        "ID": 3698,
        "phrase": ", w (\u2022|x, h) \u226a \u00b5 y , with the density function f(y|x, h) = 1 \u03c0 ml \u03c3 2ml e \u2212 y\u2212hx 2 2 \u03c3 2 ",
        "prob": 0.21000000000000002
    }, {
        "ID": 3873,
        "phrase": " if the obstacle is in pipe p5 connecting manholes m12 and m17, then we can just disconnect the connection between m12 and m17 and then let the ai planner find a new route, if one exists",
        "prob": 0.38125
    }, {
        "ID": 4047,
        "phrase": " for ml channel estimation, the free energy is given by f k r, \u0125 = r log cosh \u221a f z + e dz \u2212 em \u2212 f (1 \u2212 q) 2 \u2212 1 2\u03b2 log 1 + 1 + \u2206 2 h (1 \u2212 q)b + b b \u22121 0 + 1 \u2212 2m + (1 + \u2206 2 h )q 1 + b(1 \u2212 q)(1 + \u2206 2 h ) ",
        "prob": 0.20666666666666667
    }, {
        "ID": 4061,
        "phrase": " recall that in order to implement the rmdl estimator ml estimates of the unknown parameters must be found for every possible number of sources",
        "prob": 0.4263157894736842
    }, {
        "ID": 4061,
        "phrase": " since no closed-form expression for these ml estimates exists, multi-dimensional numerical searches must be used in order to find them",
        "prob": 0.5842105263157894
    }, {
        "ID": 4061,
        "phrase": ", p = 6, the number of unknown parameters is a few dozen, which makes the task of finding the ml estimates impractical",
        "prob": 0.2928571428571428
    }, {
        "ID": 4061,
        "phrase": " in order to overcome the computational burden of computing the ml estimates, we propose to replace the ml estimates by estimates obtained using a low-complexity estimation algorithm",
        "prob": 0.3681818181818182
    }, {
        "ID": 4061,
        "phrase": " (8) replacing the ml estimates with their ls counterparts raises two important questions",
        "prob": 0.3153846153846154
    }, {
        "ID": 4061,
        "phrase": " one is whether replacing the ml estimates with the ls estimates results in performance loss; and the second is whether efficient algorithms for computing the ls estimates exist",
        "prob": 0.24285714285714283
    }, {
        "ID": 4061,
        "phrase": " it was pointed out by one of the reviewers that for finite sample sizes since the ml estimates are replaced by the ls estimates, it is not guaranteed that l \u03b8q,ls < l \u03b8q+1,ls ",
        "prob": 0.2833333333333333
    }, {
        "ID": 4061,
        "phrase": " since no closed expression for the ml estimates exists, some numerical maximization method must be used",
        "prob": 0.47333333333333333
    }, {
        "ID": 4061,
        "phrase": " therefore, the complexity of the ml estimator depends on the number of iterations and the exact numerical maximization method used",
        "prob": 0.5687500000000001
    }, {
        "ID": 4061,
        "phrase": " it follows that for p > 3, the complexity of the ml estimator is higher by several orders of magnitude than our proposed iterative algorithm",
        "prob": 0.2733333333333333
    }, {
        "ID": 4071,
        "phrase": " the second-order ml estimate of a ijk is given by the equation: a ijk = t \u03b7 t (i, j, k) k,t \u03b7 t (i, j, k) = t \u22122 t=1 \u03b7 t+1 (i, j, k) t \u22122 t=1 \u03be t (i, j) ",
        "prob": 0.46923076923076923
    }, {
        "ID": 4071,
        "phrase": " ( 16 ) the ml estimates of the mean and covariance are given by the formulas: \u00b5 i = t \u03b3 t (i)o t t \u03b3 t (i) , (17) \u03c3 i = t \u03b3 t (i)(o t \u2212 \u00b5 i )(o t \u2212 \u00b5 i ) t t \u03b3 t (i) ",
        "prob": 0.51
    }, {
        "ID": 4096,
        "phrase": " a space frequency code is given by a discrete set c \u2282 v c nt ,k and provided the received signal c = \u03c1 k nt \u03c8h + n at the receiver the maximum likelihood decision reads (see  [7] ) \u03c6 ml : c \u2212 \u03c1 k n t \u03c6 ml h f \u2264 c \u2212 \u03c1 k n t \u03c6h f \u2200 \u03c6\u2208c (3) in the sequel let us adopt the notation that in order to emphasize the space frequency (code) or space time (code) interpretation of a given quantity subscripts \u2022 f , respectively \u2022 t will be added",
        "prob": 0.8119047619047618
    }, {
        "ID": 4097,
        "phrase": " a space frequency code is given by a discrete set c \u2282 v nt,k and provided the received signal c = \u03c1 k nt \u03c8h + n the maximum likelihood decision reads (see  [8] ) \u03c6 ml = arg min \u2200\u03c6\u2208c c \u2212 \u03c1 k n t \u03c6h f (4) in the sequel let us adopt the notation that in order to emphasize the space frequency (code) or space time (code) interpretation of a given quantity subscripts \u2022 f , respectively \u2022 t will be added",
        "prob": 0.8317073170731706
    }, {
        "ID": 4263,
        "phrase": " note that 0 \u2264 ai \u2264 1 for 0 \u2264 a \u2264 \u221e and ai determines the amount of correlation between sample si and si+1; ai = 0 implies that two samples are independent while for perfectly correlated signal samples we have ai = 1 ",
        "prob": 0.24117647058823527
    }, {
        "ID": 4328,
        "phrase": " again from  [20] , the invariance of the ml estimate tells us that the ml estimate for \u03c6 = g(\u03b8) = \u03b8 1 + m\u03b8 2 is \u03c6ml = \u03b81ml + m \u03b82ml ",
        "prob": 0.65
    }, {
        "ID": 4329,
        "phrase": " again from  [23] , the invariance of the ml estimate tells us that the ml estimate for \u03c6 = g(\u03b8) = \u03b8 1 + m\u03b8 2 is \u03c6ml = \u03b81ml + m \u03b82ml ",
        "prob": 0.4357142857142858
    }, {
        "ID": 4458,
        "phrase": " thus, the ml decoder estimates the codeword with the lowest cost whereas the sub-optimal graph-based iterative ms decoder estimates the pseudocodeword with the lowest cost",
        "prob": 0.4826086956521739
    }, {
        "ID": 4459,
        "phrase": " thus, the ml decoder estimates the codeword with the lowest cost whereas the sub-optimal graph-based iterative ms decoder estimates the pseudocodeword with the lowest cost",
        "prob": 0.5260869565217391
    }, {
        "ID": 4698,
        "phrase": " the 4-level, 8-level and un-quantized lower bounds apply to ml decoding, and are based on corollaries 3",
        "prob": 0.4066666666666667
    }, {
        "ID": 4727,
        "phrase": " the 4-level, 8-level and un-quantized lower bounds apply to ml decoding, and are based on corollaries 3",
        "prob": 0.33999999999999997
    }, {
        "ID": 4727,
        "phrase": " the 4-level, 8-level and un-quantized lower bounds apply to ml decoding, and are based on corollaries 3",
        "prob": 0.33999999999999997
    }, {
        "ID": 4728,
        "phrase": " the 4-level, 8-level and un-quantized lower bounds apply to ml decoding, and are based on corollaries 3",
        "prob": 0.33999999999999997
    }, {
        "ID": 4804,
        "phrase": " the ml demodulator essentially finds the transmitted symbol or code matrix, x = x n that produces the minimum distance between the matched filter outputs, y (k) and the channel output, \u221a e s h(k) x (n) (k)",
        "prob": 0.24285714285714283
    }, {
        "ID": 4856,
        "phrase": " that is, the ml decoder also fails",
        "prob": 0.4428571428571429
    }, {
        "ID": 4856,
        "phrase": " since the hdd may return a codeword which is different from the ml codeword, we do not stop the decoder once a codeword is returned by the hdd",
        "prob": 0.3
    }, {
        "ID": 4910,
        "phrase": " since \u03b8 is unknown, its ml estimate can be obtained first for a given hypothesis h k and then that estimate can be used in the llr expression",
        "prob": 0.5687500000000001
    }, {
        "ID": 5031,
        "phrase": " using the (normalized) llr vector \u03bb, the maximum likelihood (ml) decoder \u03c6 ml can be cast as x \u03c6 ml (\u03bb \u2032 ) arg max x\u2208 c n i=1 xi \u03bb \u2032 i , (1) with the trivial mapping \u03bb \u2032 i \u00b5 triv (\u03bb i ) \u03bb i , i = 1, ",
        "prob": 0.5761904761904761
    }, {
        "ID": 5031,
        "phrase": " this is in stark contrast to ml decoding whose reliability function remains non-zero for large enough signal-to-noise ratios",
        "prob": 0.205
    }, {
        "ID": 5037,
        "phrase": " x \u2022 \u03bb t for all x \u2032 \u2208 c \\ {x} be the region in the llr space where the ml decoder decides in favor of the codeword x",
        "prob": 0.5916666666666667
    }, {
        "ID": 5037,
        "phrase": " the decision region d ml x of a codeword x \u2208 c shares a facet with the decision region d ml 0 of the zero codeword if and only if x \u2208 m(c)",
        "prob": 0.7562500000000001
    }, {
        "ID": 5046,
        "phrase": " then we show that this algorithm always outputs the ml codeword of y",
        "prob": 0.51
    }, {
        "ID": 5046,
        "phrase": " we have to show that the algorithm always outputs the ml codeword x and re{y\u2022 xh }, which is potentially required for the higher stage of the decoder",
        "prob": 0.3
    }, {
        "ID": 5076,
        "phrase": " let b ml and c ml be the counting processes for the arrival of globally innovative packets and candidate packets, respectively, on arc (i l , i l+1 ) for path p m ",
        "prob": 0.45000000000000007
    }, {
        "ID": 5076,
        "phrase": " let q (nm) ml (\u03c4 ) be the number of packets queued for service at i l at time \u03c4 when there are n m jobs initially present at node s",
        "prob": 0.25625
    }, {
        "ID": 5118,
        "phrase": " given the formulation in (  22 )-(  27 ) and neglecting scalar energy normalization factors for simplicity, the ml decision metric becomes t = \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 s 1 x 3 \u2212 s 2 x 4 ) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x 2 + s 2 x 3 \u2212 s 1 x 4 ) 2 \u03c3 2 1 \u2212 (\u1ef9 3 \u2212 r 3 x 3 ) 2 \u03c3 2 1 r 3 \u2212 (\u1ef9 4 \u2212 r 3 x 4 ) 2 \u03c3 2 1 r 3 (32) the ml demodulator finds the maximum value of the metric over all possible values of the sequence x r ",
        "prob": 0.8039999999999999
    }, {
        "ID": 5118,
        "phrase": " the final ml estimate is then given as x = arg max x 3 ,x 4 \u2208\u03c9 2 x \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x1 (x 3 , x 4 ) \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x2 (x 3 , x 4 ) \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212c 3 (x 3 , x 4 )} (37) this implies that the number of points that has to be searched in this formulation to find the true ml estimator is m 2 (with two slicing operations per searched point) and not m 4 ",
        "prob": 0.8374999999999999
    }, {
        "ID": 5119,
        "phrase": " given the formulation in (  22 )-(  27 ) and neglecting scalar energy normalization factors for simplicity, the ml decision metric becomes t = \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 s 1 x 3 \u2212 s 2 x 4 ) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x 2 + s 2 x 3 \u2212 s 1 x 4 ) 2 \u03c3 2 1 \u2212 (\u1ef9 3 \u2212 r 3 x 3 ) 2 \u03c3 2 1 r 3 \u2212 (\u1ef9 4 \u2212 r 3 x 4 ) 2 \u03c3 2 1 r 3 (32) the ml demodulator finds the maximum value of the metric over all possible values of the sequence x r ",
        "prob": 0.844
    }, {
        "ID": 5119,
        "phrase": " the final ml estimate is then given as x = arg max x 3 ,x 4 \u2208\u03c9 2 x \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x1 (x 3 , x 4 ) \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x2 (x 3 , x 4 ) \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212c 3 (x 3 , x 4 )} (37) this implies that the number of points that has to be searched in this formulation to find the true ml estimator is m 2 (with two slicing operations per searched point) and not m 4 ",
        "prob": 0.8374999999999999
    }, {
        "ID": 5120,
        "phrase": " given the formulation in (20)-(25) and neglecting scalar energy normalization factors for simplicity, the ml decision metric becomes t (x r ) = \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 s 1 x 3 \u2212 s 2 x 4 ) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x 2 + s 2 x 3 \u2212 s 1 x 4 ) 2 \u03c3 2 1 \u2212 (\u1ef9 3 \u2212 r 3 x 3 ) 2 \u03c3 2 1 r 3 \u2212 (\u1ef9 4 \u2212 r 3 x 4 ) 2 \u03c3 2 1 r 3 (27) the ml demodulator finds the maximum value of the metric over all possible values of the sequence x r ",
        "prob": 0.7639999999999999
    }, {
        "ID": 5120,
        "phrase": " the final ml estimate is then given as { x1 ( x3 , x4 ), x2 ( x3 , x4 ), x3 , x4 } = arg max x 3 ,x 4 \u2208\u03c9 2 x \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x1 (x 3 , x 4 ) \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x2 (x 3 , x 4 ) \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 c 3 (x 3 , x 4 ) (31) this implies that the number of points that has to be searched in this formulation to find the true ml estimator is m 2 (with two slicing operations per searched point) and not m 4 ",
        "prob": 0.8374999999999999
    }, {
        "ID": 5210,
        "phrase": " maximum likelihood the ml estimator maximizes the joint pdf in  (5) ",
        "prob": 0.3727272727272727
    }, {
        "ID": 5334,
        "phrase": " a soft-decision ml decoding algorithm was proposed by vardy and be'ery  [5] ",
        "prob": 0.3416666666666666
    }, {
        "ID": 5401,
        "phrase": " at the receiver the maximum likelihood decision reads (see  [4] ) \u03c6 ml : x \u2212 \u03c1 n k \u03c6 ml h f \u2264 x \u2212 \u03c1 n k \u03c6h f \u2200 \u03c6\u2208c (9) whereas x = \u03c1 n k \u03c8h + w is the received signal",
        "prob": 0.6733333333333333
    }, {
        "ID": 5401,
        "phrase": " so finally we can consider codes c g \u2282 n k g k,n always as discrete subsets of n k v k,n and the maximum likelihood criterion for the unknown channel receiver reads now (  [4] ) \u03c6 ml : \u03c1 n k \u03c6 \u2020 ml x f \u2265 \u03c1 n k \u03c6 \u2020 x f \u2200 \u03c6\u2208c (20) whereas x = \u03c1 n k \u03c8h + w is the received signal",
        "prob": 0.5458333333333333
    }, {
        "ID": 5402,
        "phrase": " at the receiver the maximum likelihood decision reads (see  [2] ) \u03c6 ml = arg min \u2200\u03c6\u2208c x \u2212 \u03c1 t nt \u03c6h f ( 11 ) whereas x = \u03c1 t nt \u03c8h +w is the received signal",
        "prob": 0.7705882352941176
    }, {
        "ID": 5402,
        "phrase": " throwing away the noise term allows a formulation of a code design criterion in the signal space v c nt,t , induced from the ml receiver: the maximization of the pairwise distances d, given by d(\u03c6, \u03c8) := \u2206 f = nt i=1 \u03c3 2 i (\u2206) = \u03c3 (12) where we have set \u2206 := \u03c6 \u2212 \u03c8 (13) \u03c3 := (\u03c3 1 , ",
        "prob": 0.44400000000000006
    }, {
        "ID": 5402,
        "phrase": " we consider codes c g \u2282 g c nt,t always as discrete subsets of v c nt,t and the maximum likelihood criterion for the noncoherent channel receiver reads now (  [2] ) \u03c6 ml = arg max \u2200\u03c6\u2208c \u03c1 t nt \u03c6 \u2020 x f ( 25 ) whereas x = \u03c1 t nt \u03c8h +w is the received signal",
        "prob": 0.5807692307692307
    }, {
        "ID": 5402,
        "phrase": " , \u03c3 nt ) , \u03c3 i := \u03c3 i (\u2206) = cos \u03d1 i (28) the ml criterion demands the maximization of the pairwise distances d(\u03c6, \u03c8) := n t \u2212 \u2206 2 f = tr 1 \u2212 \u2206 \u2020 \u2206 = nt i=1 1 \u2212 \u03c3 2 i = nt i=1 sin 2 \u03d1 i ( 29 ) formally d is defined on all of v c nt,t , but independent of the choice of the representing n t -frame as already indicated",
        "prob": 0.29583333333333334
    }, {
        "ID": 5404,
        "phrase": " then we have that, if x \u2208 c, the region d ml x in the llr space where the ml decoder decides in favor of the codeword x,  1  shares a facet with the decision region d ml zero codeword if and only if x \u2208 m(c)",
        "prob": 0.7666666666666666
    }, {
        "ID": 5404,
        "phrase": " indeed, the significance of the hamming weight w h (x) of a minimal codeword x for ml decoding is the following: it can be shown that the squared euclidean distance from the point +1 in signal space, corresponding to the codeword 0, to the boundary plane \u03bb \u2208 r n | x \u2022 \u03bb t = 0 of the decision region of 0 under ml decoding is w h (x)",
        "prob": 0.325
    }, {
        "ID": 5645,
        "phrase": " the ml decoder makes a joint decision on both these codes using the three received vectors y 1 , y 2 , y 3 ",
        "prob": 0.22142857142857142
    }, {
        "ID": 5646,
        "phrase": " the ml decoder makes a joint decision on both these codes using the three received vectors y 1 , y 2 , y 3 ",
        "prob": 0.2928571428571428
    }, {
        "ID": 5728,
        "phrase": " a second approach is to consider the soft value of the llr which forms a sufficient statistics of ml decoding",
        "prob": 0.20666666666666667
    }, {
        "ID": 5728,
        "phrase": " the 2-level, 4-level, 8-level and un-quantized lower bounds on the threshold refer to ml decoding, and are based on [2, theorem 2], [26, corollaries 3",
        "prob": 0.39444444444444443
    }, {
        "ID": 5738,
        "phrase": " for given data set x and likelihood function f (x|\u03b2), rissanen defined in  [ris00]  the normalized maximum likelihood (nml) marginal density m n m l (x) by: m n m l (x) def = f (x|\u03b2 * (x)) c n m l where \u03b2 * is the ml estimator and c n m l def = z\u2208y f (z|\u03b2 * (z)) dz",
        "prob": 0.29583333333333334
    }, {
        "ID": 5789,
        "phrase": " the suboptimal controller just searches for the ml path through the trellis",
        "prob": 0.41
    }, {
        "ID": 5789,
        "phrase": " once an ml path has been identified, a control signal is applied based on the bin estimate at the end of the ml path",
        "prob": 0.43571428571428567
    }, {
        "ID": 5789,
        "phrase": " the probability that the ml path diverges from the true path at depth d is no more than 2 \u2212dner(r) ",
        "prob": 0.425
    }, {
        "ID": 5817,
        "phrase": " they provide experimental evidence that practically ml decoding is achieved for the  (8, 4)  hamming code with five rounds of the tail-biting trellis",
        "prob": 0.22777777777777775
    }, {
        "ID": 5817,
        "phrase": " propose the use of the a * algorithm for ml decoding of block codes on their conventional trellises and report significant experimental gains in decoding complexity for signal to noise ratios ranging from 5 db to 8 db",
        "prob": 0.16399999999999998
    }, {
        "ID": 5817,
        "phrase": " l in increasing order; if the lowest metric is that of a codeword path then output that path as the ml path and return, else go to next step",
        "prob": 0.7947368421052632
    }, {
        "ID": 5817,
        "phrase": " recall that this has to be an underestimate of the path length from node u to the final node if the ml path is to be output",
        "prob": 0.5785714285714286
    }, {
        "ID": 5817,
        "phrase": " we will prove later that this is indeed an underestimate and therefore guarantees that the ml path is output on termination",
        "prob": 0.5071428571428571
    }, {
        "ID": 5817,
        "phrase": "2, and the fact that all estimates on trellises on which execution is suspended are underestimates, assures us that if the final node is reached in any subtrellis then this is indeed the shortest path in the tail-biting trellis or in other words the ml codeword",
        "prob": 0.8039999999999999
    }, {
        "ID": 5817,
        "phrase": "4: during the second phase, once a critical node is closed in a subtrellis, the algorithm goes on to reach the final node in that subtrellis without switching trellises, and outputs an ml path",
        "prob": 0.7772727272727272
    }, {
        "ID": 5817,
        "phrase": "9: the algorithm will not close any node whose metric exceeds the cost of the ml path",
        "prob": 0.6230769230769231
    }, {
        "ID": 5817,
        "phrase": " since the current metric is a lower bound on the cost of the ml path the lemma follows",
        "prob": 0.43571428571428567
    }, {
        "ID": 5817,
        "phrase": " since the space explored by the algorithm, namely the space of semicodewords and codewords is a vector space, we can analyse the algorithm assuming that the ml codeword is the all 0 codeword",
        "prob": 0.605
    }, {
        "ID": 5817,
        "phrase": "12: assume the all 0 codeword is the ml codeword",
        "prob": 0.2625
    }, {
        "ID": 5817,
        "phrase": "9 it will never close the start node of any trellis t j whose initial metric exceeds that of the ml codeword, which implies that the all-0 codeword is more likely than the semicodeword survivor in t j , thus implying equation  6 ",
        "prob": 0.7958333333333333
    }, {
        "ID": 5817,
        "phrase": " since a node is closed by at most one subtrellis, it is conceivable that a shared node that is on the ml path is closed by a subtrellis that does not contain the ml codeword",
        "prob": 0.7833333333333333
    }, {
        "ID": 5817,
        "phrase": " proof: let us assume that the all-zero codeword is the ml codeword but that it is not the output of the approximate algorithm approx1",
        "prob": 0.5352941176470588
    }, {
        "ID": 5817,
        "phrase": "4, t i would have gone on to win in the exact algorithm and therefore the all-zero codeword could not have been the ml codeword giving a contradiction",
        "prob": 0.5611111111111111
    }, {
        "ID": 5817,
        "phrase": " since 0 is the ml codeword m i (f i ) > m 0 (f 0 ) implying that m i (a) > m 0 (f 0 )",
        "prob": 0.3875
    }, {
        "ID": 5817,
        "phrase": " on the average, the number of updates to get the exact ml result requires fewer than two computations at each node of the tail-biting trellis at all values of signal to noise ratio, one in the first pass and one in the second",
        "prob": 0.5807692307692307
    }, {
        "ID": 5817,
        "phrase": " we also display the bit error-rate performance of the approximate algorithms closing nodes at most once for the first approximation approx1, and at most twice for the second approximation, approx2 in figures  6, 7, 8  and and find that there is virtually no difference in the bit error rates for the second approximation and the exact ml algorithm",
        "prob": 0.503125
    }, {
        "ID": 5817,
        "phrase": " discussion and conclusions we have proposed an exact algorithm for ml decoding on tail-biting trellises and also experimented on two approximate variants",
        "prob": 0.5055555555555555
    }, {
        "ID": 5817,
        "phrase": " the approximate algorithm is analyzed, and the conditions under which its output is different from the ml output are deduced",
        "prob": 0.5461538461538461
    }, {
        "ID": 5818,
        "phrase": " l in increasing order; if the lowest metric is that of a codeword path then output that path as the ml path and return, else go to next step",
        "prob": 0.7421052631578947
    }, {
        "ID": 5818,
        "phrase": " recall that this has to be an underestimate of the path length from node u to the final node if the ml path is to be output",
        "prob": 0.65
    }, {
        "ID": 5818,
        "phrase": " we will prove later that this is indeed an underestimate and therefore guarantees that the ml path is output on termination",
        "prob": 0.5785714285714286
    }, {
        "ID": 5818,
        "phrase": "2, and the fact that all estimates on trellises on which execution is suspended are underestimates, assures us that if the final node is reached in any subtrellis then this is indeed the shortest path in the tail-biting trellis or in other words the ml codeword",
        "prob": 0.7639999999999999
    }, {
        "ID": 5818,
        "phrase": "4: during the second phase, once a critical node is closed in a subtrellis, the algorithm goes on to reach the final node in that subtrellis without switching trellises, and outputs an ml path",
        "prob": 0.7772727272727272
    }, {
        "ID": 5818,
        "phrase": "9: the algorithm will not close any node whose metric exceeds the cost of the ml path",
        "prob": 0.7000000000000001
    }, {
        "ID": 5818,
        "phrase": " since the current metric is a lower bound on the cost of the ml path the lemma follows",
        "prob": 0.5071428571428571
    }, {
        "ID": 5818,
        "phrase": " since the space explored by the algorithm, namely the space of semicodewords and codewords is a vector space, we can analyse the algorithm assuming that the ml codeword is the all 0 codeword",
        "prob": 0.5549999999999999
    }, {
        "ID": 5818,
        "phrase": "12: assume the all 0 codeword is the ml codeword",
        "prob": 0.5125000000000001
    }, {
        "ID": 5818,
        "phrase": "9 it will never close the start node of any trellis t j whose initial metric exceeds that of the ml codeword, which implies that the all-0 codeword is more likely than the semicodeword survivor in t j , thus implying equation  6 ",
        "prob": 0.8374999999999999
    }, {
        "ID": 5818,
        "phrase": " since a node is closed by at most one subtrellis, it is conceivable that a shared node that is on the ml path is closed by a subtrellis that does not contain the ml codeword",
        "prob": 0.5611111111111112
    }, {
        "ID": 5818,
        "phrase": " proof: let us assume that the all-zero codeword is the ml codeword but that it is not the output of the approximate algorithm approx1",
        "prob": 0.711764705882353
    }, {
        "ID": 5818,
        "phrase": "4, t i would have gone on to win in the exact algorithm and therefore the all-zero codeword could not have been the ml codeword giving a contradiction",
        "prob": 0.5611111111111111
    }, {
        "ID": 5818,
        "phrase": " on the average, the number of updates to get the exact ml result requires fewer than two computations at each node of the tail-biting trellis at all values of signal to noise ratio, one in the first pass and one in the second",
        "prob": 0.6192307692307693
    }, {
        "ID": 5818,
        "phrase": " we also display the bit error-rate performance of the approximate algorithms closing nodes at most once for the first approximation approx1, and at most twice for the second approximation, approx2 in figures  6, 7, 8  and and find that there is virtually no difference in the bit error rates for the second approximation and the exact ml algorithm",
        "prob": 0.47187500000000004
    }, {
        "ID": 5818,
        "phrase": " thus we get virtually ml performance for an explicit linearly bounded update complexity at all values of signal to noise ratio",
        "prob": 0.2833333333333333
    }, {
        "ID": 5818,
        "phrase": " discussion and conclusions we have proposed an exact algorithm for ml decoding on tail-biting trellises and also experimented on two approximate variants",
        "prob": 0.5055555555555555
    }, {
        "ID": 5818,
        "phrase": " the approximate algorithm is analyzed, and the conditions under which its output is different from the ml output are deduced",
        "prob": 0.5461538461538461
    }, {
        "ID": 5908,
        "phrase": " these two properties motivate the use of an adaptive approach in lp decoding which can be summarized as follows: given a set of constraints that describe a code, start the lp decoding with a few of them, and sequentially and adaptively add more of the constraints to the problem until either the ml codeword is found or no further \"useful\" constraint exists",
        "prob": 0.23823529411764705
    }, {
        "ID": 5934,
        "phrase": " if the pseudo-codeword obtained by the lp decoder has only integral entries then it must be a codeword, in fact it is the codeword given back by ml decoder",
        "prob": 0.531578947368421
    }, {
        "ID": 5935,
        "phrase": " if the pseudo-codeword obtained by the lp decoder has only integral entries then it must be a codeword, in fact it is the codeword given back by ml decoder",
        "prob": 0.531578947368421
    }, {
        "ID": 5953,
        "phrase": " in particular, although the approximate algorithm proposed in  [11] , achieves performance close to an ideal ml decoder, it has a worst case time complexity of o(m log m), where m is the number of nodes in the tbt",
        "prob": 0.2652173913043478
    }, {
        "ID": 5953,
        "phrase": " theorem 2: assume the 0 codeword is the ml codeword corresponding to the path s 1 \u2212f 1 in the tail biting trellis",
        "prob": 0.5071428571428571
    }, {
        "ID": 5953,
        "phrase": " to yield the left inequality, first observe that the first phase of the algorithm does an ml decoding on the semi-codeword space",
        "prob": 0.3588235294117647
    }, {
        "ID": 5953,
        "phrase": " any s k \u2212 f j path p in the tail-biting trellis with k = j and l(s k , f j ) \u2264 l(s 1 , f 1 ) corresponds to a semi-codeword that an ideal ml decoder operating on the space of semicodewords will prefer to the all zero codeword",
        "prob": 0.5954545454545455
    }, {
        "ID": 5953,
        "phrase": " the performance of the above codes is compared with that of the ideal ml decoder two phase algorithm exact ml decoding algorithm in  [11] ",
        "prob": 0.41764705882352937
    }, {
        "ID": 5953,
        "phrase": " a necessary condition for the output of the algorithm to differ from the output of the ideal ml decoder is deduced and simulation results on an awgn channel using tail-biting trellises for two rate 1/2 convolutional codes with memory 4 and 6 respectively, are reported",
        "prob": 0.4517241379310345
    }, {
        "ID": 6100,
        "phrase": " let \u266f be a symbol not belonging to ml + ",
        "prob": 0.2625
    }, {
        "ID": 6100,
        "phrase": " , n are compositions of boxes in ml + and a 1 , ",
        "prob": 0.3
    }, {
        "ID": 6109,
        "phrase": " ( 92 ) the ml rule is: decide in favor of s i , if and only if p n (r/s i ) \u2265 p n (r/s k ), \u2200 i = k",
        "prob": 0.21000000000000002
    }, {
        "ID": 6165,
        "phrase": ", when the lp decoder outputs a codeword, it is guaranteed to be the ml codeword",
        "prob": 0.4636363636363636
    }, {
        "ID": 6175,
        "phrase": " the ml receiver for x \u2295 is given by x \u2295;ml = arg min \u2200 x\u2295 ||y \u2212 h \u2295 x \u2295 || 2 ",
        "prob": 0.5666666666666667
    }, {
        "ID": 6176,
        "phrase": " the ml receiver for x \u2295 is given by x \u2295;ml = arg min x \u2295 ||y \u2212 h \u2295 x \u2295 || 2 ",
        "prob": 0.4555555555555555
    }, {
        "ID": 6176,
        "phrase": " guarantees that the coset containing the ml lattice point is promoted as the most likely coset-when iterations start",
        "prob": 0.6312500000000001
    }, {
        "ID": 6177,
        "phrase": " the ml algorithm searches all possible valid codewords then selects the one that maximizes the likelihood; ml's optimal performance serves as benchmark",
        "prob": 0.2833333333333333
    }, {
        "ID": 6177,
        "phrase": " this guarantees that the coset containing the ml lattice point is promoted as the most likely cosetwhen iterations start",
        "prob": 0.6733333333333333
    }, {
        "ID": 6190,
        "phrase": "  [12] ) let c be a binary linear code of length n and for x \u2208 c let d ml x \u03bb \u2208 r n x \u2032 , \u03bb x, \u03bb for all x \u2032 \u2208 c \\ {x} be the region in the llr space where the ml decoder decides in favor of the codeword x",
        "prob": 0.3736842105263158
    }, {
        "ID": 6190,
        "phrase": "  3  then the decision region d ml x of a codeword x \u2208 c shares a facet 4 with the decision region d ml 0 of the zero codeword if and only if x is a minimal codeword",
        "prob": 0.711764705882353
    }, {
        "ID": 6193,
        "phrase": " in this case, ml estimates of the parameters are given by \u03b8 s (x s ) = log \u00b5 s (x s ), with all of the coupling terms \u03b8 st (x s , x t ) equal to zero",
        "prob": 0.34
    }, {
        "ID": 6308,
        "phrase": " this technique estimates the ml parameters from the sequence x n and then quantizes them onto a grid of points",
        "prob": 0.3153846153846154
    }, {
        "ID": 6308,
        "phrase": " this means that if the ml estimates of two letters separated by at least one grid spacing unit are within the boxes defined in (45), then these ml estimates are still ordered in the same order as the original letters",
        "prob": 0.42083333333333334
    }, {
        "ID": 6308,
        "phrase": " hence, the only case where ml estimates of two different letters may not be in the original order of the letters is when \u03c4 b j = \u03c4 b i for j > i",
        "prob": 0.4066666666666666
    }, {
        "ID": 6308,
        "phrase": " if \u03b8i < \u03b8 k , \u03b8 k \u2212 \u03b8k = \u03b8 k \u2212 \u03b8i + \u03b8i \u2212 \u03b8k \u2265 \u2206 (\u03c4 b k ) 2 , ( 50 ) where the inequality is, again, by definition of the case, and by the assumption that \u03b8i is the maximum component of the ml estimate of \u03b8",
        "prob": 0.3416666666666666
    }, {
        "ID": 6308,
        "phrase": " for a given sequence with k distinct symbols, we find the best k-dimensional pattern probability vector \u03c8 (\u03b8), which is the vector that gives the kth-order ml probability for the pattern of the sequence",
        "prob": 0.36818181818181817
    }, {
        "ID": 6308,
        "phrase": " (furthermore, the actual ml estimate of a pattern may contain more letters than those actually observed",
        "prob": 0.2928571428571428
    }, {
        "ID": 6308,
        "phrase": " the last term is the cost of coding the pattern using the quantized ml estimates in \u03d5",
        "prob": 0.3153846153846154
    }, {
        "ID": 6308,
        "phrase": " the k-dimensional ml estimate is not smaller than the probability w",
        "prob": 0.34444444444444444
    }, {
        "ID": 6308,
        "phrase": " these two costs are the cost of coding \u03d5, and the cost of using the quantized version \u03d5 of the k-dimensional pattern ml probability estimator \u03c8 (\u03b8) instead of using the actual k-dimensional pattern ml probability estimator",
        "prob": 0.444
    }, {
        "ID": 6308,
        "phrase": " however, the cost of quantizing the pattern ml estimator, which is shown next, will overwhelm this cost for large k",
        "prob": 0.47333333333333333
    }, {
        "ID": 6308,
        "phrase": " for the sake of simple notation, let \u03c8 \u25b3 = \u03c8 (\u03b8) denote the pattern ml probability parameter vector from this point on to the end of the proof of the redundancy of the code for the first region",
        "prob": 0.205
    }, {
        "ID": 6308,
        "phrase": "2 let \u03c8 be the k-dimensional pattern ml estimator obtained from x n for k \u2264 \u221a n 1\u2212\u03b5 , let \u03d5 be its quantized version, and let \u03c3 be a permutation vector such that \u03c8(\u03c3) \u2208 a",
        "prob": 0.6937500000000001
    }, {
        "ID": 6308,
        "phrase": " one can show that quantization of the ml parameters into the vector \u03d5 whose components are on the grid points of \u03c4 defined in (68) can result in representation cost of o n (1+\u03b5)/3 even for large k's",
        "prob": 0.40499999999999997
    }, {
        "ID": 6308,
        "phrase": " consider representing the quantized ml pattern probability parameters of \u03d5 as follows: for each of the first \u03b2 grid points in \u03c4 use up to (1 + \u03b5) log k bits to represent how many letters have probabilities quantized in \u03d5 to this grid point",
        "prob": 0.44400000000000006
    }, {
        "ID": 6308,
        "phrase": " from (95) we know that the representation of a quantized version of the pattern ml estimator whose components are quantized as proposed in section 7 can cost o n (1+\u03b5)/3 bits for every k, including all large values of k up to k = n",
        "prob": 0.41363636363636364
    }, {
        "ID": 6308,
        "phrase": "7), will give the exact same ml estimator \u03b8i as the one obtained from x n ",
        "prob": 0.4555555555555555
    }, {
        "ID": 6308,
        "phrase": " in the third case, we also assume that a nonzero ml estimator must satisfy \u03b8i \u2265 1/n to obtain the bound",
        "prob": 0.2928571428571428
    }, {
        "ID": 6308,
        "phrase": " let \u03b8 be the ml estimator of \u03b8 from x n ",
        "prob": 0.15714285714285717
    }, {
        "ID": 6308,
        "phrase": " \u03c8 (\u03b8), thus contradicting the fact that \u03c8 (\u03b8) is the pattern ml probability vector",
        "prob": 0.4636363636363636
    }, {
        "ID": 6308,
        "phrase": " otherwise, \u03c8 (\u03b8) \u2208 a, and cannot be the pattern ml estimate, using lemma 7",
        "prob": 0.51
    }, {
        "ID": 6325,
        "phrase": "01 3(l + 1)/2 n 3l \u2264 l 4l m n 3 2 (1\u2212 1 l ) l \u2264 ml 4 n 3 2 (1\u2212 1 l ) l ",
        "prob": 0.22000000000000003
    }, {
        "ID": 6340,
        "phrase": " given the formulation in (  23 )-(  28 ) and neglecting scalar energy normalization factors to simplify the notation, the ml decision metric becomes t (x r ) = \u1ef9r \u2212 rx r 2 = (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 s 1 x 3 \u2212 s 2 x 4 ) 2 \u03c3 2 1 + (\u1ef9 2 \u2212 \u03c3 2 1 x 2 + s 2 x 3 \u2212 s 1 x 4 ) 2 \u03c3 2 1 + (\u1ef9 3 \u2212 r 3 x 3 ) 2 \u03c3 2 1 r 3 + (\u1ef9 4 \u2212 r 3 x 4 ) 2 \u03c3 2 1 r 3 (35) the ml demodulator finds the maximum value of the metric over all possible values of the sequence x r ",
        "prob": 0.7444444444444444
    }, {
        "ID": 6340,
        "phrase": " the final ml estimate is then given as {x 1 (x 3 , x4 ), x2 (x 3 , x4 ), x3 , x4 } = arg min x 3 ,x 4 \u2208\u03c9 2 x (\u1ef9 1 \u2212 \u03c3 2 1 x1 (x 3 , x 4 ) \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 + (\u1ef9 2 \u2212 \u03c3 2 1 x2 (x 3 , x 4 ) \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 + c 3 (x 3 , x 4 ) (39) this implies that the number of points that has to be searched in this formulation to find the true ml estimator is m 2 (with two slicing operations per searched point)",
        "prob": 0.8304347826086956
    }, {
        "ID": 6435,
        "phrase": " continuing from this point, we have ( )  - \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ed + + - + + \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e8 \u00ee \u00ed k ml m e k m m l l m l m m l l 2 1 2 1 1 2 2 1 1 1 2 1 1 2 2 2 2 2 2 2 2 s b b b b b b b \u00e2 a a a a a a a \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 - + - ( ) + ( ) \u00ea \u00eb \u00e1 \u00e8 \u00ee \u00ed \u00ed \u2022 \u00fa k y k ml m e dx p l l 1 1 1 2 1 2 1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 - + - ( ) + ( ) \u00ea \u00eb \u00e1 \u00e8 \u00ee \u00ed \u00ed \u2022 \u00fa k y k ml m e dx l l 1 1 1 2 1 2 1 2 2 ln \u015d b b a a \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u02c6( ) \u2022 \u00fa p y dy y 0 ",
        "prob": 0.23846153846153847
    }, {
        "ID": 6618,
        "phrase": "2) where \u03b8j (x n ) and \u03b8i (w n ) are the ml estimates of \u03b8 j and \u03b8 i from x n and w n , respectively",
        "prob": 0.15714285714285717
    }, {
        "ID": 6687,
        "phrase": " (4) under this model, network inference consists in computing the maximum likelihood (ml) estimates, ( a ml , \u03c0 ml ) = arg max a,\u03c0 log p [y|a, \u03c0]",
        "prob": 0.33888888888888885
    }, {
        "ID": 6687,
        "phrase": " (5) with the ml estimates in hand, we may determine the most likely permutation for each cooccurrence observation according to (a ml , \u03c0 ml ), and obtain a feasible reconstruction using our procedure for ordered observations described above",
        "prob": 0.37916666666666665
    }, {
        "ID": 6779,
        "phrase": " applying the ml criterion and the normality of the noise, we can obtain the ml channel estimate, which is given by \u00e2 = arg max a p (r|a) = arg min a r \u2212 sa = (s t s) \u22121 s t r = r \u22121 y, (3) where r = s t s and y = s t r",
        "prob": 0.39444444444444443
    }, {
        "ID": 6876,
        "phrase": " in this special case the sdr will always have rank one solutions which are unique as long as the ml problem has a unique solution  [22] ",
        "prob": 0.25625
    }, {
        "ID": 6969,
        "phrase": " if the code is ml decoded, an error occurs if for some m \u2032 = m d m (x m \u2032 , y) \u2264 d m (x m , y) ",
        "prob": 0.23333333333333334
    }, {
        "ID": 7144,
        "phrase": " the question is thus \"how many samples of h t (x n ) should be taken?\" the trivial answer, which we exclude, is to fix some number r of samples and use the corresponding map or ml estimates",
        "prob": 0.355
    }, {
        "ID": 7232,
        "phrase": " we begin with some simple observations: (i) ml decoding corresponds to finding the vertex in the relaxed polytope that has the highest likelihood and integral coordinates; and (ii) standard lp decoding succeeds if and only if the ml codeword has the highest likelihood over all pseudocodewords",
        "prob": 0.4111111111111111
    }, {
        "ID": 7232,
        "phrase": " this motivates facet-guessing: suppose that there exists only one fractional pseudocodeword x pc 1 that has higher likelihood than the ml codeword x cw ",
        "prob": 0.5941176470588235
    }, {
        "ID": 7232,
        "phrase": " we now provide a characterization of when the efg algorithm fails: lemma 6: the exhaustive facet-guessing algorithm fails to find the ml codeword c \u21d0\u21d2 every facet f \u2208 a c contains a fractional pseudocodeword with likelihood greater than c",
        "prob": 0.724
    }, {
        "ID": 7232,
        "phrase": " also, since c is the ml codeword, there can be no other integral codeword with higher likelihood in the list, and therefore the algorithm will output c",
        "prob": 0.5399999999999999
    }, {
        "ID": 7232,
        "phrase": " by using this characterization and theorem 1 for expander codes, we obtain the following result: corollary 1: for expander codes, the efg algorithm will always succeed if there are c 1 fractional pseudocodewords with likelihood higher than the ml codeword and c 1 < \u03b3cw \u03b3pc ",
        "prob": 0.5592592592592592
    }, {
        "ID": 7232,
        "phrase": " even though there is a linear number of facets that contain the ml codeword, we show that it will require a constant number of fractional pseudocodewords to cover them",
        "prob": 0.32105263157894737
    }, {
        "ID": 7232,
        "phrase": " while the lp decoder succeeds only if the ml codeword has the highest likelihood over all pseudocodewords, we prove that for expander codes the proposed algorithm succeeds even with a constant number of pseudocodewords of higher likelihood",
        "prob": 0.5458333333333333
    }, {
        "ID": 7233,
        "phrase": " this motivates facet-guessing: suppose that there exists only one fractional pseudocodeword x pc 1 that has higher likelihood than the ml codeword x cw ",
        "prob": 0.5941176470588235
    }, {
        "ID": 7233,
        "phrase": " we now provide a characterization of when the efg algorithm fails: lemma 6: the exhaustive facet-guessing algorithm fails to find the ml codeword c \u21d0\u21d2 every facet f \u2208 a c contains a fractional pseudocodeword with likelihood greater than c",
        "prob": 0.724
    }, {
        "ID": 7233,
        "phrase": " also, since c is the ml codeword, there can be no other integral codeword with higher likelihood in the list, and therefore the algorithm will output c",
        "prob": 0.5399999999999999
    }, {
        "ID": 7233,
        "phrase": " by using this characterization and theorem 1 for expander codes, we obtain the following result: corollary 1: for expander codes, the efg algorithm will always succeed if there are c 1 fractional pseudocodewords with likelihood higher than the ml codeword and c 1 < \u03b3cw \u03b3pc ",
        "prob": 0.44814814814814813
    }, {
        "ID": 7233,
        "phrase": " while the lp decoder succeeds only if the ml codeword has the highest likelihood over all pseudocodewords, we prove that for expander codes the proposed algorithm succeeds even with a constant number of pseudocodewords of higher likelihood",
        "prob": 0.5875
    }, {
        "ID": 7311,
        "phrase": " since the codewords depend on the feedback, two different messages can have the same codeword for two different outputs, therefore the regular ml arg max x n p (y n |x n ) cannot be used for decoding the message",
        "prob": 0.2652173913043478
    }, {
        "ID": 7393,
        "phrase": ", x k | \u03b8) \u2212 \u03be(n + log |r|) (31) since the second term in (31) does not depend on \u03b8, the rce estimate of r \u03b8 will be identical to the ml estimate",
        "prob": 0.36428571428571427
    }, {
        "ID": 7486,
        "phrase": " from  (7) , the ml estimate \u015d of s is given by \u015d = arg min s\u2208c (y d \u2212 wx)r \u22121 (y d \u2212 wx) h = arg min s\u2208c \u22122\u211c wxr \u22121 y h d + wxr \u22121 x h w h , ( 9 ) where c is the set containing all the possible symbol vector s and it depends on the modulation scheme of s n ",
        "prob": 0.6565217391304349
    }, {
        "ID": 7487,
        "phrase": " from  (7) , the ml estimate \u015d of s is given by \u015d = arg min s\u2208c (y d \u2212 wx)r \u22121 (y d \u2212 wx) h = arg min s\u2208c \u22122\u211c wxr \u22121 y h d + wxr \u22121 x h w h , ( 9 ) where c is the set containing all the possible symbol vector s and it depends on the modulation scheme of s n ",
        "prob": 0.7
    }, {
        "ID": 7539,
        "phrase": " run the ml algorithm on q using a set s of independent samples from p, where s = m",
        "prob": 0.3727272727272727
    }, {
        "ID": 7736,
        "phrase": " decoding of the concatenated code to decode y with respect to the inner code, we use a maximum likelihood (ml) decoder for the code b to find the ml estimates bt j = arg max b\u2208b p (b t |y t j ) (26) for all columns of y ",
        "prob": 0.364
    }, {
        "ID": 7737,
        "phrase": " decoding of the concatenated code to decode y with respect to the inner code, we use a maximum likelihood (ml) decoder for the code b to find the ml estimates bt j = arg max b\u2208b p (b t |y t j ) (26) for all columns of y ",
        "prob": 0.364
    }, {
        "ID": 7850,
        "phrase": " this can be implemented using either an ml decoder or a sequential decoder from  [23] ",
        "prob": 0.3727272727272727
    }, {
        "ID": 7963,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.35000000000000003
    }, {
        "ID": 7965,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.35000000000000003
    }, {
        "ID": 8403,
        "phrase": " the algorithm then searches for the code path with the minimum path metric over c \u223c * , which, from equation (  6 ), is exactly the code path labeled by the permuted ml codeword",
        "prob": 0.6368421052631579
    }, {
        "ID": 8404,
        "phrase": " the algorithm then searches for the code path with the minimum path metric over c \u223c * , which, from equation  (12) , is exactly the code path labelled by the permuted ml codeword",
        "prob": 0.531578947368421
    }, {
        "ID": 8686,
        "phrase": " using the memoryless property of the channel, it can be seen that the maximum likelihood (ml) codeword is y ml = argmin y\u2208c n i=1 \u03b3 i y i ",
        "prob": 0.31875
    }, {
        "ID": 8687,
        "phrase": " using the memoryless property of the channel, it can be seen that the maximum likelihood (ml) codeword is y ml = arg min y\u2208c n i=1 \u03b3 i y i ",
        "prob": 0.38125
    }, {
        "ID": 8907,
        "phrase": " to do ml decoding, we first make a hard decision on the received sequence r \u2032 ",
        "prob": 0.425
    }, {
        "ID": 8907,
        "phrase": " if the max-flow value is equal to the sum of the capacities of the edges from s to u \u0169, then declare x \u2032 as the ml sequence",
        "prob": 0.2928571428571428
    }, {
        "ID": 8907,
        "phrase": " lemma 6: if the max-flow attains the sum of edge capacities from the source s to u \u0169 for some a \u2265 \u230a c 2 \u230b + 1, then x \u2032 must be an exact ml codeword",
        "prob": 0.5687500000000001
    }, {
        "ID": 8907,
        "phrase": " also, the maximum flow instances provide the exact ml sequence",
        "prob": 0.3727272727272727
    }, {
        "ID": 9161,
        "phrase": " the rational reconstruction of each ai and its shift back of x by \u2212a cost o(m(\u03b7) log(\u03b7))",
        "prob": 0.31
    }, {
        "ID": 9163,
        "phrase": " these two properties motivate the use of an adaptive approach in lp decoding which can be summarized as follows: given a set of constraints that describe a code, start the lp decoding with a few of them, then sequentially and adaptively add more of the constraints to the problem until either an ml codeword is found or no further \"useful\" constraint exists",
        "prob": 0.2676470588235294
    }, {
        "ID": 9163,
        "phrase": " in order to find a proper value for this maximum, we ran the algorithm with a very large value of c max and measured the total decoding time for the cases where the algorithm was successful in finding the ml solution",
        "prob": 0.29583333333333334
    }, {
        "ID": 9163,
        "phrase": " in order to obtain the ml lower bound, we counted the number of times that the cutting-plane lp algorithm, using a large value of c max , converged to a codeword other than the transmitted codeword, and then divided that by the number of blocks",
        "prob": 0.48518518518518516
    }, {
        "ID": 9228,
        "phrase": " \n values \n values of the language ml include \n trapping failures an attempt to perform an illegal operation, such as division by zero, causes ml to signal failure",
        "prob": 0.24285714285714283
    }, {
        "ID": 9332,
        "phrase": " for this to occur, the replayed path must be decision-sequencable with respect to the new problem, which is de ned as follows: de nition 1 (decision-sequencable search path) a search path which contains a sequence of decisions d is decision-sequencable with respect to a new problem, hi 0 ; g 0 ; ai , if and only if there exist two decision sequences e and e 0 such that e d e 0 (where \\ \" is the decision sequencing operator) will produce a plan which is correct for hi 0 ; g 0 ; ai",
        "prob": 0.41707317073170735
    }, {
        "ID": 9450,
        "phrase": " shenker , \\anal ys i s and si mu l a t i o n o f a f ai r queuei ng algorithm , \" p r o c ",
        "prob": 0.21000000000000002
    }, {
        "ID": 9468,
        "phrase": " as some, but not all, of the similarity measures require smoothed models, we calculated both a katz back-off model (p = p in equation (  2 ), with p r (w 2 |w 1 ) = p (w 2 )), and a maximumlikelihood model (p = p ml )",
        "prob": 0.2833333333333333
    }, {
        "ID": 9572,
        "phrase": " if we cut this edge from the tree t , then we obtain two disconnected trees t a (containing v ai ) and t b (containing v bi )",
        "prob": 0.3153846153846154
    }, {
        "ID": 9572,
        "phrase": " therefore, the unique path linking v ci to v cj goes through the edge {v ai , v bi }, and thus contains the vertex v ai ",
        "prob": 0.43571428571428567
    }, {
        "ID": 9572,
        "phrase": " by fact 7, v ai lies on the unique path from v ci to v cj ",
        "prob": 0.34444444444444444
    }, {
        "ID": 9665,
        "phrase": " first, it adds to the frequency estimate of each word to that word's frequency in the ml segmentation of the current block",
        "prob": 0.20666666666666667
    }, {
        "ID": 9670,
        "phrase": " for example, the confidence factors method found in machine learning literature relies on the interpretation of the outputs as the belief that a pattern belongs to a given class  [32] ",
        "prob": 0.255
    }]
}, {
    "topic_id": 22,
    "top_words": ["ml", "fb", "cause", "match", "set", "since", "either", "would", "arsonist", "formula", "applied", "open", "true", "variables", "first"],
    "phrases": [{
        "ID": 414,
        "phrase": " , b ml , b 1r , ",
        "prob": 0.22000000000000003
    }, {
        "ID": 423,
        "phrase": " then the causal model would have the following endogenous variables (and perhaps others): \u2022 f for fire (f = 1 if there is one, f = 0 otherwise) \u2022 l for lightning (l = 1 if lightning occurred, l = 0 otherwise) \u2022 ml for match lit (ml = 1 if the match was lit and 0 otherwise)",
        "prob": 0.844
    }, {
        "ID": 423,
        "phrase": " then, for example, f f ( u, l, ml) is such that f = 1 if either l = 1 or ml = 1",
        "prob": 0.5125000000000001
    }, {
        "ID": 423,
        "phrase": " for example, suppose we have, as before, a random variable ml for match lit, and another variable wb for wood burning, with values 0 (it's not) and 1 (it is)",
        "prob": 0.5941176470588235
    }, {
        "ID": 423,
        "phrase": " \u2022 endogenous variables ml 1 and ml 2 , each either 0 or 1, where ml i = 0 if arsonist i doesn't drop the match and ml i = 1 if he does, for i = 1, 2",
        "prob": 0.7400000000000001
    }, {
        "ID": 423,
        "phrase": " ml 1 ml 2 u fb figure 1: the causal network for m 1 and m 2 ",
        "prob": 0.51
    }, {
        "ID": 423,
        "phrase": " despite the differences in the underlying models, each of ml 1 = 1 and ml 2 = 1 is a cause of fb = 1 (representing \u03d5) in both scenarios",
        "prob": 0.5785714285714286
    }, {
        "ID": 423,
        "phrase": " to show that ml 1 = 1 is a cause in m 1 let z = {ml 1 , fb}, so w = {ml 2 }",
        "prob": 0.5545454545454546
    }, {
        "ID": 423,
        "phrase": " ac2(b) is satisfied because, if the first match is lit (ml 1 = 1) the contingency ml 2 = 0 does not prevent the fire from burning the forest",
        "prob": 0.7562500000000001
    }, {
        "ID": 423,
        "phrase": " thus, ml 1 = 1 is a cause of fb = 1 in m 1 ",
        "prob": 0.3875
    }, {
        "ID": 423,
        "phrase": ") to see that ml 1 = 1 is also a cause of fb = 1 in m 2 , again let z = {ml 1 , fb} and w = {ml 2 }",
        "prob": 0.5916666666666667
    }, {
        "ID": 423,
        "phrase": " since (m 2 , u 11 ) |= [ml 1 \u2190 0, ml 2 \u2190 1](fb = 0), ac2(a) is satisfied",
        "prob": 0.61
    }, {
        "ID": 423,
        "phrase": " moreover, since the value of ml 2 required for ac2(a) is the same as its current value (i",
        "prob": 0.3416666666666666
    }, {
        "ID": 423,
        "phrase": " a purely counterfactual definition of causality would make ml 1 = 1 \u2228 ml 2 = 1 a cause of fb = 1 in m 1 (since, if ml 1 = 1 \u2228 ml 2 = 1 were not true, then fb = 1 would not be true), but would make neither ml 1 = 1 nor ml 2 = 1 individually a cause (since, for example, if ml 1 = 1 were not true in m 1 , fb = 1 would still be true)",
        "prob": 0.836111111111111
    }, {
        "ID": 423,
        "phrase": " interestingly, as we shall see in section 5, our definition of explanation does distinguish m 1 from m 2 ; each of ml 1 = 1 and ml 2 = 1 is an explanation of fb = 1 in m 1 under our definition of explanation, but neither is an explanation of fb = 1 in m 2 ",
        "prob": 0.5549999999999999
    }, {
        "ID": 423,
        "phrase": " in m 2 , the explanation of fb = 1 is ml 1 = 1 \u2227 ml 2 = 1: both matches being lit are necessary to explain the forest burning down",
        "prob": 0.5785714285714286
    }, {
        "ID": 423,
        "phrase": " the reason we consider ml 1 = 1 to be a cause of fb = 1 in m 1 is that if ml 2 had been 0, rather than 1, fb would depend on ml 1 ",
        "prob": 0.47333333333333333
    }, {
        "ID": 423,
        "phrase": " but how do we express this formally in a context u in which ml 2 = 1 is in fact true? to (hypothetically) suppress ml 2 = 1 in the context created by u 11 , we must use a structural contingency and imagine that ml 2 is set to 0 by some external intervention (or \"miracle\") that violates whatever causal laws (or equations) made ml 2 = 1 in u 11 ",
        "prob": 0.596875
    }, {
        "ID": 423,
        "phrase": " for example, if u 11 includes the motivations and conspiratorial plans of the two arsonists, then ml 2 may be 0 due to a mechanical failure (say, the match box fell into a creek) or to arsonist 2 having second thoughts",
        "prob": 0.42083333333333334
    }, {
        "ID": 423,
        "phrase": " although ml 1 = 1 is a cause of fb = 1 in both the disjunctive and conjunctive scenarios, the models m 1 and m 2 differ in regard to explanation, as we shall see in section 5",
        "prob": 0.5055555555555555
    }, {
        "ID": 423,
        "phrase": " intuitively, we feel that if both matches are needed for establishing a forest fire, then both ml 1 = 1 and ml 2 = 1 together would be required to fully explain the unfortunate fate of the forest; pointing to just one of these events would only beg another \"how come?\" question, and would not stop any serious investigating team from continuing its search for a more complete answer",
        "prob": 0.28055555555555556
    }, {
        "ID": 423,
        "phrase": " if we assume that there is a context where only arsonist 1 lit the fire (and, say, there was lightning) and another where only arsonist 2 lit the fire then, in the conjunctive scenario, ml 1 = 1 \u2227 ml 2 = 1 is an explanation of fb = 1, but neither ml 1 = 1 nor ml 2 = 1 by itself is an explanation (since neither by itself is a cause in all contexts in k that satisfy the formula)",
        "prob": 0.8419354838709677
    }, {
        "ID": 423,
        "phrase": " on the other hand, in the disjunctive scenario, both ml 1 = 1 and ml 2 = 1 are explanations",
        "prob": 0.51
    }, {
        "ID": 423,
        "phrase": " for example, although ml 1 = 1 \u2227 ml 2 = 1 is an explanation of fire (if k includes contexts where there are other possible causes of fire), it is a cause of fire in none of the contexts in which it holds",
        "prob": 0.705
    }, {
        "ID": 423,
        "phrase": " the minimality condition ac3 would say that each of ml 1 = 1 and ml 2 = 1 is a cause, but their conjunction is not",
        "prob": 0.3923076923076923
    }, {
        "ID": 423,
        "phrase": " if this seems desirable, then it can be easily accomplished by replacing the variables ml 1 and ml 2 in the model by a variable ml which is then ml = 1 becomes an explanation, without requiring disjunctive explanations",
        "prob": 0.7318181818181818
    }, {
        "ID": 423,
        "phrase": " why not just add ml to the model rather than using to replace ml 1 and ml 2 ? we have implicitly assumed in our framework that all possible combinations of assignments to the variables are possible (i",
        "prob": 0.255
    }, {
        "ID": 423,
        "phrase": " if we add ml and view it as being logically equivalent to ml 1 \u2228 ml 2 (that is, ml = 1 by definition iff at least one of ml 1 and ml 2 is 1) then, for example, it is logically impossible for there to be a structural contingency where ml 1 = 0, ml 2 = 0, and ml = 1",
        "prob": 0.524
    }, {
        "ID": 424,
        "phrase": " then the causal model would have the following endogenous variables (and perhaps others): \u2022 f for fire (f = 1 if there is one, f = 0 otherwise); \u2022 l for lightning (l = 1 if lightning occurred, l = 0 otherwise); \u2022 ml for match lit (ml = 1 if the match was lit, ml = 0 otherwise)",
        "prob": 0.8115384615384614
    }, {
        "ID": 424,
        "phrase": " then, for example, f f ( u, l, ml) is such that f = 1 if either l = 1 or ml = 1",
        "prob": 0.3875
    }, {
        "ID": 424,
        "phrase": " for example, suppose we have, as before, a random variable ml for match lit, and another variable wb for wood burning, with values 0 (it's not) and 1 (it is)",
        "prob": 0.6529411764705882
    }, {
        "ID": 424,
        "phrase": " \u2022 endogenous variables ml 1 and ml 2 , each either 0 or 1, where ml i = 0 if arsonist i doesn't drop the lit match and ml i = 1 if he does, for i = 1, 2",
        "prob": 0.7562500000000001
    }, {
        "ID": 424,
        "phrase": " despite the differences in the underlying models, each of ml 1 = 1 and ml 2 = 1 is a cause of fb = 1 in both scenarios",
        "prob": 0.7000000000000001
    }, {
        "ID": 424,
        "phrase": " to show that ml 1 = 1 is a cause in m 1 let z = {ml 1 , fb}, so w = {ml 2 }",
        "prob": 0.5545454545454546
    }, {
        "ID": 424,
        "phrase": " ac2(b) is satisfied because, if the first match is lit (ml 1 = 1) the contingency ml 2 = 0 does not prevent the fire from burning the forest",
        "prob": 0.7562500000000001
    }, {
        "ID": 424,
        "phrase": " thus, ml 1 = 1 is a cause of fb = 1 in m 1 ",
        "prob": 0.3875
    }, {
        "ID": 424,
        "phrase": ") to see that ml 1 = 1 is also a cause of fb = 1 in m 2 , again let z = {ml 1 , fb} and w = {ml 2 }",
        "prob": 0.5916666666666667
    }, {
        "ID": 424,
        "phrase": " since (m 2 , u 11 ) |= [ml 1 \u2190 0, ml 2 \u2190 1](fb = 0), ac2(a) is satisfied",
        "prob": 0.61
    }, {
        "ID": 424,
        "phrase": " a purely counterfactual definition of causality would make ml 1 = 1 \u2228 ml 2 = 1 a cause of fb = 1 in m 1 (since, if ml 1 = 1 \u2228 ml 2 = 1 were not true, then fb = 1 would not be true), but would make neither ml 1 = 1 nor ml 2 = 1 individually a cause (since, for example, if ml 1 = 1 were not true in m 1 , fb = 1 would still be true)",
        "prob": 0.836111111111111
    }, {
        "ID": 424,
        "phrase": " it is not hard to check that ml 1 and ml 2 are strong causes of fb in both scenarios",
        "prob": 0.3416666666666666
    }, {
        "ID": 424,
        "phrase": " however, for ml 1 to be a strong cause of fb in the conjunctive scenario, we must include ml 2 in z (so that w is empty); if ml 2 is in w , then ac2(c) fails",
        "prob": 0.7277777777777777
    }, {
        "ID": 424,
        "phrase": " we can model this by allowing ml 1 and ml 2 to have a value of 2 (where ml i = 2 if arsonist i calls the fire department)",
        "prob": 0.5071428571428571
    }, {
        "ID": 424,
        "phrase": " in this situation, it is easy to check that now neither ml 1 = 1 nor ml 2 = 1 by itself is a strong cause of fb = 1 in the disjunctive scenario",
        "prob": 0.6066666666666667
    }, {
        "ID": 424,
        "phrase": " ml 1 = 1 \u2227 ml 2 = 1 is a cause, but it seems strange that in the disjunctive scenario, we should need to take both arsonists dropping a lit match to (strongly) cause the fire, just because we allow for the possibility that an arsonist can call the fire department",
        "prob": 0.844
    }, {
        "ID": 424,
        "phrase": " the reason we consider ml 1 = 1 to be a cause of fb = 1 in m 1 is that if ml 2 had been 0, rather than 1, fb would depend on ml 1 ",
        "prob": 0.54
    }, {
        "ID": 424,
        "phrase": " although ml 1 = 1 is a cause of fb = 1 in both the disjunctive and conjunctive scenarios, the models m 1 and m 2 differ in regard to explanation, as we shall see in the companion paper",
        "prob": 0.5842105263157894
    }, {
        "ID": 425,
        "phrase": " then the causal model would have the following endogenous variables (and perhaps others): \u2022 f for fire (f = 1 if there is one, f = 0 otherwise); \u2022 l for lightning (l = 1 if lightning occurred, l = 0 otherwise); \u2022 ml for match lit (ml = 1 if the match was lit, ml = 0 otherwise)",
        "prob": 0.8115384615384614
    }, {
        "ID": 425,
        "phrase": " then, for example, f f ( u, l, ml) is such that f = 1 if either l = 1 or ml = 1",
        "prob": 0.5125000000000001
    }, {
        "ID": 425,
        "phrase": "1 has the following form: ml l f u figure 1: a simple causal network",
        "prob": 0.2818181818181818
    }, {
        "ID": 425,
        "phrase": " for example, suppose we have, as before, a random variable ml for match lit, and another variable wb for wood burning, with values 0 (it's not) and 1 (it is)",
        "prob": 0.5941176470588235
    }, {
        "ID": 425,
        "phrase": " \u2022 endogenous variables ml 1 and ml 2 , each either 0 or 1, where ml i = 0 if arsonist i doesn't drop the lit match and ml i = 1 if he does, for i = 1, 2",
        "prob": 0.7562500000000001
    }, {
        "ID": 425,
        "phrase": " ml 1 ml 2 u fb figure 2: the causal network for m 1 and m 2 ",
        "prob": 0.51
    }, {
        "ID": 425,
        "phrase": " despite the differences in the underlying models, each of ml 1 = 1 and ml 2 = 1 is a cause of fb = 1 in both scenarios",
        "prob": 0.7000000000000001
    }, {
        "ID": 425,
        "phrase": " to show that ml 1 = 1 is a cause in m 1 let z = {ml 1 , fb}, so w = {ml 2 }",
        "prob": 0.5545454545454546
    }, {
        "ID": 425,
        "phrase": " ac2(b) is satisfied because, if the first match is lit (ml 1 = 1) the contingency ml 2 = 0 does not prevent the fire from burning the forest",
        "prob": 0.7562500000000001
    }, {
        "ID": 425,
        "phrase": " thus, ml 1 = 1 is a cause of fb = 1 in m 1 ",
        "prob": 0.2625
    }, {
        "ID": 425,
        "phrase": " (note that we needed to set ml 2 to 0, contrary to fact, in order to reveal the latent dependence of fb on ml 1 ",
        "prob": 0.31875
    }, {
        "ID": 425,
        "phrase": ") to see that ml 1 = 1 is also a cause of fb = 1 in m 2 , again let z = {ml 1 , fb} and w = {ml 2 }",
        "prob": 0.675
    }, {
        "ID": 425,
        "phrase": " since (m 2 , u 11 ) |= [ml 1 \u2190 0, ml 2 \u2190 1](fb = 0), ac2(a) is satisfied",
        "prob": 0.51
    }, {
        "ID": 425,
        "phrase": " moreover, since the value of ml 2 required for ac2(a) is the same as its current value (i",
        "prob": 0.3416666666666666
    }, {
        "ID": 425,
        "phrase": " a purely counterfactual definition of causality would make ml 1 = 1 \u2228 ml 2 = 1 a cause of fb = 1 in m 1 (since, if ml 1 = 1 \u2228 ml 2 = 1 were not true, then fb = 1 would not be true), but would make neither ml 1 = 1 nor ml 2 = 1 individually a cause (since, for example, if ml 1 = 1 were not true in m 1 , fb = 1 would still be true)",
        "prob": 0.8638888888888889
    }, {
        "ID": 425,
        "phrase": " it is not hard to check that ml 1 and ml 2 are strong causes of fb in both scenarios",
        "prob": 0.5916666666666667
    }, {
        "ID": 425,
        "phrase": " however, for ml 1 to be a strong cause of fb in the conjunctive scenario, we must include ml 2 in z (so that w is empty); if ml 2 is in w , then ac2(c) fails",
        "prob": 0.7277777777777777
    }, {
        "ID": 425,
        "phrase": " we can model this by allowing ml 1 and ml 2 to have a value of 2 (where ml i = 2 if arsonist i calls the fire department)",
        "prob": 0.36428571428571427
    }, {
        "ID": 425,
        "phrase": " in this situation, it is easy to check that now neither ml 1 = 1 nor ml 2 = 1 by itself is a strong cause of fb = 1 in the disjunctive scenario",
        "prob": 0.6733333333333333
    }, {
        "ID": 425,
        "phrase": " ml 1 = 1 \u2227 ml 2 = 1 is a cause, but it seems strange that in the disjunctive scenario, we should need to take both arsonists dropping a lit match to (strongly) cause the fire, just because we allow for the possibility that an arsonist can call the fire department",
        "prob": 0.844
    }, {
        "ID": 425,
        "phrase": " the reason we consider ml 1 = 1 to be a cause of fb = 1 in m 1 is that if ml 2 had been 0, rather than 1, fb would depend on ml 1 ",
        "prob": 0.54
    }, {
        "ID": 777,
        "phrase": " so we can write t ai (a, i) as t \u03b1 a, z |b (i) for some boolean t \u03b1 -or even more strongly as t \u03b1 (a, t \u03b2 (i)), since we know that t ai does not depend on b",
        "prob": 0.25833333333333336
    }, {
        "ID": 777,
        "phrase": " furthermore, since t ai and z ib do not depend on u, neither does t tiz|u=u , and we can write it as t tiz ",
        "prob": 0.3416666666666666
    }, {
        "ID": 1464,
        "phrase": " (note that in the sequential ml method the rejection criteria mentioned are not applied on the last round of viterbi segmentation",
        "prob": 0.19375
    }, {
        "ID": 1464,
        "phrase": " to follow the mdl approach where model cost is also optimized, hua includes the model cost as a penalty term on pure ml probabilities",
        "prob": 0.2157894736842105
    }, {
        "ID": 1704,
        "phrase": " \u2022 endogenous variables ml 1 and ml 2 , each either 0 or 1, where ml i = 0 if arsonist i doesn't drop the match and ml i = 1 if he does, for i = 1, 2",
        "prob": 0.7400000000000001
    }, {
        "ID": 1704,
        "phrase": "1, then (m 1 ) ml 1 \u21900 is the model where fb = ml 2 : if the first match is not dropped, then there is a fire if and only if the second match is dropped",
        "prob": 0.7400000000000001
    }, {
        "ID": 1704,
        "phrase": " similarly, (m 2 ) ml 2 \u21900 is the model where fb =: if the first match is not dropped, then there is no fire in the conjunctive scneario",
        "prob": 0.65
    }, {
        "ID": 1704,
        "phrase": "1, note that ml 1 = 1 is an actual cause of fb = 1 in both the conjunctive and the disjunctive scenarios",
        "prob": 0.675
    }, {
        "ID": 1704,
        "phrase": " setting ml 1 to 0 results in the forest not burning down",
        "prob": 0.23333333333333334
    }, {
        "ID": 1704,
        "phrase": " to see that ml 1 = 1 is also a cause in the disjunctive scenario, let w be ml 2 ",
        "prob": 0.6454545454545454
    }, {
        "ID": 1704,
        "phrase": " note that (m 1 , u 00 ) |= [ml 1 \u2190 0, ml 2 \u2190 0]fb = 0, so the counterfactual condition is satisfied",
        "prob": 0.5545454545454546
    }, {
        "ID": 1704,
        "phrase": " moreover, (m 1 , u 00 ) |= [ml 1 \u2190 1, ml 2 \u2190 0]fb = 1; that is, in the disjunctive scenario, if the first arsonist drops the match, that is enough to burn down the forest, no matter what the second arsonist does",
        "prob": 0.8049999999999999
    }, {
        "ID": 1704,
        "phrase": " if there is a context in k where only arsonist 1 dropped a lit match (and, say, there was lightning), another where only arsonist 2 dropped a lit match, and a third where both arsonists dropped matches, then, in the conjunctive scenario, ml 1 = 1 \u2227 ml 2 = 1 is an explanation of fb = 1, but neither ml 1 = 1 nor ml 2 = 1 by itself is an explanation (since neither by itself is a cause in all contexts in k that satisfy the formula)",
        "prob": 0.8916666666666665
    }, {
        "ID": 1704,
        "phrase": " on the other hand, in the disjunctive scenario, both ml 1 = 1 and ml 2 = 1 are explanations",
        "prob": 0.51
    }, {
        "ID": 1704,
        "phrase": " if we want to allow \"there was an arsonist\" to be an explanation without specifically mentioning who the arsonist is, then it can be easily accomplished by replacing the variables ml 1 and ml 2 in the model by a variable ml which is then ml = 1 becomes an explanation, without requiring disjunctive explanations",
        "prob": 0.8555555555555555
    }, {
        "ID": 1705,
        "phrase": " \u2022 endogenous variables ml 1 and ml 2 , each either 0 or 1, where ml i = 0 if arsonist i doesn't drop the match and ml i = 1 if he does, for i = 1, 2",
        "prob": 0.7400000000000001
    }, {
        "ID": 1705,
        "phrase": "1, then (m 1 ) ml 1 \u21900 is the model where fb = ml 2 : if the first match is not dropped, then there is a fire if and only if the second match is dropped",
        "prob": 0.7400000000000001
    }, {
        "ID": 1705,
        "phrase": " similarly, (m 2 ) ml 2 \u21900 is the model where fb = 0: if the first match is not dropped, then there is no fire in the conjunctive scenario",
        "prob": 0.7214285714285715
    }, {
        "ID": 1705,
        "phrase": "1, note that ml 1 = 1 is an actual cause of fb = 1 in both the conjunctive and the disjunctive scenarios",
        "prob": 0.675
    }, {
        "ID": 1705,
        "phrase": " setting ml 1 to 0 results in the forest not burning down",
        "prob": 0.34444444444444444
    }, {
        "ID": 1705,
        "phrase": " to see that ml 1 = 1 is also a cause in the disjunctive scenario, let w be ml 2 ",
        "prob": 0.4636363636363636
    }, {
        "ID": 1705,
        "phrase": " note that (m 1 , u 00 ) |= [ml 1 \u2190 0, ml 2 \u2190 0]fb = 0, so the counterfactual condition is satisfied",
        "prob": 0.5545454545454546
    }, {
        "ID": 1705,
        "phrase": " moreover, (m 1 , u 00 ) |= [ml 1 \u2190 1, ml 2 \u2190 0]fb = 1; that is, in the disjunctive scenario, if the first arsonist drops the match, that is enough to burn down the forest, no matter what the second arsonist does",
        "prob": 0.755
    }, {
        "ID": 1705,
        "phrase": " if there is a context in k where only arsonist 1 dropped a lit match (and, say, there was lightning), another where only arsonist 2 dropped a lit match, and a third where both arsonists dropped matches, then, in the conjunctive scenario, ml 1 = 1 \u2227 ml 2 = 1 is an explanation of fb = 1, but neither ml 1 = 1 nor ml 2 = 1 by itself is an explanation (since neither by itself is a cause in all contexts in k that satisfy the formula)",
        "prob": 0.8916666666666665
    }, {
        "ID": 1705,
        "phrase": " on the other hand, in the disjunctive scenario, both ml 1 = 1 and ml 2 = 1 are explanations",
        "prob": 0.31
    }, {
        "ID": 1705,
        "phrase": " if we want to allow \"there was an arsonist\" to be an explanation without specifically mentioning who the arsonist is, then it can be easily accomplished by replacing the variables ml 1 and ml 2 in the model by a variable ml which is 1 iff at least one arsonist drops a match",
        "prob": 0.844
    }, {
        "ID": 1705,
        "phrase": " then ml = 1 becomes an explanation, without requiring disjunctive explanations",
        "prob": 0.6454545454545454
    }, {
        "ID": 1705,
        "phrase": " m 1 0 1 1 ml 00 11 2 ml u 2 u 1 or fb 0 1 2 ml 0 1 1 ml u 2 u 1 fb and m 2 (a) (b) figure 1 : 1 figure 1: the causal network for m 1 and m 2 ",
        "prob": 0.43571428571428567
    }, {
        "ID": 1706,
        "phrase": " \u2022 endogenous variables ml 1 and ml 2 , each either 0 or 1, where ml i = 0 if arsonist i doesn't drop the match and ml i = 1 if he does, for i = 1, 2",
        "prob": 0.7400000000000001
    }, {
        "ID": 1706,
        "phrase": "1, then (m 1 ) ml 1 \u21900 is the model where fb = ml 2 : if the first match is not dropped, then there is a fire if and only if the second match is dropped",
        "prob": 0.7400000000000001
    }, {
        "ID": 1706,
        "phrase": " similarly, (m 2 ) ml 2 \u21900 is the model where fb = 0: if the first match is not dropped, then there is no fire in the conjunctive scenario",
        "prob": 0.65
    }, {
        "ID": 1706,
        "phrase": "1, note that ml 1 = 1 is an actual cause of fb = 1 in both the conjunctive and the disjunctive scenarios",
        "prob": 0.675
    }, {
        "ID": 1706,
        "phrase": " setting ml 1 to 0 results in the forest not burning down",
        "prob": 0.3444444444444444
    }, {
        "ID": 1706,
        "phrase": " to see that ml 1 = 1 is also a cause in the disjunctive scenario, let w be ml 2 ",
        "prob": 0.6454545454545454
    }, {
        "ID": 1706,
        "phrase": " note that (m 1 , u 00 ) |= [ml 1 \u2190 0, ml 2 \u2190 0]fb = 0, so the counterfactual condition is satisfied",
        "prob": 0.4636363636363636
    }, {
        "ID": 1706,
        "phrase": " moreover, (m 1 , u 00 ) |= [ml 1 \u2190 1, ml 2 \u2190 0]fb = 1; that is, in the disjunctive scenario, if the first arsonist drops the match, that is enough to burn down the forest, no matter what the second arsonist does",
        "prob": 0.755
    }, {
        "ID": 1706,
        "phrase": " if there is a context in k where only arsonist 1 dropped a lit match (and, say, there was lightning), another where only arsonist 2 dropped a lit match, and a third where both arsonists dropped matches, then, in the conjunctive scenario, ml 1 = 1 \u2227 ml 2 = 1 is an explanation of fb = 1, but neither ml 1 = 1 nor ml 2 = 1 by itself is an explanation (since neither by itself is a cause in all contexts in k that satisfy the formula)",
        "prob": 0.8916666666666665
    }, {
        "ID": 1706,
        "phrase": " on the other hand, in the disjunctive scenario, both ml 1 = 1 and ml 2 = 1 are explanations",
        "prob": 0.41
    }, {
        "ID": 1706,
        "phrase": " if we want to allow \"there was an arsonist\" to be an explanation without specifically mentioning who the arsonist is, then it can be easily accomplished by replacing the variables ml 1 and ml 2 in the model by a variable ml which is 1 iff at least one arsonist drops a match",
        "prob": 0.844
    }, {
        "ID": 1706,
        "phrase": " then ml = 1 becomes an explanation, without requiring disjunctive explanations",
        "prob": 0.6454545454545454
    }, {
        "ID": 1884,
        "phrase": "  2  can be represented by the following hamiltonian function with two degrees of freedom: h = 1 ml 2 (1 + sen 2 (\u03b8 1 \u2212 \u03b8 2 )) p 2 1 2 + p 2 2 \u2212 cos (\u03b8 1 \u2212 \u03b8 2 ) p 1 p 2 + \u2212mgl (cos(\u03b8 1 ) + 2 cos(\u03b8 2 )) \u2212 \u03b8 1 t 1 (t) \u2212 \u03b8 2 t 2 (t), ( 1 ) where g is the acceleration of gravity and (p 1 , p 2 ) are the conjugate momenta to the angular variables (\u03b8 1 , \u03b8 2 ), respectively",
        "prob": 0.39565217391304347
    }, {
        "ID": 1884,
        "phrase": " the hamiltonian equations of motion yield the non-integrable, non- linear dynamical system \u03b81 = \u2202h \u2202p 1 = p 1 \u2212 cos(\u03b8 1 \u2212 \u03b8 2 )p 2 ml 2 1 + sin 2 (\u03b8 1 \u2212 \u03b8 2 ) (2) \u1e571 = \u2212 \u2202h \u2202\u03b8 1 = (p 2 1 + 2p 2 2 \u2212 2 cos(\u03b8 1 \u2212 \u03b8 2 )p 1 p 2 ) cos(\u03b8 1 \u2212 \u03b8 2 ) sin(\u03b8 1 \u2212 \u03b8 2 ) ml 2 1 + sin 2 (\u03b8 1 \u2212 \u03b8 2 ) 2 + \u2212 sin(\u03b8 1 \u2212 \u03b8 2 )p 1 p 2 ml 2 (1 + sin 2 (\u03b8 1 \u2212 \u03b8 2 )) \u2212 2mgl sin(\u03b8 1 ) + t 1 (t) (3) \u03b82 = \u2202h \u2202p 2 = 2p 2 \u2212 cos(\u03b8 1 \u2212 \u03b8 2 )p 1 ml 2 1 + sin 2 (\u03b8 1 \u2212 \u03b8 2 ) (4) \u1e572 = \u2212 \u2202h \u2202\u03b8 2 = \u2212 (p 2 1 + 2p 2 2 \u2212 2 cos(\u03b8 1 \u2212 \u03b8 2 )p 1 p 2 ) cos(\u03b8 1 \u2212 \u03b8 2 ) sin(\u03b8 1 \u2212 \u03b8 2 ) ml 2 1 + sin 2 (\u03b8 1 \u2212 \u03b8 2 ) 2 + + sin(\u03b8 1 \u2212 \u03b8 2 )p 1 p 2 ml 2 1 + sin 2 (\u03b8 1 \u2212 \u03b8 2 ) \u2212 mgl sin(\u03b8 2 ) + t 2 (t)",
        "prob": 0.5392857142857143
    }, {
        "ID": 1884,
        "phrase": " the vector x i has the general form xi = (\u03b8 1 , p 1 , \u03b8 2 , p 2 ), and the jacobian matrices j i are j 1 = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed 0 1 ml 2 0 \u2212 1 ml 2 \u22122mgl 0 0 0 0 \u2212 1 ml 2 0 2 ml 2 0 0 \u2212mgl 0 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (9) j 2 = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed 0 1 ml 2 0 1 ml 2 \u22122mgl 0 0 0 0 1 ml 2 0 2 ml 2 0 0 mgl 0 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (10) j 3 = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed 0 1 ml 2 0 1 ml 2 2mgl 0 0 0 0 1 ml 2 0 2 ml 2 0 0 \u2212mgl 0 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 , (11) j 4 = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed 0 1 ml 2 0 \u2212 1 ml 2 2mgl 0 0 0 0 \u2212 1 ml 2 0 2 ml 2 0 0 mgl 0 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 ",
        "prob": 0.7676470588235292
    }, {
        "ID": 2333,
        "phrase": " if true it would imply universality of \u03be ai alt and convergence to computable \u00b5 ai ",
        "prob": 0.31
    }, {
        "ID": 2597,
        "phrase": " while aixi clarifies certain theoretical limits of machine learning, it is computationally intractable, especially when m includes all computable distributions",
        "prob": 0.5941176470588235
    }, {
        "ID": 2598,
        "phrase": " while aixi clarifies certain theoretical limits of machine learning, it is computationally intractable, especially when m includes all computable distributions",
        "prob": 0.6529411764705882
    }, {
        "ID": 2599,
        "phrase": " while aixi clarifies certain theoretical limits of machine learning, it is computationally intractable, especially when m includes all computable distributions",
        "prob": 0.5941176470588235
    }, {
        "ID": 2600,
        "phrase": " while aixi clarifies certain theoretical limits of machine learning, it is computationally intractable, especially when m includes all computable distributions",
        "prob": 0.6529411764705882
    }, {
        "ID": 2601,
        "phrase": " while aixi clarifies certain theoretical limits of machine learning, it is computationally intractable, especially when m includes all computable distributions",
        "prob": 0.5941176470588235
    }, {
        "ID": 2627,
        "phrase": " tolmach and appel [ta93] describe a debugger for ml which is based on \"reversible execution",
        "prob": 0.25833333333333336
    }, {
        "ID": 2740,
        "phrase": " we partition the set of l-formulas into boolean combinations bc l and monolithic formulas ml l : \u03b1 belongs to bc l if its outermost operator is a boolean connective; otherwise it belongs to ml l ",
        "prob": 0.3681818181818182
    }, {
        "ID": 4047,
        "phrase": " ( 37 ) similarly to the case of ml channel estimation, the equations m = q and e = f are recovered as well",
        "prob": 0.3416666666666666
    }, {
        "ID": 4061,
        "phrase": " it is easily seen that \u03b8 * q\u22121 is the limit of the ml estimates under the assumption of q \u2212 1 sources, i",
        "prob": 0.19090909090909092
    }, {
        "ID": 4389,
        "phrase": "q \u2208 q m \u2203 and that c is eventually accepting; c \u2208 ai for even i means that c",
        "prob": 0.1375
    }, {
        "ID": 4855,
        "phrase": " otherwise, we assume that the ml decoder does not make an error",
        "prob": 0.21000000000000002
    }, {
        "ID": 4885,
        "phrase": " we therefore must have t = 2kl + v \u21d2 t = ml + v for some l, which contradicts (t \u2212 v) \u2261 0 (mod m)",
        "prob": 0.34444444444444444
    }, {
        "ID": 5076,
        "phrase": " let c m0 (\u03c4 ) := n m for all \u03c4 \u2265 0, x ml := c m(l\u22121) \u2212 c ml , and y ml := c ml \u2212 b ml ",
        "prob": 0.5545454545454546
    }, {
        "ID": 5076,
        "phrase": " (1) moreover, we have q (nm) ml (\u03c4 )dy ml (\u03c4 ) = 0, (2) dy ml (\u03c4 ) \u2265 0, (3) and q (nm) ml (\u03c4 ) \u2265 0 (4) for all \u03c4 \u2265 0 and l = 1, 2, ",
        "prob": 0.23846153846153847
    }, {
        "ID": 5076,
        "phrase": " let c(nm) ml (\u03c4 ) := c ml (n m \u03c4 )/n m , x(nm) ml (\u03c4 ) := x ml (n m \u03c4 )/n m , and q(nm) ml (\u03c4 ) := q (nm) ml (n m \u03c4 )/n m ",
        "prob": 0.4066666666666667
    }, {
        "ID": 5969,
        "phrase": " by the definition of \u03b1, m ai (0 8 k ) queries neither 0 (5/8)8 k \u03b1 nor 0 (9/8)8 k \u03b1",
        "prob": 0.3
    }, {
        "ID": 6100,
        "phrase": " a pure formula in ml + is a formula which contains no propositional variables, but which may contain nominals",
        "prob": 0.7214285714285715
    }, {
        "ID": 6100,
        "phrase": " let a, b(p) be formulae in ml + ",
        "prob": 0.5125000000000001
    }, {
        "ID": 6100,
        "phrase": " when applied to closed sets in a descriptive frame it produces a closed set; \u03b3 is a closed formula in ml if whenever applied to admissible sets in any descriptive frame it produces a closed set",
        "prob": 0.7958333333333333
    }, {
        "ID": 6100,
        "phrase": " similarly, a formula from m l + is an open operator in ml if whenever applied to open sets in a descriptive frame it produces an open set; it is an open formula in ml if whenever applied to admissible sets it produces an open set",
        "prob": 0.8607142857142857
    }, {
        "ID": 6100,
        "phrase": " let a, b(p) be formulae in ml + such that the propositional variable p does not occur in a and b(p) is negative in p",
        "prob": 0.3923076923076923
    }, {
        "ID": 6101,
        "phrase": " let m be a model and \u03d5 a formula from ml + ",
        "prob": 0.3875
    }, {
        "ID": 6101,
        "phrase": " a pure formula in ml + is a formula which contains no propositional variables, but which may contain nominals",
        "prob": 0.7214285714285715
    }, {
        "ID": 6101,
        "phrase": " let a, b(p) be formulae in ml + ",
        "prob": 0.3875
    }, {
        "ID": 6101,
        "phrase": " when applied to closed sets in a descriptive frame it produces a closed set; \u03b3 is a closed formula in ml if whenever applied to admissible sets in any descriptive frame it produces a closed set",
        "prob": 0.8374999999999999
    }, {
        "ID": 6101,
        "phrase": " similarly, a formula from m l + is an open operator in ml if whenever applied to open sets in a descriptive frame it produces an open set; it is an open formula in ml if whenever applied to admissible sets it produces an open set",
        "prob": 0.8607142857142857
    }, {
        "ID": 6102,
        "phrase": " let m be a model and \u03d5 a formula from ml + ",
        "prob": 0.3875
    }, {
        "ID": 6102,
        "phrase": " a pure formula in ml + is a formula which contains no propositional variables, but which may contain nominals",
        "prob": 0.65
    }, {
        "ID": 6102,
        "phrase": " let a, b(p) be formulae in ml + ",
        "prob": 0.3875
    }, {
        "ID": 6102,
        "phrase": " when applied to closed sets in a descriptive frame it produces a closed set; \u03b3 is a closed formula in ml if whenever applied to admissible sets in any descriptive frame it produces a closed set",
        "prob": 0.8374999999999999
    }, {
        "ID": 6102,
        "phrase": " similarly, a formula from m l + is an open operator in ml if whenever applied to open sets in a descriptive frame it produces an open set; it is an open formula in ml if whenever applied to admissible sets it produces an open set",
        "prob": 0.7178571428571429
    }, {
        "ID": 6102,
        "phrase": " let a, b(p) be formulae in ml + such that the propositional variable p does not occur in a and b(p) is negative in p",
        "prob": 0.46923076923076923
    }, {
        "ID": 6103,
        "phrase": " let m be a model and \u03d5 a formula from ml + ",
        "prob": 0.2625
    }, {
        "ID": 6103,
        "phrase": " a pure formula in ml + is a formula which contains no propositional variables, but which may contain nominals",
        "prob": 0.7214285714285715
    }, {
        "ID": 6103,
        "phrase": " let a, b(p) be formulae in ml + ",
        "prob": 0.5125000000000001
    }, {
        "ID": 6103,
        "phrase": " when applied to closed sets in a descriptive frame it produces a closed set; \u03b3 is a closed formula in ml if whenever applied to admissible sets in any descriptive frame it produces a closed set",
        "prob": 0.8374999999999999
    }, {
        "ID": 6103,
        "phrase": " similarly, a formula from m l + is an open operator in ml if whenever applied to open sets in a descriptive frame it produces an open set; it is an open formula in ml if whenever applied to admissible sets it produces an open set",
        "prob": 0.8607142857142857
    }, {
        "ID": 6308,
        "phrase": " (12) note that the ml probability is now different from that for the simple i",
        "prob": 0.23333333333333334
    }, {
        "ID": 6308,
        "phrase": " the ml probability of x n , \u03c8(\u03c3) must have, for every j, no more than j \u2212 1 components for which (75) is satisfied (where \u03b4 i is replaced by \u03b4 \u03b8i , \u03c8(\u03c3 i ) , and \u03c6 i by \u03c8(\u03c3 i ))",
        "prob": 0.19090909090909092
    }, {
        "ID": 6876,
        "phrase": " = p (\u015d ml = e) ",
        "prob": 0.22000000000000003
    }, {
        "ID": 7311,
        "phrase": " ( 33 ) theorem 8: suppose that an arbitrary message m, 1 \u2264 m \u2264 m , enters the encoder with feedback and that ml decoding is employed",
        "prob": 0.22142857142857145
    }, {
        "ID": 7448,
        "phrase": " for ||a|| = 1 each relation r ai is either empty or contains the single tuple x a i , where x is the sole element of a",
        "prob": 0.3416666666666666
    }, {
        "ID": 7858,
        "phrase": " for all these three scenarios in sections v, vi and vii, both ml and universal decoding rules are studied",
        "prob": 0.23846153846153847
    }, {
        "ID": 7858,
        "phrase": " lemma 1: for all \u03b3 \u2208 [0, 1] e ml x (r x , r y , \u03b3) = e un x (r x , r y , \u03b3), (21) and e ml y (r x , r y , \u03b3) = e un y (r x , r y , \u03b3)",
        "prob": 0.3
    }, {
        "ID": 7858,
        "phrase": " for example, we can define e x (r x , r y , \u03b3) as e x (r x , r y , \u03b3) = e ml x (r x , r y , \u03b3) = e un x (r x , r y , \u03b3) , and can similarly define e y (r x , r y , \u03b3)",
        "prob": 0.34444444444444444
    }, {
        "ID": 7961,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.18333333333333335
    }, {
        "ID": 7962,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.35000000000000003
    }, {
        "ID": 7966,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.35000000000000003
    }, {
        "ID": 8125,
        "phrase": " the mechanism of generalized puncturing when p x m |v n (x m |v n ) = q m i=1 p x (x) where u l = fn (v n ) and l \u2265 ml 0 since r(f n ) is assumed to be very low",
        "prob": 0.3153846153846154
    }, {
        "ID": 8126,
        "phrase": " then we may define the encoder by \u03c6 n (v n ) = q(u 1\u2022\u2022\u2022l0 )q(u l0+1\u2022\u2022\u20222l0 ) \u2022 \u2022 \u2022 q(u (m\u22121)l0+1\u2022\u2022\u2022ml0 ) where u l = fn (v n ), and l \u2265 ml 0 since r(f n ) is assumed to be very small",
        "prob": 0.36428571428571427
    }, {
        "ID": 8127,
        "phrase": " note that l \u2265 ml 0 since r(f n ) is assumed to be very small",
        "prob": 0.61
    }, {
        "ID": 8128,
        "phrase": " note that l \u2265 ml 0 since r(f n ) is assumed to be very small",
        "prob": 0.61
    }, {
        "ID": 8129,
        "phrase": " note that l \u2265 ml 0 since r(f n ) is assumed to be very small",
        "prob": 0.61
    }, {
        "ID": 8555,
        "phrase": " this is a general sociological problem which successful ai will cause, which has nothing specifically to do with aixi",
        "prob": 0.3416666666666666
    }, {
        "ID": 8766,
        "phrase": " also, suppose that \u03c8(\u03c6 1 , \u03c6 2 ) = ai for some 0 = a \u2208 f q ",
        "prob": 0.22000000000000003
    }, {
        "ID": 8766,
        "phrase": " moreover, assume that \u03c8(\u03c6 1 , \u03c6 2 ) = ai for some 0 = a \u2208 f q , and \u03c8(\u03c6 1 , \u03c8) = 0",
        "prob": 0.18333333333333335
    }, {
        "ID": 8766,
        "phrase": " if \u03c8 = (u, v, \u2212v, w ) \u2208 \u03bb 0 0 (g, g) and \u03c8(\u03c6 1 , \u03c8) = 0, then either \u03c8 = 0 or u = \u2212a \u22121 cx 1 , where \u03c8(\u03c6 1 , \u03c6 2 ) = ai and \u03c8(\u03c6 2 , \u03c8) = ci",
        "prob": 0.18333333333333335
    }, {
        "ID": 9223,
        "phrase": " the ml code should fill in the details: it is far from obvious that norm terminates",
        "prob": 0.175
    }, {
        "ID": 9228,
        "phrase": " ml does not allow quoted theorems as expressions, since they would construct theorems without proof",
        "prob": 0.2733333333333333
    }, {
        "ID": 9799,
        "phrase": " suppose ps computes \u22b2\u22b3i\u2208s j ai first",
        "prob": 0.2625
    }, {
        "ID": 9826,
        "phrase": " \u03c7 : [ai 1 , ai 2 ], \u2297 is ground if there are no variables in either \u03c7 or in [ai 1 , ai 2 ]",
        "prob": 0.3
    }]
}, {
    "topic_id": 23,
    "top_words": ["learning", "machine", "methods", "set", "techniques", "using", "approach", "method", "used", "based", "statistical", "examples", "training", "rules", "text"],
    "phrases": [{
        "ID": 7,
        "phrase": " this is the traditional machine learning problem",
        "prob": 0.2625
    }, {
        "ID": 7,
        "phrase": " finally, while we have given some examples as to how learning rates can be determined for particular machine learning implementations, we do not have any general method for determining these rates",
        "prob": 0.44999999999999996
    }, {
        "ID": 8,
        "phrase": " finally, while we have given some examples as to how learning rates can be determined for particular machine learning implementations, we do not have any general method for determining these rates",
        "prob": 0.44999999999999996
    }, {
        "ID": 117,
        "phrase": " rather a combination of shallow text processing (stp) with statistics-based machine learning techniques (sml) is called for",
        "prob": 0.711764705882353
    }, {
        "ID": 117,
        "phrase": " this paper describes a new approach to the classification of e-mail requests based on shallow text processing and machine learning techniques",
        "prob": 0.5611111111111111
    }, {
        "ID": 128,
        "phrase": " this software  [q]  was written for machine learning, but suffices for our purpose since the data set is not large and both the offline mining and online classification are fast",
        "prob": 0.26842105263157895
    }, {
        "ID": 129,
        "phrase": "5% on the same task, using a combination of machine learning techniques, as well as additional data obtained from a second dictionary",
        "prob": 0.25625
    }, {
        "ID": 164,
        "phrase": "introduction word sense disambiguation is often cast as a problem in supervised learning, where a disambiguator is induced from a corpus of manually sense-tagged text using methods from statistics or machine learning",
        "prob": 0.564
    }, {
        "ID": 173,
        "phrase": " the fact that combination of classifiers leads to improved performance has been reported in a large body of machine learning work",
        "prob": 0.31875
    }, {
        "ID": 173,
        "phrase": "the performance of machine learning algorithms can be improved by combining the output of different systems",
        "prob": 0.1615384615384615
    }, {
        "ID": 180,
        "phrase": " a set of mapping functions equipped with an algorithm such as a is called a learning machine in the area of artificial intelligence and computational learning theory",
        "prob": 0.33888888888888885
    }, {
        "ID": 252,
        "phrase": " the machine learning approach is to generate a model using training data in which acronyms have already been marked by hand",
        "prob": 0.31875
    }, {
        "ID": 259,
        "phrase": " the most successful current line of research is the corpus-based approach in which statistical or machine learning (ml) algorithms have been applied to learn statistical models or classifiers from corpora in order to perform wsd",
        "prob": 0.444
    }, {
        "ID": 259,
        "phrase": " for that reason, it is worth further investigating the application of new supervised ml methods to better resolve the wsd problem",
        "prob": 0.44375
    }, {
        "ID": 260,
        "phrase": " one of the most successful current lines of research is the corpusbased approach in which statistical or machine learning (ml) algorithms have been applied to learn statistical models or classifiers from corpora in order to perform wsd",
        "prob": 0.37916666666666665
    }, {
        "ID": 260,
        "phrase": " for that reason, it is worth further investigating the application of supervised ml methods to wsd, and thoroughly comparing existing alternatives",
        "prob": 0.31875
    }, {
        "ID": 267,
        "phrase": " in this paper we describe a new method that uses machine learning and a very small corpus sample annotated in the new tagset",
        "prob": 0.5941176470588235
    }, {
        "ID": 267,
        "phrase": " in stacking  (wolpert, 1992) , the outputs of the component systems are used as features for a second level machine learning module, that is trained on held out data to correct the errors that the components make",
        "prob": 0.26521739130434785
    }, {
        "ID": 267,
        "phrase": " combi-bootstrap is based on the principle of stacking machine learning algorithms, and shows very good performance on the cgn corpus that we have experimented with",
        "prob": 0.5055555555555555
    }, {
        "ID": 267,
        "phrase": " combi-bootstrap uses existing resources as features for a second level machine learning module, that is trained to make the mapping to the new tagset on a very small sample of annotated corpus material",
        "prob": 0.6839999999999999
    }, {
        "ID": 311,
        "phrase": " first, we investigate the level of accuracy that can be obtained using various machine learning techniques trained on two available lexical databases containing examples of the pronunciation of flemish and dutch",
        "prob": 0.29583333333333334
    }, {
        "ID": 311,
        "phrase": " in the machine learning literature, this approach is called ensemble, stacked or combined classifiers  (dietterich, 1997) ",
        "prob": 0.5785714285714285
    }, {
        "ID": 311,
        "phrase": " section 4 shows that the use of machine learning techniques, and especially the use of rule induction techniques, leads to an increased insight into the linguistic regularities determining the variation between the two pronunciation variants",
        "prob": 0.524
    }, {
        "ID": 311,
        "phrase": " using rule induction techniques, we investigate whether machine learning techniques reproduce the theoretical analysis of linguists, and whether rules can be induced that accurately translate one variant into the other",
        "prob": 0.4826086956521739
    }, {
        "ID": 311,
        "phrase": " we were able to show that for this text-to-pronunciation task, machine learning techniques provide an excellent approach to bootstrapping the annotation and modeling the linguistic knowledge involved",
        "prob": 0.3227272727272727
    }, {
        "ID": 311,
        "phrase": " we also show that the application of machine learning methods indeed leads to increased insight into the linguistic regularities determining the variation between the two pronunciation variants studied",
        "prob": 0.4809523809523809
    }, {
        "ID": 312,
        "phrase": "introduction the machine learning paradigm of memory-based learning, based on the assumption that new problems are solved by direct reference to stored experiences of previously solved problems, has been successfully applied to a number of linguistic phenomena, such as part-of-speech tagging, np-chunking and stress acquisition (consult  daelemans (1999)  for an overview)",
        "prob": 0.31025641025641026
    }, {
        "ID": 330,
        "phrase": "introduction this paper is about machine learning methods for identifying bunsetsus, which correspond to english phrasal units such as noun phrases and prepositional phrases",
        "prob": 0.32105263157894737
    }, {
        "ID": 330,
        "phrase": " \n method 1 (use of category-exclusive rules) so far, we have described the four existing machine learning methods",
        "prob": 0.5062500000000001
    }, {
        "ID": 340,
        "phrase": " a machine learning approach such as the one followed in this paper sidesteps this issue altogether, since it is left to the algorithm to learn what is an appropriate sf for a verb",
        "prob": 0.26842105263157895
    }, {
        "ID": 343,
        "phrase": " we consider problems for which the best method for classifying or ranking instances is not well defined, so the system builders may consider machine learning methods, neural networks, casebased systems, and hand-crafted knowledge bases as potential classification models",
        "prob": 0.22903225806451613
    }, {
        "ID": 343,
        "phrase": " some models built by machine learning methods can be built in seconds (once data are available)",
        "prob": 0.3153846153846154
    }, {
        "ID": 344,
        "phrase": " ramshaw and  marcus (1995)  approached chunking by using a machine learning method",
        "prob": 0.5916666666666667
    }, {
        "ID": 360,
        "phrase": " one of the most successful current lines of research is the corpus-based approach in which statistical or machine learning (ml) algorithms have been applied to learn statistical models or classifiers from corpora in order to perform wsd",
        "prob": 0.444
    }, {
        "ID": 360,
        "phrase": ", 2000b) , none of them addresses the issue of the portability of supervised ml algorithms for wsd, i",
        "prob": 0.25833333333333325
    }, {
        "ID": 365,
        "phrase": " machine learning based classifiers and maximum entropy models which, in principle, are not restricted to features of these forms have used them nevertheless, perhaps under the influence of probabilistic methods  (brill, 1995; yarowsky, 1994; ratnaparkhi et al",
        "prob": 0.46249999999999997
    }, {
        "ID": 449,
        "phrase": " however, more and more structural ie systems for the web are built (semi-) automatically using machine learning techniques or other algorithms as building the systems manually is no longer appropriate  [76] ",
        "prob": 0.2772727272727273
    }, {
        "ID": 449,
        "phrase": " these systems are usually built by using machine learning or data mining techniques, which learn extraction rules from the annotated corpora",
        "prob": 0.45000000000000007
    }, {
        "ID": 449,
        "phrase": " on the other hand, there are some other methods used for web mining besides machine learning methods",
        "prob": 0.3923076923076923
    }, {
        "ID": 615,
        "phrase": " -machine-learning 2 -when machine learning is performed by using the maximum entropy method, the number of events in each category of the  learning set is multiplied by the inverse of its occurrence",
        "prob": 0.45909090909090905
    }, {
        "ID": 615,
        "phrase": " we also found that, in machine learning, making the frequencies of the categories uniform can help to make their accuracy rates more uniform",
        "prob": 0.31875
    }, {
        "ID": 615,
        "phrase": " 3 machine learning 1 (learning set) indef def gen other total usage of the articles (140 sentences, 380 nouns) correct 95 199 32 0 326 incorrect 5 13 34 2 54 % of correct 95",
        "prob": 0.7947368421052632
    }, {
        "ID": 615,
        "phrase": " 4 machine learning 1 (test set) indef def gen other total a folktale turu (263 sentences, 699 nouns) correct 104 408 0 0 512 incorrect 43 115 19 10 187 % of correct 70",
        "prob": 0.7421052631578947
    }, {
        "ID": 615,
        "phrase": " 5 machine learning 2 (learning set) indef def gen other total usage of the articles (140 sentences, 380 nouns) correct 97 188 57 0 342 incorrect 3 24 9 2 38 % of correct 97",
        "prob": 0.7947368421052632
    }, {
        "ID": 615,
        "phrase": " 6 machine learning 2 (test set) indef def gen other total a folktale turu (263 sentences, 699 nouns) correct 112 360 13 0 485 incorrect 35 163 6 10 214 % of correct 76",
        "prob": 0.7947368421052632
    }, {
        "ID": 632,
        "phrase": " these approaches use techniques from statistics and machine learning to induce models of language usage from large samples of text",
        "prob": 0.6529411764705882
    }, {
        "ID": 660,
        "phrase": " among the machine learning algorithms studied, rule based systems have proven effective on many natural language processing tasks, including part-of-speech tagging  (brill, 1995; ramshaw and marcus, 1994) , spelling correction  (mangu and brill, 1997) , word-sense disambiguation  (gale et al",
        "prob": 0.46
    }, {
        "ID": 661,
        "phrase": " faced with the costs associated with data acquisition, rationalists may argue that it would be more cost effective to construct systems of handcoded rule lists that capture the linguistic characteristics of the task at hand, rather than spending comparable effort annotating data and expecting the same knowledge to be acquired indirectly by a machine learning system",
        "prob": 0.16052631578947368
    }, {
        "ID": 661,
        "phrase": " \n active learning from annotation supervised statistical machine learning systems have traditionally required large amounts of annotated data from which to extract linguistic properties of the task at hand",
        "prob": 0.4826086956521739
    }, {
        "ID": 698,
        "phrase": ", utterance boundaries or no boundaries), to what extent features are automatically extractable and normalizable, and the machine learning approach",
        "prob": 0.5399999999999999
    }, {
        "ID": 725,
        "phrase": " wrapper generation can be semi-automatic, when support tools are used in their generation, or automatic, using machine learning techniques",
        "prob": 0.35882352941176476
    }, {
        "ID": 784,
        "phrase": "introduction the conll-2001 shared task aims at discovering clause boundaries with machine learning methods",
        "prob": 0.54
    }, {
        "ID": 784,
        "phrase": " the task has been divided in three parts in order to allow basic machine learning methods to participate in this task by processing the data in a bottom-up fashion",
        "prob": 0.33809523809523806
    }, {
        "ID": 785,
        "phrase": " \n machine learning techniques this section introduces the ten learning methods that have been applied by the project members to the three tasks: lscgs, allis, lsommbl, maximum entropy, aleph, mdlbased dcg learners, finite state transducers, ib1ig, igtree and c5",
        "prob": 0.3903225806451613
    }, {
        "ID": 785,
        "phrase": " standard data sets for machine learning approaches to this task were put forward by  ramshaw and marcus (1995) ",
        "prob": 0.4066666666666666
    }, {
        "ID": 785,
        "phrase": " \n prospects the project has proven to be successful in its results for applying machine learning techniques to all three of its selected tasks: chunking, np chunking and np bracketing",
        "prob": 0.4333333333333333
    }, {
        "ID": 786,
        "phrase": "introduction currently, there is considerable interest in machine learning methods for corpus-based language learning",
        "prob": 0.47333333333333333
    }, {
        "ID": 815,
        "phrase": " the same trick can be used to speed training of other machine learning techniques, e",
        "prob": 0.4636363636363636
    }, {
        "ID": 869,
        "phrase": " the last wave of systems using machine learning techniques on hand-tagged corpora seems to have reached its highest point, far from the expectations raised in the past",
        "prob": 0.2772727272727273
    }, {
        "ID": 869,
        "phrase": " an alternative approach consists on hand-tagging word occurrences in corpora and training machine learning methods on them",
        "prob": 0.5687500000000001
    }, {
        "ID": 869,
        "phrase": " hand tagged corpora has been used to train machine learning algorithms",
        "prob": 0.5083333333333333
    }, {
        "ID": 869,
        "phrase": " \n algorithms based on corpora hand tagged corpora has been used to train machine learning algorithms",
        "prob": 0.6733333333333333
    }, {
        "ID": 1034,
        "phrase": " in the '90s this approach has increasingly lost popularity (especially in the research community) in favour of the machine learning (ml) paradigm, according to which a general inductive process automatically builds an automatic text classifier by learning, from a set of preclassified documents, the characteristics of the categories of interest",
        "prob": 0.3781250000000001
    }, {
        "ID": 1034,
        "phrase": " current-day tc is thus a discipline at the crossroads of ml and ir, and as such it shares a number of characteristics with other tasks such as information/knowledge extraction from texts and text mining  [knight 1999; pazienza 1997 ]",
        "prob": 0.48260869565217396
    }, {
        "ID": 1034,
        "phrase": " \n the machine learning approach to text categorization in the '80s the most popular approach (at least in operational settings) for the creation of automatic document classifiers consisted in manually building, by means of knowledge engineering (ke) techniques, an expert system capable of taking tc decisions",
        "prob": 0.35806451612903223
    }, {
        "ID": 1034,
        "phrase": "90 \"breakeven\" result (see section 7) on a subset of the reuters test collection, a figure that outperforms even the best classifiers built in the late '90s by state-of-the-art ml techniques",
        "prob": 0.16399999999999998
    }, {
        "ID": 1034,
        "phrase": " in ml terminology, the classification problem is an activity of supervised learning, since the learning process is \"supervised\" by the knowledge of the categories and of the training instances that belong to them 2 ",
        "prob": 0.45499999999999996
    }, {
        "ID": 1034,
        "phrase": " sebastiani in the ml approach the preclassified documents are then the key resource",
        "prob": 0.3727272727272727
    }, {
        "ID": 1034,
        "phrase": " \n training set, test set, and validation set the ml approach relies on the availability of an initial corpus \u03c9 = {d 1 , ",
        "prob": 0.50625
    }, {
        "ID": 1034,
        "phrase": " it relies on an adaptation to tc of the well-known rocchio's formula for relevance feedback in the vector-space model, and it is perhaps the only tc method rooted in the ir tradition rather than in the ml one",
        "prob": 0.2125
    }, {
        "ID": 1034,
        "phrase": " in tc, ml researchers have found a challenging application, since datasets consisting of hundreds of thousands of documents and characterized by tens of thousands of terms are widely available",
        "prob": 0.2318181818181818
    }, {
        "ID": 1034,
        "phrase": " in the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories",
        "prob": 0.604
    }, {
        "ID": 1034,
        "phrase": " this survey discusses the main approaches to text categorization that fall within the machine learning paradigm",
        "prob": 0.4066666666666666
    }, {
        "ID": 1156,
        "phrase": " in this study, in order to construct more accurate taggers we developed new tagging methods using three machine learning methods: the decision-list, maximum entropy, and support vector machine methods",
        "prob": 0.6576923076923077
    }, {
        "ID": 1156,
        "phrase": " postagging problems can thus be regarded as classification problems and can be handled by machine learning methods",
        "prob": 0.43571428571428567
    }, {
        "ID": 1156,
        "phrase": " because our approach uses machine learning methods, the probabilities were output with estimated results",
        "prob": 0.3923076923076923
    }, {
        "ID": 1156,
        "phrase": " \n machine learning methods in this paper, we used the following three machine learning methods: 2 \u2022 decision-list method \u2022 maximum-entropy method \u2022 support-vector machine method in this section, these machine-learning methods are explained",
        "prob": 0.6586206896551724
    }, {
        "ID": 1156,
        "phrase": " the machine learning methods (decision list method and maximum entropy method) based on features as used in this paper, however, are difficult to use with continual values such as probabilities in the features",
        "prob": 0.5458333333333333
    }, {
        "ID": 1156,
        "phrase": " since the order information is at most the number of ambiguities in pos and thus not so large, the machine learning methods used in this paper can handle the order",
        "prob": 0.4263157894736842
    }, {
        "ID": 1156,
        "phrase": " the other words always serve as the same pos, and they were assigned to a pos by using a word dictionary rather than a machine learning method",
        "prob": 0.5941176470588235
    }, {
        "ID": 1156,
        "phrase": " we can thus say that the support vector machine method is an effective machine learning method in that we do not have to examine and features by hand",
        "prob": 0.6529411764705882
    }, {
        "ID": 1156,
        "phrase": " in this study, in order to construct more accurate taggers we developed new tagging methods using three machine learning methods: the decision-list, maximum entropy, and support vector machine methods",
        "prob": 0.7346153846153846
    }, {
        "ID": 1281,
        "phrase": " there are a lot of effective machine learning algorithms based on two classes",
        "prob": 0.17499999999999996
    }, {
        "ID": 1281,
        "phrase": " sebastiani  [20]  provides a good survey of current machine learning techniques and de roure  [5]  a review of recommender systems",
        "prob": 0.38125
    }, {
        "ID": 1282,
        "phrase": " the presented taxonomy ought to be robust to the increase in new systems, since the fundamental technology of machine learning and user modelling are unlikely to change as quickly",
        "prob": 0.1952380952380952
    }, {
        "ID": 1282,
        "phrase": " the statistical information generated by these approaches is usually fed to some form of machine learning algorithm",
        "prob": 0.2928571428571428
    }, {
        "ID": 1282,
        "phrase": " machine learning techniques help here, but which should be used and why? \n since most users will not have 100,000 examples of what they like, interface agent profile accuracy falls below what most people find acceptable",
        "prob": 0.29047619047619044
    }, {
        "ID": 1282,
        "phrase": " lastly, an analysis of the machine learning and user modelling techniques used by today's agents is presented",
        "prob": 0.33999999999999997
    }, {
        "ID": 1332,
        "phrase": "  [34, 43] ), machine learning and data mining (e",
        "prob": 0.2625
    }, {
        "ID": 1358,
        "phrase": " we think that the reason for this is that our feature set for basque is better, although our ml algorithm is worse",
        "prob": 0.22142857142857145
    }, {
        "ID": 1387,
        "phrase": " machine learning approaches towards noun phrase chunking started with work by  church (1988)  who used bracket frequencies associated with pos tags for finding noun phrase boundaries in text",
        "prob": 0.404
    }, {
        "ID": 1422,
        "phrase": "information personalization is fertile ground for application of ai techniques",
        "prob": 0.31
    }, {
        "ID": 1466,
        "phrase": " other implicit methods used include machine learning techniques [bmm96, pap01, pb97, giw01], and user interaction monitoring, e",
        "prob": 0.33888888888888885
    }, {
        "ID": 1480,
        "phrase": " these systems were all based on the combination of lexical features with standard machine learning algorithms",
        "prob": 0.6230769230769231
    }, {
        "ID": 1482,
        "phrase": " these are all based on standard machine learning algorithms that induce classifiers from sense-tagged training text where the context in which ambiguous words occur are represented by simple lexical features",
        "prob": 0.5695652173913043
    }, {
        "ID": 1483,
        "phrase": " in this paper, we examine the effectiveness of applying machine learning techniques to the sentiment classification problem",
        "prob": 0.5071428571428571
    }, {
        "ID": 1483,
        "phrase": " an expert on using machine learning for text categorization predicted relatively low performance for automatic methods",
        "prob": 0.31875
    }, {
        "ID": 1483,
        "phrase": " \n machine learning methods our aim in this work was to examine whether it suffices to treat sentiment classification simply as a special case of topic-based categorization (with the two \"topics\" being positive sentiment and negative sentiment), or whether special sentiment-categorization methods need to be developed",
        "prob": 0.29705882352941176
    }, {
        "ID": 1511,
        "phrase": "  mani and bloedorn (1998)  used machine learning techniques to produce document summarization rules based on the user's focus (i",
        "prob": 0.4764705882352942
    }, {
        "ID": 1667,
        "phrase": "introduction we train children and most machine learning systems on sequences of harder and harder tasks",
        "prob": 0.2928571428571428
    }, {
        "ID": 1717,
        "phrase": " furthermore, if necessary, in the classifying step, by repeating the use of machine learning methods \n fig",
        "prob": 0.2928571428571428
    }, {
        "ID": 1718,
        "phrase": " symbolic formalisms in ai  (sowa, 1984)  reflect this approach",
        "prob": 0.34444444444444444
    }, {
        "ID": 1808,
        "phrase": "we propose a novel criterion for support vector machine learning: maximizing the margin in the input space, not in the feature (hilbert) space",
        "prob": 0.39444444444444443
    }, {
        "ID": 1823,
        "phrase": " after transformation to gnf, the grammar contains n 5 rules of the form ai 1 /ai 2 \u2192 ai 3 ai 2 /ai 4 ai 1 /ai 5 , with 1 \u2264 i1, i2, i3, i4, i5 \u2264 n",
        "prob": 0.31
    }, {
        "ID": 1867,
        "phrase": " both approaches use supervised machine learning from examples",
        "prob": 0.41
    }, {
        "ID": 1867,
        "phrase": " a document is converted to a vector of features and machine learning techniques are used to induce a mapping from the feature space to the list of keyphrases",
        "prob": 0.6166666666666667
    }, {
        "ID": 1869,
        "phrase": " \n genex: genitor plus extractor the parameters in extractor are set using the standard machine learning paradigm of supervised learning",
        "prob": 0.6166666666666667
    }, {
        "ID": 1869,
        "phrase": " given a set of phrases with a shared single-word stem (for example, the set of phrases {\"learning\", \"machine learning\", \"learnability\"} shares the single-word stem \"learn\"), genex tends to choose the best member of the set, rather than choosing the whole set",
        "prob": 0.42727272727272725
    }, {
        "ID": 1870,
        "phrase": " we approach this problem from the perspective of machine learning research",
        "prob": 0.31
    }, {
        "ID": 1877,
        "phrase": " this is the classical machine learning problem of learning from examples",
        "prob": 0.31
    }, {
        "ID": 1877,
        "phrase": " \n genex the parameters in extractor are set using the standard machine learning paradigm of supervised learning",
        "prob": 0.47333333333333333
    }, {
        "ID": 1877,
        "phrase": "5 has become a standard benchmark in machine learning research for evaluating the performance of supervised classification algorithms",
        "prob": 0.2733333333333333
    }, {
        "ID": 1881,
        "phrase": " i assume a familiarity with standard techniques of statistical estimation and machine learning",
        "prob": 0.2583333333333333
    }, {
        "ID": 1881,
        "phrase": " \n machine learning of natural languages the study of machine learning is a wide field of academic study in its own right, with a large variety of different techniques being employed  (carbonell, 1990) ; i shall not attempt a survey here",
        "prob": 0.244
    }, {
        "ID": 1881,
        "phrase": " \n statistical learning there are a number of different types of statistical model that can be used in machine learning",
        "prob": 0.36428571428571427
    }, {
        "ID": 1891,
        "phrase": " typically a machine learning researcher is given a small set of cases, and acquiring further cases is either very expensive or practically impossible",
        "prob": 0.22777777777777775
    }, {
        "ID": 1894,
        "phrase": " it is the task of the machine learning system to induce a model for predicting the class of an example from its features",
        "prob": 0.36428571428571427
    }, {
        "ID": 1895,
        "phrase": " that is, it is the responsibility of the user of the machine learning software to identify context-sensitive features",
        "prob": 0.3153846153846154
    }, {
        "ID": 1895,
        "phrase": " these definitions make it possible for machine learning software to automatically distinguish primary and contextual features",
        "prob": 0.4066666666666666
    }, {
        "ID": 1895,
        "phrase": "a large body of research in machine learning is concerned with supervised learning from examples",
        "prob": 0.5461538461538461
    }, {
        "ID": 2100,
        "phrase": " this is not just due to increased resources: a succession of breakthroughs in machine learning algorithms has allowed us to leverage existing resources much more effectively",
        "prob": 0.4789473684210526
    }, {
        "ID": 2124,
        "phrase": " \n machine learning: the machine can be used to learn the rules of approximate grammar by analyzing an annotated text",
        "prob": 0.54
    }, {
        "ID": 2124,
        "phrase": " \n machine learning to generate approximate grammars in this part of the paper, we discuss how we achieved the generation of an approximate grammar by learning patterns from a set of tagged documents",
        "prob": 0.33809523809523806
    }, {
        "ID": 2124,
        "phrase": " by increasing the value of rho, we could eliminate the faulty productions generated after machine learning of the training set",
        "prob": 0.25625
    }, {
        "ID": 2124,
        "phrase": " the machine learning algorithm to learn the rules of approximate grammars is giving good results as experimented",
        "prob": 0.33999999999999997
    }, {
        "ID": 2301,
        "phrase": " we have, therefore, opted for a machine learning approach that allows factordering rules to be captured automatically from sets of manually reordered facts",
        "prob": 0.39444444444444443
    }, {
        "ID": 2301,
        "phrase": " \n previous work in recent years, ml approaches have been introduced to nlg to address problems such as the construction and maintenance of domain and language resources, which is a timeconsuming process in systems that use handcrafted rules",
        "prob": 0.324
    }, {
        "ID": 2301,
        "phrase": " ml approaches to nlg have also been used in syntactic and lexical realization (langkilde and  knight, 1998; bangalore and rambow, 2000; ratnaparkhi, 2000; varges and mellish, 2001; shaw and hatzivassiloglou, 1999; malouf 2000) , as well as in sentence planning tasks  (walker et al",
        "prob": 0.27307692307692305
    }, {
        "ID": 2301,
        "phrase": " furthermore, unlike previous machine learning approaches, our method does not interleave fact ordering with content determination",
        "prob": 0.25625
    }, {
        "ID": 2301,
        "phrase": " \n figure 4 : 4 figure 4: ordering of facts as specified by the human annotator \n table 1 : database facts and facts selected as input to the discourse planner 1 \n\t\t\t for an extensive bibliography on statistical and machine learning approaches to nlg, see: http://www",
        "prob": 0.18214285714285713
    }, {
        "ID": 2333,
        "phrase": " in other words: the ai problem has not yet been well-defined",
        "prob": 0.12222222222222223
    }, {
        "ID": 2436,
        "phrase": " a problem of substantial recent interest in machine learning, computer vision, signal processing and statistics  [34, 14, 27, 16, 26, 35]  is the determination of the so-called intrinsic dimension of the manifold and the reconstruction of the manifold from a set of samples from the signal class",
        "prob": 0.37407407407407406
    }, {
        "ID": 2481,
        "phrase": " attributes, probabilities and entropy while we used the terminology of events earlier, we will now migrate to common machine learning terminology",
        "prob": 0.19375
    }, {
        "ID": 2482,
        "phrase": " \n attributes, probabilities and entropy while we used the terminology of events earlier, we will now migrate to common machine learning terminology",
        "prob": 0.5062500000000001
    }, {
        "ID": 2506,
        "phrase": " such a parallel corpus along with machine learning techniques can be used to produce example based machine translation system",
        "prob": 0.41764705882352937
    }, {
        "ID": 2524,
        "phrase": " both approaches use supervised machine learning from examples",
        "prob": 0.51
    }, {
        "ID": 2582,
        "phrase": " [2002]  have also addressed the task of review classification, but they used standard machine learning text classification techniques",
        "prob": 0.54
    }, {
        "ID": 2795,
        "phrase": " we therefore take a machine learning approach to generating text classification rules automatically from examples",
        "prob": 0.5071428571428571
    }, {
        "ID": 2941,
        "phrase": " this approach can be combined with other inference techniques, such as those provided by machine learning theory",
        "prob": 0.5083333333333333
    }, {
        "ID": 2941,
        "phrase": " this approach can be combined with other inference techniques, such as those provided by machine learning theory",
        "prob": 0.5083333333333333
    }, {
        "ID": 2942,
        "phrase": " this approach can be combined with other inference techniques, such as those provided by machine learning theory",
        "prob": 0.3416666666666666
    }, {
        "ID": 2942,
        "phrase": " this approach can be combined with other inference techniques, such as those provided by machine learning theory",
        "prob": 0.425
    }, {
        "ID": 2971,
        "phrase": " these algorithms will draw heavily on techniques from statistics and machine learning, but will also require new approaches that scale linearly with data size",
        "prob": 0.17222222222222222
    }, {
        "ID": 3105,
        "phrase": " classified e-mail request from customers based on shallow text processing and machine learning techniques",
        "prob": 0.47333333333333333
    }, {
        "ID": 3105,
        "phrase": " using a combination of machine learning, statistical analysis, modeling techniques and database technology, data mining finds patterns and subtle relationships in data and infers rules that allow the prediction of future results",
        "prob": 0.22592592592592592
    }, {
        "ID": 3193,
        "phrase": " we have used our approach in two types of situations: a machine learning paradigm where the algorithm is trained on a data set and tested on a different data set, and also a data mining paradigm where the algorithm is trained on the same set onto which it is applied",
        "prob": 0.2892857142857143
    }, {
        "ID": 3333,
        "phrase": " given annotated data, such as those used in our experiments, machine learning methods can potentially be used to produce a set of viewpoints and patterns for a specific application",
        "prob": 0.605
    }, {
        "ID": 3354,
        "phrase": "2 make it possible to use it in a machine learning scenario (for both training and run-time application)",
        "prob": 0.43571428571428567
    }, {
        "ID": 3382,
        "phrase": " after the raw examples are converted to feature vectors, the weka machine learning software is used to induce a model of the training data and predict the classes of the testing examples  (witten and frank, 1999) ",
        "prob": 0.37916666666666665
    }, {
        "ID": 3382,
        "phrase": " the nrc system approaches wsd as a classical supervised machine learning problem, using familiar tools such as the weka machine learning software and brill's rule-based part-of-speech tagger",
        "prob": 0.37407407407407406
    }, {
        "ID": 3474,
        "phrase": " the machine learning application was developed in a windows xp based desktop using sun's java",
        "prob": 0.4066666666666666
    }, {
        "ID": 3600,
        "phrase": " for example, with regard to discrete emotion types, recognition rates for 5 types (comparison (a)) show that, for the same feature extraction and machine learning method, the performance with acted speech (ep) in sd mode is better than that with spontaneous speech (cf) in si mode (75% vs",
        "prob": 0.26129032258064516
    }, {
        "ID": 3810,
        "phrase": " in all cases where kl (q, p ) grows faster than logarithmically in n (the generic case in machine learning) these bounds will therefore be weaker than (4) above",
        "prob": 0.19375
    }, {
        "ID": 3959,
        "phrase": " the required nlp techniques involve both statistical and machine learning approaches computational linguistics (acl, eacl) also has to be stressed  [acl] ",
        "prob": 0.2833333333333333
    }, {
        "ID": 3959,
        "phrase": " hence some efforts are being pursued to automate lexicon creation using machine learning[habert98extending][faure98acquisition] or to construct multilingual lexicon  [calzolari02towards] ",
        "prob": 0.3588235294117647
    }, {
        "ID": 3962,
        "phrase": " using a machine learning approach trained on a large corpus, the tagger can deduce the pos category of each word in the document",
        "prob": 0.6529411764705882
    }, {
        "ID": 4085,
        "phrase": " \n machine learning methods we experimented with three machine learning methods for classifying sentences",
        "prob": 0.65
    }, {
        "ID": 4085,
        "phrase": " \n 2-class classification all three machine learning methods were evaluated in classifying among 2 classes",
        "prob": 0.2928571428571428
    }, {
        "ID": 4404,
        "phrase": " a related area of research lies in the study of ensemble methods in machine learning; examples of these techniques include bagging, boosting, mixtures of experts, and others  [13] ,  [4] ,  [9] ,  [10] ,  [15] ",
        "prob": 0.4809523809523809
    }, {
        "ID": 4405,
        "phrase": " a related area of research lies in the study of ensemble methods in machine learning; examples of these techniques include bagging, boosting, mixtures of experts, and others  [13] ,  [4] ,  [9] ,  [10] ,  [15] ",
        "prob": 0.5285714285714287
    }, {
        "ID": 4406,
        "phrase": " a related area of research lies in the study of ensemble methods in machine learning; examples of these techniques include bagging, boosting, mixtures of experts, and others  [11, 4, 8, 9, 13] ",
        "prob": 0.5285714285714287
    }, {
        "ID": 4537,
        "phrase": " recently, the machine learning methods have been exploited to extract symbolic rules  [2, 3, 16] ",
        "prob": 0.5083333333333333
    }, {
        "ID": 4542,
        "phrase": " the second category of extractive techniques concerns the creation of a graph (or tree) representation of the document(s) to be summarized exploiting machine learning and/or language processing techniques",
        "prob": 0.3227272727272727
    }, {
        "ID": 4552,
        "phrase": " an incremental ka based classification works well in a certain domain where the information continually increases and the creation of training set for machine learning is hard",
        "prob": 0.29047619047619044
    }, {
        "ID": 4552,
        "phrase": " existing research for automatic document classification by machine learning uses a range of techniques such as probability  [3] [4], statistical methods  [5] [6], vector similarity  [4]  and so on",
        "prob": 0.32105263157894737
    }, {
        "ID": 4876,
        "phrase": "we propose a new framework for building and evaluating machine learning algorithms",
        "prob": 0.3416666666666666
    }, {
        "ID": 4900,
        "phrase": " in other words, \u2206(s , s ai ) \u2265 3, i = 1, 2, 3",
        "prob": 0.22000000000000003
    }, {
        "ID": 5278,
        "phrase": "introduction classification is a machine learning task that requires construction of a function that classifies examples into one of a discrete set of possible categories",
        "prob": 0.39444444444444443
    }, {
        "ID": 5714,
        "phrase": " of course, there was other activity in ais at this time, machine learning was one small area",
        "prob": 0.25833333333333336
    }, {
        "ID": 5894,
        "phrase": " a related area of research lies in the study of ensemble methods in machine learning; examples of these techniques include bagging, boosting, and mixtures of experts (e",
        "prob": 0.505
    }, {
        "ID": 6240,
        "phrase": " the content alignment tool (cat), currently in development by a team led by anne diekema and elizabeth liddy of syracuse university, uses machine learning techniques to support the alignment of nsdl resources to state and national educational standards  [10] ",
        "prob": 0.3482758620689655
    }, {
        "ID": 6340,
        "phrase": " the use of lr techniques can only help in making the convergence to the ml solution faster, but precludes the detection algorithm from computing soft-output values, because the boundaries of the information set are no more recognizable after the application of such techniques",
        "prob": 0.23461538461538461
    }, {
        "ID": 6508,
        "phrase": " learning classifier systems  [25]  are a machine learning technique which combines evolutionary computing and reinforcement learning to produce adaptive systems",
        "prob": 0.33888888888888885
    }, {
        "ID": 6602,
        "phrase": " this has led to interest in using machine learning methods for automatically learning ranked retrieval functions",
        "prob": 0.4066666666666666
    }, {
        "ID": 6754,
        "phrase": " more specifically, we leverage the techniques from machine learning and data mining to analyze the wlan trace, which is a new approach that augments the existing work on the traces",
        "prob": 0.255
    }, {
        "ID": 7042,
        "phrase": " on the one hand, some systems use a set of manually developed patterns that will be applied on the text to accurately recognize and tag  (muc-6, 1995) ; on the other hand, fully automatic learning-based systems use machine learning techniques to learn a model in order to accurately tag texts",
        "prob": 0.5181818181818182
    }, {
        "ID": 7042,
        "phrase": " to automatically process these cases, nissim and markert propose a supervised machine learning algorithm, which exploits the similarity between examples of conventional metonymy",
        "prob": 0.26842105263157895
    }, {
        "ID": 7175,
        "phrase": " \n learning problems in artificial intelligence systems learning can be modeled by traditional methods such as statistical, fuzzy, and approximation methods",
        "prob": 0.3
    }, {
        "ID": 7333,
        "phrase": " our technical reason for this is to produce labeled training data for supervised machine learning, i",
        "prob": 0.46923076923076923
    }, {
        "ID": 7333,
        "phrase": "  2  systems that analyze spoken language tend to look at it as a stream of features (machine learning) or phonetic/lexical/syntactic units (speech recognition)",
        "prob": 0.7833333333333333
    }, {
        "ID": 7334,
        "phrase": " our technical reason for this is to produce labeled training data for supervised machine learning, i",
        "prob": 0.3153846153846154
    }, {
        "ID": 7334,
        "phrase": "  2  systems that analyze spoken language tend to look at it as a stream of features (machine learning) or phonetic/lexical/syntactic units (speech recognition)",
        "prob": 0.7277777777777777
    }, {
        "ID": 7408,
        "phrase": " it is shallow confluent when \u2192 * ai and \u2192 * aj commute for all i, j \u2265 0",
        "prob": 0.2625
    }, {
        "ID": 7409,
        "phrase": " it is shallow confluent when \u2192 * ai and \u2192 * aj commute for all i, j \u2265 0",
        "prob": 0.2625
    }, {
        "ID": 7429,
        "phrase": " this problem was approached from a number of different disciplines, including statistical data analysis  (dobson, 1990; limnios and nikulin, 2000) , machine learning  (carbonell et al, 1983; shavlik and dietterich, 1990; aha,  as decision trees, fuzzy models and many others) are equivalent to a set of rules",
        "prob": 0.26129032258064516
    }, {
        "ID": 7429,
        "phrase": "an approach to the classification problem of machine learning, based on building local classification rules, is developed",
        "prob": 0.5399999999999999
    }, {
        "ID": 7483,
        "phrase": " \n methods for transliterating existing automatic name transliteration systems either use hand-crafted linguistic rules, or they use machine learning methods (e",
        "prob": 0.605
    }, {
        "ID": 7492,
        "phrase": " we have therefore started applying machine learning methods to infer such rules",
        "prob": 0.425
    }, {
        "ID": 7493,
        "phrase": " to speak with text classification terminology (sebastiani, 1999), the mapping of texts onto the euro-voc thesaurus is a category ranking classification task using a machine learning approach, where an inductive process builds a profile-based classifier by observing the manual classification on a training set of documents with only positive examples",
        "prob": 0.7594594594594595
    }, {
        "ID": 7498,
        "phrase": " due to a lack of manpower and due to the limited availability of machineusable linguistic resources, we developed the following preferences: (a) limiting language-specific text processing to a minimum, by using heuristics and other shallow methods; (b) using statistics and machine learning (ml) methods rather than hand-crafted linguistic rules, where possible; (c) making use of various available multilingual lexical resources, even if they were not initially developed for machine use",
        "prob": 0.562
    }, {
        "ID": 7498,
        "phrase": " (2003a) so that we only summarise the procedure here: the system maps documents onto euro-voc by carrying out category-ranking classification using machine learning methods",
        "prob": 0.605
    }, {
        "ID": 7498,
        "phrase": " before feeding the training texts to the ml algorithm, some linguistic pre-processing was carried out to lemmatise words and to mark up multi-word terms such as power_plant and new_york as one token and a large stop word list of words with low semantic content was used",
        "prob": 0.3258064516129032
    }, {
        "ID": 7498,
        "phrase": "2, this machine learning method to map documents onto thesauri requires training material, i",
        "prob": 0.36428571428571427
    }, {
        "ID": 7498,
        "phrase": " they mainly rely on tokenisation, case information, dictionary lookup procedures, stop word lists, simple local patterns, heuristics, and statistics and machine learning methods operating on 'words' without part-of-speech information",
        "prob": 0.26999999999999996
    }, {
        "ID": 7498,
        "phrase": " instead, we exploit existing multilingual lexical resources (even if they had not initially been developed for machine use) and languageindependent text features, and we make use of machine learning techniques, statistical methods and heuristics",
        "prob": 0.5423076923076923
    }, {
        "ID": 7593,
        "phrase": " to identify the only relevant sentences among thoses, classical supervised ml methods have been applied to a bacillus subtilis corpus in which relevant and irrelevant sentences had been annotated by a biological expert",
        "prob": 0.4826086956521739
    }, {
        "ID": 7595,
        "phrase": " 1987  for tuning nl processing to a given type of texts, is now popularized by machine learning (ml) papers in the ie field for learning extraction rules",
        "prob": 0.305
    }, {
        "ID": 7595,
        "phrase": " next, ml systems tend to learn non-understandable rules by picking details in training examples that do not look as related",
        "prob": 0.33888888888888885
    }, {
        "ID": 7595,
        "phrase": " the ml systems learn extraction rules by generalizing from annotated training examples",
        "prob": 0.3923076923076923
    }, {
        "ID": 7613,
        "phrase": " first, a machine learning-style approach is used to find the cores",
        "prob": 0.425
    }, {
        "ID": 7923,
        "phrase": " in order to exploit a strategy based on the reuse of written material, over the years we developed several computational writing tools with varied levels of sophistication in the use of artificial intelligence methods -the overall environment is called amadeus (amiable article development for user support)  [1] [2] [3] [4] [5] [6] [7] [8] [9] ",
        "prob": 0.20882352941176469
    }, {
        "ID": 8108,
        "phrase": " lastly, ekm is also inspired by the dynamic subset selection first proposed by gathercole and ross  [17]  and further developed by  [18]  to address scalability issues in ec-based machine learning",
        "prob": 0.3227272727272727
    }, {
        "ID": 8248,
        "phrase": " with this rather cunning device, searle set the cat among the pigeons and has helped induce self-doubt in the best of ai theorists",
        "prob": 0.1823529411764706
    }, {
        "ID": 8555,
        "phrase": " \n supervised learning from examples (ex) the developed ai models provide a frame for reinforcement learning",
        "prob": 0.2928571428571428
    }, {
        "ID": 9221,
        "phrase": " p q p \u2227 q , is provided gordon's tutorial on ml  [13]  describes how to implement inference rules and tactics for a simple logic",
        "prob": 0.2733333333333333
    }, {
        "ID": 9228,
        "phrase": " the method is implemented in the programming language ml [$gordon79,$gordon82]",
        "prob": 0.21000000000000002
    }, {
        "ID": 9241,
        "phrase": " self-customizing software uses machine learning techniques to automatically customize task generic software to a specific user",
        "prob": 0.6722222222222222
    }, {
        "ID": 9254,
        "phrase": " \n irrelevant attributes irrelevant attributes pose a signi cant problem for most machine learning methods  (breiman et al",
        "prob": 0.25625
    }, {
        "ID": 9256,
        "phrase": " while hand-coded targets represent a labor-intensive investment on the part of domain experts, no knowledge of natural language processing or of machine learning technologies is needed to generate these answer keys, so any domain expert can produce answer keys for use by wrap-up",
        "prob": 0.24545454545454545
    }, {
        "ID": 9277,
        "phrase": " machine learning techniques can be used to generate concepts that are consistent with observed examples",
        "prob": 0.46923076923076923
    }, {
        "ID": 9277,
        "phrase": " these membership functions are ideal candidates to be learned from examples using a machine learning approach",
        "prob": 0.2928571428571428
    }, {
        "ID": 9281,
        "phrase": " no other previous admissible search algorithm has been employed in machine learning to find classifiers that are inconsistent with the training set and maximize an arbitrary preference function",
        "prob": 0.205
    }, {
        "ID": 9281,
        "phrase": " as fixed-order search is representative of previous approaches to unordered search employed in machine learning, and thus it is important to obtain a realistic evaluation of its performance, ten alternative random orders were generated and all employed for each fixed-order search task",
        "prob": 0.19677419354838707
    }, {
        "ID": 9285,
        "phrase": " on the other hand some new results are presented, which resolve a question which was open both in ai and in the database domain",
        "prob": 0.16153846153846155
    }, {
        "ID": 9298,
        "phrase": " again, the majority of machine learning researchers would be unconcerned that their systems failed to perform well in such circumstances",
        "prob": 0.2733333333333333
    }, {
        "ID": 9298,
        "phrase": " starting from the similarity assumption, machine learning can be viewed as the inference of a suitable similarity metric for a learning task",
        "prob": 0.38125
    }, {
        "ID": 9310,
        "phrase": " just as the machine learning approach made it easy to retrain when new training examples became available (experiment set 2), machine learning also made it easy to retrain when new features become available",
        "prob": 0.4653846153846154
    }, {
        "ID": 9343,
        "phrase": " for the intensive machine learning methods studied here, this condition is safely satis ed",
        "prob": 0.3416666666666666
    }, {
        "ID": 9470,
        "phrase": " successful taggers have been built using several approaches, such as statistical techniques, symbolic machine learning techniques, neural networks, etc",
        "prob": 0.4789473684210527
    }, {
        "ID": 9470,
        "phrase": " from a machine learning perspective, the relevant noise in the corpus is that of non systematically mistagged words (i",
        "prob": 0.3153846153846154
    }, {
        "ID": 9480,
        "phrase": " some of the techniques used are basically machine learning techniques",
        "prob": 0.41
    }, {
        "ID": 9518,
        "phrase": " we use: p interp (f |w i ) = (1 \u2212 \u03bb)p ml (f |w i ) + \u03bbp ml (f ) we set \u03bb to the probability that the presence of feature f is independent of the presence of word w i ; to the extent that this independence holds, p (f ) is an accurate (but more robust) estimate of p (f |w i )",
        "prob": 0.24285714285714283
    }, {
        "ID": 9524,
        "phrase": " instead of selecting and combining these features in an adhoc manner, which would require re-adjustment for each new genre of text, a natural suggestion would be to use machine learning on a training corpus of documents and their abstracts to discover salience functions which describe what combination of features is optimal for a given summarization task",
        "prob": 0.5162162162162163
    }, {
        "ID": 9524,
        "phrase": " in this paper we describe a machine learning approach which learns both generic summaries and userfocused ones",
        "prob": 0.4357142857142858
    }, {
        "ID": 9524,
        "phrase": " our focus is on machine learning aspects, in particular, performance-level comparison between different learning methods, stability of the learning under different compression rates, and relationships between rules learnt in the generic and the userfocused case",
        "prob": 0.23461538461538464
    }, {
        "ID": 9524,
        "phrase": " the training sentences (positive and negative examples) are fed to machine learning algorithms, which construct a rule or function which labels any new sentence's feature vector as a summary vector or not",
        "prob": 0.5260869565217391
    }, {
        "ID": 9524,
        "phrase": " \n conclusion we have described a corpus-based machine learning approach to produce generic and user-specific summaries",
        "prob": 0.6937500000000001
    }, {
        "ID": 9524,
        "phrase": " this paper describes the use of machine learning on a training corpus of documents and their abstracts to discover salience functions which describe what combination of features is optimal for a given summarization task",
        "prob": 0.5695652173913043
    }, {
        "ID": 9528,
        "phrase": " developing learning techniques for language disambiguation has been an active field in recent years and a number of statistics based and machine learning techniques have been proposed",
        "prob": 0.40499999999999997
    }, {
        "ID": 9528,
        "phrase": " transformation based learning (tbl) transformation based learning  (brill 1995 ) is a machine learning approach for rule learning",
        "prob": 0.711764705882353
    }, {
        "ID": 9528,
        "phrase": "we analyze a few of the commonly used statistics based and machine learning algorithms for natural language disambiguation tasks and observe that they can be recast as learning linear separators in the feature space",
        "prob": 0.48260869565217396
    }, {
        "ID": 9564,
        "phrase": " the method used by the agents in their lifetime need not necessarily be machine learning",
        "prob": 0.3416666666666666
    }, {
        "ID": 9566,
        "phrase": " multi-agent systems having learning capabilities will reduce cost, time, and resources and increase quality in a number of forms  [11] : \u2022 ease of programming \u2022 ease of maintenance \u2022 widened scope of application \u2022 efficiency \u2022 coordination of activity on the other hand machine learning in a multi-agent set-up becomes faster and more robust  [11] ",
        "prob": 0.2189189189189189
    }, {
        "ID": 9571,
        "phrase": ", word pronunciation, is a well-known benchmark task in machine learning (sejnowski and rosenberg, 1987;  stanfill and waltz, 1986; stanfill, 1987; lehnert, 1987; wolpert, 1989; shavlik, mooney, and towell, 1991; dietterich, hild, and bakiri, 1995) ",
        "prob": 0.32400000000000007
    }, {
        "ID": 9595,
        "phrase": " both use machine learning methods, and require for training purposes a set of documents with keyphrases already attached",
        "prob": 0.5687500000000001
    }, {
        "ID": 9595,
        "phrase": " this binary feature is the class feature used by the machine learning scheme",
        "prob": 0.425
    }, {
        "ID": 9595,
        "phrase": " the machine learning scheme first builds a prediction model using training documents with known keyphrases, and then uses the model to find keyphrases in new documents",
        "prob": 0.55
    }, {
        "ID": 9604,
        "phrase": " home options profile help add documents feedback papers about find: order by: field: order by: max: field: searching for c l giles in machine learning (30161 documents 532908 citations total  as a citation example, figure  1  shows the top part of the results of a scienceindex query 3 for all citation to the author \"c",
        "prob": 0.3361111111111111
    }, {
        "ID": 9604,
        "phrase": " important issues that have concerned researchers include document representation home options profile help add documents feedback papers about find: order by: field: order by: max: field: searching for support vector machine in machine learning (30161 documents 532908 citations total)",
        "prob": 0.4441176470588235
    }, {
        "ID": 9604,
        "phrase": " \n\t\t\t currently, we are using only a small test scienceindex database on machine learning and artificial intelligence having about 30,000 documents and 533,000 citations",
        "prob": 0.5062500000000001
    }, {
        "ID": 9616,
        "phrase": " if statistical or knowledge-free methods are to solve some or most cases of any linguistic phenomenon, like wsd, how do we then locate that subclass of the phenomena that other, deeper, techniques like ai and knowledge-based reasoning are then to deal with? conversely, how can we know which cases the deeper techniques cannot or need not deal with? if there is an upper bound to empirical methods, and i have argued that that will be lower for wsd than for some other nlp tasks for the reasons set out above, then how can we pull in other techniques smoothly and seamlessly for the \"hard\" examples? the experience of pos tagging, to return to where we started, suggests that rule-driven taggers can do as well as purely machine learning-based taggers, which, if true, suggests that symbolic methods, in a broad sense, might still be the right approach for the whole task",
        "prob": 0.36133333333333334
    }, {
        "ID": 9616,
        "phrase": " we currently claim about 90% correct sense assignment  (wilks and stevenson, 1998b)  and do not expect to be able to improve much on that for the reasons set out above; we believe the rest is ai or lexical tuning! the general argument for continuing with the all-word paradigm, rather than the highly successful paradigm of yarowsky et al",
        "prob": 0.253125
    }, {
        "ID": 9691,
        "phrase": " transformation-based learning is a symbolic supervised machine learning method that generates a sequence of rules",
        "prob": 0.4066666666666666
    }, {
        "ID": 9691,
        "phrase": "  (brill 1995)  our machine learning algorithm makes use of several abstract features extracted from utterances  (samuel et al",
        "prob": 0.38125
    }, {
        "ID": 9691,
        "phrase": " however, we hypothesize that the repetitions should be eliminated in order to produce a more concise set of phrases, since this may increase the effectiveness of the machine learning method in tagging dialogue acts",
        "prob": 0.2652173913043478
    }, {
        "ID": 9691,
        "phrase": " as we hypothesized above, it appears that the irrelevant phrases in all limit the accuracy of the machine learning method",
        "prob": 0.23846153846153847
    }, {
        "ID": 9691,
        "phrase": " and we expect that this effect would be more pronounced for a larger training corpus (with more phrases) or another machine learning method (that is more susceptible to irrelevant features)",
        "prob": 0.3736842105263158
    }, {
        "ID": 9695,
        "phrase": " \n conclusions in the work presented here we have applied a popular machine learning technique, the transformation-based error-driven learning, to the task of part-of-speech tagging in the context of the greek language",
        "prob": 0.28400000000000003
    }, {
        "ID": 9716,
        "phrase": "an efficient algorithm for segmenting child-directed speech into words has recently been proposed in the machine learning journal",
        "prob": 0.25625
    }, {
        "ID": 9779,
        "phrase": " \n ai and machine learning there is an extensive body of work in ai and machine learning that is related to coin design",
        "prob": 0.43571428571428567
    }]
}, {
    "topic_id": 24,
    "top_words": ["ml", "algorithm", "decoding", "property", "theorem", "certificate", "decoder", "codes", "lp", "polynomial", "code", "time", "codeword", "length", "large"],
    "phrases": [{
        "ID": 425,
        "phrase": " we present the argument for ml 1 = 1 here",
        "prob": 0.15714285714285717
    }, {
        "ID": 541,
        "phrase": " , b ml , b 1r , ",
        "prob": 0.22000000000000003
    }, {
        "ID": 661,
        "phrase": " the higher starting point for the annotation-driven learning curves was due to the fact that the machine learning algorithm could do initial training immediately on this data",
        "prob": 0.29047619047619044
    }, {
        "ID": 1301,
        "phrase": " \n\t\t\t a 2-adic integer a is an infinite to the left formal sum i\u22650 ai2 i , with ai \u2208 {0, 1}",
        "prob": 0.51
    }, {
        "ID": 1312,
        "phrase": " trees, in particular tilings with an arbi-6 a 2-adic integer a is an infinite to the left formal sum i\u22650 ai2 i , with ai \u2208 {0, 1}",
        "prob": 0.43571428571428567
    }, {
        "ID": 1315,
        "phrase": "  6  a 2-adic integer a is an infinite to the left formal sum i\u22650 ai2 i , with ai \u2208 {0, 1}",
        "prob": 0.51
    }, {
        "ID": 1316,
        "phrase": " 7 a 2-adic integer a is an infinite to the left formal sum p i\u22650 ai2 i , with ai \u2208 {0, 1}",
        "prob": 0.51
    }, {
        "ID": 1464,
        "phrase": " the sequential ml method is more prone to excessive splitting, even for words that are not rare",
        "prob": 0.23846153846153847
    }, {
        "ID": 1464,
        "phrase": " however, both it and the sequential ml method can produce excessive splitting, as is shown for the latter, e",
        "prob": 0.23846153846153847
    }, {
        "ID": 2137,
        "phrase": " however, their algorithm can not handle evidence for c ai \u222a { a i c }",
        "prob": 0.2625
    }, {
        "ID": 2600,
        "phrase": " \n q: isn't automated theorem-proving very hard? current ai systems cannot prove nontrivial theorems without human intervention at crucial decision points",
        "prob": 0.305
    }, {
        "ID": 2601,
        "phrase": " q: isn't automated theorem-proving very hard? current ai systems cannot prove nontrivial theorems without human intervention at crucial decision points",
        "prob": 0.255
    }, {
        "ID": 2647,
        "phrase": " [24] proved that cbc mac is secure for fixed length messages, say for messages of length ml for some m",
        "prob": 0.74
    }, {
        "ID": 2647,
        "phrase": " as h em ac (k 1 , k 2 , m) = e(k 2 , h cbc (k 1 , m)) with an additional key k 2 = k 1 , even though we have expanded the domain of securely hashed messages from {0, 1} ml to ({0, 1} l ) + , we are still not able to mac arbitrary length messages",
        "prob": 0.5260869565217391
    }, {
        "ID": 2648,
        "phrase": " [24] proved that cbc mac is secure for fixed length messages, say for messages of length ml for some m",
        "prob": 0.74
    }, {
        "ID": 2648,
        "phrase": " as h em ac (k 1 , k 2 , m) = e(k 2 , h cbc (k 1 , m)) with an additional key k 2 = k 1 , even though we have expanded the domain of securely hashed messages from {0, 1} ml to ({0, 1} l ) + , we are still not able to mac arbitrary length messages",
        "prob": 0.5695652173913043
    }, {
        "ID": 3374,
        "phrase": " our prescription consists in taking p map b (\u01eb) = z good (\u01eb) for \u01eb < \u01eb ml and p map b (\u01eb) = z bad (\u01eb) for \u01eb > \u01eb map ",
        "prob": 0.3153846153846154
    }, {
        "ID": 3601,
        "phrase": " we show that an area theorem holds for such a function, implying, among other things, an upper bound on the ml threshold",
        "prob": 0.25625
    }, {
        "ID": 3622,
        "phrase": " a ? j+1 a ? n w w !c ai c w ?ai ( ) =a ( ) =a z = z l ! = z' l ! \n theorem 2",
        "prob": 0.22000000000000003
    }, {
        "ID": 3623,
        "phrase": " a ? j+1 a ? n w w !c ai c w ?ai ( ) =a z = z' l ! \n theorem 2",
        "prob": 0.22000000000000003
    }, {
        "ID": 3895,
        "phrase": " this property can be directly exploited for preprocessing, which allows a very efficient linear ml detection (corollary 4",
        "prob": 0.43571428571428567
    }, {
        "ID": 4061,
        "phrase": " however, we can still demonstrate that the complexity of the ml estimator is higher than that of our proposed algorithm",
        "prob": 0.3153846153846154
    }, {
        "ID": 4339,
        "phrase": " uniquety implies from the following fact: for arbitrary vector y = i ai \u2297 bi the linear independence of ai vectors implies that y = 0 \u21d4 bi = 0 for all bi",
        "prob": 0.43571428571428567
    }, {
        "ID": 4383,
        "phrase": " then pr ml {decoding failure} = 24 \u2211 w=0 \u03c8 ml (w) p w (1\u2212p) 24\u2212w where p is the erasure probability of the bec",
        "prob": 0.25833333333333336
    }, {
        "ID": 4383,
        "phrase": " it remains to compute \u03c8 h 24 , \u03c8 h \u2032 24 , and \u03c8 ml ",
        "prob": 0.3
    }, {
        "ID": 4384,
        "phrase": " pr ml {decoding failure} = 24 \u2211 w=0 \u03c8 ml (w) p w (1\u2212p) \u03c8 ml (w) = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 golay code g 12 h 12 = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ed 1 0 0 0 0 0 0 1 1 1 1 1 0 1 0 0 0 0 1 0 1 \u2212 \u2212 1 0 0 1 0 0 0 1 1 0 1 \u2212 \u2212 0 0 0 1 0 0 1 \u2212 1 0 1 \u2212 0 0 0 0 1 0 1 \u2212 \u2212 1 0 1 0 0 0 0 0 1 1 1 \u2212 \u2212 1 0 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f8 h \u2032 12 = \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed 0 0 0 0 0 1 1 1 \u2212 \u2212 1 0 1 1 \u2212 \u2212 1 0 0 0 0 0 0 \u2212 0 0 0 \u2212 1 0 0 0 1 1 \u2212 \u2212 \u2212 \u2212 1 0 0 1 1 1 0 0 0 0 0 0 \u2212 0 0 1 0 0 \u2212 1 \u2212 1 1 \u2212 0 1 1 0 1 \u2212 0 0 0 0 1 1 0 0 0 0 1 1 \u2212 0 0 \u2212 0 1 0 1 0 1 0 0 1 1 1 0 1 0 \u2212 0 1 0 0 \u2212 0 1 \u2212 0 0 0 \u2212 1 1 0 1 0 0 0 \u2212 1 1 0 0 1 1 1 0 0 0 1 0 1 0 0 1 0 1 1 0 1 1 1 0 0 \u2212 1 0 0 0 0 1 \u2212 0 1 1 0 0 \u2212 \u2212 1 0 0 \u2212 1 0 0 0 \u2212 0 0 0 0 1 1 \u2212 0 1 0 1 1 \u2212 0 1 1 0 1 0 0 \u2212 \u2212 0 0 0 \u2212 1 0 \u2212 1 0 0 \u2212 0 1 0 \u2212 0 0 \u2212 1 0 0 \u2212 0 0 1 1 0 \u2212 0 \u2212 1 0 \u2212 0 0 \u2212 0 1 1 0 \u2212 0 1 1 1 0 \u2212 0 0 0 1 0 1 1 1 0 0 0 1 0 1 0 0 1 0 \u2212 \u2212 1 0 0 0 0 \u2212 1 \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 \n vi",
        "prob": 0.3416666666666666
    }, {
        "ID": 4384,
        "phrase": " it remains to compute \u03c8 h 24 , \u03c8 h \u2032 24 w=0 \u2211 \u03c8 h 24 (w) p w (1\u2212p) 24\u2212w pr h \u2032 24 {decoding failure} = 24 \u2211 w=0 \u03c8 h \u2032 24 (w) p w (1\u2212p) 24\u2212w 24, and \u03c8 ml ",
        "prob": 0.51
    }, {
        "ID": 4786,
        "phrase": " however, it is clear that although modifying the boundary control may result in a significant complexity increase for ml decoding, lattice decoding is not affected at all, since tz m = z m ",
        "prob": 0.2318181818181818
    }, {
        "ID": 4786,
        "phrase": " the dependence of the first error term on \u03c1 is of the form \u03c1 \u2212(n/2) for large values of snr, and hence has the same diversity as the ml decoder",
        "prob": 0.19375
    }, {
        "ID": 5037,
        "phrase": " ii discusses ml and lp decoding and secs",
        "prob": 0.23333333333333334
    }, {
        "ID": 5046,
        "phrase": " in  [7]  the latter approach was extended to a list-decoding scheme, and it was shown that ml decoding of rm 2 (1, m) is possible if the list length is equal to 2",
        "prob": 0.2833333333333333
    }, {
        "ID": 5046,
        "phrase": " in  [11]  an ml decoder was given for rm 4 (1, m), by treating rm 4 (1, m) itself as a union of 2 m cosets of rm 2 (1, m + 1)",
        "prob": 0.46923076923076923
    }, {
        "ID": 5046,
        "phrase": " consequently an ml decoder for rm q (1, m) for arbitrary q was obtained",
        "prob": 0.41
    }, {
        "ID": 5046,
        "phrase": " in this letter we present a new ml decoder for rm q (1, m), which appears to have lower complexity than the above mentioned ml decoding schemes",
        "prob": 0.3588235294117647
    }, {
        "ID": 5046,
        "phrase": " this property will be used in the next section to derive an efficient ml decoding scheme for rm q (1, m)",
        "prob": 0.2928571428571428
    }, {
        "ID": 5046,
        "phrase": " proof: we will show that, if algorithm 2 is an ml decoder for rm q (1, m \u2212 1), then it is also an ml decoder for rm q (1, m)",
        "prob": 0.6230769230769231
    }, {
        "ID": 5046,
        "phrase": " we finally remark that the ml decoder for rm 4 (1, m) in  [11]  requires (m + 1)2 2m+1 real additions",
        "prob": 0.3416666666666666
    }, {
        "ID": 5075,
        "phrase": " however, unlike in ml decoding, the output of the lp decoder may not be a 0-1 vector, in which case the decoder simply declares an error",
        "prob": 0.2833333333333333
    }, {
        "ID": 5288,
        "phrase": " note that, although the ml performance does not translate directly to the iterative decoding performance of the codes, the value of this result is twofold",
        "prob": 0.3588235294117647
    }, {
        "ID": 5289,
        "phrase": " note that, although the ml performance does not translate directly to the iterative decoding performance of the codes, the value of this result is twofold",
        "prob": 0.3588235294117647
    }, {
        "ID": 5379,
        "phrase": " in this work, we develop an efficient approximate ml decoder for mimo systems based on sdp",
        "prob": 0.3153846153846154
    }, {
        "ID": 5379,
        "phrase": " the sdp soft decoder is derived as an efficient solution of the max-approximated soft ml decoder",
        "prob": 0.2733333333333333
    }, {
        "ID": 5379,
        "phrase": " \n gangster operation \u2212 rounding sdp model \u2212 gangster operation \u2212 algorithm i sdp model \u2212 gangster operation \u2212 algorithm ii sdp model \u2212 non negative constraint \u2212 rounding ml decoding \n , \u2022 \u2022 \u2022 , sk } with an average energy of \u1ebdsav ",
        "prob": 0.3964285714285714
    }, {
        "ID": 5817,
        "phrase": " in such a case the result produced will not be the ml codeword",
        "prob": 0.4555555555555555
    }, {
        "ID": 5818,
        "phrase": " in such a case the result produced will not be the ml codeword",
        "prob": 0.4555555555555555
    }, {
        "ID": 5888,
        "phrase": " for each i = 1 to n, find a nonzero coefficient \u03b6e i of x e i in some polynomial f a,b l (x) \u2208 \u03c6 such that ai \u2264 ei \u2264 bi",
        "prob": 0.2333333333333333
    }, {
        "ID": 5908,
        "phrase": " another characteristic of lp decoding (the ml certificate property) is that its failure to find the ml codeword is detectable",
        "prob": 0.63125
    }, {
        "ID": 5908,
        "phrase": " due to the ml certificate property of lp decoding, we know that ml decoding would fail in those cases, as well",
        "prob": 0.41764705882352937
    }, {
        "ID": 5908,
        "phrase": " the key idea was to use the fact that we can always recognize the failure of lp decoding to find the ml codeword, a property that message-passing algorithms only have in specific cases such as the erasure channel",
        "prob": 0.25416666666666665
    }, {
        "ID": 5932,
        "phrase": " map is reduced to ml in the limit of infinite snr",
        "prob": 0.41
    }, {
        "ID": 5932,
        "phrase": " decoding to a codeword can also be a failure, but this would as well counts as a failure under the ml decoding",
        "prob": 0.5461538461538461
    }, {
        "ID": 5932,
        "phrase": " at large snr splitting of the two fer vs snr curves, representing ml decoding and approximate decoding (say lp decoding) is due to the pseudo codewords",
        "prob": 0.5695652173913043
    }, {
        "ID": 5932,
        "phrase": " the lp asymptotic is normally shallower than the ml one, d lp < d ml ",
        "prob": 0.4636363636363636
    }, {
        "ID": 5933,
        "phrase": " decoding to a codeword can also be a failure, but this also counts as a failure under the ml decoding",
        "prob": 0.6454545454545454
    }, {
        "ID": 5933,
        "phrase": " for large snr, splitting of the two (fer vs snr) curves, representing ml decoding and approximate decoding (say lp decoding) is due to the pseudo-codewords",
        "prob": 0.4826086956521739
    }, {
        "ID": 5933,
        "phrase": " the lp asymptotic is normally shallower than the ml one, d lp < d ml ",
        "prob": 0.6454545454545454
    }, {
        "ID": 5934,
        "phrase": ", there is a unique path connecting any two bits through a sequence of other bits and their neighboring checks), the sum-product algorithm (with sufficient number of iterations) is exactly equivalent to the so-called maximum-a-posteriori (map) decoding, which is reduced to ml in the asymptotic limit of infinite snr",
        "prob": 0.27575757575757576
    }, {
        "ID": 5934,
        "phrase": " decoding to a codeword can also be a failure, which counts as a failure under the ml decoding",
        "prob": 0.6454545454545454
    }, {
        "ID": 5934,
        "phrase": " for large snr, splitting of the two (fer vs snr) curves, representing the ml decoding and an approximate decoding (say lp decoding) is due to the pseudo-codewords",
        "prob": 0.6130434782608696
    }, {
        "ID": 5934,
        "phrase": " the lp asymptotic is normally shallower than the ml one, d lp < d ml ",
        "prob": 0.6454545454545454
    }, {
        "ID": 5935,
        "phrase": ", there is a unique path connecting any two bits through a sequence of other bits and their neighboring checks), the sum-product algorithm (with sufficient number of iterations) is exactly equivalent to the so-called maximum-a-posteriori (map) decoding, which is reduced to ml in the asymptotic limit of infinite snr",
        "prob": 0.33636363636363636
    }, {
        "ID": 5935,
        "phrase": " decoding to a codeword can also be a failure, which counts as a failure under ml decoding",
        "prob": 0.5545454545454546
    }, {
        "ID": 5935,
        "phrase": " the lp error-floor asymptotic is normally shallower than the ml one, d lp < d ml ",
        "prob": 0.3923076923076923
    }, {
        "ID": 5953,
        "phrase": " from the results of simulations on the rate 1/2, memory 4 convolutional code with a circle size of 20 and a rate 1/2 memory 6 convolutional code with a circle size of 48, it is seen that the algorithm performs close to the ideal ml decoder",
        "prob": 0.324
    }, {
        "ID": 6149,
        "phrase": " theorem 2 implies that the \"early stopping\" rule can guarantee ml decoding successful at node 1",
        "prob": 0.36428571428571427
    }, {
        "ID": 6165,
        "phrase": " one desirable property of the lp decoder is the ml certificate property, i",
        "prob": 0.5545454545454546
    }, {
        "ID": 6165,
        "phrase": " first we prove that if the algorithm terminates, then we have an ml decoder",
        "prob": 0.41
    }, {
        "ID": 6165,
        "phrase": " in this context, improved turbo decoding is near ml decoding when the fraction of ml-decodable frame errors observed in the simulation is 0",
        "prob": 0.2833333333333333
    }, {
        "ID": 6177,
        "phrase": " m in the ml sense",
        "prob": 0.18333333333333335
    }, {
        "ID": 6190,
        "phrase": " \n ml and lp decoding in this section we briefly review ml and lp decoding  [1, 2] ",
        "prob": 0.3923076923076923
    }, {
        "ID": 6229,
        "phrase": " due to its generalization property, the cc4 algorithm can be used efficiently for certain ai problems",
        "prob": 0.23846153846153845
    }, {
        "ID": 6308,
        "phrase": " ml probability in the individual case",
        "prob": 0.2625
    }, {
        "ID": 6308,
        "phrase": ", there exist sequences x n that can be generated by \u03b8 and result in an ml i",
        "prob": 0.34444444444444444
    }, {
        "ID": 6308,
        "phrase": " (we note that the derivation above also applies in the limit if there exist components of \u03d5 whose ml estimates are 0",
        "prob": 0.23846153846153847
    }, {
        "ID": 6617,
        "phrase": ") the ml estimator of letter i from z n thus satisfies \u03b8i (z n ) = \u03b8j (x n )",
        "prob": 0.23333333333333334
    }, {
        "ID": 6969,
        "phrase": " for a comprehensive tutorial paper on performance bounds of linear codes under ml decoding, the reader is referred to  [29] ",
        "prob": 0.2733333333333333
    }, {
        "ID": 7232,
        "phrase": " in fact, the existence of a polynomial-time separation oracle for the codeword polytope of a general linear code is very unlikely since ml decoding for arbitrary linear codes is np-hard  [2] ",
        "prob": 0.6708333333333333
    }, {
        "ID": 7233,
        "phrase": " in fact, the existence of a polynomial-time separation oracle for the codeword polytope of a general linear code is very unlikely since ml decoding for arbitrary linear codes is np-hard  [2] ",
        "prob": 0.5875
    }, {
        "ID": 7408,
        "phrase": " hence it remains to show that l\u03c3 \u2032 \u2704 ai r\u03b8 \u2032 ",
        "prob": 0.3
    }, {
        "ID": 7420,
        "phrase": " moreover, if r covers y with ykdkd = il (k,r,t)t ai h i ( y ) for all (k, r, t) e a g ( y ) , then, we say that (y, z) \"consists of' t",
        "prob": 0.21000000000000002
    }, {
        "ID": 7534,
        "phrase": " the sum-product algorithm  [6]  can be viewed as a generalization of the belief propagation (bp) algorithm developed in ai  [10] ",
        "prob": 0.2928571428571428
    }, {
        "ID": 7539,
        "phrase": " it remains only to bound kl(z||z ml )",
        "prob": 0.2625
    }, {
        "ID": 7539,
        "phrase": " by proposition 3 we have kl(z||z ml ) \u2264 28\u01eb + 4\u01eb + 2\u01eb \u2022 kl(z||z ml ) which implies that kl(z||z ml ) \u2264 33\u01eb",
        "prob": 0.6749999999999999
    }, {
        "ID": 7736,
        "phrase": " we say that the decoding algorithm exhibits the ml certificate property, if whenever the decoder decides on a codeword \u0109 \u2208 c, there does not exist another codeword c \u2032 \u2208 c, which has a smaller hamming distance to y than \u0109",
        "prob": 0.6714285714285714
    }, {
        "ID": 7736,
        "phrase": " to show that algorithm 2 exhibits the ml certificate property, we state the following lemma, which immediately follows from the definitions of the error locator polynomial and the syndromes in section iii: lemma 3 consider a codeword a \u2208 a of an irs code according to definition 3",
        "prob": 0.41724137931034483
    }, {
        "ID": 7736,
        "phrase": " lemma 3 is helpful for proving the following theorem: theorem 4 (ml certificate of algorithm 2) the decoder specified by algorithm 2 exhibits the ml certificate property",
        "prob": 0.705
    }, {
        "ID": 7736,
        "phrase": " error probability now, we derive an upper bound on p e for the general case that a linear block code is decoded by a bd decoder which exhibits the ml certificate property",
        "prob": 0.33809523809523806
    }, {
        "ID": 7736,
        "phrase": " theorem 4 and lemma 4 enable us to prove the following theorem, which overbounds the error probability p e (t): theorem 5 (error probability) let c(q; n, k, d) be a linear block code of length n , dimension k, and minimum distance d over the field f q , decoded by a bd decoder which exhibits the ml certificate property",
        "prob": 0.5323529411764706
    }, {
        "ID": 7736,
        "phrase": " however, we only count the points on s \u2032 , which have a maximum distance of t to c \u2032 , since otherwise they are closer to c than to c \u2032 , and due to the ml certificate property we know that they are correctly decoded into the codeword c",
        "prob": 0.5549999999999999
    }, {
        "ID": 7736,
        "phrase": " theorem 5 basically holds for arbitrary linear block codes over the field f q , which are decoded up to the maximum error correcting radius t max by a decoder exhibiting the ml certificate property",
        "prob": 0.6130434782608696
    }, {
        "ID": 7736,
        "phrase": " due to theorem 4, algorithm 2 exhibits the ml certificate property, and hence  (13)  provides us with an upper bound on the error probability p e (t)",
        "prob": 0.39444444444444443
    }, {
        "ID": 7737,
        "phrase": " we say that the decoding algorithm exhibits the ml certificate property, if whenever the decoder decides on a codeword \u0109 \u2208 c, there does not exist another codeword c \u2032 \u2208 c, which has a smaller hamming distance to y than \u0109",
        "prob": 0.5761904761904761
    }, {
        "ID": 7737,
        "phrase": " to show that algorithm 2 exhibits the ml certificate property, we state the following lemma, which immediately follows from the definitions of the error locator polynomial and the syndromes in section iii: lemma 3 consider a codeword a \u2208 a of an irs code according to definition 3",
        "prob": 0.4862068965517241
    }, {
        "ID": 7737,
        "phrase": " lemma 3 is helpful for proving the following theorem: theorem 4 (ml certificate of algorithm 2) the decoder specified by algorithm 2 exhibits the ml certificate property",
        "prob": 0.755
    }, {
        "ID": 7737,
        "phrase": " error probability now, we derive an upper bound on p e for the general case that a linear block code is decoded by a bd decoder which exhibits the ml certificate property",
        "prob": 0.3857142857142857
    }, {
        "ID": 7737,
        "phrase": " theorem 4 and lemma 4 enable us to prove the following theorem, which overbounds the error probability p e (t): theorem 5 (error probability) let c(q; n, k, d) be a linear block code of length n , dimension k, and minimum distance d over the field f q , decoded by a bd decoder which exhibits the ml certificate property",
        "prob": 0.5323529411764706
    }, {
        "ID": 7737,
        "phrase": " however, we only count the points on s \u2032 , which have a maximum distance of t to c \u2032 , since otherwise they are closer to c than to c \u2032 , and due to the ml certificate property we know that they are correctly decoded into the codeword c",
        "prob": 0.655
    }, {
        "ID": 7737,
        "phrase": " theorem 5 basically holds for arbitrary linear block codes over the field f q , which are decoded up to the maximum error correcting radius t max by a decoder exhibiting the ml certificate property",
        "prob": 0.6130434782608696
    }, {
        "ID": 7849,
        "phrase": " it was realized early on that in an infinite  7  constraint length convolutional code under ml decoding, all bits will eventually be decoded correctly  [4] ",
        "prob": 0.711764705882353
    }, {
        "ID": 7850,
        "phrase": " it was realized early on that in an infinite-constraint-length convolutional code under ml decoding, all bits will eventually be decoded correctly  [8] ",
        "prob": 0.7705882352941176
    }, {
        "ID": 7851,
        "phrase": " it was realized early on that in an infinite 1 constraint length convolutional code under ml decoding, all bits will eventually be decoded correctly  [7] ",
        "prob": 0.7705882352941176
    }, {
        "ID": 7852,
        "phrase": " it was realized early on that in an infinite 1 constraint length convolutional code under ml decoding, all bits will eventually be decoded correctly  [7] ",
        "prob": 0.7705882352941176
    }, {
        "ID": 7857,
        "phrase": " both the encoder and decoder must be causal so ai and b bi are functions only of quantities to the left of them on the timeline",
        "prob": 0.25833333333333336
    }, {
        "ID": 7858,
        "phrase": " lemma 2: p n (l) \u2264 exp{\u2212(n \u2212 l + 1)e ml (r x )}",
        "prob": 0.3
    }, {
        "ID": 7939,
        "phrase": " this immediately implies that for the corresponding families of codes, the ml decoding problem can be solved in time polynomial in the length of the code",
        "prob": 0.6529411764705882
    }, {
        "ID": 7939,
        "phrase": " given the fact that the ml decoding problem is known to be np-hard in general  [4] , the existence of \"non-trivial\" classes of codes for which ml decoding can be implemented in polynomial time, is obviously a significant result",
        "prob": 0.4269230769230769
    }, {
        "ID": 7939,
        "phrase": " however, they do illustrate the important point that polynomial-time ml decoding is possible",
        "prob": 0.3153846153846154
    }, {
        "ID": 7939,
        "phrase": " moreover, the matroid-theoretic arguments used by gr\u00f6tschel and truemper do not rule out the possibility that there may exist other code families for which polynomial-time ml decoding algorithms exist, which are also good in terms of rate and minimum distance",
        "prob": 0.6107142857142857
    }, {
        "ID": 7939,
        "phrase": " thus, the ml decoding problem can be solved in polynomial time for almost-graphic codes",
        "prob": 0.5071428571428571
    }, {
        "ID": 7939,
        "phrase": " this result does not, however, preclude the existence of good code families for which ml decoding can be performed in polynomial time",
        "prob": 0.56875
    }, {
        "ID": 7939,
        "phrase": " however, ml decoding of an arbitrary code is known to be np-hard  [4] ",
        "prob": 0.17500000000000002
    }, {
        "ID": 7939,
        "phrase": " therefore, we have the following corollary to the above theorem, again with the caveat that a true implementation of a polynomial-time algorithm for ml decoding would require real-number arithmetic",
        "prob": 0.4333333333333333
    }, {
        "ID": 7939,
        "phrase": " we translate matroid-theoretic results of gr\u00f6tschel and truemper from the combinatorial optimization literature to give examples of non-trivial families of codes for which the ml decoding problem can be solved in time polynomial in the length of the code",
        "prob": 0.5592592592592592
    }, {
        "ID": 7940,
        "phrase": " this immediately implies that for the corresponding families of codes, the ml decoding problem can be solved in time polynomial in the length of the code",
        "prob": 0.711764705882353
    }, {
        "ID": 7940,
        "phrase": " given the fact that the ml decoding problem is known to be np-hard in general  [4] , the existence of \"non-trivial\" classes of codes for which ml decoding can be implemented in polynomial time, is obviously a significant result",
        "prob": 0.23461538461538461
    }, {
        "ID": 7940,
        "phrase": " moreover, the matroid-theoretic arguments used by gr\u00f6tschel and truemper do not rule out the possibility that there may exist other code families for which polynomial-time ml decoding algorithms exist, which are also good in terms of rate and minimum distance",
        "prob": 0.6107142857142857
    }, {
        "ID": 7940,
        "phrase": " however, ml decoding of an arbitrary code is known to be np-hard  [4] ",
        "prob": 0.25833333333333336
    }, {
        "ID": 7940,
        "phrase": " the fact that c = j (h) for such a polytope q(h) implies that the polytope has the following \"ml certificate\" property [15, proposition 2]: if the lp min x\u2208q(h) \u03b3, x , where \u03b3 is the vector defined via  (9) , attains its minimum at some x \u2208 j (h), then x is guaranteed to be the ml codeword",
        "prob": 0.6291666666666667
    }, {
        "ID": 7940,
        "phrase": " for such codes, ml decoding can be exactly implemented as an lp over q(h)",
        "prob": 0.5545454545454546
    }, {
        "ID": 7940,
        "phrase": " fortunately, as we shall describe next, for the family, g, of geometrically perfect codes, ml decoding can always be implemented in time polynomial in codelength, not using an lp-solving algorithm, but by means of a combinatorial optimization algorithm that uses code decompositions",
        "prob": 0.33666666666666667
    }, {
        "ID": 7940,
        "phrase": " for example, it is known  [37] ,  [31]  that the ml decoding problem over a memoryless binary symmetric channel can be solved in polynomial time for the family of graphic codes using edmonds' matching algorithm  [13] ,  [14] ",
        "prob": 0.30869565217391304
    }, {
        "ID": 7940,
        "phrase": " therefore, we have the following corollary to the above theorem, again with the caveat that a true implementation of a polynomial-time algorithm for ml decoding would require real-number arithmetic",
        "prob": 0.3857142857142857
    }, {
        "ID": 7940,
        "phrase": " we translate matroid-theoretic results of gr\u00f6tschel and truemper from the combinatorial optimization literature to give examples of non-trivial families of codes for which the ml decoding problem can be solved in time polynomial in the length of the code",
        "prob": 0.5592592592592592
    }, {
        "ID": 8489,
        "phrase": " decoding to a codeword can also be a failure, which counts as a failure under the ml decoding",
        "prob": 0.5545454545454546
    }, {
        "ID": 8489,
        "phrase": " for large snr, splitting of the two (fer vs snr) curves, representing ml decoding and approximate decoding (say lp decoding) is due to the pseudo-codewords",
        "prob": 0.4826086956521739
    }, {
        "ID": 8489,
        "phrase": " the lp asymptotic is normally shallower than the one of map, d lp < d ml ",
        "prob": 0.6454545454545454
    }, {
        "ID": 8490,
        "phrase": " decoding to a codeword can also be a failure, which counts as a failure under the ml decoding",
        "prob": 0.5545454545454546
    }, {
        "ID": 8490,
        "phrase": " for large snr, splitting of the two (fer vs snr) curves, representing ml decoding and approximate decoding (say lp decoding) is due to the pseudocodewords",
        "prob": 0.41363636363636364
    }, {
        "ID": 8490,
        "phrase": " the lp asymptotic is normally shallower than the one of map, d lp < d ml ",
        "prob": 0.6454545454545454
    }, {
        "ID": 8707,
        "phrase": " it was recognized that for moderate and large snrs splitting of the two (fer vs snr) curves, representing ml decoding and approximate bp/lp decoding, is due to the pseudo-codewords, which are confused by the suboptimal algorithm for actual codewords of the code",
        "prob": 0.5206896551724138
    }, {
        "ID": 8708,
        "phrase": " it was recognized that for moderate and large snrs splitting of the two (fer vs snr) curves, representing ml decoding and approximate bp/lp decoding, is due to the pseudo-codewords, which are confused by the suboptimal algorithm for actual codewords of the code",
        "prob": 0.5551724137931034
    }, {
        "ID": 8882,
        "phrase": " the term ml certificate property was introduced in  [26] , where it is shown that a decoding algorithm based on linear programming exhibits this property",
        "prob": 0.5352941176470588
    }, {
        "ID": 8882,
        "phrase": " formally, we define the ml certificate property as follows: definition 4 (ml certificate property) consider a code c, and assume that the word y is received when a codeword c \u2208 c is transmitted over a memoryless noisy channel",
        "prob": 0.29583333333333334
    }, {
        "ID": 8882,
        "phrase": " we say that the decoding algorithm exhibits the ml certificate property, if it behaves in such a way that whenever it yields a codeword \u0109 \u2208 c, this codeword fulfills dist (y, \u0109) = min c\u2208c {dist (y, c)} ",
        "prob": 0.6238095238095238
    }, {
        "ID": 8882,
        "phrase": " moreover, it is shown that this algorithm possesses the ml certificate property",
        "prob": 0.4636363636363636
    }, {
        "ID": 8882,
        "phrase": " theorem 1 algorithm 2 possesses the ml certificate property",
        "prob": 0.51
    }, {
        "ID": 8882,
        "phrase": " moreover, we are able to use the following result from  [20] : theorem 2 (error probability) let c(q; n, k, d) be a linear block code of length n, dimension k, and minimum distance d over the field f q , decoded by a bd decoder which exhibits the ml certificate property",
        "prob": 0.6241379310344828
    }, {
        "ID": 8882,
        "phrase": " ( 16 ) since algorithm 2 possesses the ml certificate property, theorem 2 can directly be applied for overbounding the error probability p e ",
        "prob": 0.50625
    }, {
        "ID": 8907,
        "phrase": " the current paper deals with both these issues; we show that a certain class of asymptotically good ldpcs (so-called expander codes) admit average polynomial-time ml decoding over bscs and binary input awgn (bi-awgn) channels in certain rate regions",
        "prob": 0.23823529411764705
    }, {
        "ID": 8907,
        "phrase": "it is based on the existence of polynomialtime suboptimal decoders with an ml certificate property",
        "prob": 0.5083333333333333
    }, {
        "ID": 8907,
        "phrase": " then if we perform exhaustive search over the codebook whenever the suboptimal decoder fails to give an ml certificate, the expected complexity of the resulting ml algorithm, en ml (n), will clearly be en ml (n) = n (n) + k(n)p e (n)2 nr , (1) where k(n) is a polynomial constant representing the compu-tation incurred per codeword in the exhaustive search",
        "prob": 0.46
    }, {
        "ID": 8907,
        "phrase": " clearly, if p e (n)2 nr \u2192 0, then the ml algorithm will have expected polynomial-time complexity (equal to the complexity of the suboptimal decoder)",
        "prob": 0.44375
    }, {
        "ID": 8907,
        "phrase": " one such ml certificate decoder is the lp decoder of feldman  [11] ",
        "prob": 0.51
    }, {
        "ID": 8907,
        "phrase": " we also propose a more efficient ml certificate decoder (reducing the worst-case complexity of the lp decoder from o(n 9 ) to o(n 2 )) which is based on the work of sipser and spielman  [12]  and the ford-fulkerson algorithm",
        "prob": 0.6409090909090909
    }, {
        "ID": 8907,
        "phrase": " we further characterize the achievable rate region r ml (albeit loosely) in which there exists a family of asymptotically good expander codes whose error probability goes to zero exponentially under an exact ml decoding algorithm with expected polynomial complexity",
        "prob": 0.5033333333333333
    }, {
        "ID": 8907,
        "phrase": " section ii studies exact ml decoding for expander codes with expected polynomial complexity under unlimited preprocessing of the codes",
        "prob": 0.6529411764705882
    }, {
        "ID": 8907,
        "phrase": " section iii proposes a new ml certificate algorithm and shows that exact ml decoding in expected polynomial-time is possible even without preprocessing",
        "prob": 0.45909090909090905
    }, {
        "ID": 8907,
        "phrase": " expected polynomial complexity exact ml decoding with unlimited preprocessing we begin by allowing for unlimited preprocessing of the codebook as it makes the problem simpler and sets the stage for the subsequent proofs",
        "prob": 0.46249999999999997
    }, {
        "ID": 8907,
        "phrase": " the novelty here is that, if the minimum distance is known, an ml certificate can be provided",
        "prob": 0.4636363636363636
    }, {
        "ID": 8907,
        "phrase": " so if the fraction of errors is no larger than \u03b1 2 , the algorithm will provide the ml certificate",
        "prob": 0.4636363636363636
    }, {
        "ID": 8907,
        "phrase": " then the expected computational time of an ml decoding algorithm over the bsc channel, n ml (n), is polynomial in n, given that p < \u03b1 2 and r < d( \u03b1 2 p)",
        "prob": 0.47333333333333333
    }, {
        "ID": 8907,
        "phrase": " theorem 2: for any rate 0 < r < 1, there exists a threshold 0 < p * < 1 and a family of asymptotically good block codes with rate r and length n such that when allowing preprocessing of the codes, exact ml decoding can be achieved with an expected polynomial complexity in n over the bsc with bit flipping probability 0 \u2264 p < p * ",
        "prob": 0.41724137931034483
    }, {
        "ID": 8907,
        "phrase": " lemma 5: for any family of (\u03b1n, 3c/4) expander codes with increasing code length n and a constant \u03b1 > 0, the improvement in the lower bound of the error exponent by using the ml algorithm instead of the \"simple sequential decoding algorithm\"  [12]  for this family of codes is arbitrarily large if p is sufficiently small but remains positive",
        "prob": 0.4878787878787879
    }, {
        "ID": 8907,
        "phrase": " in this section, the key to obtaining a polynomial-time ml certificate algorithm was knowing the minimum distance of the code (which must be precomputed)",
        "prob": 0.44999999999999996
    }, {
        "ID": 8907,
        "phrase": " we now show that such ml certificate algorithms can be obtained without preprocessing",
        "prob": 0.3727272727272727
    }, {
        "ID": 8907,
        "phrase": " expected polynomial complexity exact ml decoding without preprocessing in lp decoding over memoryless channels the problem is relaxed to a linear programming problem with polynomial complexity  [11] ",
        "prob": 0.43913043478260866
    }, {
        "ID": 8907,
        "phrase": " the above theorem implies that p e (n) can be computed as in the previous section and that the lp decoder, in conjunction with exhaustive search, is an expected polynomial time ml decoder",
        "prob": 0.4263157894736842
    }, {
        "ID": 8907,
        "phrase": " we now show that the ml certificate property can be achieved with worst-case complexity o(n 2 ), without sacrificing the guaranteed performance",
        "prob": 0.63125
    }, {
        "ID": 8907,
        "phrase": " moreover, without looking for the dual feasible edge weight assignment, the new algorithm and its direct proof provide more intuition about why expander codes efficiently correct a constant fraction of errors while having the ml certificate property even without preprocessing",
        "prob": 0.4225806451612903
    }, {
        "ID": 8907,
        "phrase": " the ford-fulkerson algorithm can be easily integrated into any belief propagation decoder to efficiently offer them the ml certificate property,which can help the decoder decide whether it is necessary to perform more computations to improve the performance",
        "prob": 0.31153846153846154
    }, {
        "ID": 8907,
        "phrase": " the following lemma gives a performance guarantee of the new ml certificate algorithm",
        "prob": 0.3923076923076923
    }, {
        "ID": 8907,
        "phrase": " then if x \u2032 is in the code c and is different from r in at most 3\u03b4\u22122 2\u03b4\u22121 (\u03b1n \u2212 1) positions, x \u2032 will be certified to be an ml codeword in the new ml certificate algorithm",
        "prob": 0.5785714285714285
    }, {
        "ID": 8907,
        "phrase": " when \u03b4 = 3/4, the new algorithm is guaranteed to correct up to \u03b1/2 fraction of errors while providing ml certificate property,which matches the proved capability of lp decoder",
        "prob": 0.531578947368421
    }, {
        "ID": 8907,
        "phrase": " from lemma 6 and 7, we see that the new ml certificate algorithm corrects a constant fraction of errors with low complexity",
        "prob": 0.56875
    }, {
        "ID": 8907,
        "phrase": " since the lp decoder and the newly proposed ml certificate decoder can correct a constant fraction of errors without preprocessing, we have a counterpart of theorem 2 for the case of no preprocessing allowed",
        "prob": 0.6130434782608696
    }, {
        "ID": 8907,
        "phrase": " by constructing a linear code with rate t from the expander graph (noticing that the rate of the code t can be made smaller than r) and applying the expected polynomialtime ml decoders described, we get the desired result",
        "prob": 0.5041666666666667
    }, {
        "ID": 8907,
        "phrase": " then from lemma 8,there is a p * such that for 0 < p < p * ,such that t = r \u2208 r ml (p)",
        "prob": 0.35000000000000003
    }, {
        "ID": 8907,
        "phrase": " expected complexity versus worse-case complexity:a contrast in this part, we prove that for any 0 < t < 1, t \u2264 r < 1, the exact ml decoding problem remains np-hard for the family of codes c of rate r \u2264 t constructed by adding linear constraints to the ldp c codes c \u2032 of rate at least r defined by tanner graphs g with regular left degree c \u2265 3",
        "prob": 0.35405405405405405
    }, {
        "ID": 8907,
        "phrase": " so the ml decoding of the considered family of codes is np-hard in the worst case",
        "prob": 0.3153846153846154
    }, {
        "ID": 8907,
        "phrase": " in this paper, we show that exact ml decoding of a classs of asymptotically good error correcting codes-expander codes, a special case of low density parity check (ldpc) codesover binary symmetric channels (bscs) is possible with an expected polynomial complexity",
        "prob": 0.36666666666666664
    }, {
        "ID": 8907,
        "phrase": " the result is based on the existence of polynomial-time suboptimal decoding algorithms that provide an ml certificate and the ability to compute the probability that the suboptimal decoder yields the ml solution",
        "prob": 0.4826086956521739
    }, {
        "ID": 8907,
        "phrase": " one such ml certificate decoder is the lp decoder of feldman; we also propose a more efficient o(n 2 ) algorithm based on the work of sipser and spielman and the ford-fulkerson algorithm",
        "prob": 0.655
    }, {
        "ID": 9163,
        "phrase": " another characteristic of lp decoding -the ml certificate property -is that its failure to find an ml codeword is always detectable",
        "prob": 0.4789473684210526
    }, {
        "ID": 9163,
        "phrase": " due to the ml certificate property of lp decoding, we know that ml decoding would fail in those cases, as well",
        "prob": 0.5352941176470588
    }, {
        "ID": 9163,
        "phrase": " key to this approach is the ml certificate property of lp decoders, that is, the ability to detect the failure to find the ml codeword",
        "prob": 0.5941176470588235
    }, {
        "ID": 9163,
        "phrase": " the ml certificate property makes it possible to selectively and adaptively add only those constraints that are \"useful,\" depending on the current status of the lp decoding process",
        "prob": 0.355
    }, {
        "ID": 9224,
        "phrase": " \n the lcf interactive theorem prover edinburgh lcf introduced a new approach to theorem proving: embed the formal logic in a programmable meta language, ml  [15] ",
        "prob": 0.2318181818181818
    }, {
        "ID": 9228,
        "phrase": " ml provides functions to decompose a theorem into its conclusion and assumptions, but not to construct an arbitrary theorem",
        "prob": 0.2928571428571428
    }, {
        "ID": 9228,
        "phrase": "  gordon [$gordon82 ] gives a good introduction to ml and its use in theorem-proving",
        "prob": 0.3923076923076923
    }, {
        "ID": 9259,
        "phrase": " indeed, the idea of employing error-correcting, distributed representations can be traced to early research in machine learning  (duda, machanik, & singleton, 1963) ",
        "prob": 0.1631578947368421
    }, {
        "ID": 9579,
        "phrase": " this property is very useful for ai due to possibility of \"learning\" by constructing of new algorithms",
        "prob": 0.25833333333333336
    }, {
        "ID": 9725,
        "phrase": " , x q ) denote the polynomial n i=1 f ai \u2212 n i=1 f bi ",
        "prob": 0.18333333333333335
    }]
}, {
    "topic_id": 25,
    "top_words": ["ij", "nm", "two", "definition", "let", "aj", "without", "st", "since", "equal", "relation", "tcs", "mt", "key", "defined"],
    "phrases": [{
        "ID": 141,
        "phrase": "y n , is therefore \u00b5 ai (y 1 x 1 ",
        "prob": 0.22000000000000003
    }, {
        "ID": 661,
        "phrase": " since annotated data can be used by other current or future machine learning techniques, subsequent algorithmic improvements may yield performance improvements without any change in the data",
        "prob": 0.2652173913043478
    }, {
        "ID": 1154,
        "phrase": " \u2022 the relation r i of \u03c6(a) is defined via: for any u \u2208 |\u03c6(a)| ai = |a| kai , r i (u) holds in \u03c6(a) if, and only if, \u03c8 i (u) holds in a",
        "prob": 0.31
    }, {
        "ID": 1276,
        "phrase": "1, [ [ e ] ] \u2294ar id = ai\u2208ar [ [ e ] ] ai id , so there will be an a i such that t \u2208 [ [ e ] ] ai id that means a i |= id e \u2192 t",
        "prob": 0.51
    }, {
        "ID": 1283,
        "phrase": " we simply take the transitive closure of the union of the agents' belief states: proposition 18 let a and s be as in definition 21, \u227a ai , agent a i 's induced belief state, and \u2292 s , fully connected",
        "prob": 0.305
    }, {
        "ID": 1506,
        "phrase": ") the most general linear attachment kernel for a directed graph has the form a ij = ai + bj",
        "prob": 0.46923076923076923
    }, {
        "ID": 1632,
        "phrase": " the following definition is central: definition 1 let a 1 and a 2 be two alphabets such that a 1 \u2286 a 2 , and, for i = 1, 2, let s i \u2286 nlp ai be a class of nested logic programs closed under unions",
        "prob": 0.32105263157894737
    }, {
        "ID": 1883,
        "phrase": " ) in \u03be such that for any j \u2265 1, the selected atom ai j of qi j is an ancestor of the selected atom ai j+1 of qi j+1 and size(ai j+1 ) \u2265 size(ai j )",
        "prob": 0.3923076923076923
    }, {
        "ID": 2137,
        "phrase": " it can also calculate belief in partitions of the form c ai \u222a { a i c }, where c ai is the set of children of a i ",
        "prob": 0.21000000000000002
    }, {
        "ID": 2137,
        "phrase": " this is simply done by substituting each nonterminal node with subset a i in a hierarchical tree by a parent-child pair with the dichotomy {a i , a i c } as subset at the parent and the family c ai \u222a { a i c } as subset at the child and furthermore substituting terminal nodes with subset a i with the dichotomy {a i , a i c }",
        "prob": 0.4111111111111111
    }, {
        "ID": 2197,
        "phrase": " , m, let \u03c0 + ai = \u03c0 ai {a i }, and for i \u2208 k let \u03c0 * ai = i\u22121 j=0 \u03c0 + ai ",
        "prob": 0.35000000000000003
    }, {
        "ID": 2197,
        "phrase": " now let \u00b5 am+1 = 1 \u00b5 ai = min aj \u2208aj aj \u2208(\u03c0 + a i \\\u03c0 * a i )\u2229r p 0 (a i |\u03c0 \u2032 ai ) p 0 (a i |\u03c0 \u2032\u2032 ai ) \u00b5 ai+1 , \u2200i \u2208 k \u00b5 a0 = min aj \u2208aj , aj \u2208\u03c0c \u2229r p 0 (c \u2032 |\u03c0 c ) p 0 (c \u2032\u2032 |\u03c0 c ) \u00b5 a1 (4) note that \u00b5 ai , i = 1, ",
        "prob": 0.5916666666666667
    }, {
        "ID": 2734,
        "phrase": " an alternative to low-level instrumentation is source-level instrumentation; run-time behavior information can be extracted by source-to-source transformation, as done for ml  [tolmach & appel, 1995 ,kishon et al",
        "prob": 0.244
    }, {
        "ID": 2813,
        "phrase": " this is without loss of generality, since if \u03b3i does not appear, we can put it in, taking ai = 0",
        "prob": 0.4636363636363636
    }, {
        "ID": 3124,
        "phrase": " without loss of generality, we consider a particular ordering of keys in the key ring of one node and we define ai as the event that the ith key from the key ring of the node is selected by the other node given that previous (i \u2212 1) keys from that key ring are not selected it, 1 \u2264 i \u2264 k",
        "prob": 0.7620689655172413
    }, {
        "ID": 3124,
        "phrase": " therefore, 1 \u2212 p ran = k i=1 (1 \u2212 k l \u2212 i + 1 ) (25) under the two-phase scheme, we define p i x as the probability that event ai occurs with two nodes of id difference x",
        "prob": 0.5941176470588235
    }, {
        "ID": 3125,
        "phrase": " without loss of generality, we consider a particular ordering of keys in the key ring of one node and we define ai as the event that the ith key from the key ring of the node is selected by the other node given that previous (i \u2212 1) keys from that key ring are not selected it, 1 \u2264 i \u2264 k",
        "prob": 0.796551724137931
    }, {
        "ID": 3125,
        "phrase": " therefore, 1 \u2212 p ran = k i=1 (1 \u2212 k l \u2212 i + 1 ) (25) under the two-phase scheme, we define p i x as the probability that event ai occurs with two nodes of id difference x",
        "prob": 0.5941176470588235
    }, {
        "ID": 3234,
        "phrase": " \u2228 an (t) \u2190 b do begin insert ai \u2190 b for 1 \u2264 i \u2264 n into esv ; insert ai \u2190 aj , b for 1 \u2264 i, j \u2264 n and i = j into esv ; end for each constraint c \u2208 pc of the form \u2190 a1, \u2022 \u2022 \u2022, a k , b1, \u2022\u2022, bm , \u00acc1, \u2022 \u2022 \u2022, \u00accn do insert bi \u2190 b1, \u2022\u2022, bi\u22121, bi+1, \u2022\u2022, b k , a1, \u2022 \u2022 \u2022, a k , \u00acc1, \u2022 \u2022 \u2022, \u00accn for1 \u2264 i \u2264 m into esv ; // p(x1, \u2022\u2022, x k ) \u2190 p \u03b1 (x1, \u2022\u2022, x k ) into coll ; return sm(rv \u222a pc \u222a coll \u222a magic \u222a d); end",
        "prob": 0.364
    }, {
        "ID": 3254,
        "phrase": ") to appreciate the difference, consider a proof ordering such that c > ai c > b c , for i \u2265 0, with all the ai c incomparable",
        "prob": 0.41
    }, {
        "ID": 3298,
        "phrase": " an environment \u03c3 is now an encoding of a database d if (1) \u03c3(r) is an encoding of d(r) (as before), and (2) \u03c3(x ai ) = \u03c3(x aj ) when i = j",
        "prob": 0.31
    }, {
        "ID": 3374,
        "phrase": " definition 2 let h = {h ai : a \u2208 c; i \u2208 v} be the adjacency matrix of a tanner graph from the ensemble (n, \u03b3, p ): h ai = 1 if (i, a) \u2208 e and h ai = 0 otherwise",
        "prob": 0.5083333333333333
    }, {
        "ID": 3375,
        "phrase": " definition 1 let h = {h ai : a \u2208 c; i \u2208 v} be the adjacency matrix of a tanner graph from the ensemble (\u2022 \u2022 \u2022): h ai = 1 if (i, a) appears in e an odd number of times, and h ai = 0 otherwise",
        "prob": 0.38125
    }, {
        "ID": 3401,
        "phrase": " the ai and bj word positions are connected so that an a-node points to a b-node for even indices, whereas a b-node points to an a-node for odd indices",
        "prob": 0.3736842105263158
    }, {
        "ID": 3549,
        "phrase": " , ai m ) belongs to the mary relation r (an m-ary relation over the universe u is any subset of u m \n a) : a \u2208 u }, and the universal relation \u22a4 b u = u \u00d7 u ",
        "prob": 0.3923076923076923
    }, {
        "ID": 3780,
        "phrase": "1 that if there is a transmission from a node ai in some tile, other transmissions in neighboring tiles can affect the transmissions of ai",
        "prob": 0.19090909090909086
    }, {
        "ID": 4389,
        "phrase": " let the sets of configurations ai be inductively defined as a1 := {c | \u2203c \u2032 (c, c \u2032 ) \u2208 \u03c8 k\u2022n \u2227 c \u2032 \u2208 acceptingconfigs \u2227 c",
        "prob": 0.5545454545454546
    }, {
        "ID": 4390,
        "phrase": " let the sets of configurations ai be inductively defined as a1 := {c | \u2203c \u2032 (c, c \u2032 ) \u2208 \u03c8 k\u2022n \u2227 c \u2032 \u2208 acceptingconfigs \u2227 c",
        "prob": 0.5545454545454546
    }, {
        "ID": 4422,
        "phrase": " for 1 \u2264 i \u2264 n, let f (a i ) = # ai (s) + 1 2(m + n) + i\u22121 j=1 # aj (s) + 1 m + n < 1 ",
        "prob": 0.35000000000000003
    }, {
        "ID": 4454,
        "phrase": " we define two index sets in the following way: i 1 \u25b3 = {i \u2208 [1, m] : s ai = s bi } (42) i 2 \u25b3 = {i \u2208 [1, m] : s ai = s bi }",
        "prob": 0.31
    }, {
        "ID": 4458,
        "phrase": " ex 3, n=12,m=11, ml dec",
        "prob": 0.2625
    }, {
        "ID": 4458,
        "phrase": " ex 3, n=11,m=10, ml dec",
        "prob": 0.3875
    }, {
        "ID": 4459,
        "phrase": " ex 3, n=12,m=11, ml dec",
        "prob": 0.3875
    }, {
        "ID": 4459,
        "phrase": " ex 3, n=11,m=10, ml dec",
        "prob": 0.3875
    }, {
        "ID": 4783,
        "phrase": " for 1 \u2264 i \u2264 n, let f i = i\u22121 j=1 # aj (s) m + # ai (s) 2m ",
        "prob": 0.35000000000000003
    }, {
        "ID": 5028,
        "phrase": " a cp selects a generator, g \u2208 g q , then chooses a random polynomial, f (x) := 2k\u22121 i=0 a i x i , where a i \u2208 z q (i = 0, \u2022 \u2022 \u2022 , 2k \u2212 1) , publishes its public key, p k := (g, p, q, y 0 , y 1 , \u2022 \u2022 \u2022 , y 2k\u22121 ), where y i = g ai , and sends a personal secret key, d i := f (u i ), to each user, u i (i = 1, 2, \u2022 \u2022 \u2022 , n )",
        "prob": 0.2833333333333333
    }, {
        "ID": 5037,
        "phrase": " for this setup, when studying the ml decoder in (1) or (2), we can without loss of generality assume that the zero codeword was sent, because all decision regions are congruent",
        "prob": 0.44999999999999996
    }, {
        "ID": 5042,
        "phrase": " a series \u221e i=1 ai is convergent when limn\u2192\u221e n i=1 ai exists in the standard reals; otherwise it is divergent",
        "prob": 0.25833333333333336
    }, {
        "ID": 5076,
        "phrase": " therefore, c (nm) ml (\u03c4 ) is the sum of a i l i l+1 (\u03c4 ) bernoulli-distributed random variables with param- eter (1 \u2212 1/q)r m /z i l i l+1 ",
        "prob": 0.2733333333333333
    }, {
        "ID": 5076,
        "phrase": " hence cml (\u03c4 ) := lim nm\u2192\u221e c(nm) ml (\u03c4 ) = lim nm\u2192\u221e 1 n m (1 \u2212 1/q)r m z i l i l+1 a i l i l+1 (n m \u03c4 ) a",
        "prob": 0.46923076923076923
    }, {
        "ID": 5076,
        "phrase": " therefore, xml (\u03c4 ) := lim nm\u2192\u221e x(nm) ml (\u03c4 ) = 1 \u2212 (1 \u2212 1/q)r m \u03c4 if l = 1, 0 otherwise a",
        "prob": 0.5083333333333333
    }, {
        "ID": 5076,
        "phrase": " then \u03bd \u2265 n \u2212 m m=1 lm l=1 q (nm) ml (\u2206), where n m = c m1 (\u2206)",
        "prob": 0.3
    }, {
        "ID": 5076,
        "phrase": " then lim n \u2192\u221e \u03bd n \u2265 lim n \u2192\u221e 1 \u2212 m m=1 lm l=1 n m n q(nm) ml n n m (1 \u2212 1/q)r = 1 a",
        "prob": 0.51
    }, {
        "ID": 5250,
        "phrase": " (  1 ) hold, the proxy signcrypter group computes \u2211 = = n i ai a s s 1 ",
        "prob": 0.34444444444444444
    }, {
        "ID": 5250,
        "phrase": " x and corresponding public key ai y , such that * q r ai z x \u2208 and p x y ai ai = ",
        "prob": 0.3
    }, {
        "ID": 5255,
        "phrase": " without loss of generality, assume that only one secret huffman table is used to encrypt all vlc-codewords and there are m entries in the huffman table: (a1, v1), \u2022 \u2022 \u2022 , (am, vm), where ai means the i-th value to be encoded by the huffman table and vi denotes the vlccodeword corresponding to ai",
        "prob": 0.3607142857142857
    }, {
        "ID": 5500,
        "phrase": "\u00d7\u00f8\u00f6 \u00f8 \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f0 \u00f6 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00e5\u00f3\u00f2\u00f8 \u00f6\u00f0\u00f3 \u00f0\u00b9 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00f6 \u00f2 \u00f3\u00f1 \u00f0 \u00d7 \u00d7 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00ba \u00e1\u00f8 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8 \u00fd\u00f2 \u00f1 \u00d7 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00fb \u00f3\u00d7 \u00f2\u00f3 \u00d7 \u00fa \u00d7\u00f6 \u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00d7 \u00f8\u00f3 \u00d7\u00f4 \u00b9 \u00fd \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f2 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f8 \u00d7 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00ec \u00d7 \u00f3\u00f6\u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f6 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fd\u00f2 \u00f1\u00b9 \u00d7 \u00d7 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f8 \u00f8 \u00f6 \u00d7 \u00f1 \u00f0 \u00f6 \u00f8\u00f3 \u00f8 \u00f3\u00d7 \u00f3 \u00f5\u00f9 \u00f2\u00f8\u00f9\u00f1 \u00f0 \u00f8 \u00f3\u00f6\u00fd \u00f3 \u00f3\u00d7\u00f3\u00f2\u00d7\u00b8\u00fb \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f6 \u00f9\u00d7 \u00f3 \u00f1 \u00f2\u00fd \u00f3\u00f2 \u00f4\u00f8\u00f9 \u00f0 \u00f2 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00d7 \u00f6\u00f3\u00f1 \u00e9 \u00ec\u00ba \u00ec \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00fa \u00f3\u00f9\u00f6 \u00f3 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00e5\u00ea \u00d7 \u00f2 \u00f3 \u00f8 \u00f4\u00f8 \u00fa \u00f0\u00f9\u00d7\u00f8 \u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b4 \u00f2 \u00f8\u00b5 \u00f6 \u00d7 \u00f3\u00fb\u00f2 \u00f8\u00f3 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8\u00b8\u00fb \u00f4\u00f6\u00f3\u00fa \u00d7 \u00fb \u00fd \u00f3 \u00f9\u00f2 \u00fd \u00f2 \u00f8 \u00d7 \u00f8\u00fb\u00f3 \u00f8 \u00f3\u00f6 \u00d7\u00ba \u00bd \u00e1\u00f2\u00f8\u00f6\u00f3 \u00f9\u00f8 \u00f3\u00f2 \u00ec \u00f1 \u00f3 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00d7 \u00f8\u00f3 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00f9 \u00f0 \u00f2 \u00f6 \u00f9\u00f6\u00f6 \u00f2\u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f1\u00f3 \u00f0\u00d7 \u00fb \u00f6 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7 \u00f6 \u00d7\u00f6 \u00f8 \u00b9\u00fa \u00f0\u00f9 \u00b8\u00fb \u00fb \u00f0\u00f0 \u00f2 \u00f2 \u00f6 \u00f0 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00d7\u00f6 \u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f8 \u00f8 \u00f2 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f2 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f6 \u00f8 \u00f8\u00f9\u00f6 \u00d7\u00ba \u00ec \u00f2\u00f8\u00f6\u00f3 \u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00f6 \u00f9\u00f6\u00f6 \u00f2 \u00f2\u00f8\u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f1 \u00d7 \u00f8 \u00f1 \u00f1\u00f9 \u00f1\u00f3\u00f6 \u00f9\u00f0\u00f8 \u00f8\u00f3 \u00f2 \u00f0\u00fd\u00d7 \u00f2 \u00f3\u00f2\u00f8\u00f6\u00f3\u00f0 \u00f8 \u00f2 \u00b9 \u00f3\u00f6\u00fb \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00ba \u00ec \u00d7 \u00f6 \u00d7\u00f3\u00f2 \u00f3\u00f6 \u00f8 \u00d7 \u00f9\u00f0\u00f8 \u00d7 \u00d7 \u00f8 \u00f8 \u00f0\u00f3\u00f3\u00f4\u00fd \u00f4\u00f6\u00f3\u00f4 \u00f8 \u00f3\u00f2 \u00f2 \u00f6 \u00f9\u00f6\u00f6 \u00f2\u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f9\u00d7 \u00d7 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3 \u00d7 \u00f6\u00fa \u00f0 \u00f8\u00f3 \u00d7\u00f9\u00f1 \u00f3 \u00f2 \u00f2 \u00f2 \u00f8 \u00b4\u00f3\u00f6\u00b8 \u00f8 \u00f0 \u00d7\u00f8\u00b8 \u00fa \u00f6\u00fd \u00f0 \u00f6 \u00b5 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2\u00d7\u00ba \u00e7\u00f2 \u00f8\u00fd\u00f4 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8 \u00f8 \u00f2 \u00f1\u00f3 \u00f0\u00f0 \u00f9\u00d7 \u00f2 \u00f8 \u00d7 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00d7 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3 \u00d7\u00f4 \u00f2 \u00f2 \u00f9\u00f6\u00f3\u00f2\u00d7\u00b8\u00fb \u00f6 \u00f8 \u00f4\u00f6 \u00d7 \u00f2 \u00f3\u00f6 \u00d7 \u00f2 \u00f3 \u00d7\u00f4 \u00d7 \u00f2 \u00f6\u00fd \u00f5\u00f9 \u00f2\u00f8 \u00f8\u00fd \u00b4 \u00ba \u00ba \u00f8 \u00d7 \u00d7\u00f6 \u00f8 \u00b9\u00fa \u00f0\u00f9 \u00b5\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6\u00b8\u00f8 \u00f6 \u00d7 \u00f2\u00f3 \u00d7\u00f4 \u00f1 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f3\u00f0\u00f3 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00b8 \u00f9\u00f8 \u00f8 \u00f6 \u00fb \u00f0\u00f0 \u00f2 \u00fa \u00f6\u00f8 \u00f0 \u00d7\u00d7 \u00f4\u00f3 \u00f2\u00f8\u00d7 \u00f3 \u00f3\u00f2\u00f8 \u00f8 \u00f8\u00fb \u00f2 \u00f8 \u00f2 \u00f6 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f6 \u00f2 \u00f8 \u00d7\u00f4 \u00f8 \u00f0\u00d7 \u00f3 \u00f3\u00f0\u00f3 \u00f0 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00ba \u00ec \u00f3\u00f2\u00f0\u00fd \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8 \u00fb \u00fd \u00f3 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f9\u00d7 \u00fd \u00d7 \u00f2 \u00f1 \u00f8 \u00b9 \u00f3 \u00d7 \u00bd\u2104\u00b8\u00fb \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00fd \u00f9\u00d7 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7\u00b8 \u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00b4\u00f3\u00f6 \u00f1 \u00f2 \u00f6 \u00f2 \u00d7\u00b5 \u00fd \u00f1 \u00f2 \u00f4\u00b9 \u00f9\u00f0 \u00f8 \u00f2 \u00f8 \u00d7 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f3\u00f6 \u00f2 \u00f8\u00f3 \u00fb \u00f0\u00f0\u00b9 \u00f2 \u00f6\u00f9\u00f0 \u00d7 \u00d7\u00f9 \u00d7 \u00fd \u00d7 \u00f8 \u00f3\u00f6 \u00f1\u00ba \u00ec \u00fd \u00d7 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00fa \u00d7 \u00f8\u00d7 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00fd \u00fd \u00f2\u00f3\u00f8 \u00d7 \u00f6 \u00f2 \u00f2\u00fd \u00bd \u00f3 \u00f8 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00f2 \u00f6 \u00f2 \u00d7 \u00f8 \u00f8 \u00f2 \u00f1 \u00b8 \u00f2 \u00fd \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00f9\u00f4 \u00f8 \u00f3\u00f2\u00d7 \u00f5\u00f9 \u00f2 \u00d7 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00d7 \u00f8 \u00f2\u00d7\u00f9\u00f6 \u00d7 \u00f8 \u00f8 \u00f8 \u00f6 \u00f6 \u00f2 \u00fa \u00f6 \u00f2\u00fd \u00f3 \u00f8 \u00f3\u00f2\u00f8\u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8 \u00f8 \u00fb\u00f3\u00f9\u00f0 \u00f3\u00f8 \u00f6\u00fb \u00d7 \u00f3\u00f9\u00f6\u00b8\u00d7\u00f9 \u00d7 \u00f6 \u00f2 \u00f3\u00f2\u00f0\u00f9\u00d7 \u00f3\u00f2\u00d7 \u00f8 \u00f8 \u00f4 \u00f2 \u00f3\u00f2 \u00fb \u00f6\u00f3\u00f9\u00f8 \u00f3\u00f2 \u00f8 \u00d7 \u00f8 \u00f6\u00f3\u00f9 \u00f8 \u00f1 \u00fe \u00f3 \u00f2 \u00f6 \u00f2 \u00d7\u00ba \u00fd \u00d7 \u00f2 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f2 \u00d7 \u00fc \u00f0 \u00fb \u00fd \u00f3 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f2 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f2 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7\u00ba \u00f2 \u00f0 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00f8 \u00d7 \u00d7 \u00e5 \u00f6 \u00f3\u00fa \u00f6 \u00f2 \u00f3\u00f1 \u00f0 \u00b4\u00e5\u00ea \u00b5 \u00f8 \u00f3\u00f6\u00fd \u00be\u2104\u00b8 \u00f9\u00d7 \u00f8 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f3\u00f2 \u00f8\u00f3 \u00d7\u00fd\u00d7\u00f8 \u00f1 \u00f8 \u00f0\u00f0\u00fd \u00f9 \u00f0 \u00f9\u00f4 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f1\u00f3 \u00f0 \u00f3\u00f9\u00f8 \u00f3 \u00f4 \u00d7 \u00f8 \u00f8 \u00fa \u00d7 \u00f1\u00f4\u00f0 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00f8 \u00f9\u00f2 \u00f6\u00f0\u00fd \u00f2 \u00d7\u00f8 \u00f8 \u00fa \u00f6 \u00f0 \u00d7\u00ba \u00f3\u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00f8 \u00f8 \u00fa \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f2\u00f3 \u00d7\u00b8 \u00f3 \u00fb \u00d7 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f4 \u00f4 \u00f6 \u00f2\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00fd \u00f2 \u00d7\u00d7\u00f9\u00f1\u00f4\u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f0\u00f0 \u00f1 \u00f3\u00f9\u00f8 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8\u00f3\u00f4\u00f3\u00f0\u00f3 \u00fd\u00b8 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f6 \u00f8 \u00f8 \u00f1\u00f3\u00d7\u00f8 \u00f2 \u00f6 \u00f0 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00d7\u00f6 \u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00ba \u00ec \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8 \u00f8\u00fd\u00f4 \u00f3 \u00e5 \u00e5 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00d7\u00f8\u00f3 \u00d7\u00f8 \u00b9 \u00f0\u00f0\u00fd \u00f9\u00f4 \u00f8 \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00e5\u00ea \u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00f1\u00f3\u00fa \u00d7 \u00f6\u00f3\u00f9\u00f2 \u00f8\u00d7 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00fa \u00d7 \u00f8 \u00f2 \u00fa \u00f6\u00fd \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00fb \u00f8 \u00f6 \u00f5\u00f9 \u00f2\u00fd \u00f8 \u00f8 \u00d7 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00d7\u00f4 \u00fd \u00f8 \u00e5\u00ea \u00ba \u00e5\u00f3\u00f6 \u00d7\u00f3\u00f4 \u00d7\u00f8 \u00f8 \u00e5 \u00e5 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00d7 \u00f1 \u00f8 \u00f2 \u00f9\u00f8 \u00fb \u00f8 \u00f2 \u00f2\u00d7 \u00f1 \u00f0 \u00f3 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00e5\u00ea \u00f8 \u00d7 \u00f6 \u00f2\u00f3\u00fb\u00f2 \u00d7 \u00f4 \u00f6\u00f8 \u00f0 \u00f0\u00f8 \u00f6 \u00f2 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00bf\u2104\u00ba \u00ec \u00f1 \u00f2 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f8 \u00f8 \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00d7 \u00f2 \u00fb \u00fb \u00fd \u00f3 \u00d7\u00f6 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00b8 \u00f2 \u00fb \u00f8 \u00f9\u00f4 \u00f8 \u00f2 \u00f3 \u00f8 \u00e5\u00ea \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00b4 \u00ba \u00ba \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7\u00b5 \u00d7 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00f2\u00f8\u00f3 \u00d7 \u00f8 \u00f3 \u00f1\u00f3\u00f6 \u00f0 \u00f1 \u00f2\u00f8 \u00f6\u00fd \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00b8\u00fb \u00f6 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8 \u00d7 \u00b8 \u00d7 \u00f2 \u00f0 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f2 \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f2 \u00e5\u00ea \u00fd \u00f1\u00f3 \u00fd \u00f2 \u00f8\u00d7 \u00d7\u00f8 \u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00f2\u00f3 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b8\u00fb \u00f2 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00f2\u00f8\u00f3 \u00f6\u00d7\u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00f8 \u00f3\u00f0 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00f8 \u00f2 \u00f6 \u00f8 \u00f2 \u00f8 \u00f2 \u00fb \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00ba \u00f2\u00fd \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f2 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00f3\u00f9\u00f8 \u00f3 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00d7\u00f9 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00f9\u00f6\u00f8 \u00f6\u00f1\u00f3\u00f6 \u00b8\u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f2 \u00f8 \u00f8 \u00d7 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f6 \u00fa \u00f6\u00fd \u00f1 \u00f0 \u00f6 \u00f8\u00f3 \u00f4 \u00fd\u00d7 \u00d7\u00f8\u00d7\u00b8 \u00f9\u00d7 \u00f8 \u00fd \u00f6 \u00f2\u00f8 \u00f0 \u00f8\u00f3 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f4\u00f4 \u00f6 \u00f2 \u00f5\u00f9 \u00f2\u00f8\u00f9\u00f1 \u00f0 \u00f8 \u00f3\u00f6\u00fd \u00b4\u00e9 \u00ec\u00b5 \u00f3 \u00f3\u00d7\u00f3\u00f2\u00d7 \u2104\u00ba \u00ec \u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f0\u00f3\u00f8 \u00f3 \u00f4\u00f6 \u00fc \u00d7\u00f8 \u00f2 \u00f3\u00f2 \u00f4\u00f8\u00f9 \u00f0 \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f1 \u00f2 \u00f6\u00fd \u00f8\u00f3 \u00f6\u00f3\u00f9 \u00f8 \u00f8\u00f3 \u00f6 \u00f9\u00f4\u00f3\u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f1 \u00f3 \u00d7\u00f6 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00ba \u00fd \u00f6 \u00fb \u00f2 \u00f2 \u00f2 \u00f0\u00f3 \u00fd \u00fb \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00b9\u00f4 \u00f6\u00f8 \u00f0 \u00e9 \u00ec \u00d7\u00f8 \u00f8 \u00d7\u00b8\u00f8 \u00e5\u00ea \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f2 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8\u00f0\u00fd \u00f2 \u00f6 \u00f0 \u00d7 \u00d7\u00f3 \u00f8 \u00f8 \u00f2\u00f3 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fc \u00d7\u00f8\u00d7 \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00d7 \u00f2 \u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00ba \u00ec \u00f6 \u00f6 \u00f0\u00d7\u00f3 \u00f1 \u00f2\u00fd \u00f3\u00f8 \u00f6 \u00f4\u00f3 \u00f2\u00f8\u00d7 \u00f3 \u00f3\u00f2\u00f8 \u00f8 \u00fb \u00f8 \u00e9 \u00ec\u00ba \u00ec \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00e5\u00ea \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f3\u00f2\u00f8 \u00f8 \u00f8\u00f3 \u00f1 \u00fb \u00f8 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f8\u00fd\u00f4 \u00f3 \u00d7 \u00f0 \u00b9\u00f3\u00f6 \u00f2 \u00d7 \u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b4\u00eb\u00e7ae\u00b5 \u00f8 \u00f3\u00f6\u00fd \u00f2\u00f3\u00fb\u00f2 \u00d7 \u00f8 \u00f4\u00f8 \u00fa \u00f0\u00f9\u00d7\u00f8 \u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00b4 \u00f2 \u00f8\u00b5 \u2104\u00ba \u00be \u00e7\u00f2 \u00f3 \u00f8 \u00f1\u00d7 \u00f3 \u00eb\u00e7ae \u00d7 \u00f8\u00f3 \u00d7\u00f3\u00fa \u00f6 \u00f3\u00f6 \u00f8\u00d7 \u00f0 \u00fb \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f6 \u00f8 \u00f8\u00f9\u00f6 \u00f8\u00f3 \u00f9\u00d7 \u00f8\u00f3 \u00d7\u00f3\u00f0\u00fa \u00f2 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f8 \u00d7 \u00b8\u00d7\u00f3 \u00f8 \u00f1\u00f9\u00d7\u00f8 \u00f0 \u00f8\u00f3 \u00fd\u00f2 \u00f1 \u00f0\u00f0\u00fd \u00f2 \u00f8\u00d7 \u00f6 \u00f8 \u00f8\u00f9\u00f6 \u00ba \u00ec \u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00d7 \u00d7\u00f4\u00f0 \u00f8\u00f8 \u00f2 \u00f2 \u00f1 \u00f6 \u00f2 \u00f3 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7\u00b8 \u00f2 \u00f0\u00d7\u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f0 \u00f2 \u00d7 \u00f8\u00fb \u00f2 \u00f8 \u00f1\u00ba \u00e1\u00f2 \u00f2 \u00e5\u00ea \u00b8 \u00f2\u00f3 \u00d7 \u00d7\u00f4\u00f0 \u00f8 \u00f2\u00f8\u00f3 \u00f8\u00fb\u00f3 \u00f2\u00f3 \u00d7 \u00f8 \u00f6 \u00d7 \u00f2\u00f3 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8 \u00fb \u00fd \u00f3 \u00d7\u00d7 \u00f2 \u00f2 \u00f4 \u00f6\u00fb \u00d7 \u00d7\u00f8 \u00f8 \u00f8\u00f3 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f4 \u00f6 \u00f3 \u00f2\u00f3 \u00d7\u00b8\u00f9\u00f2\u00f0 \u00d7\u00d7 \u00f8 \u00f4\u00f6 \u00fc \u00d7\u00f8 \u00f2 \u00d7 \u00f2 \u00f0 \u00f2\u00f3 \u00f8\u00fb\u00f3 \u00b4\u00f3\u00f6 \u00f1\u00f3\u00f6 \u00b5 \u00d7\u00f8 \u00f8 \u00d7 \u00d7\u00d7 \u00f2 \u00f8\u00f3 \u00f8 \u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00f4\u00f0 \u00ba \u00ec \u00d7 \u00d7 \u00fc \u00f8\u00f0\u00fd \u00fb \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f2 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7 \u00e5\u00ea \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f4\u00f6\u00f3\u00fa \u00d7\u00b8\u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4\u00b9 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f8 \u00d7 \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00ec \u00f9\u00d7 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f4\u00f4\u00f6\u00f3 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00e5\u00ea \u00f8 \u00f3\u00f6\u00fd \u00f2 \u00eb\u00e7ae \u00f8 \u00f3\u00f6\u00fd \u00f2 \u00f0 \u00f2\u00f0\u00fd \u00f9\u00f2 \u00ba \u00ec \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f3 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00d7 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7\u00ba \u00e1\u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be \u00f8 \u00f8 \u00f3\u00f6\u00fd \u00f3 \u00e5\u00ea \u00d7 \u00d7 \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00b8\u00f8\u00f3 \u00f8 \u00f6 \u00fb \u00f8 \u00f8 \u00f8 \u00f0\u00d7 \u00f3 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f2 \u00e5\u00ea \u00d7\u00ba \u00e1\u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf \u00f8 \u00f1 \u00f2 \u00f2 \u00fb \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00fb \u00d7 \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f8 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7 \u00d7 \u00e5\u00ea \u00f8 \u00f3\u00f6\u00fd \u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00f2 \u00f0\u00f0\u00fd\u00b8 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00d7\u00f3\u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f6 \u00f9\u00d7 \u00f8\u00f3 \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00f8 \u00f9\u00d7 \u00f3 \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2\u00b8\u00f3\u00f2 \u00f3 \u00fb \u00d7 \u00f8 \u00f1\u00f3\u00f2\u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00f3 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f8\u00fd\u00f4 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00e5\u00ea \u00d7 \u00f8 \u00d7 \u00f1 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00d7 \u00f2 \u00f8\u00ba \u00be \u00e5 \u00f6 \u00f3\u00fa \u00ea \u00f2 \u00f3\u00f1 \u00f0 \u00d7 \u00ec \u00f1 \u00f3 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f6 \u00fa \u00fb \u00f8 \u00e5\u00ea \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00f9 \u00f0 \u00f2 \u00f2 \u00f1 \u00b9 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f1\u00f3 \u00f0\u00d7 \u00f8 \u00f8 \u00f6 \u00f9\u00d7 \u00fb \u00f2 \u00f3 \u00f2 \u00fd \u00d7 \u00f2 \u00f2\u00b9 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00ba \u00ec \u00d7 \u00f2\u00f0\u00f9 \u00d7 \u00d7\u00f3\u00f1 \u00f2 \u00f3\u00f6\u00f1 \u00f0 \u00f1 \u00f8 \u00f6 \u00f0 \u00f2 \u00fb \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f3 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f6 \u00fa \u00f2 \u00f8 \u00f1\u00f3\u00f6 \u00f3\u00f6\u00f1 \u00f0 \u00fa \u00f0\u00f3\u00f4\u00f1 \u00f2\u00f8 \u00f0 \u00f8 \u00f6 \u00f3\u00f2 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bd \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00d7 \u00e5\u00ea \u00d7 \u00f2 \u00f8 \u00e0 \u00f1\u00f1 \u00f6\u00d7\u00f0 \u00fd\u00b9 \u00f0 \u00f3\u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00f3 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7\u00b8 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be \u00d7\u00f6 \u00d7 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f3\u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f2 \u00e5\u00ea \u00ba \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00d7 \u00f8 \u00f3\u00f2 \u00f4\u00f8 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f9\u00b9 \u00f4 \u00f2\u00fd \u00d7\u00f8 \u00f8 \u00fb \u00d7 \u00d7\u00d7 \u00f2\u00f8 \u00f0 \u00f3\u00f6 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00e5\u00ea \u00d7 \u00f8 \u00f8 \u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f0 \u00f8 \u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00f2 \u00f0\u00f0\u00fd\u00b8\u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bf \u00d7\u00f6 \u00d7 \u00f3\u00fb \u00e5\u00ea \u00d7 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f3 \u00fd \u00d7 \u00f2 \u00f2 \u00f6 \u00f2 \u00ba \u00be\u00ba\u00bd \u00d7 \u00e5 \u00f6 \u00f3\u00fa \u00ea \u00f2 \u00f3\u00f1 \u00f0 \u00ec \u00f3\u00f6\u00fd \u00e5\u00ea \u00d7 \u00f6 \u00fc \u00f0 \u00fb \u00fd \u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f2 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00d7 \u00f3\u00f2 \u00f8 \u00e0 \u00f1\u00f1 \u00f6\u00d7\u00f0 \u00fd\u00b9 \u00f0 \u00f3\u00f6 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00b4\u00e0 \u00b5\u00b8\u00fb \u00d7 \u00f2 \u00d7 \u2104 pr(\u00fc ) = 1 z k c p k c (\u00fc c ) \u00b4\u00bd\u00b5 \u00fb \u00f6 \u00fc \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 (x 1 , x 2 , \u2022 \u2022 \u2022 , x n ) \u00f3 \u00f2 \u00e5\u00ea \u00fb \u00f8 n \u00f2\u00f3 \u00d7\u00b8k \u00d7 \u00f8 \u00f3\u00f6 \u00f6 \u00f3 \u00f8 \u00f8 \u00f6\u00f1 \u00f2 \u00f8 \u00fc\u00f4 \u00f2\u00d7 \u00f3\u00f2 \u00b4 \u00ba \u00ba k \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00f3 \u00fc \u00f8 \u00f8 \u00f8 \u00f8 \u00f6\u00f1 \u00f4 \u00f2 \u00d7 \u00f3\u00f2\u00b8\u00fb \u00d7 \u00f8 \u00f9\u00d7 k\u00b9\u00f8\u00f9\u00f4\u00f0 \u00b5\u00b8c \u00f0 \u00f0\u00d7 \u00f8 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 k\u00b9 \u00f8\u00f9\u00f4\u00f0 \u00b4\u00f3\u00f6 k\u00b9\u00f0 \u00f5\u00f9 \u00b5 \u00f8 \u00f8 \u00f8 \u00f8 \u00f6\u00f1 \u00f4 \u00f2 \u00d7 \u00f3\u00f2\u00b8\u00fc c \u00d7 \u00f8 k\u00b9\u00f8\u00f9\u00f4\u00f0 \u00b4\u00f3\u00f6 \u00f0 \u00f5\u00f9 \u00d7\u00f8 \u00f8 \u00b5p k c (\u00fc c ) \u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6 \u00b4\u00f3\u00f6 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00b5 \u00d7\u00d7\u00f3 \u00f8 \u00fb \u00f8 \u00fc c \u00b8 \u00f2 z \u00bf \u00d7 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f8\u00f3\u00f6 \u00f8\u00f3 \u00f2\u00d7\u00f9\u00f6 \u00f8 \u00f8 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00d7\u00f9\u00f1\u00d7 \u00f8\u00f3 \u00f9\u00f2 \u00f8\u00fd \u00d7 \u00fc pr(\u00fc ) = 1\u00b8\u00d7\u00f3 z \u00d7 \u00f2 \u00d7 z \u2261 \u00fc k c p k c (\u00fc c ) \u00b4\u00be\u00b5 \u00ec \u00f6 \u00f6 \u00d7\u00f3\u00f1 \u00f1 \u00f2\u00f3\u00f6 \u00f8 \u00f2 \u00f0 \u00d7\u00d7\u00f9 \u00d7 \u00f8\u00f3 \u00f3 \u00fb \u00f8 \u00fc \u00f8\u00f0\u00fd \u00f3\u00fb \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00fc c \u00f6 \u00f2\u00f9\u00f1 \u00f6 \u00f8 \u00f2 \u00f8 \u00e0 \u00f8\u00f3 \u00f2\u00d7\u00f9\u00f6 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f2\u00f3\u00f8 \u00f3\u00f9 \u00f0 \u00b9\u00f3\u00f9\u00f2\u00f8 \u00b8 \u00f9\u00f8 \u00f8 \u00d7 \u00f6 \u00f2\u00f3\u00f8 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00f6 \u00ba \u00ec\u00f3 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00fa \u00f6 \u00eb \u00f3 \u00d7\u00f8 \u00f8 \u00d7\u00f8 \u00eb(\u00fc ) \u00fd\u00f3\u00f9 \u00f2 \u00f8\u00f3 \u00fa \u00f0\u00f9 \u00f8 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00eb = \u00fc pr(\u00fc )\u00eb (\u00fc ) = \u00fc k c p k c (\u00fc c)\u00eb (\u00fc ) \u00fc k c p k c (\u00fc c) \u00b4\u00bf\u00b5 \u00fb \u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6 pr(\u00fc ) \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f0\u00fd \u00fb \u00f8\u00d7 \u00f8 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00fc \u00f2 \u00f8 \u00d7\u00f9\u00f1\u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f8 \u00f3\u00f6\u00f6 \u00f8 \u00fb \u00f8 \u00fa \u00f6 \u00eb \u00d7 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00ba \u00d7\u00f4 \u00f8 \u00f8 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00e0 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 pr(\u00fc )\u00b8 \u00f8 \u00d7 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00f2\u00f3\u00f8 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00f3 \u00fa \u00f0\u00f9 \u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00f2 \u00f0\u00f3\u00d7 \u00b9 \u00f3\u00f6\u00f1\u00b8\u00d7\u00f3 \u00f2\u00f9\u00f1 \u00f6 \u00f0 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00f1\u00f9\u00d7\u00f8 \u00f9\u00d7 \u00ba \u00f2 \u00f2\u00f8\u00f9 \u00f8 \u00fa \u00f0 \u00f3\u00f6 \u00f3\u00fb \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00f2 \u00fa \u00f0\u00f9 \u00f8 \u00f2 \u00f3 \u00f8 \u00f2 \u00fd \u00f2\u00f3\u00f8 \u00f2 \u00f8 \u00f8 \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f4 \u00f6 \u00f3 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00fc 1 \u00f2 \u00fc 2 \u00d7 \u00fa \u00f2 \u00fd pr(\u00fc 1 ) pr(\u00fc 2 ) = k c p k c ((\u00fc 1 ) c ) k c p k c ((\u00fc 2 ) c ) \u00b4 \u00b5 \u00fb \u00f6 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f2 z \u00f8\u00f3\u00f6 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f2 \u00f0\u00d7\u00b8 \u00f2 \u00f0\u00d7\u00f3 \u00f2\u00fd \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f3\u00f1\u00f1\u00f3\u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f8\u00f3\u00f6 \u00f2 \u00f2\u00f3\u00f1 \u00f2 \u00f8\u00f3\u00f6 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00fb \u00f0\u00f0 \u00f2 \u00f0\u00ba \u00ec \u00f9\u00d7\u00b8 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00fc 1 \u00f2 \u00fc 2 \u00f6 \u00f2 \u00f3\u00f2\u00f0\u00fd \u00fb \u00f3 \u00f8 \u00f6 \u00fa \u00f8\u00f3\u00f6 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7\u00b8\u00f8 \u00f2 \u00f2\u00fd \u00f3 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6\u00d7 p k c (\u00fc c ) \u00f8 \u00f8 \u00f3 \u00f2\u00f3\u00f8 \u00f4 \u00f2 \u00f3\u00f2 \u00f8 \u00d7 \u00f6 \u00f2 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 \u00fb \u00f0\u00f0 \u00f2 \u00f0 \u00f3\u00f9\u00f8\u00b8\u00f0 \u00fa \u00f2 \u00f6 \u00f0 \u00f8 \u00fa \u00f0\u00fd \u00d7 \u00f1\u00f4\u00f0 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 \u00f8 \u00f6 \u00f8 \u00f3 pr(\u00fc 1) pr(\u00fc 2) \u00ba \u00ec \u00d7 \u00f2 \u00f0\u00f0 \u00f8 \u00f3\u00f2 \u00d7 \u00fd \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8\u00fd \u00f3 \u00f8 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f6\u00f1 \u00f3 \u00f8 \u00e0 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00ba \u00e7\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr(\u00fc 1 ) pr(\u00fc 2 ) \u00f3 \u00f4 \u00f6 \u00f3 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00fc 1 \u00f2 \u00fc 2 \u00d7 \u00fa \u00f0 \u00f0 \u00b8 \u00f8 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f2 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00b4\u00d7 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be\u00b5 \u00f3\u00f6 \u00f3\u00f4\u00f4 \u00f2 \u00f6\u00f3\u00f9\u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00fc\u00b8 \u00f2 \u00fb \u00d7 \u00d7 \u00f2 \u00f8\u00f3 \u00fa \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00fb \u00f8 \u00f6 \u00f5\u00f9 \u00f2\u00fd \u00f8 \u00f8 \u00d7 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00f3 \u00e8\u00f6(\u00fc )\u00b8 \u00d7 \u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f3\u00f6 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f2 \u00f2\u00f9\u00f1 \u00f6 \u00f0 \u00d7\u00f8 \u00f1 \u00f8 \u00f3 \u00eb \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00be\u00ba\u00be \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00e5\u00f3\u00f2\u00f8 \u00f6\u00f0\u00f3 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00e1\u00f8 \u00d7 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f3\u00f6 \u00f3\u00f4\u00f4 \u00f2 \u00f8\u00fb \u00f2 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f2 \u00e5\u00ea \u00f8 \u00f8 \u00f6 \u00d7\u00f4 \u00f8\u00d7 \u00f8 \u00f6 \u00f6 \u00f0 \u00f8 \u00fa \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00ba \u00e1\u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f8\u00f6 \u00fa\u00b9 \u00f0\u00f0\u00fd \u00f3 \u00fa \u00f3\u00f9\u00d7 \u00f3\u00fb \u00f8\u00f3 \u00d7 \u00f2 \u00f3\u00f4\u00f4 \u00f2 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00fb \u00f8 \u00f8 \u00d7 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7\u00b8 \u00f9\u00d7 \u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7 \u00f6 \u00f8 \u00f2 \u00f8 \u00f8 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00fb \u00fd\u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00b3\u00d7 \u00f4\u00f6\u00f3\u00f4\u00f3\u00d7 \u00f0 \u00f3\u00b9 \u00f6 \u00f8 \u00f1 \u00f2 \u00f3\u00f4 \u00f2 \u00f8\u00f3 \u00f2 \u00f3\u00f9\u00f8 \u00f3 \u00d7\u00f8 \u00f8 \u00b8 \u00f2 \u00f8\u00f3 \u00f8 \u00f8 \u00f8 \u00d7 \u00f3 \u00d7 \u00f2 \u00fa \u00f6 \u00d7 \u00f8\u00f3 \u00f8 \u00f3\u00f6\u00f6 \u00f8 \u00f3 \u00f2\u00f8 pr(\u00fc )\u00ba \u00f3\u00f2\u00d7 \u00f6 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3 \u00f2\u00f3 \u00d7 \u00fb \u00f3\u00d7 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8\u00d7 \u00f2\u00f3 \u00d7 \u00d7\u00f4\u00f0 \u00f8\u00d7 \u00f2\u00f8\u00f3 \u00f8\u00fb\u00f3 \u00f4 \u00f6\u00f8\u00d7 (\u00fc , \u00fd) \u00fb \u00f3\u00d7 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00d7 pr(\u00fc , \u00fd)\u00ba \u00ec \u00d7 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2 \u00d7\u00f4\u00f0 \u00f8 \u00f2\u00f8\u00f3 \u00f8\u00fb\u00f3 \u00f4 \u00f6\u00f8\u00d7 \u00d7 pr(\u00fc , \u00fd) = pr(\u00fc |\u00fd) pr(\u00fd) \u00b4 \u00b5 \u00fb \u00f6 pr(\u00fc |\u00fd) \u00f2 pr(\u00fd ) \u00f6 \u00f3 \u00f8 \u00f2 \u00f6\u00f3\u00f1 pr(\u00fc , \u00fd) \u00d7 pr(\u00fc |\u00fd ) \u2261 pr(\u00fc ,\u00fd ) \u00fc pr(\u00fc ,\u00fd ) \u00f2 pr(\u00fd) \u2261 \u00fc pr(\u00fc , \u00fd)\u00ba ae\u00f3\u00fb \u00f9\u00f4 \u00f8 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f9\u00d7 \u00f2 (\u00fc , \u00fd) pr(\u00fc \u2032 |\u00fd ) \u2212\u2192 (\u00fc \u2032 , \u00fd) \u00fb \u00f6 \u00fc \u2032 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f8 \u00d7 \u00f6 \u00fb\u00f2 \u00f6\u00f3\u00f1 pr(\u00fc \u2032 |\u00fd )\u00b8\u00fb \u00f6 pr(\u00fc \u2032 |\u00fd ) \u00d7 \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00d7 \u00f8 \u00d7 \u00f1 \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00f8\u00d7 \u00f6 \u00f9\u00f1 \u00f2\u00f8\u00d7 \u00d7 pr(\u00fc |\u00fd) \u00f3\u00fa \u00ba \u00ec \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr(\u00fc \u2032 , \u00fd) \u00f3 \u00f8 \u00f9\u00f4 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f2 pr(\u00fc \u2032 , \u00fd) = pr(\u00fc \u2032 |\u00fd ) pr(\u00fd) \u00b4 \u00b5 \u00f3\u00f1\u00f4 \u00f6 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f8 \u00f2 \u00fb \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr(\u00fc \u2032 , \u00fd) \u00d7 \u00f8 \u00d7 \u00f1 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f3 \u00f8\u00d7 \u00f6 \u00f9\u00f1 \u00f2\u00f8\u00d7 \u00d7 \u00f8 \u00f3\u00f0 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr(\u00fc , \u00fd)\u00b8 \u00fd \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f2\u00ba \u00ec \u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f2\u00f3\u00f8 \u00f8 \u00d7 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00fc \u2032 \u00fb \u00d7 \u00f6 \u00fb\u00f2 \u00f6\u00f3\u00f1 pr(\u00fc \u2032 |\u00fd) \u00f8 \u00f8 \u00f2\u00f3\u00f8 \u00fa \u00f8 \u00d7 \u00f1 \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00f8\u00d7 \u00f6 \u00f9\u00f1 \u00f2\u00f8\u00d7 \u00d7 pr(\u00fc |\u00fd) \u00f3\u00fa \u00ba \u00ec \u00f3\u00fa \u00f6 \u00f9\u00f1 \u00f2\u00f8 \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00fd\u00f3\u00f9 \u00fa \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fb \u00f3\u00d7 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00b9 \u00f0 \u00f8\u00fd \u00d7 pr(\u00fc , \u00fd)\u00b8 \u00f2 \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00f8 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00f8 \u00f6\u00f8\u00d7 \u00f2 \u00f2 \u00f2 \u00f8 \u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 (\u00fc , \u00fd) \u00f8 \u00f8 \u00d7 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr(\u00fc , \u00fd)\u00b8\u00f8 \u00f2 \u00f9\u00f4 \u00f8 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f9\u00d7 \u00f2 (\u00fc , \u00fd) pr(\u00fc \u2032 |\u00fd ) \u2212\u2192 (\u00fc \u2032 , \u00fd) \u00f9 \u00f6 \u00f2\u00f8 \u00d7 \u00f8 \u00f8 \u00f8 \u00f2 \u00fb \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 (\u00fc \u2032 , \u00fd) \u00d7 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00b9 \u00f0 \u00f8\u00fd pr(\u00fc \u2032 , \u00fd) \u00b4\u00fb \u00d7 \u00f8 \u00d7 \u00f1 \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00f8\u00d7 \u00f6 \u00f9\u00f1 \u00f2\u00f8\u00d7 \u00d7 pr(\u00fc , \u00fd)\u00b5\u00ba \u00ec \u00f9\u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7 \u00f1 \u00f4\u00d7 \u00f8\u00f3 \u00f8\u00d7 \u00f0 \u00f9\u00f2 \u00f6 \u00f8 \u00f9\u00f4 \u00f8 \u00f4\u00f6 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 (\u00fc , \u00fd) pr(\u00fc \u2032 |\u00fd ) \u2212\u2192 (\u00fc \u2032 , \u00fd)\u00ba \u00ec\u00fd\u00f4 \u00f0\u00f0\u00fd\u00b8 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00f9\u00f4 \u00f8 \u00d7 \u00d7 \u00f4\u00f4\u00f0 \u00b8\u00fb \u00f6 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7 \u00d7\u00f4\u00f0 \u00f8 \u00f2\u00f8\u00f3 \u00f8\u00fb\u00f3 \u00f4 \u00f6\u00f8\u00d7 \u00f2 \u00f6 \u00f2\u00f8 \u00fb \u00fd\u00d7 \u00f3\u00f6 \u00d7\u00f9 \u00d7\u00d7 \u00fa \u00f9\u00f4 \u00f8 \u00d7\u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00fa \u00f2\u00f8\u00f9 \u00f0\u00f0\u00fd \u00f0\u00f0 \u00f8 \u00f2\u00f3 \u00d7 \u00f2 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f6 \u00fa \u00d7 \u00f8 \u00f3\u00f6 \u00f9\u00f4 \u00f8 \u00f2 \u00ba \u00ec \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f8 \u00d7 \u00f8 \u00f8 \u00f9\u00f4 \u00f8 \u00f2 \u00f9\u00d7 \u00d7 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f8\u00f3 \u00f1\u00f3\u00fa \u00f6\u00f3\u00f9\u00f2 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00f3 \u00f8\u00d7 \u00f2\u00f3 \u00d7\u00b8\u00fb \u00f0\u00d7\u00f8 \u00f9 \u00f6 \u00f2\u00f8 \u00f2 \u00f8 \u00f8 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00d7\u00f8 \u00fd\u00d7 \u00f8 \u00d7 \u00f1 \u00ba \u00e7\u00f2 \u00f8 \u00f3\u00f8 \u00f6 \u00f2 \u00b8 \u00f8 \u00f2 \u00f8 \u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 (\u00fc , \u00fd) \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00fa \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00b9 \u00f0 \u00f8\u00fd pr(\u00fc , \u00fd)\u00b8\u00f8 \u00f2 pr(\u00fc \u2032 , \u00fd) \u00f2 pr(\u00fc , \u00fd) \u00fb \u00f0\u00f0 \u00f2\u00f3\u00f8 \u00f8 \u00d7 \u00f1 \u00f9\u00f2\u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00f6 \u00f6 \u00f9\u00f1 \u00f2\u00f8\u00d7\u00b8\u00d7\u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00fb \u00f0\u00f0 \u00f2 \u00d7 \u00f8 \u00f9\u00f4 \u00f8 \u00f2 \u00d7 \u00f1 \u00d7 \u00f4\u00f4\u00f0 \u00ba \u00e1 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00f9\u00f4 \u00f8 \u00d7 \u00b4\u00f9\u00d7 \u00f2 \u00fa \u00f6 \u00f8\u00fd \u00f3 \u00d7\u00f4\u00f0 \u00f8\u00f8 \u00f2 \u00d7 \u00f3 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f3 \u00f2\u00f3 \u00d7\u00b8 \u00d7 \u00d7\u00f6 \u00f3\u00fa \u00b5 \u00d7 \u00f4\u00f4\u00f0 \u00f8 \u00f2 \u00f8 \u00d7 \u00fa\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f2 \u00f3\u00f2\u00fa \u00f6 \u00f8\u00f3 \u00fc \u00f4\u00f3 \u00f2\u00f8 \u00fb \u00f6 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00d7 \u00d7\u00f8 \u00f8 \u00f3\u00f2 \u00f6\u00fd \u00f9\u00f2 \u00f6 \u00f9\u00f4 \u00f8 \u00f2 \u00ba \u00e0\u00f3\u00fb\u00b9 \u00fa \u00f6\u00b8\u00f3\u00f2\u00fa \u00f6 \u00f2 \u00f8\u00f3 \u00f9\u00f2 \u00f5\u00f9 \u00fc \u00f4\u00f3 \u00f2\u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f8\u00f9 \u00f0\u00f0\u00fd \u00f9 \u00f6 \u00f2\u00f8 \u00b8 \u00f9\u00d7 \u00f2 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f9\u00f4 \u00f8 \u00f4\u00f6 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00f3\u00f9\u00f0 \u00f9\u00d7 \u00f8 \u00f8 \u00f0 \u00d7 \u00f8\u00f3 \u00f2\u00f3\u00f2\u00b9 \u00f6 \u00f3 \u00b9 \u00fa \u00f3\u00f9\u00f6 \u00fb \u00f6 \u00f8 \u00fb \u00f3\u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00d7 \u00f2\u00f3\u00f8 \u00fc\u00f4\u00f0\u00f3\u00f6 \u00b8 \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00f2 \u00f4\u00f6 \u00f8 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f1\u00d7 \u00fb \u00f8 \u00d7\u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f3\u00f2\u00fa \u00f6 \u00f2 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00f3\u00f9\u00f6\u00d7\u00ba \u00e1\u00f2 \u00f2 \u00e5\u00ea \u00f8 \u00f6 \u00f8 \u00f3 \u00f3 \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 pr(\u00fc \u2032 1|\u00fd ) pr(\u00fc \u2032 2|\u00fd ) \u00f8 \u00f8 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 (\u00fc , \u00fd) pr(\u00fc \u2032 |\u00fd ) \u2212\u2192 (\u00fc \u2032 , \u00fd) \u00d7 \u00fa \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00ba \u00e1 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00fc \u2032 1 \u00f2 \u00fc \u2032 2 \u00f6 \u00f2 \u00f3\u00f2\u00f0\u00fd \u00fb \u00f3 \u00f8 \u00f6 \u00fa \u00f8\u00f3\u00f6 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7\u00b8 \u00f8 \u00f2 \u00f8 \u00f6 \u00d7 \u00f0\u00f3\u00f8 \u00f3 \u00f2 \u00f0\u00f0 \u00f8 \u00f3\u00f2 \u00f2 pr(\u00fc \u2032 1|\u00fd ) pr(\u00fc \u2032 2|\u00fd ) \u00d7\u00f3 \u00f8 \u00f9\u00f0\u00f0\u00fd \u00d7 \u00f1\u00f4\u00f0 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 pr(\u00fc \u2032 1|\u00fd ) pr(\u00fc \u2032 2|\u00fd ) \u00d7 \u00f6 \u00f0 \u00f8 \u00fa \u00f0\u00fd \u00d7 \u00f1\u00f4\u00f0 \u00ba \u00ec \u00d7 \u00d7 \u00fb \u00f8 \u00f1 \u00d7 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00d7\u00f3 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f3\u00f6 \u00e5\u00ea \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00ba \u00be\u00ba\u00bf \u00e1\u00f2 \u00f6 \u00f2 \u00ed\u00d7 \u00f2 \u00f2 \u00e5\u00ea \u00e1\u00f1 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00d7 \u00f2 \u00f6 \u00fb \u00f6 \u00e5\u00ea \u00d7 \u00fa \u00f4\u00f6\u00f3\u00fa \u00f8\u00f3 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6\u00f0\u00fd \u00f9\u00d7 \u00f9\u00f0 \u2104\u00ba \u00ec \u00d7\u00f8 \u00f6\u00f8 \u00f2 \u00f4\u00f3 \u00f2\u00f8 \u00d7 \u00f8\u00f3 \u00f2 \u00f2 \u00e5\u00ea \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr(\u00fc ) \u00f3 \u00f8 \u00f1 \u00f4 \u00fc \u00f0\u00d7 pr(\u00fc ) \u2261 \u00fd pr(\u00fc , \u00fd) pr(\u00fc , \u00fd) = pr(\u00fc |\u00fd) pr(\u00fd) \u00b4 \u00b5 \u00fb \u00f6 pr(\u00fc ) \u00d7 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00d7 \u00f8 \u00f1 \u00f6 \u00f2 \u00f0 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 pr(\u00fc , \u00fd) \u00f8 \u00f6 \u00f8 \u00b9 \u00f2 \u00fa \u00f6 \u00f0 \u00d7 \u00fd \u00fa \u00f2 \u00fa \u00f6 \u00f3\u00fa \u00f6\u00b8 \u00f2 \u00f3\u00f8 pr(\u00fc |\u00fd ) \u00f2 pr(\u00fd) \u00f1 \u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 \u00f4\u00f6\u00f3 \u00f9\u00f8\u00d7 \u00f3 \u00f8\u00f3\u00f6\u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00e0 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00ba \u00ec \u00f2 \u00fa \u00f6 \u00b9 \u00f0 \u00d7 \u00fd \u00f6 \u00f8 \u00f9\u00f2\u00f3 \u00d7 \u00f6\u00fa \u00f9\u00d7 \u00d7 \u00f8 \u00f8 \u00f8 \u00f6\u00f1 \u00f2 \u00f8 \u00fa \u00f0\u00f9 \u00d7 \u00f3 \u00f8 \u00f1 \u00f4 \u00fc \u00f0\u00d7 \u00fc\u00b8 \u00f2 \u00f6 \u00f8 \u00f9\u00d7 \u00f8 \u00f9\u00d7 \u00f0 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f6 \u00f9\u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00f1 \u00ba \u00ec \u00d7 \u00f2 \u00f6 \u00f8 \u00fa \u00f1\u00f3 \u00f0 \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00b9\u00f0 \u00fd \u00f6 \u00fb \u00f8 \u00d7 \u00fa \u00f6 \u00f0 \u00f0 \u00fa \u00f0\u00d7 \u00f3 \u00f2 \u00fa \u00f6 \u00f0 \u00d7\u00ba \u00ec\u00f3 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00f2 \u00fa \u00f6 \u00f0 \u00d7 \u00fd \u00fa \u00f2 \u00f2 \u00f3 \u00d7 \u00f6\u00fa \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f1 \u00f4 \u00fc \u00f0 \u00fa \u00f0\u00f9 \u00d7 \u00fc \u00f8 \u00f4\u00f3\u00d7\u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd pr(\u00fd |\u00fc ) \u00f1\u00f9\u00d7\u00f8 \u00f9\u00d7 \u00b8\u00fb \u00f1 \u00fd \u00f3 \u00f8 \u00f2 \u00f9\u00d7 \u00f2 \u00fd \u00d7 \u00f8 \u00f3\u00f6 \u00f1 \u00d7 pr(\u00fd|\u00fc ) = pr(\u00fc |\u00fd ) pr(\u00fd) \u00fd pr(\u00fc |\u00fd) pr(\u00fd ) \u00b4 \u00b5 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00b4\u00d7 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be\u00b5 \u00f2 \u00f8 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00fb \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6\u00f3\u00f1 pr(\u00fd|\u00fc )\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00d7\u00f9 \u00d7\u00d7 \u00fa \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f4\u00f6\u00f3 \u00f9 \u00fd \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f6 \u00d7\u00f8\u00f6\u00f3\u00f2 \u00f0\u00fd \u00f3\u00f6\u00f6 \u00f0 \u00f8 \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00f9\u00d7 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00d7 \u00f2 \u00f8 \u00f1 \u00f1\u00f3\u00f6\u00fd \u00f8 \u00f1 \u00f8 \u00d7 \u00f1 \u00d7 \u00e5 \u00e5 \u00f6\u00f9\u00f2 \u00f8 \u00f1 \u00d7 \u00b4 \u00f3\u00f6 \u00fa \u00f2 \u00d7 \u00fe \u00f3 \u00f6\u00f6\u00f3\u00f6 \u00f6\u00b5 \u00f1\u00f9 \u00f0\u00f3\u00f2 \u00f6 \u00f8 \u00f2 \u00fb\u00f3\u00f9\u00f0 \u00f8 \u00d7 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f3\u00f9\u00f0 \u00d7\u00f3\u00f1 \u00f3\u00fb \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f6 \u00fb\u00f2 \u00f6\u00f3\u00f1 pr(\u00fd|\u00fc )\u00ba \u00f0\u00d7\u00f3\u00b8 pr(\u00fd|\u00fc ) \u00d7 \u00d7 \u00f2 \u00f0 \u00fb \u00f0\u00f0\u00b9 \u00f2 \u00f4 \u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b8\u00f8 \u00f2 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f0\u00f3 \u00f8 \u00f8 \u00d7\u00b8\u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00fb \u00f8 \u00f8 \u00d7\u00d7 \u00d7\u00f8 \u00f2 \u00f3 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f2\u00f2 \u00f0 \u00f2 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f8\u00f3 \u00d7\u00f3 \u00f8 \u00f2 pr(\u00fd |\u00fc ) \u00f9\u00f6 \u00f2 \u00f8 \u00f6\u00f0\u00fd \u00d7\u00f8 \u00d7 \u00f3 \u00f8 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00b8 \u00f2 \u00f8 \u00f2 \u00e5 \u00e5 \u00f9\u00f8\u00f9 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f9\u00f8 \u00f8 \u00d7 \u00f4 \u00f2 \u00f3 \u00d7 \u00f6\u00fa \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f9 \u00f8 \u00f6\u00f3 \u00f9\u00d7\u00f8\u00f2 \u00d7\u00d7 \u00f3 \u00f8 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2\u00ba \u00ec\u00fd\u00f4 \u00f0\u00f0\u00fd\u00b8 \u00f2 \u00f1 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f8 \u00f6 \u00d7 \u00d7 \u00f2 \u00f0 \u00f3\u00fa \u00f6\u00fb \u00f0\u00f1 \u00f2 \u00f0\u00fd \u00f0 \u00f0\u00fd \u00f2 \u00fa \u00f6 \u00f0 \u00d7 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f1 \u00f4 \u00fc \u00f0\u00d7 \u00b4 \u00ba \u00ba pr(\u00fd |\u00fc ) \u00d7 \u00d7 \u00f2\u00b9 \u00f0 \u00fb \u00f0\u00f0\u00b9 \u00f2 \u00f4 \u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b5\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00f3\u00fa \u00f4\u00f4\u00f6\u00f3 \u00f6 \u00f9\u00f0\u00f0\u00fd \u00b4 \u00f2 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8\u00f0\u00fd\u00b5 \u00f6 \u00d7 \u00fb \u00f2 \u00f8 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f1 \u00f9\u00f3\u00f9\u00d7 \u00b4 \u00ba \u00ba pr(\u00fd |\u00fc ) \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00fa \u00d7 \u00f2 \u00f0 \u00fb \u00f0\u00f0\u00b9 \u00f2 \u00f4 \u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b5\u00ba \u00ec \u00d7 \u00f6 \u00f9\u00f0 \u00f6 \u00b9 \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f3 \u00f1 \u00f9 \u00f8\u00fd \u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00d7\u00f8\u00f6 \u00f2 \u00f8 \u00d7 \u00f3 \u00f8 \u00fd \u00d7 \u00f2 \u00f4\u00f4\u00f6\u00f3 \u00ba \u00be\u00ba \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00e7\u00f9\u00f4 \u00eb\u00f8 \u00f8 \u00d7 \u00e1\u00f8 \u00d7 \u00f9\u00d7 \u00f9\u00f0 \u00f8\u00f3 \u00fa \u00f0\u00f3\u00f4 \u00f3\u00f2\u00f6 \u00f8 \u00fb \u00fd \u00f3 \u00fa \u00d7\u00f9 \u00f0 \u00d7 \u00f2 \u00f8 \u00f3\u00f4\u00f4 \u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f9\u00f2 \u00f6\u00f0 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be\u00ba \u00ec \u00d7 \u00d7 \u00f4\u00f6 \u00f6 \u00f5\u00f9 \u00d7 \u00f8 \u00f3\u00f6 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f8 \u00f8 \u00fa \u00f0\u00f3\u00f4 \u00f0 \u00f8 \u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00ec \u00d7\u00f8 \u00f8 \u00fc \u00f3 \u00f2 n \u00b9\u00f2\u00f3 \u00e5\u00ea \u00d7 \u00fc \u2261 (x 1 , x 2 , \u2022 \u2022 \u2022 , x n )\u00b8 \u00f2 \u00f3\u00f6 \u00fa \u00f2 \u00fc \u00f3 \u00f8\u00d7 \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8\u00d7 x i \u00f0 \u00fa \u00d7 \u00f2 \u00f3\u00f2 \u00f3 \u00f2 \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 m \u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f8 \u00f6 \u00fa \u00f0 \u00f0 \u00f8\u00f3 x i \u00b8\u00fb \u00f6 \u00f3\u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00f8\u00fd \u00fb \u00d7\u00d7\u00f9\u00f1 \u00f8 \u00f8 \u00f0\u00f0 \u00f8 x i \u00fa \u00f8 \u00d7 \u00f1 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 m\u00ba \u00e7\u00f2 \u00fb \u00fd \u00f3 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 x i \u00d7 \u00d7 \u00f2 m\u00b9\u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 \u00fa \u00f8\u00f3\u00f6 (0, 0, \u2022 \u2022 \u2022 , 0, 1, 0, \u2022 \u2022 \u2022 , 0, 0)\u00b8\u00fb \u00f6 \u00f8 \u00bd \u00f2\u00f8 \u00d7 \u00fb \u00f3 \u00f8 m \u00d7\u00f8 \u00f8 \u00d7 x i \u00f4\u00f4 \u00f2\u00d7 \u00f8\u00f3 \u00fa \u00ba \u00ec \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00d7\u00d7 \u00f2\u00f8 \u00f0\u00f0\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 m \u00f2\u00d7\u00b8\u00fb \u00f8 \u00d7 \u00f2 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00f3\u00f9\u00f4\u00fd \u00f2 \u00f3\u00f2 \u00f3 \u00f8 \u00f2\u00d7\u00ba \u00ec \u00fb \u00f3\u00f0 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 n \u00f3\u00f1\u00f4\u00f3\u00f2 \u00f2\u00f8 \u00fc \u00fa \u00f8\u00f3\u00f6 \u00d7 \u00f8 \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00fd n \u00d7\u00f9 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00b8 \u00fb \u00f8 \u00d7 \u00f2 \u00f0 \u00bd \u00f4\u00f0 \u00f2 \u00f8 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f2 \u00f8\u00f3 \u00f2\u00f8 \u00fd \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f0\u00f0 \u00f3 \u00f8 x i \u00f3\u00f6 i = 1, 2, \u2022 \u2022 \u2022 , n \u00ba ae \u00f8\u00f9\u00f6 \u00f0\u00f0\u00fd\u00b8\u00f8 \u00d7 \u00f9\u00d7 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00d7 \u00f2 \u00fc \u00f2 \u00f0\u00fd \u00fb \u00d7\u00f8 \u00f9\u00f0 \u00f3 \u00f2 \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00fc \u00f9\u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00f8\u00d7 \u00f1\u00f3\u00d7\u00f8\u00f0\u00fd \u00f3 \u00bc \u00f2\u00f8\u00f6 \u00d7\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00f8 \u00f3 \u00d7 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00f3\u00f4\u00f4 \u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8 \u00f8 \u00f6 \u00f2 \u00f6 \u00f8 \u00fd \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f8\u00f3 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f6 \u00f8\u00f0\u00fd \u00d7 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00fb \u00bd \u00f3\u00f4\u00d7 \u00f6\u00f3\u00f9\u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f2\u00d7 \u00f3 \u00f8\u00d7 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00ba \u00e5\u00f3\u00f6 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8\u00f0\u00fd\u00b8\u00f8 \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00e5\u00ea \u00d7\u00f8 \u00f8 \u00d7 \u00d7\u00f9 \u00f8 \u00f0 \u00f3\u00f6 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf \u00fb \u00f6 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f0\u00f0 \u00fa \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f3\u00f9\u00f4\u00fd \u00f2 \u00f8\u00d7 \u00f2\u00d7 \u00b4 \u00ba \u00ba \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f0\u00f0 \u00f6 \u00f3\u00f6 \u00f8 \u00e5\u00ea \u00f2\u00f3 \u00b5\u00ba \u00ec \u00d7 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00f1\u00f3\u00f6 \u00f8 \u00f0 \u00f0\u00f3\u00fb\u00ba \u00f9\u00f6 \u00bd \u00d7 \u00f3\u00fb\u00d7 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00fb \u00f8 \u00f2\u00f3 \u00d7 \u00b4 \u00ba \u00ba n = 7\u00b5\u00b8 \u00f3 \u00fb \u00d7 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u00b4 \u00ba \u00ba m = 7\u00b5\u00ba \u00ec \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00f3 \u00f2\u00f3 \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00fd \u00f3\u00f2 \u00f3 \u00f8 \u00f6 \u00f8 \u00f2 \u00f0 \u00d7\u00b8\u00f8 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f2 \u00f8 \u00f8 \u00d7 \u00f3\u00f9\u00f4 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00d7 \u00f0\u00f3 \u00b4\u00f8 \u00f9\u00f2\u00f3\u00f9\u00f4 \u00f2\u00d7 \u00f6 \u00d7 \u00f3\u00fb\u00f2 \u00d7 \u00f3\u00f8\u00d7\u00b5\u00b8 \u00f2 \u00f8 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00b5 \u00f8 \u00f8 \u00f6 \u00f8 \u00fa \u00f8 \u00fd \u00f8 \u00f3\u00f9\u00f4 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00d7 \u00f3\u00fb\u00f2 \u00d7 \u00f3\u00f0 \u00f0 \u00f2 \u00d7\u00ba \u00bd\u00ba \u00ec \u00f8\u00f3\u00f4 \u00f6\u00f3\u00fb \u00f3 \u00f9\u00f6 \u00bd \u00d7 \u00f3\u00fb\u00d7 \u00f6 \u00f2 \u00f3\u00f1 \u00f2 \u00f8 \u00f0 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00ba \u00be\u00ba \u00ec \u00f1 \u00f0 \u00f6\u00f3\u00fb \u00f3 \u00f9\u00f6 \u00bd \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2\u00f3 \u00bf \u00d7 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00ba \u00ec \u00d7 \u00d7 \u00f8 \u00f6\u00d7\u00f8 \u00d7\u00f8 \u00f4 \u00f3 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00b8 \u00f2 \u00fb \u00f2\u00f3 \u00d7 \u00f3\u00d7 \u00f2 \u00f8 \u00f6 \u00f2 \u00f3\u00f1 \u00f2 \u00f8\u00d7 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00d7 \u00ba \u00bf\u00ba \u00ec \u00f3\u00f8\u00f8\u00f3\u00f1 \u00f6\u00f3\u00fb \u00f3 \u00f9\u00f6 \u00bd \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2\u00f3 \u00bf \u00d7 \u00f2 \u00f6 \u00f8 \u00ba \u00ec \u00d7 \u00d7 \u00f8 \u00d7 \u00f3\u00f2 \u00d7\u00f8 \u00f4 \u00f3 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00b8 \u00f2 \u00fb \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6 \u00f8 \u00f2 \u00f2\u00f3 \u00bf \u00fb \u00f3\u00d7 \u00d7\u00f8 \u00f8 \u00fb \u00d7 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7\u00f0\u00fd \u00f6 \u00d7 \u00f2 \u00d7\u00f8 \u00f4 \u00be \u00f3\u00fa \u00ba \u00ec \u00f2 \u00f9 \u00f2 \u00f3 \u00f8 \u00f2 \u00f3\u00f9\u00f6 \u00f2 \u00f2\u00f3 \u00d7 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00d7\u00f8 \u00f0\u00f0\u00fd \u00f8 \u00f6\u00f1 \u00f2 \u00f8 \u00d7\u00f8 \u00f8 \u00f2 \u00fb \u00f8\u00f3 \u00f6 \u00f8 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00b8 \u00d7 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be\u00ba \u00ec \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f2 \u00fb \u00e5\u00ea \u00f2\u00f3 \u00d7 \u00f3\u00f9\u00f4 \u00fd \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00b8\u00fb \u00f2 \u00f8 \u00d7 \u00d7 \u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00ba \u00f9\u00f6 \u00be \u00d7 \u00f3\u00fb\u00d7 \u00f2 \u00fc \u00f1\u00f4\u00f0 \u00f3 \u00f8 \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00e5\u00ea \u00d7\u00f8 \u00f8 \u00ba \u00e1\u00f8 \u00d7 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00f2\u00f3\u00f8 \u00f8\u00f3 \u00f3\u00f2 \u00f9\u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00f9\u00d7 \u00d7 \u00f3 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00bd\u00ba \u00e0 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00fb \u00f8 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6 \u00f2\u00f3\u00f8 \u00f8 \u00d7 \u00f1 \u00d7 \u00f2\u00d7 \u00f1 \u00f0 \u00d7 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00fb \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00ba \u00ec \u00d7 \u00d7 \u00f9\u00d7 \u00f8 \u00f3\u00f6\u00f1 \u00f6 \u00f0\u00f0\u00f3\u00fb \u00f3\u00f6 \u00f8 \u00f9\u00f6 \u00bd \u00eb\u00f8 \u00f4\u00d7 \u00f3 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00fb \u00f8 n = 7 \u00f2 m = 7\u00ba \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f2 \u00f9\u00d7 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8\u00f3 \u00f2\u00f8 \u00f6 \u00f8 \u00fb \u00f8 \u00f3\u00f8 \u00f6\u00b8\u00fb \u00f6 \u00d7 \u00f8 \u00f0 \u00f8\u00f8 \u00f6 \u00d7 \u00f1 \u00f2\u00d7 \u00f3 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00d7\u00f8 \u00f2 \u00f6 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f2 \u00f4 \u00f6 \u00f0\u00f0 \u00f0\u00ba \u00be\u00ba \u00e0 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00fb \u00f8 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f3\u00f9\u00f0 \u00fa \u00fb \u00d7 \u00fa \u00f2 \u00d7 \u00f2 \u00f0 \u00d7\u00f9\u00f4 \u00f6 \u00b9\u00d7\u00f8 \u00f8 \u00f8 \u00f8 \u00f6 \u00f3\u00f6 \u00d7 \u00d7 \u00f2 \u00f0 \u00d7\u00f8 \u00f8 \u00f8 \u00f2\u00f8 \u00f6 \u00f3\u00f2\u00f8 \u00f2\u00f8\u00d7 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00b8\u00fb \u00fb\u00f3\u00f9\u00f0 \u00d7 \u00f9 \u00d7 \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00d7 \u00f8\u00f9 \u00f0\u00f0\u00fd \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f9\u00f8 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f3\u00f9\u00f4\u00fd \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00ba \u00ec \u00f6 \u00f0 \u00fa \u00f0 \u00d7\u00f9\u00f4 \u00f6\u00b9\u00d7\u00f8 \u00f8 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00d7 \u00f1 \u00f8 \u00f1 \u00f8 \u00f0\u00f0\u00fd \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f8\u00f3 \u00f8 \u00f0\u00f3\u00fb \u00f6\u00b9\u00f0 \u00fa \u00f0 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f6\u00f1\u00d7 \u00f3 \u00f2 \u00fa \u00f9 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b8 \u00f9\u00f8 \u00f8 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00fa \u00f0\u00f3\u00f4\u00f1 \u00f2\u00f8 \u00f3 \u00f8 \u00f0 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00ba \u00ef \u00f4\u00f6 \u00f6 \u00f8\u00f3 \u00fa \u00fb \u00f8 \u00f6 \u00f0 \u00fa \u00f0 \u00d7\u00f9\u00f4 \u00f6\u00b9\u00d7\u00f8 \u00f8 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00d7 \u00f2 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00d7 \u00f9\u00d7 \u00f8 \u00f6 \u00f8 \u00f0\u00f3\u00fb \u00f6 \u00f0 \u00fa \u00f0 \u00f8 \u00f0\u00d7 \u00fa \u00f2 \u00fb\u00f3\u00f6 \u00f3\u00f9\u00f8 \u00f9\u00d7 \u00f2 \u00f8 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00f8 \u00f8 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6\u00ba \u00e1\u00f2 \u00f9\u00f6 \u00be \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00d7\u00f3 \u00f8 \u00fb \u00f8 \u00f2\u00f3 \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00ba \u00eb\u00f9 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00fb \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00d7 \u00e5\u00ea \u00f8 \u00f3\u00f6\u00fd \u00f3 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bd\u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f0 \u00f3\u00f6\u00f1 \u00f3 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f3 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be \u00f1\u00f9\u00d7\u00f8 \u00f2\u00f3\u00fb \u00f2 \u00f6 \u00f0 \u00d7 \u00ba \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00d7 \u00fc\u00f4\u00f0\u00f3\u00f6 \u00f2 \u00f8 \u00f0 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf \u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00f8\u00f3 \u00f3\u00f4 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8\u00fb \u00f2 \u00f9\u00f6 \u00be \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f3\u00fb \u00f2 \u00f6 \u00f2 \u00f3\u00f1 \u00d7\u00f8 \u00f8 \u00ba \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00b8\u00fb \u00d7 \u00fa \u00fd \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f3\u00f2 \u00f2 \u00f2 \u00f6 \u00f8\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2\u00f3\u00f8 \u00f6 \u00f2\u00b8 \u00d7 \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00f2 \u00f9\u00f6 \u00bd\u00ba \u00ef \u00f2 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f4 \u00f6 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00f2 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f2 \u00fb \u00f8\u00fd\u00f4 \u00d7 \u00f3 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f3\u00f1 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00bd\u00ba \u00ec \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f4 \u00f6 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00fa \u00f6 \u00fb \u00f8 \u00f8 \u00f1 \u00ba \u00ec \u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00d7 \u00f6\u00f8 \u00f2 \u00f8 \u00f6\u00f9\u00f0 \u00d7 \u00d7 \u00fb \u00f0\u00f0 \u00d7 \u00f1 \u00f6 \u00f8 \u00f3\u00f2 \u00b4\u00f3\u00f6 \u00f3\u00f4\u00f4 \u00f2 \u00b5 \u00f6\u00f9\u00f0 \u00d7 \u00f3\u00f6 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f4\u00f4\u00f0 \u00f2 \u00fb \u00fd\u00d7 \u00f8 \u00f8 \u00f3 \u00f2\u00f3\u00f8 \u00f2 \u00f3\u00f6 \u00f3\u00f2\u00d7 \u00f6\u00fa \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00b8\u00d7\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00f3\u00f9\u00f8 \u00d7\u00f9 \u00d7 \u00f5\u00f9 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00b4 \u00f2 \u00fa \u00fa \u00f6\u00d7 \u00b5 \u00f6 \u00f4 \u00f6\u00f1 \u00f8\u00f8 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00ec \u00d7 \u00d7 \u00f3\u00fb \u00f6 \u00fa \u00f6\u00d7 \u00f0 \u00f9\u00f1\u00f4 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u2104 \u00f1 \u00f8 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00be\u00ba \u00ec \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00fb \u00fd\u00d7 \u00f8\u00f3 \u00f3\u00f6\u00f1 \u00f3\u00f9\u00f2 \u00d7\u00f8 \u00f8 \u00d7 \u00b8\u00fb \u00fb\u00f3\u00f9\u00f0 \u00f8 \u00f2 \u00fa \u00f0 \u00f6 \u00f0 \u00fa \u00f0 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7 \u00b4 \u00ba \u00ba \u00d7 \u00f8\u00d7 \u00f3 \u00f2\u00f8 \u00f6 \u00f8 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b5 \u00f8 \u00f8 \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f9\u00f8 \u00f3 \u00d7\u00f9 \u00b9 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7 \u00b4 \u00ba \u00ba \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f1\u00d7 \u00f0\u00fa \u00d7\u00b5\u00ba \u00ec \u00d7 \u00d7 \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00f2 \u00f9\u00f6 \u00bf\u00b8 \u00f9\u00f6 \u00f2 \u00f9\u00f6 \u00f0\u00f3\u00fb\u00ba \u00f9\u00f6 \u00bf \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f3\u00fb \u00f2 \u00f8\u00f9 \u00b9\u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00ba \u00f9\u00f6 \u00bf \u00d7 \u00f3\u00fb\u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00b9\u00d7 \u00f1\u00f4\u00f0 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 \u00f9\u00f6 \u00bd \u00f8 \u00f8 \u00d7 \u00f1\u00f3\u00f6 \u00f0\u00fd \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f8 \u00f2 \u00f8 \u00fc \u00f1\u00f4\u00f0 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f9\u00f6 \u00be\u00ba \u00f3\u00f6 \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00fa \u00f4\u00f9\u00f6\u00f4\u00f3\u00d7 \u00d7\u00b8\u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6 \u00f2\u00f3\u00fb \u00d7\u00d7\u00f9\u00f1 \u00f8\u00f3 \u00f2 \u00f2 \u00f3\u00f9\u00f6 \u00f2 \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f2\u00f3 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00d7\u00f4\u00f6 \u00f3\u00f9\u00f8 \u00f8 \u00f6 \u00f2 \u00f3\u00f1 \u00f8\u00fd\u00f4 \u00f0\u00f0\u00fd \u00f8 \u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f8 \u00d7 \u00f3\u00f6 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00fb \u00f3\u00d7 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f6 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8\u00f3 \u00f2\u00f3 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f2 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f0\u00f0\u00fd \u00f3\u00f6 \u00f6 \u00fb \u00fd\u00ba \u00ec \u00be\u00b9\u00f0 \u00f5\u00f9 \u00d7 \u00f8 \u00f8 \u00f8 \u00f2 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f8\u00fd\u00f4 \u00f0\u00f0\u00fd \u00f3\u00f6\u00f1 \u00f8 \u00f8\u00f9 \u00b9\u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00fa \u00f8 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f9\u00f6 \u00bf\u00ba \u00f9\u00f6 \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f3\u00fb \u00f2 \u00f8\u00fb\u00f3 \u00f4 \u00f6 \u00f0\u00f0 \u00f0 \u00f8\u00f9 \u00b9\u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00f9\u00f6 \u00d7 \u00f3\u00fb\u00d7 \u00f2\u00f3\u00f8 \u00f6 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f2 \u00f6 \u00d7 \u00fb \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00f3\u00b9 \u00f9\u00f4 \u00f2\u00fd\u00b8\u00fb \u00f6 \u00f8 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f3 \u00f2\u00f3 \u00d7\u00f4\u00f0 \u00f8\u00d7 \u00f2\u00f8\u00f3 \u00f8\u00fb\u00f3 \u00d7 \u00f4 \u00f6 \u00f8 \u00f0\u00f9\u00d7\u00f8 \u00f6\u00d7 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b8 \u00f2 \u00fb \u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6\u00d7 \u00d7\u00d7\u00f3 \u00f8 \u00fb \u00f8 \u00f8 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00d7 \u00d7 \u00d7\u00f9 \u00f8 \u00f8 \u00f3\u00f2\u00f0\u00fd \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f8 \u00f6 \u00f3\u00f8 \u00f2 \u00f8 \u00f8\u00f3\u00f4 \u00f0 \u00f3 \u00f8 \u00f6 \u00f1 \u00f6 \u00f3\u00f2\u00f2 \u00f8 \u00b4 \u00f2 \u00d7 \u00f1 \u00f0 \u00f6\u00f0\u00fd \u00f3\u00f6 \u00f8 \u00f3\u00f8\u00f8\u00f3\u00f1 \u00f0 \u00f3 \u00f8 \u00f6 \u00f1\u00b5\u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00f6 \u00f6 \u00f2\u00f3 \u00f8 \u00b9 \u00fa \u00f8 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00d7 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f8\u00f3\u00f4 \u00f2 \u00f3\u00f8\u00f8\u00f3\u00f1 \u00f0\u00fa \u00d7 \u00f3 \u00f8 \u00f6 \u00f1 \u00b4\u00f3\u00f6 \u00f8 \u00f0 \u00d7\u00f8 \u00f8 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00d7 \u00f2 \u00f0 \u00f0 \u00b5\u00ba \u00f8 \u00fa \u00f0\u00fd\u00b8\u00f8 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00b9 \u00f4 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f8\u00fb\u00f3 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f0\u00fd \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00f1 \u00fb \u00f8 \u00f2 \u00f8\u00b8 \u00f3 \u00fb \u00d7 \u00f8\u00d7 \u00f3\u00fb\u00f2 \u00f8\u00f9 \u00b9\u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00fa \u00f8 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00d7\u00ba \u00ec \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f1 \u00f6 \u00d7 \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00d7 \u00f8 \u00f8 \u00fa \u00f0 \u00f1 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00fa \u00f0 \u00f0 \u00f8\u00f3 \u00f2\u00f3 \u00f3 \u00f8 \u00f2\u00b8 \u00f2 \u00fb \u00f6 \u00f3\u00f4\u00f8 \u00f1 \u00d7 \u00f8\u00f3 \u00f2\u00f3 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f8\u00f3\u00f4\u00f3 \u00f6 \u00f4 \u00f0\u00f0\u00fd \u00b4\u00fb \u00f2\u00d7\u00f9\u00f6 \u00d7 \u00f8 \u00f8 \u00f8 \u00f8\u00f9 \u00b9 \u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f0\u00f3 \u00f0 \u00d7 \u00f2 \u00f8 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00d7\u00b5\u00ba \u00ec \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00fa \u00f3\u00f9\u00f6 \u00f1 \u00f6 \u00d7 \u00fb \u00f2 \u00eb\u00e7ae \u00f8\u00f6 \u00f2 \u00f2 \u00f1 \u00f8 \u00f3 \u00d7 \u00f6 \u00f9\u00d7 \u00b8 \u00f9\u00f8 \u00f8 \u00fb \u00f0\u00f0 \u00f2\u00f3\u00f8 \u00d7\u00f9\u00d7\u00d7 \u00f9\u00f6\u00f8 \u00f6 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6\u00ba \u00f9\u00f6 \u00d7 \u00f3\u00fb\u00d7 \u00f3\u00fb \u00f9\u00f6 \u00f2 \u00f1\u00f3 \u00f8 \u00f8\u00fb\u00f3 \u00f8\u00f9 \u00b9\u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00fa \u00d7\u00f3\u00f1 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00f2 \u00f3\u00f1\u00f1\u00f3\u00f2\u00b8\u00fb \u00f2 \u00d7 \u00f8 \u00f8\u00f9 \u00d7 \u00f8\u00f3 \u00f8 \u00f6\u00ba \u00f2 \u00fc\u00f8\u00f6 \u00f1 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f2 \u00f2 \u00f8\u00fb \u00f2 \u00f8\u00f9 \u00d7 \u00f2 \u00f3\u00f9\u00f6 \u00f8 \u00d7 \u00f8\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f9\u00f6 \u00b8 \u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f0\u00f0\u00fd \u00f8 \u00f6 \u00f6 \u00d7\u00f3\u00f1 \u00fb \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00fb \u00f2 \u00f8 \u00f8\u00f9 \u00d7\u00ba \u00bd\u00bc \u00f9\u00f6 \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f3\u00fb \u00f2 \u00f8\u00fb\u00f3 \u00f4 \u00f6 \u00f0\u00f0 \u00f0 \u00f8\u00f9 \u00d7\u00f8 \u00f8 \u00d7 \u00f3\u00f9\u00f2 \u00f8\u00f3 \u00f8 \u00f6\u00ba \u00bf \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00e1\u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00ec \u00f1 \u00f3 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00b8\u00fb \u00d7 \u00d7 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00fa \u00fa \u00f6\u00fd \u00d7 \u00f1\u00f4\u00f0 \u00f0 \u00f6 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7\u00b8 \u00f9\u00f8 \u00fb \u00d7 \u00f2 \u00fa \u00f6\u00f8 \u00f0 \u00d7\u00d7 \u00d7\u00f9 \u00f2\u00f8\u00f0\u00fd \u00fc \u00f0 \u00f8 \u00f8 \u00f8 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f0 \u00f6 \u00f0 \u00d7\u00d7 \u00f3 \u00e5 \u00e5 \u00b9\u00f0 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f8\u00f3 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00ba \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00bd \u00fa \u00d7 \u00d7\u00f3\u00f1 \u00f6\u00f3\u00f9\u00f2 \u00f1 \u00f8 \u00f6 \u00f0 \u00f8 \u00f8 \u00f1\u00f3\u00f8 \u00fa \u00f8 \u00d7 \u00f8 \u00f9\u00d7 \u00f3 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00d7 \u00f8 \u00f4\u00f6 \u00f1 \u00f6\u00fd \u00f1 \u00f2\u00d7 \u00f3 \u00f9 \u00f0 \u00f2 \u00fd\u00f2 \u00f1 \u00f0 \u00f1\u00f3 \u00f0\u00d7 \u00f3\u00f6 \u00d7\u00f6 \u00f8 \u00f2 \u00f8\u00b9 \u00fb\u00f3\u00f6 \u00d7\u00ba \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00d7 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f3\u00f6 \u00f1 \u00f2 \u00f4\u00f9\u00b9 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f2\u00f3 \u00d7\u00ba \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00bf \u00f9\u00d7 \u00d7 \u00f8 \u00d7 \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3\u00f1\u00f4\u00f3\u00d7 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f2 \u00f6 \u00f8 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7\u00b8 \u00f2 \u00f0\u00f0\u00fd\u00b8\u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00d7 \u00f6 \u00f1\u00f1 \u00f8 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00e5 \u00e5 \u00f0 \u00f3\u00b9 \u00f6 \u00f8 \u00f1\u00d7\u00ba \u00bf\u00ba\u00bd \u00f6\u00f3\u00f9\u00f2 \u00ec \u00f1 \u00f6 \u00d7 \u00f8\u00f3 \u00f6 \u00fb\u00f6 \u00f8 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f3\u00f6 \u00f6\u00f9\u00f2\u00f2 \u00f2 \u00f2 \u00e5\u00ea \u00b4\u00d7 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be\u00b5 \u00f9\u00d7 \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f0 \u00f6 \u00ba \u00ec \u00d7 \u00fb \u00f0\u00f0 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f8\u00f3 \u00f6\u00f9\u00f2 \u00f2 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00d7 \u00fb \u00f6 \u00f8 \u00d7 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7\u00f0\u00fd \u00f2 \u00f9\u00d7 \u00b8 \u00f2 \u00fb \u00f0\u00f0 \u00f8 \u00f9\u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00ba \u00ec \u00f6\u00f3\u00f9 \u00f3\u00f9\u00f8 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f8 \u00f1\u00f4 \u00d7 \u00d7 \u00d7 \u00f3\u00f2 \u00f9\u00d7 \u00f2 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00d7 \u00f8 \u00d7\u00f8 \u00f6\u00f8 \u00f2 \u00f4\u00f3 \u00f2\u00f8 \u00f3\u00f6 \u00f9 \u00f2 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f2 \u00e5\u00ea \u00b8\u00d7\u00f3 \u00f8 \u00e5\u00ea \u00d7 \u00fa \u00fb \u00d7 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f8\u00f3 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00fa \u00f3\u00f9\u00f6 \u00f3 \u00b4\u00d7\u00f8\u00f3 \u00d7\u00f8 \u00b5 \u00d7\u00f6 \u00f8 \u00b9\u00f8 \u00f1 \u00fd\u00f2 \u00f1 \u00f0 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00ba \u00e0 \u00f8 \u00f6\u00f8\u00f3\u00b8\u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f3\u00f9\u00f0 \u00fa \u00fb \u00d7 \u00f2 \u00f6\u00f8 \u00f8 \u00f3 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00fb \u00fd \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f6\u00f3\u00f1 \u00f2 \u00e5\u00ea \u00b8 \u00f9\u00f8 \u00f6 \u00f8 \u00d7 \u00fa \u00fb \u00d7 \u00f8 \u00fb \u00fd \u00f2 \u00fb \u00f8 \u00e5\u00ea \u00f8\u00f9 \u00f0\u00f0\u00fd \u00fa \u00d7\u00ba \u00ec \u00d7 \u00f1\u00f3\u00fa \u00d7 \u00d7\u00f0 \u00f8\u00f0\u00fd \u00fb \u00fd \u00f6\u00f3\u00f1 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00f1\u00f3\u00f8 \u00fa \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f9\u00d7 \u00f2 \u00e5\u00ea \u00d7 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f2 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3 \u00f2\u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f3\u00f6 \u00f9\u00d7 \u00f2 \u00fd \u00d7 \u00f2 \u00f0\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00b4\u00d7 \u00eb \u00f8 \u00f3\u00f2 \u00bd\u00b51 \u00bd \u00f9\u00f8 \u00f8 \u00d7 \u00f2 \u00f3 \u00f1\u00f4 \u00d7 \u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f9\u00f0\u00f0 \u00fa \u00f2\u00f8 \u00f8\u00f3 \u00f8 \u00f2 \u00f3 \u00f8 \u00fc \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00e5 \u00e5 \u00f4\u00f4\u00f6\u00f3 \u00b8 \u00f2 \u00f2 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f8\u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00ec \u00d7 \u00f9\u00f1\u00f4 \u00f8\u00f3 \u00f9\u00d7 \u00f2 \u00d7\u00f6 \u00f8 \u00b9\u00f8 \u00f1 \u00fd\u00f2 \u00f1 \u00f0 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00d7 \u00d7 \u00f8 \u00d7\u00f8 \u00f6\u00f8 \u00f2 \u00f4\u00f3 \u00f2\u00f8 \u00f3\u00f6 \u00f9 \u00f0 \u00f2 \u00f1\u00f3 \u00f0\u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f1\u00f9 \u00f0 \u00f6 \u00f6 \u00f0 \u00d7\u00d7 \u00f3 \u00fa \u00f3\u00f9\u00f6\u00d7 \u00f8\u00f3 \u00fc\u00f4\u00f0\u00f3\u00f6 \u00b8 \u00f2\u00f0\u00f9 \u00f2 \u00f3\u00f2 \u00d7 \u00f8 \u00f8 \u00f3 \u00f2\u00f3\u00f8 \u00fa \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00e0 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00fa \u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6\u00d7\u00b8 \u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00b5\u00b8\u00f3\u00f6 \u00f3 \u00f2\u00f3\u00f8 \u00fa \u00d7\u00f8 \u00fd \u00d7\u00f8 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00fa \u00f3\u00f9\u00f6 \u00f8 \u00f0\u00f0 \u00b4 \u00ba \u00ba \u00f0 \u00f1 \u00f8 \u00fd\u00f0 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f0 \u00f1 \u00f8 \u00f4\u00f3 \u00f2\u00f8\u00b8 \u00f8\u00b5\u00ba \u00ec \u00e5 \u00e5 \u00f4\u00f4\u00f6\u00f3 \u00f1\u00f3 \u00f0\u00d7 \u00fa \u00f6\u00fd\u00f8 \u00f2 \u00d7 \u00f4 \u00f6\u00f8 \u00f3 \u00fd\u00f2 \u00f1 \u00f0 \u00fa\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7\u00b8\u00fb \u00f6 \u00d7\u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f8 \u00f0 \u00f1\u00f3 \u00f0 \u00f3 \u00f8 \u00fb\u00f3\u00f6\u00f0 \u00d7 \u00f3 \u00f8 \u00f2 \u00fd \u00f8 \u00f2 \u00d7\u00f2 \u00f4\u00d7 \u00f3\u00f8 \u00f3 \u00f8 \u00fa\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00fd\u00f2 \u00f1 \u00f0 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00ba \u00ec \u00f3\u00d7 \u00fb \u00f3 \u00f2\u00d7 \u00d7\u00f8 \u00f3\u00f2 \u00d7\u00f8 \u00f6\u00f8 \u00f2 \u00f6\u00f3\u00f1 \u00fc \u00f6 \u00f4 \u00f0 \u00f1\u00f3 \u00f0 \u00d7 \u00f3\u00f2 \u00f8 \u00e0 \u00b4\u00f3\u00f6 \u00d7 \u00f8 \u00f3 \u00d7\u00f9 \u00f1\u00f3 \u00f0\u00d7\u00b5 \u00f1 \u00f8 \u00d7 \u00f4\u00f4\u00f3 \u00f2\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00d7\u00f8 \u00f6\u00f8 \u00f2 \u00f4\u00f3 \u00f2\u00f8 \u00f8 \u00f8 \u00d7 \u00f9\u00d7 \u00f6 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00f8 \u00fd \u00d7 \u00f3\u00f9\u00f0 \u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f9\u00f2 \u00f6\u00f0\u00fd \u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f8 \u00f8 \u00f2 \u00f6 \u00f8 \u00d7 \u00f8 \u00f6 \u00f6 \u00f4 \u00f0 \u00f1\u00f3 \u00f0 \u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00f4\u00f0 \u00d7 \u00f8\u00f9 \u00f0\u00f0\u00fd \u00fd\u00f2 \u00f1 \u00f0\u00b8 \u00f2 \u00f8 \u00f8 \u00f8 \u00f6 \u00f1\u00f3 \u00f0 \u00f1 \u00f6 \u00f0\u00fd \u00d7\u00f6 \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f8 \u00f0 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f8 \u00f6\u00f3\u00f9 \u00f8 \u00f1 \u00d7\u00f0 \u00f3 \u00f8 \u00d7 \u00fd\u00f2 \u00f1 \u00f0 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00f2 \u00f3\u00f8 \u00f6 \u00fb\u00f3\u00f6 \u00d7\u00b8\u00f8 \u00f6 \u00f1\u00f3 \u00f0 \u00d7\u00f6 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00f1 \u00f6 \u00f2 \u00f0 \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2\u00ba \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00b8 \u00f2 \u00e5\u00ea \u00f1 \u00f1\u00f3 \u00f0 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f8\u00f8 \u00f1\u00f4\u00f8 \u00f8\u00f3 \u00f1\u00f3 \u00f0 \u00f8 \u00d7\u00f8\u00f3\u00f6\u00fd \u00f3 \u00f8 \u00fd\u00f2 \u00f1 \u00f0 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f9\u00d7 \u00f8 \u00b4 \u00f2\u00b5 \u00f3 \u00f8\u00d7 \u00f8\u00f3 \u00fa \u00f2\u00f8\u00f9 \u00f0\u00f0\u00fd \u00fa \u00f6 \u00d7 \u00f8\u00f3 \u00f8 \u00f3 \u00d7 \u00f6\u00fa \u00f4 \u00fc \u00f0 \u00fa \u00f0\u00f9 \u00d7\u00ba \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7\u00f0\u00fd\u00b8 \u00f0\u00f0 \u00e5\u00ea \u00d7 \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00f2 \u00fd\u00f2 \u00f1 \u00f0 \u00f4\u00f6\u00f3 \u00d7\u00d7\u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f1 \u00f9\u00d7 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00f8 \u00f3\u00f4\u00f4 \u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f9\u00f2 \u00f6\u00f0 \u00e5 \u00e5 \u00f0\u00b9 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00b8\u00fb \u00f0\u00f0\u00f3\u00fb\u00d7 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f8\u00f3 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f9\u00d7 \u00f2 \u00fa \u00f6\u00fd \u00f3\u00f1\u00f4 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2\u00ba \u00ec \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00fb \u00f0\u00f0 \u00f1 \u00f0 \u00f6 \u00f8\u00f3 \u00f4 \u00fd\u00d7 \u00d7\u00f8\u00d7 \u00fb \u00f3 \u00f9\u00d7 \u00f5\u00f9 \u00f2\u00b9 \u00f8\u00f9\u00f1 \u00f0 \u00f8 \u00f3\u00f6\u00fd \u00b4\u00e9 \u00ec\u00b5 \u2104\u00b8 \u00f2 \u00f3\u00f6 \u00f8 \u00f3\u00f2\u00fa \u00f2 \u00f2 \u00f3 \u00f4 \u00fd\u00d7 \u00d7\u00f8\u00d7 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f9\u00d7 \u00f6 \u00d7 \u00f8 \u00d7 \u00f1 \u00d7 \u00d7 \u00f9\u00d7 \u00f2 \u00e9 \u00ec\u00ba \u00f2 \u00f6 \u00f0\u00f0\u00fd\u00b8\u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4\u00b9 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00f6\u00f8 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00b4\u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd\u00b5\u00b8\u00fb \u00f8 \u00f9\u00d7 \u00f2\u00f6 \u00d7 \u00f2 \u00f6 \u00d7 \u00f8 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00b4\u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd\u00b5\u00d7 \u00f3 \u00f8 \u00d7 \u00f4\u00f4\u00f6\u00f3 \u00f2 \u00f8\u00f9\u00f6 \u00f0\u00f0\u00fd \u00f0 \u00f2 \u00d7 \u00f8\u00d7 \u00f0 \u00f8\u00f3 \u00d7\u00f6 \u00f2 \u00f4\u00f6\u00f3 \u00d7\u00d7 \u00d7 \u00f8 \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f8\u00f3 \u00f6 \u00fa \u00f6\u00d7 \u00f0 \u00f9\u00f1\u00f4 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u2104\u00ba \u00bf\u00ba\u00be \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00f8 \u00f1 \u00f8 \u00f1 \u00f8 \u00f0 \u00fa \u00f0\u00f3\u00f4\u00f1 \u00f2\u00f8 \u00f3 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00d7 \u00f0 \u00f6 \u00f8 \u00f0\u00fd \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f2 \u00f2 \u00f3\u00f6\u00f1 \u00f0 \u00fb \u00fd\u00b8 \u00fd \u00fc\u00f4\u00f6 \u00d7\u00d7\u00b9 \u00f2 \u00f8 \u00f2 \u00f8 \u00f6\u00f1\u00d7 \u00f3 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f2 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f3\u00f9\u00f4\u00fd \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00ba \u00ec \u00d7 \u00d7 \u00f8\u00f3 \u00f2\u00f3\u00f9\u00f6 \u00f3\u00f2\u00f6 \u00f8 \u00f2 \u00f2\u00f8\u00f9 \u00f8 \u00fa \u00f9\u00f2 \u00f6\u00d7\u00f8 \u00f2 \u00f2 \u00f3 \u00f3\u00fb \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b8\u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f8\u00f3 \u00f1 \u00f6 \u00f0\u00fd \u00f8 \u00f2 \u00f3 \u00f8 \u00f1 \u00d7 \u00f3 \u00f8\u00d7 \u00f8 \u00f8 \u00fa \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f0 \u00f6 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7\u00ba \u00ec\u00f3 \u00f4 \u00fd\u00d7 \u00d7\u00f8 \u00fb \u00f3 \u00d7 \u00f1 \u00f0 \u00f6 \u00fb \u00f8 \u00f8 \u00f9\u00d7 \u00f3 \u00f8 \u00d7 \u00f8 \u00b9 \u00f2 \u00f5\u00f9 \u00d7 \u00f2 \u00e9 \u00ec\u00b8\u00f8 \u00fc\u00f4\u00f0 \u00f2 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f0\u00f0 \u00f4\u00f4 \u00f6 \u00f8\u00f3 \u00fa \u00f6\u00fd \u00f0\u00f3\u00f2 \u00b9\u00fb \u00f2 \u00f2 \u00f8 \u00f6 \u00fa \u00f8 \u00f3\u00f2\u00d7 \u00fa \u00f6\u00fd \u00fa \u00f0 \u00f6\u00b8 \u00f2 \u00f8\u00f3 \u00f8 \u00f1 \u00fb \u00f4\u00f3\u00f0\u00f3 \u00d7 \u00ba \u00bd\u00be \u00bf\u00ba\u00be\u00ba\u00bd \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00e7\u00f9\u00f4 \u00eb\u00f8 \u00f8 \u00d7 \u00ec \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00d7 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba \u00f2 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00fd \u00d7\u00f9 \u00f8 \u00f0\u00fd \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00d7 \u00f2 \u00fa \u00fb \u00d7 \u00d7 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00fb \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f3\u00f9\u00f4\u00fd \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00ba \u00ec \u00d7 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f9\u00d7 \u00bd\u00ba \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 |0 \u00ba \u00ec \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f2\u00d7 \u00b4 \u00f2 \u00f2 \u00f8 \u00f6\u00f1 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f8 \u00f1\u00b5 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 \u00f2\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2\u00fd \u00f3 \u00f8 \u00f2\u00d7\u00ba \u00ec \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 |0 \u00d7 \u00f2 \u00f3\u00d7 \u00f2 \u00f8\u00f3 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00fc \u00f8\u00f0\u00fd \u00f8\u00f3 \u00f8 \u00fa \u00f9\u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00f9\u00d7 \u00fd \u00f4 \u00fd\u00d7 \u00d7\u00f8\u00d7 \u00f8 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f6\u00f3\u00f9\u00f2 \u00f2 \u00fb \u00fb \u00fb \u00f0\u00f0 \u00f6 \u00f8 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00b4\u00f3\u00f6 \u00f4 \u00f6\u00f8 \u00f0 \u00d7\u00b5\u00ba \u00be\u00ba \u00e0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2 i a i \u2020 |0 \u00ba \u00ec |0 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00b4 \u00d7 \u00f2 \u00f3\u00fa \u00b5\u00b8 \u00f2 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u2020 \u00f8 \u00f2 \u00f6\u00f3\u00f1 \u00f8 \u00f0 \u00f8 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2 i \u00f3 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00ba \u00ec \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 a i \u2020 \u00d7 \u00f2 \u00f3\u00d7 \u00f2 \u00f8\u00f3 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00fc \u00f8\u00f0\u00fd \u00f8\u00f3 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f6 \u00f8 \u00f2 \u00f4 \u00f6\u00f8 \u00f0 \u00f2 \u00d7\u00f8 \u00f8 i \u00d7 \u00f9\u00d7 \u00fd \u00f4 \u00fd\u00d7 \u00d7\u00f8\u00d7\u00b8 \u00f2 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 a i \u2020 |0 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00fc \u00f8\u00f0\u00fd \u00f8\u00f3 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00d7 \u00f2 \u00f0 \u00f4 \u00f6\u00f8 \u00f0 \u00f2 \u00d7\u00f8 \u00f8 i\u00ba \u00ec \u00f9\u00d7 \u00f3 \u00f8 \u00f6 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u2020 \u00b4 \u00ba \u00ba \u00f3 \u00f2\u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00b5 \u00d7 \u00f3\u00d7 \u00f2 \u00f8\u00f3 \u00f1 \u00f3\u00f9\u00f6 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f1\u00f4 \u00f8 \u00f0 \u00fb \u00f8 \u00f8 \u00f8 \u00f9\u00d7 \u00f2 \u00e9 \u00ec \u2104\u00b8\u00fb \u00fb \u00f0\u00f0 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00f1\u00f3\u00f6 \u00f8 \u00f0 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba \u00ba \u00bf\u00ba \u00e0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 n i \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2 i (a i \u2020 ) ni |0 \u00ba \u00ec \u00d7 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00b8\u00fb \u00d7 \u00f3 \u00f8 \u00f2 \u00fd \u00f3\u00f4 \u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 |0 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f8 \u00f1 \u00d7 \u00fb \u00f8 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u2020 \u00ba \u00ba \u00e0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 n i \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2 i \u00b4 \u00f3\u00f6 i = 1, 2, \u2022 \u2022 \u2022 , m\u00b5 m i=1 (a i \u2020 ) ni |0 \u00ba \u00ec \u00d7 \u00d7 \u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f6\u00fb \u00f6 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f3\u00fa \u00b8\u00fb \u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4\u00b9 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f6 \u00f4\u00f4\u00f0 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f8 \u00f1 \u00d7 \u00f8\u00f3 \u00f0\u00f0 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00ba \u00ec \u00f3\u00fa \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f6\u00f3\u00fa \u00f1 \u00f2\u00d7 \u00f3\u00f6 \u00f6 \u00f0\u00fd \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f2 \u00f8 \u00f1\u00ba \u00e1\u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f0 \u00f8\u00f3 \u00f3 \u00f8 \u00d7 \u00f8 \u00d7 \u00f2 \u00d7\u00d7 \u00f6\u00fd \u00f8\u00f3 \u00f0 \u00f8\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00fb \u00f0\u00f0 \u00d7 \u00f6 \u00f8 \u00f8 \u00f1 \u00d7 \u00f3\u00fa \u00ba \u00bf\u00ba\u00be\u00ba\u00be \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00ec \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f0\u00f3\u00fb \u00f1 \u00fd \u00fa \u00fd \u00f9\u00d7 \u00f2 \u00f8 \u00f2\u00b9 \u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u00fb \u00d7 \u00f8 \u00f3 \u00f2\u00f8 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u2020 \u00ba \u00eb \u00f8 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f2 \u00f3 \u00f2\u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba \u00f3\u00f6 \u00f1\u00f3\u00f6 \u00f8 \u00f0\u00d7 \u00f3\u00f2 \u00fb \u00fd \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u2020 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u00f6 \u00f3 \u00f2\u00f8\u00d7 \u00f3 \u00f3\u00f8 \u00f6\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f2 \u00f8 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00f1\u00f1 \u00f8 \u00f0\u00fd \u00f0\u00f3\u00fb \u00f8 \u00fa \u00f3\u00f9\u00f6 \u00f3 a i \u2020 \u00f2 a i \u00f3\u00f6\u00b9 \u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f3\u00f9\u00f6 \u00f2\u00f8\u00f9 \u00f8 \u00fa \u00f2\u00f3\u00f8 \u00f3\u00f2 \u00f3 \u00f3\u00fb \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00d7 \u00f3\u00f9\u00f0 \u00fa \u00b8\u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f0\u00f0\u00fd \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00f8 \u00f6 \u00f0 \u00f6 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00fb \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f0 \u00f8 \u00f6 \u00f3\u00f2 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba\u00bf\u00ba \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f6 \u00d7 \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00f8\u00b9 \u00d7 \u00f0 \u00ba \u00ec \u00d7 \u00d7 \u00f1\u00f4\u00f0\u00fd \u00f2 \u00d7 \u00fb \u00f8 \u00f4\u00f4 \u00f2\u00d7 \u00fb \u00f2 \u00fd\u00f3\u00f9 \u00f8\u00f6\u00fd \u00f8\u00f3 \u00f6 \u00f1\u00f3\u00fa \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00bd\u00bf \u00f2 \u00f0\u00f6 \u00fd \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00b8\u00fb \u00d7 \u00fa \u00f6\u00fd \u00f9\u00d7 \u00f9\u00f0 \u00f3\u00f6 \u00f0 \u00f2 \u00f2 \u00f9\u00f4 \u00f0 \u00f6 \u00fc\u00b9 \u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2\u00d7 \u00f2\u00fa\u00f3\u00f0\u00fa \u00f2 a i \u00f2 |0 \u00ba \u00e1\u00f2 \u00f8\u00b8\u00f8 \u00d7 \u00f2 \u00d7 \u00f8 \u00fa \u00f9\u00f9\u00f1 |0 \u00d7 \u00f8 \u00f6 \u00f6 \u00f2 \u00d7\u00f8 \u00f8 \u00f3\u00f6 \u00f8 \u00f6\u00f1 \u00f2 \u00f2 \u00f8 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00ba a i |0 = 0 \u00b4 \u00b5 \u00fb \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f3\u00f6 \u00f2\u00fd i \u00d7 (0, 0, 0, 0) ai \u2212\u2192 0 \u00b4\u00bd\u00bc\u00b5 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00bd\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f0 \u00fa \u00d7 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00ba \u00ec \u00d7 \u00f2 \u00f8 \u00f3\u00f2 \u00d7 \u00f8 \u00f3\u00f1\u00f1\u00f3\u00f2\u00b9\u00d7 \u00f2\u00d7 \u00f2\u00f3\u00f8 \u00f3\u00f2 \u00f3 \u00fb \u00f8 \u00d7 \u00f3\u00f9\u00f0 \u00f4\u00f4 \u00f2 \u00fb \u00f2 \u00fd\u00f3\u00f9 \u00f6 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00b8\u00f8 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f8 \u00f2\u00ba \u00ec \u00f9\u00d7 a i a i \u2020 |0 = |0 \u00b4\u00bd\u00bd\u00b5 \u00fb \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 i = 3 \u00d7 (0, 0, 0, 0) ai \u2020 \u2212\u2192 (0, 0, 1, 0) ai \u2212\u2192 (0, 0, 0, 0) \u00b4\u00bd\u00be\u00b5 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00f8 \u00fb\u00f6\u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00b4 \u00ba \u00ba j = i\u00b5 \u00f6\u00f3\u00f1 \u00bd\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f6 \u00d7 \u00d7 \u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00f8\u00d7 \u00f0 \u00ba \u00ec \u00d7 \u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f2 \u00fb \u00f8 \u00d7\u00b9 \u00f8\u00f3 \u00f6 \u00f1 \u00f0\u00f6 \u00fd \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00b8 \u00f9\u00f8 \u00f8 \u00d7 \u00f2 \u00f6 \u00f2\u00f8 \u00f2 \u00f6\u00f3\u00f1 \u00f8 \u00f3\u00f2 \u00f6\u00f3\u00f1 \u00fb \u00fb \u00f6 \u00f8\u00f6\u00fd \u00f2 \u00f8\u00f3 \u00f6 \u00f1\u00f3\u00fa \u00d7 \u00f1\u00f4\u00f0 \u00ba a j a i \u2020 |0 = 0 j = i \u00b4\u00bd\u00bf\u00b5 \u00fb \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 i = 3 \u00f2 j = i \u00d7 (0, 0, 0, 0) ai \u2020 \u2212\u2192 (0, 0, 1, 0) aj \u2212\u2192 0 \u00b4\u00bd \u00b5 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00be \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f2 \u00f2\u00f3\u00fb \u00f3\u00f1 \u00f2 \u00f8\u00f3 \u00fa \u00b4\u00f8 \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00f3\u00fb\u00d7 \u00f8 i = 3 \u00d7 \u00b5 (0, 0, 0, 0) ai \u2020 \u2212\u2192 (0, 0, 1, 0) aj \u2212\u2192 (0, 0, 0, 0) j = i 0 j = i \u00b4\u00bd \u00b5 \u00e1 \u00f8 \u00f0\u00f3 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f3\u00f9\u00f4 \u00f2 \u00d7 \u00f9\u00f2 \u00f2\u00f3\u00fb\u00f2\u00b8\u00fd \u00f8 \u00fd\u00f3\u00f9 \u00fb \u00f2\u00f8 \u00f8\u00f3 \u00f6\u00f8 \u00f2 \u00f8 \u00f8 \u00fd\u00f3\u00f9 \u00f2\u00f2 \u00f0 \u00f8 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00b8\u00f8 \u00f2 \u00fd\u00f3\u00f9 \u00fa \u00f8\u00f3 \u00f8\u00f8 \u00f1\u00f4\u00f8 \u00f8\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00fa \u00f6\u00fd \u00f3\u00f2 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00ba \u00ec \u00d7 \u00f3\u00f1 \u00f2 \u00d7 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f3\u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bd \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00bf\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 |0 \u00b4\u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00b5 \u00d7 \u00f6 \u00f2\u00f8 \u00f6\u00f3\u00f1 0 \u00b4\u00f2\u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f8 \u00f0\u00f0\u00b8 \u00ba \u00ba \u00f2\u00f3\u00f8 \u00fa \u00f2 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00f3\u00f2 \u00b5\u00ba m j=1 a j a i \u2020 |0 = a 1 a i \u2020 |0 + a 2 a i \u2020 |0 + \u2022 \u2022 \u2022 + a i a i \u2020 |0 + \u2022 \u2022 \u2022 + a m a i \u2020 |0 = 0 + 0 + \u2022 \u2022 \u2022 + 0 + |0 + 0 + \u2022 \u2022 \u2022 + 0 = |0 \u00b4\u00bd \u00b5 \u00bd \u00fb \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 i = 3 \u00d7 (0, 0, 0, 0) ai \u2020 \u2212\u2192 (0, 0, 1, 0) m j=1 aj \u2212\u2192 (0, 0, 0, 0) \u00b4\u00bd \u00b5 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00be\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00b4\u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f6 \u00f2\u00f8 \u00f2\u00d7\u00b8 \u00ba \u00ba i 1 = i 2 \u00b5 \u00f0 \u00fa \u00d7 \u00f8\u00fb\u00f3 \u00bd\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00ba \u00ec \u00d7 \u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f2 \u00fb \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f6\u00f8\u00d7 \u00fb \u00f8 \u00f8\u00fb\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00b4 \u00f2\u00f3\u00fb\u00f2 \u00f8\u00f3 \u00f2 \u00f6 \u00f2\u00f8 \u00f2\u00d7\u00b5 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00ba m j=1 a j a i1 \u2020 a i2 \u2020 |0 = a 1 a i1 \u2020 a i2 \u2020 |0 + \u2022 \u2022 \u2022 + a ii a i1 \u2020 a i2 \u2020 |0 + \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 + a i2 a i1 \u2020 a i2 \u2020 |0 + \u2022 \u2022 \u2022 + a m a i1 \u2020 a i2 \u2020 |0 = 0 + \u2022 \u2022 \u2022 + 0 + a i2 \u2020 |0 + 0 + \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 + 0 + a i1 \u2020 |0 + 0 + \u2022 \u2022 \u2022 + 0 = a i1 \u2020 |0 + a i2 \u2020 |0 i 1 = i 2 \u00b4\u00bd \u00b5 \u00fb \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 (i 1 , i 2 ) = (1, 3) \u00d7 (0, 0, 0, 0) ai 1 \u2020 \u2212\u2192 (1, 0, 0, 0) ai 2 \u2020 \u2212\u2192 (1, 0, 1, 0) m j=1 aj \u2212\u2192 (1, 0, 0, 0) + (0, 0, 1, 0) \u00b4\u00bd \u00b5 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00be\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00b4\u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00d7 \u00f1 \u00f2\u00b8 \u00ba \u00ba i 1 = i 2 = i\u00b5 \u00f0 \u00fa \u00d7 \u00f8\u00fb\u00f3 \u00f3\u00f4 \u00d7 \u00f3 \u00f8 \u00d7 \u00f1 \u00bd\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00b4 \u00f9\u00d7 \u00f8 \u00f6 \u00f3 \u00f8 \u00f8\u00fb\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f8\u00f3 \u00f0 \u00fa \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00b5\u00ba \u00ec \u00d7 \u00d7 \u00fa \u00f6 \u00f8 \u00f3\u00f2 \u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00b8 \u00f2 \u00f8 \u00d7 \u00f8 \u00f6\u00d7\u00f8 \u00fc \u00f1\u00f4\u00f0 \u00f3 \u00f8\u00f8 \u00f1\u00f4\u00f8 \u00f2 \u00f8\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f2 \u00f8 \u00f8 \u00d7 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f8\u00ba \u00ec \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fb \u00fd\u00d7 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00f2 \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00f2\u00ba m j=1 a j a i \u2020 2 |0 = a 1 a i \u2020 2 |0 + a 2 a i \u2020 2 |0 + \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 + a i a i \u2020 2 |0 + \u2022 \u2022 \u2022 + a m a i \u2020 2 |0 = 0 + 0 + \u2022 \u2022 \u2022 + 0 + 2a i \u2020 |0 + 0 + \u2022 \u2022 \u2022 + 0 = 2a i \u2020 |0 \u00b4\u00be\u00bc\u00b5 \u00fb \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 i 1 = 1 \u00d7 (0, 0, 0, 0) ai 1 \u2020 \u2212\u2192 (1, 0, 0, 0) ai 1 \u2020 \u2212\u2192 (2, 0, 0, 0) m j=1 aj \u2212\u2192 (1, 0, 0, 0) + (1, 0, 0, 0) \u00b4\u00be\u00bd\u00b5 \u00bf\u00ba\u00be\u00ba\u00bf \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00ea \u00f0 \u00f8 \u00f3\u00f2\u00d7 ae\u00f3\u00fb \u00f8 \u00f8 \u00d7\u00f3\u00f1 \u00f3 \u00f8 \u00f6 \u00f5\u00f9 \u00f6 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00fa \u00f2 \u00d7\u00f8 \u00f0 \u00d7 \u00b8\u00fb \u00f6 \u00f2 \u00f4\u00f3\u00d7 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f9 \u00d7\u00d7 \u00fb \u00f8 \u00f8 \u00f6 \u00f2 \u00f6 \u00f0 \u00f0 \u00b9 \u00f6 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00d7 \u00f3\u00f9\u00f0 \u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00fb \u00f2 \u00f3 \u00f6 \u00f8\u00f6 \u00f6 \u00f0\u00fd \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f2 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f6 \u00f8\u00f6 \u00f6\u00fd \u00f3\u00f9\u00f4 \u00f2\u00fd\u00ba \u00bd \u00f0\u00f0 \u00f3 \u00f8 \u00f3\u00fa \u00fa \u00f3\u00f9\u00f6 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00b4 \u00f4 \u00f6\u00f8 \u00f6\u00f3\u00f1 a i |0 = 0 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b5 \u00f2 \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00f2 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 a i a j \u2020 \u2212 a j \u2020 a i = \u03b4 i,j a i a j \u2212 a j a i = 0 a i \u2020 a j \u2020 \u2212 a j \u2020 a i \u2020 = 0 \u00b4\u00be\u00be\u00b5 \u00fb \u00f6 \u03b4 i,j \u00d7 \u00e3\u00f6\u00f3\u00f2 \u00f6 \u00f0\u00f8 \u00b4\u03b4i,j = 1 i = j\u00b8 \u00f2 \u03b4 i,j = 0 i = j\u00b5\u00ba \u00ec \u00d7 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f6 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f2 \u00d7 \u00f3\u00f6\u00f8 \u00f2 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00d7 a i , a j \u2020 = \u03b4 i,j [a i , a j ] = 0 a i \u2020 , a j \u2020 = 0 \u00b4\u00be\u00bf\u00b5 \u00ec [a i , a j ] = 0 \u00f2 [a i \u2020 , a j \u2020 ] = 0 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f6\u00f3\u00f1 \u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f5\u00f9 \u00f2 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2 \u00d7\u00f3\u00f0 \u00f0\u00fd \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00b4\u00f3\u00f6 \u00d7\u00f3\u00f0 \u00f0\u00fd \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00b5 \u00d7 \u00f8 \u00d7 \u00f1 \u00f8 \u00fb \u00f8 \u00fa \u00f6 \u00f8 \u00f3\u00f6 \u00f6 \u00f2 \u00fb \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f4\u00f4 \u00f6 \u00f2 \u00f8 \u00d7 \u00f5\u00f9 \u00f2 \u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00d7 \u00f3\u00f6 \u00f6 \u00f2 \u00f4 \u00f2 \u00f2 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8\u00fd \u00fa \u00f2 \u00d7 \u00d7 \u00fb \u00f2 \u00f8 \u00d7 \u00f5\u00f9 \u00f2 \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00f2\u00f8 \u00f6\u00f0 \u00fa \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00b8 \u00d7 \u00fb \u00f0\u00f0 \u00fc\u00f4\u00f0 \u00f2 \u00f0\u00f3\u00fb\u00ba \u00ec [a i , a j \u2020 ] = \u03b4 i,j \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2 \u00f1 \u00fd \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 j = 3 \u00d7 (0, 0, 0, 0) aj \u2020 \u2212\u2192 (0, 0, 1, 0) ai \u2212\u2192 (0, 0, 0, 0) i = j 0 i = j (0, 0, 0, 0) ai \u2212\u2192 0 aj \u2020 \u2212\u2192 0 \u00b4\u00be \u00b5 \u00f2 \u00f3\u00f6 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 (n 1 , n 2 , \u2022 \u2022 \u2022 ) aj \u2020 \u2212\u2192 (n 1 , n 2 , \u2022 \u2022 \u2022 , n j + 1, \u2022 \u2022 \u2022 ) ai \u2212\u2192 (n i + 1) (n 1 , n 2 , \u2022 \u2022 \u2022 ) i = j n i (n 1 , \u2022 \u2022 \u2022 , n i \u2212 1, \u2022 \u2022 \u2022 , n j + 1, \u2022 \u2022 \u2022 ) i = j (n 1 , n 2 , \u2022 \u2022 \u2022 ) ai \u2212\u2192 n i (n 1 , \u2022 \u2022 \u2022 , n i \u2212 1, \u2022 \u2022 \u2022 ) aj \u2020 \u2212\u2192 n i (n 1 , n 2 , \u2022 \u2022 \u2022 ) i = j n i (n 1 , \u2022 \u2022 \u2022 , n i \u2212 1, \u2022 \u2022 \u2022 , n j + 1, \u2022 \u2022 \u2022 ) i = j \u00b4\u00be \u00b5 \u00f2 \u00fd \u00f8 \u00f2 \u00f8 \u00f6 \u00f2 \u00f3 \u00f8 a i a j \u2020 \u00b4 \u00ba \u00ba \u00f8 \u00f6\u00d7\u00f8 \u00f0 \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f3\u00fa \u00b5 \u00f2 \u00f8 a j \u2020 a i \u00b4 \u00ba \u00ba \u00f8 \u00d7 \u00f3\u00f2 \u00f0 \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f3\u00fa \u00b5 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3\u00fa \u00f8 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8\u00f3\u00f6 \u00f6 \u00f0 \u00f8 \u00f3\u00f2 [a i , a j \u2020 ] = \u03b4 i,j \u00d7 \u00f3\u00f6\u00f6 \u00f8\u00f0\u00fd \u00fa \u00f6 \u00ba \u00ec \u00fd \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 \u00f8 i = j \u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00fb \u00d7 \u00f8\u00f3\u00f6 n i + 1 \u00f2 \u00f8 a i a j \u2020 \u00d7 \u00f2 \u00f8\u00f3\u00f6 n i \u00f2 \u00f8 a j \u2020 a i \u00d7 \u00b8\u00fb \u00f6 \u00d7 \u00d7 \u00f9\u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fb \u00fd\u00d7 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00fb \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8\u00d7 \u00f9\u00f4\u00f3\u00f2\u00b8 \u00f2 \u00f8 \u00d7 \u00f2\u00f9\u00f1 \u00f6 \u00d7 \u00f3\u00f2 \u00f6 \u00f8 \u00f6 \u00f2 \u00f8 \u00d7 \u00fb \u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f8 \u00f8\u00f3 \u00f8 \u00f3\u00f2 \u00f8 \u00f2 \u00f3\u00f6 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f8 \u00f8\u00d7 \u00f2 \u00f8\u00f3 \u00f8 \u00f3\u00f2 \u00f8 \u00d7 \u00f1 \u00f2\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bf \u00fc\u00f8 \u00f2 \u00d7 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f4 \u00f2 \u00f2\u00f8\u00f0\u00fd \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f8 \u00f8 \u00fd \u00f8 \u00f9\u00f4\u00f3\u00f2\u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2\u00f3\u00fb \u00fa \u00d7\u00f4 \u00f8\u00d7 \u00f3\u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00fb \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f2\u00d7 \u00f8 \u00d7 \u00fc\u00f8 \u00f2 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00fb \u00f6 \u00f2\u00f3\u00f8 \u00d7\u00f4 \u00b9 \u00f2 \u00f8 \u00fa \u00f0\u00f3\u00f4\u00f1 \u00f2\u00f8 \u00f9\u00f4 \u00d7 \u00f6 \u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bd\u00ba \u00ec \u00f9\u00d7 \u00f8 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00f3 \u00bd \u00f3 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bf \u00f2 \u00d7 \u00d7\u00f4 \u00d7 \u00f8 \u00f3 \u00f3\u00f1 \u00f2 \u00f8\u00f3\u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f3\u00f6 \u00f3\u00fb \u00f3\u00f2 \u00f2 \u00d7 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f3\u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2\u00b8\u00fb \u00f6 \u00d7\u00f6 \u00f3\u00fa \u00f2 \u00fb \u00fa \u00f2\u00f8\u00f9 \u00f8 \u00fa \u00f0\u00fd \u00f6 \u00d7\u00f3\u00f2 \u00f0 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7\u00ba \u00ec \u00f3\u00fa \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00fa \u00f2 \u00f9\u00d7\u00f8 \u00fd \u00f4\u00f4 \u00f0 \u00f2 \u00f8\u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f2 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00fb \u00f0 \u00d7 \u00f9\u00f8\u00f3\u00f1 \u00f8 \u00f0\u00f0\u00fd \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00fa \u00f2 \u00f8 \u00d7 \u00f1 \u00f3\u00f1 \u00f2 \u00f8\u00f3\u00f6 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00b9 \u00f8 \u00d7 \u00d7 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f6 \u00f9\u00d7 \u00f2 \u00e9 \u00ec \u00f3 \u00f3\u00d7\u00f3\u00f2\u00d7 \u2104\u00ba \u00bf\u00ba\u00be\u00ba \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00ea \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00e1\u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba\u00bf \u00d7 \u00f8 \u00f3 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00d7 \u00f2 \u00d7 \u00f3\u00f2 \u00f8 \u00f6 \u00f5\u00f9 \u00f6 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00fa \u00f6 \u00f8\u00fd \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00f8 \u00f8 \u00fb \u00f6 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba\u00be\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00d7 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f1\u00f3\u00f6 \u00f8 \u00f2 \u00f9\u00d7\u00f8 \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00f8 \u00d7 \u00d7\u00f4 \u00f0 \u00d7 \u00d7\u00b8\u00f8 \u00fd \u00fc\u00f8 \u00f2 \u00f8 \u00f9\u00d7 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f0\u00f0 \u00d7 \u00f8\u00f9 \u00f8 \u00f3\u00f2\u00d7\u00b8 \u00f2\u00f0\u00f9 \u00f2 \u00d7 \u00d7 \u00fb \u00f6 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7 \u00f6 \u00f3\u00f9\u00f4 \u00fd \u00f2 \u00f6 \u00f8\u00f6 \u00f6\u00fd \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00ba \u00ec \u00f9\u00d7 \u00f8 \u00d7 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00b9 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f4\u00f6\u00f3\u00fa \u00f2 \u00f0 \u00f6 \u00f0\u00f0\u00fd \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f9\u00f8 \u00f8\u00f3 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00ba ae\u00f3 \u00f3\u00f9 \u00f8 \u00f8 \u00f6 \u00f6 \u00f3\u00f8 \u00f6 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00b8 \u00f9\u00f8 \u00f2\u00f3\u00f2 \u00f3 \u00f8 \u00f1 \u00fb \u00f0\u00f0 \u00fa \u00f8 \u00f0 \u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00f2 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba\u00bf\u00ba \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00b8\u00f3\u00f2\u00d7 \u00f6 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 (a 1 \u2020 ) n1 \u2022 \u2022 \u2022 (a m \u2020 ) nm |0 \u00ba \u00d7 \u00f2 \u00e9 \u00ec \u2104\u00b8\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f3 \u00d7\u00f4 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f8 \u00f0\u00f0 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f3\u00f9\u00f4 \u00f2 \u00d7\u00b8 \u00f2 \u00f8 \u00d7 \u00f3 \u00d7\u00f4 \u00f2 \u00fc\u00f4\u00f0\u00f3\u00f6 \u00fd \u00f4\u00f4\u00f0\u00fd \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00ec \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00fc\u00f4\u00f0\u00f3\u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f6\u00f6 \u00b9 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00fb \u00f8 \u00d7 \u00f3\u00f2 \u00f2 \u00f6 \u00fa \u00f6\u00d7 \u00f0 \u00f9\u00f1\u00f4 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u2104\u00b8\u00fb \u00f6 \u00f8 \u00d7\u00f3\u00f4 \u00f3 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 \u00d7 \u00fc\u00f8 \u00f2 \u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f1\u00f3 \u00f0\u00d7\u00b8 \u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00f3 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00fb \u00f8 \u00f2 \u00d7 \u00f2 \u00f0 \u00f1\u00f3 \u00f0 \u00f8 \u00f8 \u00f9\u00d7\u00f9 \u00f0\u00f0\u00fd \u00f3\u00f9\u00f6\u00d7\u00ba \u00e1\u00f8 \u00f2 \u00d7 \u00f2 \u00f8 \u00f8 \u00f8 \u00f8 \u00f3 m j=1 a j \u00d7 \u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00b4 \u00ba \u00ba \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fb \u00fd\u00d7 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f2 \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00f2\u00b5\u00b8 \u00f2 \u00f8\u00f3 \u00f0\u00d7\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6\u00f3\u00f1 \u00f2\u00b8 \u00d7 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00ba \uf8eb \uf8ed m j=1 a j \uf8f6 \uf8f8 a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 = n 1 a 1 \u2020 n1\u22121 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 +n 2 a 1 \u2020 n1 a 2 \u2020 n2\u22121 \u2022 \u2022 \u2022 a m \u2020 nm |0 \u00ba \u00ba \u00ba +n m a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm\u22121 |0 \u00b4\u00be \u00b5 \u00ec \u00f3\u00fa \u00f8 \u00f3 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f6 \u00f8 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3 m j=1 a j \u00f2 \u00f6 \u00f8 \u00fd \u00f0\u00f8 \u00f6 \u00f2 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00d7 m j=1 a j \u2212\u2192 m j=1 a j \u2020 a j \u00b8 \u00f9\u00d7 \u00f8 \u00f2\u00f0\u00f9\u00d7 \u00f3\u00f2 \u00f3 a j \u2020 \u00f8\u00f3 \u00f8 \u00f0 \u00f8 \u00f3 a j \u00f2\u00d7\u00f9\u00f6 \u00d7 \u00f8 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00fb \u00f0\u00f0 \u00f6 \u00f8 \u00f2 \u00f2 j \u00f8\u00f3 \u00f1 \u00f9\u00f4 \u00f3\u00f6 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 a j \u00f2\u00f2 \u00f0 \u00f8 \u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f6 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00f3\u00f2 \u00fb \u00fd \u00f3 \u00f6 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2\u00b8 \u00f9\u00f8 \u00f8 \u00f6 \u00f6 \u00d7 \u00f1 \u00f2\u00fd \u00fb \u00fd\u00d7 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f6 \u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00f2\u00ba \u00bd \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f2 \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00f3\u00f6 n \u2265 1 \u00b4\u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f6\u00ba \u00ba\u00d7\u00ba \u00d7 \u00bc \u00f3\u00f6 n = 0\u00b5 a i a j \u2020 n |0 = n\u03b4 i,j a j \u2020 n\u22121 |0 \u00b4\u00be \u00b5 \u00fb \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 j = 3 \u00d7 (0, 0, 0, 0) (aj \u2020 ) n \u2212\u2192 (0, 0, n, 0) ai \u2212\u2192 n (0, 0, n \u2212 1, 0) i = j 0 i = j \u00b4\u00be \u00b5 \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f1 \u00fd \u00f9\u00d7 \u00f2 \u00f2 \u00f6 \u00f0 \u00f8\u00f3 \u00f1\u00f3\u00fa \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f3 \u00f0\u00f0 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00d7 \u00d7 \u00f0\u00fd \u00f4\u00f6\u00f3\u00fa \u00fd \u00f9\u00d7 \u00f2 [a i , a j \u2020 ] = \u03b4 i,j \u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f6 \u00d7\u00d7 \u00fa \u00f0\u00fd \u00f1\u00f3\u00fa a i \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f3\u00f2 a j \u2020 \u00f8 \u00f8 \u00f1 \u00b8 \u00f2 \u00f8 \u00f2 \u00f9\u00d7 \u00f2 a i |0 = 0 \u00f8\u00f3 \u00d7 \u00f6 \u00f2\u00fd \u00f8 \u00f6\u00f1\u00d7 \u00f8 \u00f8 \u00f3\u00f2\u00f8 \u00f2 a i |0 \u00ba \u00bf\u00ba\u00be\u00ba \u00f3 \u00f2 \u00f0\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00ed\u00d7 \u00f2 \u00fc\u00f4\u00f0 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00b4 \u00ba \u00ba (0, 0, 0, 0) ai \u2020 \u2212\u2192 (0, 0, 1, 0)\u00b5 \u00f3\u00f6 \u00fb \u00f8 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f6 \u00f3 \u00f2 \u00f8\u00f3 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7 \u00d7 \u00fa \u00f6\u00fd \u00f8 \u00f3\u00f9\u00d7 \u00f2 \u00d7 \u00d7 \u00f8 \u00f8 \u00f6 \u00f2\u00f3\u00f8 \u00f1\u00f9 \u00f1\u00f3\u00f6 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00fa \u00ba \u00ec \u00f4\u00f9\u00f6\u00f4\u00f3\u00d7 \u00f3 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00d7 \u00f8\u00f3 \u00f6 \u00f4\u00f0 \u00f8 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00fd \u00f0 \u00f6 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00d7 \u00f3\u00f2 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 a i |0 = 0 \u00f2 [a i , a j \u2020 ] = \u03b4 i,j \u00b8\u00fb \u00f0\u00d7\u00f3 \u00d7 \u00f8 \u00d7 \u00f6 \u00f0 \u00d7 \u00f8 \u00f8 \u00f8 \u00f8 \u00f0\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f0\u00fd \u00f9\u00f8\u00f3\u00f1 \u00f8 \u00fd \u00f9\u00d7 \u00f2 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f0 \u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00d7\u00ba \u00e1\u00f2 \u00f2 \u00f6 \u00f0\u00b8 \u00fc\u00f4\u00f0 \u00f8 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00d7 \u00f3\u00f9\u00f0 \u00f2 \u00f3\u00f2\u00f0\u00fd \u00f8\u00f3 \u00fa \u00f6 \u00fd \u00fb \u00f8 \u00d7 \u00f2 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00b8 \u00f2 \u00f8\u00f3 \u00f8 \u00f8 \u00f8 \u00d7 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00fb \u00f8 \u00fb \u00d7 \u00f2\u00f8 \u00f2 \u00ba \u00f6\u00f3\u00f1 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00f4\u00f3 \u00f2\u00f8 \u00f3 \u00fa \u00fb \u00f8 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bf \u00f6 \u00f2 \u00f0 \u00f6 \u00fb \u00fd \u00f3 \u00f3 \u00f2 \u00f8 \u00f3\u00f3 \u00b9 \u00f4 \u00f2 \u00f8\u00f3 \u00f4 \u00f8\u00f6 \u00f3 \u00f3\u00fb \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f2 \u00f1\u00f3 \u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00f4 \u00f2 \u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f6 \u00f6 \u00f2 \u00fb \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f6 \u00f4\u00f4\u00f0 \u00ba \u00ec [a i , a j \u2020 ] = \u03b4 i,j \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f6 \u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f2 \u00f8 \u00f3\u00f6\u00f1 a i a j \u2020 = a j \u2020 a i + \u03b4 i,j \u00b8\u00fb \u00f2 \u00f8 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00f4\u00f0 a i a j \u2020 \u00fd a j \u2020 a i + \u03b4 i,j \u00b8\u00fb \u00f8 \u00fa \u00f0\u00fd \u00f1\u00f3\u00fa \u00d7 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00b4 \u00fa \u00f2 \u00f8 a j \u2020 a i \u00f8 \u00f6\u00f1\u00b5 \u00fb \u00f0\u00d7\u00f8 \u00f4 \u00f2 \u00f9\u00f4 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8\u00f3\u00f6 \u00b4\u00f8 \u03b4 i,j \u00f8 \u00f6\u00f1\u00b5 \u00d7 \u00d7 \u00f8\u00ba \u00ec \u00d7 \u00d7 \u00fd\u00d7 \u00f8 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f8 \u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00b4 \u00ba \u00ba a i a j \u2020 \u00b5 \u00d7 \u00f8 \u00d7 \u00f1 \u00d7 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00b4 \u00ba \u00ba a j \u2020 a i \u00b5\u00b8 \u00fc \u00f4\u00f8 \u00f3\u00f6 \u00fb \u00f2 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f6 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f8 \u00d7 \u00f1 \u00f2\u00b8\u00fb \u00f8\u00f6 \u00f6\u00d7 \u00f8 \u00f4\u00f4 \u00f6 \u00f2 \u00f3 \u00f8 \u03b4 i,j \u00f8 \u00f6\u00f1 \u00f3\u00f6 \u00f6 \u00d7\u00f3\u00f2\u00d7 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00fa \u00ba \u00d7 \u00f1 \u00f2\u00f9 \u00f0 \u00fc \u00f6 \u00d7 \u00b8 \u00f8 \u00f2 \u00fa \u00f6 \u00f8 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00fb \u00f8 \u00f8 \u00f3\u00fa \u00f4\u00f6\u00f3\u00f4\u00b9 \u00f6\u00f8 \u00d7 \u00b4 \u00ba \u00ba a i |0 = 0 \u00f2 [a i , a j \u2020 ] = \u03b4 i,j \u00b5 \u00f3\u00f6\u00f6 \u00f8\u00f0\u00fd \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00be\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00b4\u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2\u00fd \u00f2\u00d7\u00b5 \u00f8 \u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bc \u00f8\u00f3 \u00f8 \u00d7 \u00fb \u00f6 \u00f8 \u00f2\u00d7 \u00f6 \u00f2\u00f3\u00f8 \u00d7\u00d7\u00f9\u00f1 \u00f8\u00f3 \u00f8 \u00d7 \u00f1 \u00ba \u00ec \u00d7\u00f8\u00f6 \u00f8 \u00fd \u00f2 \u00f8 \u00d7 \u00f6 \u00fa \u00f8 \u00f3\u00f2 \u00b4 \u00f2 \u00f2 \u00f0\u00f0 \u00f3\u00f8 \u00f6 \u00f6 \u00fa \u00f8 \u00f3\u00f2\u00d7 \u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6\u00b9 \u00f8\u00f3\u00f6\u00d7\u00b5 \u00d7 \u00f8\u00f3 \u00f1\u00f3\u00fa \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f3 \u00f0\u00f0 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00b4\u00f9\u00d7 \u00f2 a i a j \u2020 = a j \u2020 a i + \u03b4 i,j \u00b5\u00b8\u00f8 \u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f2 \u00d7\u00f9\u00f1 \u00f3 \u00f8 \u00f6\u00f1\u00d7 \u00f3 \u00f8 \u00f3\u00f6\u00f1 (a \u2020 a \u2020 a \u2020 a \u2020 \u2022 \u2022 \u2022 )(aaaa \u2022 \u2022 \u2022 )|0 \u00b8 \u00f2 \u00fb \u00f6 \u00fa \u00f6 \u00f8 \u00f6 \u00d7 \u00f2\u00f3\u00f2\u00b9\u00fe \u00f6\u00f3 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00bd \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f2 \u00f3\u00f2 |0 \u00f8 \u00f8 \u00f6\u00f1 \u00f1 \u00fd \u00f6 \u00f1\u00f3\u00fa \u00b4\u00f9\u00d7 \u00f2 a i |0 = 0\u00b5\u00ba \u00ec \u00d7 \u00f0 \u00fa \u00d7 \u00d7\u00f9\u00f1 \u00f3 \u00f8 \u00f6\u00f1\u00d7 \u00f8 \u00f8 \u00f3\u00f2\u00f8 \u00f2 \u00f3\u00f2\u00f0\u00fd \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f2 \u00f3\u00f2 |0 \u00ba \u00ec \u00f8 \u00f0 \u00f6 \u00fa \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f8 \u00f3 \u00f4\u00f4\u00f0\u00fd \u00f2 m j=1 a j \u00f8\u00f3 a i1 \u2020 a i2 \u2020 |0 \u00d7 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 m j=1 a j a i1 \u2020 a i2 \u2020 |0 = m j=1 a j a i1 \u2020 a i2 \u2020 |0 = m j=1 a i1 \u2020 a j + \u03b4 i1,j a i2 \u2020 |0 = m j=1 a i1 \u2020 (a j a i2 \u2020 ) + \u03b4 i1,j a i2 \u2020 |0 = m j=1 a i1 \u2020 (a i2 \u2020 a j + \u03b4 i2,j ) + \u03b4 i1,j a i2 \u2020 |0 = m j=1 a i1 \u2020 a i2 \u2020 a j + \u03b4 i2,j a i1 \u2020 + \u03b4 i1,j a i2 \u2020 |0 = m j=1 a i1 \u2020 a i2 \u2020 ( a j |0 ) + \u03b4 i2,j (a i1 \u2020 |0 ) + \u03b4 i1,j (a i2 \u2020 |0 ) = a i1 \u2020 |0 + a i2 \u2020 |0 \u00b4\u00be \u00b5 \u00f8 \u00f6 \u00f8 \u00d7 \u00d7\u00f3\u00f6\u00f8 \u00f3 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00d7 \u00f2 \u00f3\u00f2 \u00fb \u00f8 \u00f1 \u00d7 \u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00d7\u00d7 \u00f6\u00fd \u00f8\u00f3 \u00fb\u00f6 \u00f8 \u00f3\u00fb\u00f2 \u00f0\u00f0 \u00f3 \u00f8 \u00f2\u00f8 \u00f6\u00f1 \u00f8 \u00d7\u00f8 \u00f4\u00d7 \u00d7 \u00f3\u00fa \u00b8 \u00f9\u00d7 \u00f8 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00fa \u00fa \u00f6\u00fd \u00d7 \u00f1\u00f4\u00f0 \u00f3\u00f6\u00f1 \u00fb \u00f6 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u00d7 \u00f1\u00f3\u00fa \u00f6 \u00f0\u00fd \u00f8\u00f3 \u00f8 \u00f6 \u00f8\u00b8 \u00fc \u00f4\u00f8 \u00f8 \u00f8 \u00fb \u00f2 \u00fa \u00f6 \u00f8 \u00f4 \u00d7\u00d7 \u00d7 \u00f8 \u00f6\u00f3\u00f9 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a j \u2020 \u00f2 \u00f8 \u00f3\u00f2 \u00f0 \u00f8 \u00f6\u00f1 \u00d7 \u00f6 \u00f8 \u00b4 \u00ba \u00ba \u00f8 \u03b4 i,j \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8\u00f3\u00f6 \u00f8 \u00f6\u00f1\u00b5\u00ba \u00e1\u00f2 \u00f1\u00f3\u00f6 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00d7 \u00d7 \u00f8 \u00d7 \u00f1\u00f3\u00f6 \u00f3\u00f2\u00fa \u00f2 \u00f2\u00f8 \u00f8\u00f3 \u00f6 \u00f4\u00f0 \u00f1 \u00f2\u00f9 \u00f0 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f8 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00bf\u00ba\u00be\u00ba ae\u00f9\u00f1 \u00f6 \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00ec \u00f3\u00fa \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00b4 \u00ba \u00ba \u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00b5 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6\u00b9 \u00f8\u00f3\u00f6 n \u00f8 \u00f8 \u00f3\u00f9\u00f2\u00f8\u00d7 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00ba \u00ec \u00f9\u00d7 n \u2261 m i=1 a i \u2020 a i \u00b4\u00bf\u00bc\u00b5 \u00ec \u00d7 \u00fa \u00d7 n a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 = (n 1 + n 2 + \u2022 \u2022 \u2022 + n m ) a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 \u00b4\u00bf\u00bd\u00b5 \u00fb \u00f6 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00d7 n \u2261 n 1 + n 2 + \u2022 \u2022 \u2022 + n m \u00d7 \u00f8 \u00f5\u00f9 \u00f2\u00f8 \u00f8\u00fd \u00f8 \u00f8 \u00d7 \u00f1 \u00d7\u00f9\u00f6 \u00fd \u00f4\u00f4\u00f0\u00fd \u00f2 n \u00ba \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00b8n (a j \u2020 ) nj |0 \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 j = 3 \u00d7 (0, 0, 0, 0) (aj \u2020 ) n j \u2212\u2192 (0, 0, n j , 0) n \u2212\u2192 n j (0, 0, n j , 0) \u00b4\u00bf\u00be\u00b5 \u00ec \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f3 n \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00bc \u00f1 \u00d7 \u00f8 \u00f0 \u00f6 \u00f3\u00fb \u00f8\u00f3 \u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 n i \u00f3\u00f6 \u00f2 i \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00b8\u00d7\u00f3 \u00f8 \u00f8 n = m i=1 n i \u00fb \u00f6 n i \u00d7 \u00f2 \u00d7 n i \u2261 a i \u2020 a i \u00b4\u00bf\u00bf\u00b5 \u00f2 n i (a j \u2020 ) nj |0 \u00f1 \u00fd \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f3\u00f6 \u00b9 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3\u00f6 j = 3 \u00d7 (0, 0, 0, 0) (aj \u2020 ) n j \u2212\u2192 (0, 0, n j , 0) nj \u2212\u2192 n j (0, 0, n j , 0) i = j 0 i = j \u00b4\u00bf \u00b5 \u00bd \u00bf\u00ba\u00be\u00ba \u00e7\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00f8\u00fd \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f2 \u00d7\u00d7 \u00ec \u00d7\u00f8 \u00f8 \u00d7 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f9\u00d7 \u00f2 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00d7\u00f6 \u00f3\u00fa \u00f6 \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00b9 \u00f2 \u00f0 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00ba \u00f3\u00f2\u00d7 \u00f6 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 (a 1 \u2020 ) n1 (a 2 \u2020 ) n2 \u2022 \u2022 \u2022 (a m \u2020 ) nm |0 \u00f2 \u00f8\u00f8 \u00f1\u00f4\u00f8 \u00f8\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f8\u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00ba \u00ec \u00d7\u00f8\u00f6 \u00f8 \u00fd \u00f3 \u00f8 \u00f4\u00f6\u00f3\u00f3 \u00fb \u00f0\u00f0 \u00f8\u00f3 \u00f1\u00f3\u00f2\u00d7\u00f8\u00f6 \u00f8 \u00f8 \u00f8 \u00f8 \u00f6 \u00d7 \u00f9\u00f2 \u00f5\u00f9 \u00d7 \u00f8 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00fd\u00f3\u00f9 \u00fa \u00f8\u00f3 \u00f9\u00d7 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f6 \u00f3\u00fa \u00f6 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 |0 \u00ba \u00f4\u00f4\u00f0\u00fd \u00d7 \u00f2 \u00f0 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a 1 \u00b4\u00f9\u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f8\u00f3 \u00f1\u00f3\u00fa \u00f8 \u00f8\u00f3 \u00f8 \u00f6 \u00f8\u00b5 a 1 a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 = n 1 (a 1 \u2020 ) n1\u22121 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 \u00b4\u00bf \u00b5 ae\u00f3\u00fb \u00f4\u00f4\u00f0\u00fd \u00f8 \u00d7 \u00f1 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 n 1 \u22121 \u00f1\u00f3\u00f6 \u00f8 \u00f1 \u00d7 \u00f8\u00f3 \u00fa \u00f2\u00f8\u00f9 \u00f0\u00f0\u00fd \u00f3 \u00f8 \u00f2 (a 1 ) n1 a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 = n 1 ! a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 \u00b4\u00bf \u00b5 \u00ea \u00f4 \u00f8 \u00f8 \u00d7 \u00f4 \u00f8\u00f8 \u00f6\u00f2 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00d7\u00f9 \u00d7\u00d7 \u00fa \u00f0\u00fd \u00f3\u00f6 \u00f2\u00d7 2, 3, \u2022 \u2022 \u2022 , m \u00f3 \u00f8 \u00d7\u00b9 \u00f8\u00f3 \u00f6 \u00f1 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 (a m ) nm \u2022 \u2022 \u2022 (a 2 ) n2 (a 1 ) n1 a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 = n 1 !n 2 ! \u2022 \u2022 \u2022 n m ! |0 \u00b4\u00bf \u00b5 \u00fb \u00f6 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00d7\u00f8 \u00f8 \u00d7 \u00b4\u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00f3\u00b5 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 |0 \u00ba \u00ec \u00f9\u00d7 \u00fb \u00f6 \u00f3\u00fa \u00f6 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fd \u00f4\u00f4\u00f0\u00fd \u00f2 \u00fc \u00f8\u00f0\u00fd \u00f8 \u00f3\u00d7 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f8 \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00fb \u00f9\u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00f4\u00f0 \u00ba \u00ec \u00f8 \u00f8 \u00f8 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f6 \u00f3\u00fa \u00f6 \u00f3\u00f2\u00f0\u00fd \u00fd \u00f4\u00f4\u00f0\u00fd \u00f2 \u00f8 \u00d7 \u00f1 \u00d7 \u00f8 (n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00d7 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f1 \u00f2\u00d7 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00b9 \u00f2 \u00f0\u00b8 \u00f2 \u00f8 \u00f8 \u00f8 \u00f8 \u00f0\u00f0 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f0 \u00f9\u00d7 \u00f2 \u00f8 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00d7 \u00f8 (n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f1 \u00f2\u00d7 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00ba \u00ec \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f3 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00fd n 1 !n 2 ! \u2022 \u2022 \u2022 n m ! \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fb \u00fd\u00d7 \u00f2 \u00fb \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b8\u00fb \u00f3\u00f6\u00f6 \u00b9 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fb \u00fd\u00d7 \u00f3 \u00f4 \u00f6\u00f1\u00f9\u00f8 \u00f2 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00fb \u00f8 \u00f2 \u00f8 \u00d7\u00b9 \u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7 \u00b4 \u00f9\u00f8 \u00f2\u00f3\u00f8 \u00f4 \u00f6\u00f1\u00f9\u00f8 \u00f2 \u00f8\u00fb \u00f2 \u00f2\u00d7\u00b5\u00ba \u00e1 \u00f8 \u00d7 \u00f4 \u00f6\u00f1\u00f9\u00f8 \u00f8 \u00f3\u00f2 \u00f8\u00f3\u00f6 \u00d7 \u00f2\u00f3\u00f8 \u00f6 \u00f5\u00f9 \u00f6 \u00f8 \u00f2 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3\u00f9\u00f0 \u00f2 \u00d7 1 \u221a n1!n2!\u2022\u2022\u2022nm! (a 1 \u2020 ) n1 (a 2 \u2020 ) n2 \u2022 \u2022 \u2022 (a m \u2020 ) nm |0 \u00b8 \u00f2 \u00d7 \u00f1 \u00f0 \u00f6 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f8\u00f3\u00f6 1 \u221a n1!n2!\u2022\u2022\u2022nm! \u00d7 \u00f3\u00f9\u00f0 \u00f2\u00f0\u00f9 \u00fb \u00f8 \u00f8 \u00f2\u00b9 \u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00fb \u00f2 \u00f8 \u00d7 \u00fb \u00f3\u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u00f8\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00ba \u00e1\u00f8 \u00d7 \u00f1 \u00f8\u00f8 \u00f6 \u00f3 \u00f8 \u00d7\u00f8 \u00fb \u00f8 \u00f6 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f8\u00f3\u00f6 \u00d7 \u00f2\u00f0\u00f9 \u00f0\u00f3\u00f2 \u00fb \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00b8\u00f3\u00f6 \u00fb \u00f8 \u00f6 \u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f2\u00f0\u00f9 \u00f9\u00f8 \u00d7 \u00f8 \u00f2 \u00d7\u00f9 \u00d7 \u00f5\u00f9 \u00f2\u00f8\u00f0\u00fd \u00fa \u00f3\u00f9\u00f8 \u00f6\u00f3\u00f1 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3 \u00f0\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00bf\u00ba\u00be\u00ba \u00eb\u00f8 \u00f8 \u00d7 \u00f2 \u00f3 \u00f2\u00f8 \u00eb\u00f8 \u00f8 \u00d7 \u00ec \u00f3\u00fa \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f3\u00f2 \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00f8\u00fd \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f2 \u00d7\u00d7 \u00f2 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f1\u00f3\u00f6 \u00f6 \u00f3\u00f6\u00b9 \u00f3\u00f9\u00d7\u00f0\u00fd \u00fd \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f2 \u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00ba \u00e1\u00f2\u00f8\u00f9 \u00f8 \u00fa \u00f0\u00fd\u00b8\u00f8 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00f2 \u00fd \u00f8 \u00f1 \u00b9\u00f6 \u00fa \u00f6\u00d7 \u00f2 \u00fa \u00f6\u00fd\u00f8 \u00f2 \u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f2\u00d7\u00f8 \u00f3 \u00f1 \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00b4\u00fb \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f8 \u00f0 \u00f8 \u00f6 \u00f2 \u00f4\u00f0 \u00f9\u00f6\u00f8 \u00f6 \u00f8\u00f3 \u00f8 \u00f0 \u00f8\u00b5\u00b8\u00f8 \u00f3\u00f4 \u00f6\u00b9 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f2 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f8 \u00f8\u00f3 \u00f8 \u00f0 \u00f8 \u00b4\u00fb \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f8 \u00f6\u00f0 \u00f6 \u00f2 \u00be\u00bc \u00f4\u00f0 \u00f9\u00f6\u00f8 \u00f6 \u00f8\u00f3 \u00f8 \u00f6 \u00f8\u00b5\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8\u00fb \u00f2 \u00f8 \u00d7 \u00f8\u00fb\u00f3 \u00fa \u00fb\u00f4\u00f3 \u00f2\u00f8\u00d7 \u00f8 \u00f8 \u00f1 \u00f3\u00f6 \u00f6 \u00f3 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f8 \u00f3\u00f6 \u00f6 \u00f2 \u00fb \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f4\u00f4 \u00f6 \u00f2 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00ba \u00f0\u00d7\u00f3 \u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f2 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00b4 \u00ba \u00ba \u00f6 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f1 \u00f2\u00f6 \u00d7 \u00d7\u00b8 \u00d7 \u00f2 a i \u2020 |0 \u00b5 \u00fa \u00d7 \u00f2 \u00f8 \u00d7 \u00f1 \u00fb \u00fd \u00d7 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f2 \u00f8\u00f3 \u00f8 \u00f0 \u00f8 \u00b4 \u00ba \u00ba \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f1 \u00f6 \u00d7 \u00d7\u00b8 \u00d7 \u00f2 0|a i \u2020 = 0\u00b5\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00d7 a i \u2020 |0 \u00d7 \u00fd\u00d7 \u00b4\u00f6 \u00f2 \u00f6\u00f3\u00f1 \u00f6 \u00f8 \u00f8\u00f3 \u00f0 \u00f8\u00b5 \u00f8 \u00f8 \u00f8 \u00f6 \u00d7 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f8 \u00d7\u00f8 \u00f2\u00f8 \u00f4 \u00d7\u00f8 \u00fb \u00f0 \u00f8 \u00f6 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f6 \u00f8 \u00f2 \u00f2 i\u00b8\u00fb \u00f6 \u00d7 0|a i \u2020 \u00d7 \u00fd\u00d7 \u00b4\u00f6 \u00f2 \u00f6\u00f3\u00f1 \u00f0 \u00f8 \u00f8\u00f3 \u00f6 \u00f8\u00b5 \u00f8 \u00f8 \u00f8 \u00f6 \u00d7 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f8 \u00d7\u00f8 \u00f2\u00f8 \u00f9\u00f8\u00f9\u00f6 \u00fb \u00f6\u00f0 \u00f6 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f2\u00f2 \u00f0 \u00f8 \u00f6\u00f3\u00f1 \u00f2 i \u00f8\u00f3 \u00fa \u00bc \u00b4 \u00ba \u00ba 0|a i \u2020 = 0\u00b5\u00ba \u00e1\u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 \u00f3\u00f9\u00f4 \u00f2 \u00d7 (n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u03b8 n1,n2,\u2022\u2022\u2022 ,nm \u2261 a 1 \u2020 n1 a 2 \u2020 n2 \u2022 \u2022 \u2022 a m \u2020 nm |0 \u00b4\u00bf \u00b5 \u00f2 \u00f8\u00d7 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3\u00f6 \u00f6 \u00f8 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 \u00f3\u00f9\u00f4 \u00f2 \u00d7 (n 1 , n 2 , \u2022 \u2022 \u2022 , n m )\u00b8 \u00f9\u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f6 \u00fa \u00f6\u00d7 \u00f8 \u00f1 \u00d7 \u00f2\u00d7 \u00fb \u00f6 \u00f8 \u00f6 \u00d7 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f8 \u00f6 \u00f9\u00f8\u00f9\u00f6 \u00b8\u00fb \u00d7 \u00f8 \u00f2 \u00f4\u00f3\u00f4\u00f9\u00f0 \u00f8 \u00d7 \u00fb \u00f1\u00f3\u00fa \u00fb \u00f6 \u00d7 \u00f2 \u00f8 \u00f1 \u03b8 \u2020 n1,n2,\u2022\u2022\u2022 ,nm = 0| (a m ) nm \u2022 \u2022 \u2022 (a 2 ) n2 (a 1 ) n1 \u00b4\u00bf \u00b5 \u00ec \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00f8\u00fd \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8\u00fd \u00f2 \u00f8 \u00f2 \u00d7\u00f8 \u00f8 \u00d7 \u03b8 \u2020 \u03bd1,\u03bd2,\u2022\u2022\u2022 ,\u03bdm \u03b8 n1,n2,\u2022\u2022\u2022 ,nm = \u03b4 n1,\u03bd1 \u03b4 n2,\u03bd2 \u2022 \u2022 \u2022 \u03b4 nm,\u03bdm n 1 !n 2 ! \u2022 \u2022 \u2022 n m ! \u00b4 \u00bc\u00b5 \u00fb \u00f6 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00d7 \u00f9\u00d7 \u00b8 \u00f2 \u00fb \u00f6 0||0 \u2261 1 \u00d7 \u00f2 \u00ba \u00ec \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f2 \u00d7\u00d7 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8\u00fd \u00f8 \u00f2 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00f6 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2\u00b9 \u00f8 \u00f8\u00fd \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 n1,n2,\u2022\u2022\u2022 ,nm 1 n 1 !n 2 ! \u2022 \u2022 \u2022 n m ! \u03b8 n1,n2,\u2022\u2022\u2022 ,nm \u03b8 \u2020 n1,n2,\u2022\u2022\u2022 ,nm = 1 \u00b4 \u00bd\u00b5 \u00fb \u00f6 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f8 \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8\u00d7 \u00f9\u00f4\u00f3\u00f2 \u00f6 \u00d7\u00d7\u00f9\u00f1 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f2 \u00f8 \u00d7 \u00f1 \u00fb \u00fd \u00d7 \u03b8 n1,n2,\u2022\u2022\u2022 ,nm \u00b4 \u00ba \u00ba \u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00b5\u00ba \u00bf\u00ba\u00be\u00ba \u00eb\u00f9\u00f1\u00f1 \u00f6\u00fd \u00f3 \u00ed\u00d7 \u00f9\u00f0 \u00ea \u00d7\u00f9\u00f0\u00f8\u00d7 \u00bd\u00ba \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f2 i a i \u2020 \u00ba \u00ef \u00f2 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00f8 \u00d7 \u00f6 \u00f8 \u00d7 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2 i\u00ba \u00be\u00ba \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f2 i a i \u00ba \u00ef \u00f2 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00f8 \u00d7 \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f2 i \u00f2 \u00d7 \u00f1 \u00f2\u00fd \u00fb \u00fd\u00d7 \u00b4 \u00ba \u00ba n i \u00b5 \u00d7 \u00f8 \u00f6 \u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f0\u00f6 \u00fd \u00f2 \u00f2 i\u00ba \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 n i \u00f3\u00f4 \u00d7 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00fb \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2\u00f2 \u00f0 \u00f8 \u00f6\u00f3\u00f1 \u00f2 i\u00ba \u00ec \u00d7 \u00f2\u00f0\u00f9 \u00d7 \u00f8 \u00d7\u00f4 \u00f0 \u00d7 n i = 0 \u00fb \u00f6 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f2\u00f2 \u00f0 \u00f8 \u00f0\u00f8\u00f3 \u00f8 \u00f6 \u00f8\u00f3 \u00fa 0\u00ba \u00bf\u00ba \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f0\u00f0 \u00f2\u00d7 m i=1 a i \u00ba \u00ec \u00d7 \u00f4\u00f6\u00f3 \u00f9 \u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00fb \u00f8 a i \u00f0\u00f3\u00f2 \u00f3 \u00d7\u00ba \u00f3\u00f6 i \u00b4i = 1, 2, \u2022 \u2022 \u2022 , m\u00b5 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 n i \u00f3\u00f4 \u00d7 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00fb \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2\u00f2 \u00f0 \u00f8 \u00f6\u00f3\u00f1 \u00f2 i\u00b8\u00fb \u00fa \u00d7 \u00be\u00bd \u00f8\u00f3\u00f8 \u00f0 \u00f3 m i=1 n i \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00ba \u00ec \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00d7 \u00f9\u00d7 \u00f9\u00f0 \u00f3\u00f6 \u00f4\u00f6 \u00f4 \u00f6 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f3\u00f6 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f9\u00d7 \u00f8 \u00f6 \u00f1\u00f3\u00fa \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f6 \u00f2 \u00f3\u00f1 \u00f6\u00f3\u00f1 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00b4 \u00ba \u00ba \u00f8 \u00f4\u00f6 \u00f4 \u00f6 \u00d7 m i=1 n i \u00f3\u00f4 \u00d7 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3 \u00fb \u00f6 \u00f2\u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00b5\u00ba \u00ba \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8\u00f3 \u00f6 \u00f1 a i |0 = 0\u00ba \u00ec \u00d7 \u00f2 \u00d7 \u00f8 \u00fa \u00f9\u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f6 \u00f2 \u00d7\u00f8 \u00f8 \u00f3\u00f6 \u00f8 \u00f6\u00f1 \u00f2 \u00f2 \u00f8 \u00f3\u00f9\u00f4 \u00f2\u00fd \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00ba \u00ec \u00d7 \u00f2 \u00f8 \u00f3\u00f2 \u00d7 \u00fa \u00f6\u00fd \u00f9\u00d7 \u00f9\u00f0 \u00f3\u00f6 \u00f6 \u00f1\u00f3\u00fa \u00f2 \u00f8 \u00f6\u00f1\u00d7 \u00f8 \u00f8 \u00f3 \u00f2\u00f3\u00f8 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f8\u00f3 \u00f8 \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00ba \u00ba \u00f6 \u00f8 \u00f3\u00f2\u00bb \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8\u00f3\u00f6 [a i , a j \u2020 ] = \u03b4 i,j \u00ba \u00ec \u00d7 \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00d7 \u00f8 \u00d7 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00e1\u00f8 \u00d7 \u00f1 \u00f2\u00f0\u00fd \u00f9\u00d7 \u00f2 \u00f8 \u00f3\u00f6\u00f1 a i a j \u2020 = a j \u2020 a i +\u03b4 i,j \u00f8\u00f3 \u00f1\u00f3\u00fa \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00b8\u00fb \u00fa \u00f2\u00f8\u00f9 \u00f0\u00f0\u00fd \u00f6 \u00f2 \u00d7 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00fd \u00f8 \u00f6 \u00f8\u00f0\u00fd \u00f3\u00f2 |0 \u00b8\u00fb \u00f6 \u00f8 \u00fd \u00f2 \u00f6 \u00f1\u00f3\u00fa \u00b4\u00f9\u00d7 \u00f2 a i |0 = 0\u00b5\u00ba \u00ba \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2\u00bb \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00f6 \u00f8 \u00f3\u00f2\u00bb\u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8\u00f3\u00f6\u00d7 [a i , a j ] = 0 \u00f2 [a i \u2020 , a j \u2020 ] = 0\u00ba \u00ec \u00d7 \u00d7\u00f9\u00f1\u00f1 \u00f6 \u00d7 \u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f5\u00f9 \u00f2 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2 \u00d7\u00f3\u00f0 \u00f0\u00fd \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00b4\u00f3\u00f6 \u00d7\u00f3\u00f0 \u00f0\u00fd \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00b5 \u00d7 \u00f8 \u00d7 \u00f1 \u00f8 \u00fb \u00f8 \u00fa \u00f6 \u00f8 \u00f3\u00f6 \u00f6 \u00f2 \u00fb \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f4\u00f4 \u00f6 \u00f2 \u00f8 \u00d7 \u00b9 \u00f5\u00f9 \u00f2 \u00ba \u00ba \u00e5\u00f3\u00fa \u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 a i (a j \u2020 ) n |0 = n\u03b4 i,j (a j \u2020 ) n\u22121 |0 \u00ec \u00d7 \u00d7 \u00f8 \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f8 \u00f8 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00f1\u00f3\u00fa \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f6\u00f3\u00f1 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2\u00d7\u00ba \u00ec a i \u00d7 \u00f1\u00f3\u00fa \u00f4\u00f6\u00f3 \u00f6 \u00d7\u00d7 \u00fa \u00f0\u00fd \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f8 \u00f6\u00f3\u00f9 \u00f8 a j \u2020 \u00b4\u00f9\u00d7 \u00f2 a i a j \u2020 = a j \u2020 a i + \u03b4 i,j \u00b5 \u00f9\u00f2\u00f8 \u00f0 \u00f8 \u00f6 \u00d7 \u00f8 |0 \u00b8\u00fb \u00f6 \u00f8 \u00d7 \u00d7 \u00f6 \u00b4\u00f9\u00d7 \u00f2 a i |0 = 0\u00b5\u00ba \u00ba ae\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f2 i n i = a i \u2020 a i \u00ba \u00ec \u00d7 \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f8 \u00f2 \u00f6 \u00f8 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2 i\u00ba \u00f9\u00d7 \u00f8 \u00f6 \u00f6 n i \u00fb \u00fd\u00d7 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f9\u00f8 \u00f3\u00f2\u00f0\u00fd \u00bd \u00fb \u00fd \u00f3 \u00f6 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00b8\u00f8 \u00f2 \u00f8 \u00f8 \u00d7 \u00f8\u00f3 \u00f3\u00f9\u00f2\u00f8 \u00f8 \u00f2\u00f9\u00f1 \u00f6 n i \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2 i\u00ba \u00ba \u00ec\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f0\u00f0 \u00f2\u00d7 n = m i=1 a i \u2020 a i \u00ba \u00ec \u00d7 \u00f3\u00f9\u00f2\u00f8\u00d7 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00ba \u00ec \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 \u00f6 \u00f8\u00f0\u00fd \u00f6\u00f3\u00f1 n i = a i \u2020 a i \u00f3\u00fa \u00ba \u00bd\u00bc\u00ba \u00eb\u00f8 \u00f8 \u00f2 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u03b8 n1,n2,\u2022\u2022\u2022 ,nm = (a 1 \u2020 ) n1 (a 2 \u2020 ) n2 \u2022 \u2022 \u2022 (a m \u2020 ) nm |0 \u00f2 \u03b8 \u2020 n1,n2,\u2022\u2022\u2022 ,nm = 0|(a m ) nm \u2022 \u2022 \u2022 (a 2 ) n2 (a 1 ) n1 \u00b4\u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd\u00b5\u00ba \u00ec \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f2 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f8 \u00f0 \u00f8 \u00f3 \u00d7\u00f8 \u00f8 \u00f2 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f2 \u00f1\u00f3\u00fa \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f9\u00d7 \u00f2 a i (a j \u2020 ) n |0 = n\u03b4 i,j (a j \u2020 ) n\u22121 |0 \u00f8\u00f3 \u00f1\u00f3\u00f2\u00b9 \u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00f8\u00fd \u00b4 \u00d7\u00d7\u00f9\u00f1 \u00f2 0||0 \u2261 1\u00b5\u00ba \u00ec \u00f3 \u00f2\u00f8 \u00f3 a i |0 = 0 \u00f1\u00f4\u00f0 \u00d7 0|a i \u2020 = 0\u00ba \u00bd\u00bd\u00ba \u00e7\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00f8\u00fd \u03b8 \u2020 \u03bd1,\u03bd2,\u2022\u2022\u2022 ,\u03bdm \u03b8 n1,n2,\u2022\u2022\u2022 ,nm = \u03b4 n1,\u03bd1 \u03b4 n2,\u03bd2 \u2022 \u2022 \u2022 \u03b4 nm,\u03bdm n 1 !n 2 ! \u2022 \u2022 \u2022 n m !\u00ba \u00e0 \u00f6 0||0 \u2261 1 \u00d7 \u00d7\u00d7\u00f9\u00f1 \u00fd \u00f2 \u00f8 \u00f3\u00f2\u00ba \u00bd\u00be\u00ba \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f2 \u00d7\u00d7 \u00f0\u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u03b8 n1,n2,\u2022\u2022\u2022 ,nm \u00f6 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f0 \u00fd \u00f9\u00d7 \u00f2 \u00f8 \u00f4\u00b9 \u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00d7 \u00f8 (n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00be\u00be \u00bf\u00ba\u00be\u00ba\u00bd\u00bc \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00e5\u00ea ae\u00f3 \u00d7 \u00ec \u00f3\u00fa \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f6 \u00f3\u00f6 \u00d7 \u00f2 \u00f0 \u00e5\u00ea \u00f2\u00f3 \u00ba \u00ef \u00f2 \u00f8 \u00f6 \u00f6 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f2\u00f3 \u00d7\u00b8 \u00e5\u00ea \u00f2\u00f3 \u00d7 \u00f8 \u00f3\u00fb\u00f2 \u00d7 \u00f8 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00b8\u00fb \u00fa \u00f0\u00f0 \u00f3 \u00f8 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00d7\u00f6 \u00f3\u00fa \u00ba \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f3\u00f6 \u00f6 \u00f2\u00f8 \u00f2\u00f3 \u00d7 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00f9\u00d7 \u00f8 \u00fd \u00f8 \u00f3\u00f2 \u00f6 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00d7\u00b8\u00d7\u00f3 \u00f8 \u00f2 \u00f6 \u00f0 \u00d7 \u00f3\u00f6\u00f1 \u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00bf \u00d7 a s i , a t \u2020 j = \u03b4 i,j \u03b4 s,t a s i , a t j = 0 a s \u2020 i , a t \u2020 j = 0 \u00b4 \u00be\u00b5 \u00fb \u00f6 s \u00f2 t \u00f6 \u00f2\u00f3 \u00f2 \u00d7\u00ba \u00ec \u00f6 \u00f6 \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f0\u00f0 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba \u00ba \u00bf\u00ba\u00bf \u00e5 \u00e5 \u00ed\u00f4 \u00f8 \u00e7\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00e1\u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba \u00f8 \u00fb \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f3\u00fb \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f2 n \u00b9\u00f2\u00f3 \u00e5\u00ea \u00f2 \u00f6 \u00f4\u00f6 \u00b9 \u00d7 \u00f2\u00f8 \u00d7 \u00d7 \u00f8 \u00f3 n \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f3 \u00fb \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f3\u00f2 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00b8 \u00f2 \u00f3\u00fb \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 \u00f3 \u00f8 \u00e5\u00ea \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00d7 \u00f3\u00f4\u00f4 \u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00f3\u00f4\u00d7 \u00f6\u00f3\u00f9\u00f2 \u00f8\u00fb \u00f2 \u00f8 \u00f2\u00d7 \u00f3 \u00f8\u00d7 \u00d7\u00b9 \u00f8\u00f3 \u00f6 \u00f1\u00ba \u00ec \u00f1 \u00f2\u00f3\u00fb \u00d7 \u00f8\u00f3 \u00f9\u00d7 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be \u00f8\u00f3 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00d7 \u00e5 \u00e5 \u00f3\u00f4\u00f4 \u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00ba \u00ec \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f2 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f2 \u00d7 \u00fa \u00f6 \u00f0 \u00d7\u00fd \u00d7\u00f8 \u00f4\u00d7\u00b8 \u00f2 \u00fb \u00e5 \u00e5 \u00f3\u00f4\u00f4 \u00f2 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00f6\u00f3 \u00f2 \u00f3\u00fb\u00f2 \u00f2\u00f8\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f0\u00f0\u00f3\u00fb \u00fd \u00d7\u00f9 \u00d7 \u00f5\u00f9 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00ba \u00bd\u00ba \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00b4\u00d7 \u00f8 \u00f1 \u00f0 \u00f6\u00f3\u00fb \u00f3 \u00f9\u00f6 \u00bd\u00b5\u00ba \u00f4\u00f4\u00f0\u00fd m j=1 a j \u00f8\u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00f8\u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f2\u00b8\u00fb \u00f4\u00f6 \u00f4 \u00f6 \u00d7 m i=1 n i \u00f3\u00f4 \u00d7 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3 \u00fb \u00f6 \u00f2\u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00ba \u00ec \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f3 \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00f8 \u00f9\u00d7 \u00f0 \u00f2 \u00f6 \u00f3\u00f1 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7\u00b8\u00fb \u00f6 \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f8 \u00fd \u00f8 \u00d7 \u00f1 \u00f8\u00f3\u00f6 \u00f3 \u00f9\u00f2 \u00f8\u00fd \u00b4 \u00ba \u00ba \u00f0\u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f5\u00f9 \u00f0\u00f0\u00fd \u00f0 \u00f0\u00fd\u00b5\u00ba \u00ec \u00d7 \u00f0 \u00f2 \u00f6 \u00f3\u00f1 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 m i=1 n i \u00f8 \u00f6\u00f1\u00d7 \u00b4\u00f3 \u00fb \u00f3\u00f2\u00f0\u00fd m \u00f6 \u00d7\u00f8 \u00f2\u00f8\u00b5 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f2\u00d7 \u00f1 \u00f0 \u00f3 \u00f0\u00f0 \u00f8 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f3\u00f9\u00f8\u00f3\u00f1 \u00d7 \u00f3 \u00f2\u00f2 \u00f0 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00ba \u00be\u00ba \u00f6 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00b4\u00d7 \u00f8 \u00f3\u00f8\u00f8\u00f3\u00f1 \u00f6\u00f3\u00fb \u00f3 \u00f9\u00f6 \u00bd\u00b5\u00ba \u00f4\u00f4\u00f0\u00fd m i=1 p i a i \u2020 \u00f8\u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00f2 \u00f8 \u00f2\u00d7 \u00f1 \u00f0 \u00f2 \u00f6 \u00f8 \u00f3\u00fa \u00b8\u00fb \u00f4\u00f6 \u00f4 \u00f6 \u00d7 m \u00f3\u00f4 \u00d7 \u00f3 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2 \u00f3 \u00fb \u00f6 \u00f2\u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f6 \u00f8 \u00b8 \u00f2 \u00fb \u00f8 \u00f3 \u00f8 \u00d7 m \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00d7\u00f3 \u00f8 \u00f8 \u00fb \u00f6 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6 \u00f8 \u00f2 \u00f2 i \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f8 \u00fd \u00f8\u00f3\u00f6 p i \u00ba \u00e1 \u00f8 p i \u00d7 \u00f8 \u00d7 \u00fd p i \u2265 0 \u00f2 m i=1 p i = 1 \u00f8 \u00f2 p i \u00f2 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00b9 \u00f0 \u00f8\u00fd \u00f3 \u00f6 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f2 i\u00ba \u00f8\u00f9 \u00f0\u00f0\u00fd\u00b8\u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f2 m i=1 p i = 1 \u00f2 \u00f3\u00f1 \u00f8\u00f8 \u00f9\u00d7 \u00f8 \u00f6 \u00f0 \u00f8 \u00fa \u00d7 \u00fe \u00f3 \u00f8 p i \u00d7 \u00f0\u00f0 \u00f8 \u00f8 \u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00ba \u00ec \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00f3 \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2 \u00d7 \u00f8 \u00f9\u00d7 \u00f0 \u00f2 \u00f6 \u00f3\u00f1 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7\u00b8\u00fb \u00f6 \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f8 \u00fd \u00f8 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00b9 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6 p i \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f8\u00f3 \u00f8 \u00f2 i \u00f2 \u00fb \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f9\u00d7\u00f8 \u00f2 \u00f6 \u00f8 \u00ba \u00ec \u00d7 \u00f0 \u00f2 \u00f6 \u00f3\u00f1 \u00f2 \u00f8 \u00f3\u00f2 \u00f3 m \u00f8 \u00f6\u00f1\u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f2\u00d7 \u00f1 \u00f0 \u00f3 \u00be\u00bf \u00f0\u00f0 \u00f8 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f3\u00f9\u00f8\u00f3\u00f1 \u00d7 \u00f3 \u00f6 \u00f8 \u00f2 \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f3\u00f2 \u00f3 \u00f8 \u00f2\u00d7 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00ba \u00f3\u00f2 \u00f8 \u00f2 \u00f8 \u00f8 \u00d7 \u00f8\u00fb\u00f3 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f2 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h h \u2261 m i=1 p i a i \u2020 m j=1 a j \u00b4 \u00bf\u00b5 \u00fb \u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 m j=1 a j \u00f4\u00f6\u00f3 \u00f9 \u00d7 m i=1 n i \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00b8\u00f8 \u00f2 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 m i=1 p i a i \u2020 \u00f3\u00f2 \u00f3 \u00f8 \u00d7 m i=1 n i \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f4\u00f6\u00f3 \u00f9 \u00d7 m \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00ba \u00f2 \u00f0\u00f0\u00fd\u00b8 \u00f0\u00f0 \u00f3 \u00f8 \u00d7 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00d7 \u00f3\u00f9\u00f0 \u00f6 \u00f6\u00f3\u00f9\u00f4 \u00d7\u00f3 \u00f8 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f4 \u00d7 \u00f3 \u00f2\u00f8 \u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f6 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00d7 \u00d7 \u00f2 \u00f0 \u00f3\u00f4\u00fd \u00fb \u00f8 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00fb \u00f8 \u00f2 \u00f8\u00f3\u00f6\u00ba \u00ec \u00fb \u00f8 \u00f2 \u00f8\u00f3\u00f6 \u00f8 \u00f8 \u00d7 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00b4 \u00d7 \u00f9\u00d7 \u00f6 \u00b5 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00d7 \u00f0 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f1\u00f4\u00f0 \u00f8\u00f9 \u00b4 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00b9 \u00f2 \u00e9 \u00ec\u00b5\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00e9 \u00ec \u00d7 \u00ef \u00f6\u00f3\u00f8 \u00f8 \u00f8\u00f3 \u00f3\u00f1 \u00f9\u00f0 \u00f2 \u00e9 \u00ec \u00f8 \u00f2 \u00f8 \u00d7 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f8\u00f3 \u00f5\u00f9 \u00f2\u00f8\u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00d7\u00f8 \u00f0 \u00f1 \u00f2 \u00d7 \u2104\u00b8\u00fb \u00f6 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b9\u00fb \u00f8 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00f3 \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00eb\u00f3 \u00f8 \u00f4\u00f4\u00f6\u00f3 \u00d7\u00f9\u00d7\u00d7 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00d7 \u00f1 \u00f8 \u00f1 \u00f8 \u00f0 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f8 \u00f8 \u00d7 \u00d7 \u00f1 \u00f0 \u00f6 \u00f8\u00f3 \u00f8 \u00f9\u00f0 \u00f2 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 \u00e9 \u00ec \u00f3 \u00f3\u00d7\u00f3\u00f2\u00d7\u00ba \u00ec \u00f4 \u00d7 p i a i \u2020 a j \u00f3 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f1 \u00fd \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00b9 \u00f6 \u00f1\u00f1 \u00f8 \u00f0\u00f0\u00fd \u00d7 p i \uf8eb \uf8ec \uf8ed j aj \u2212\u2192 \u2022 ai \u2020 \u2212\u2192 i \u21d1 source \uf8f6 \uf8f7 \uf8f8 \u00fb \u00f6 \u00d7\u00f8 \u00f8 j \u00f3\u00f1 \u00d7 \u00f2 \u00f6\u00f3\u00f1 \u00f8 \u00f0 \u00f8 \u00f2 \u00d7 \u00f2\u00f2 \u00f0 \u00f8 \u00fd a j \u00b8 \u00f2 \u00f2 \u00fb \u00d7\u00f8 \u00f8 i \u00d7 \u00f6 \u00f8 \u00fd a i \u2020 \u00fb \u00f8 \u00f2 \u00f3 \u00d7 \u00f3\u00f9\u00f8 \u00f8\u00f3 \u00f8 \u00f6 \u00f8\u00b8 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f8 \u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00d7 p i \u00fb \u00f4 \u00f2 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00f3\u00f2 \u00f8 \u00f3\u00f9\u00f8\u00f4\u00f9\u00f8 \u00d7\u00f8 \u00f8 \u00b4\u00d7\u00f3 \u00f8 \u00d7 \u00f1 \u00f1\u00f3\u00f6\u00fd\u00f0 \u00d7\u00d7\u00b5\u00b8\u00fb \u00d7 \u00f2 \u00f8\u00f9\u00f6\u00f2 \u00f2 \u00f6 \u00f8 \u00fd \u00d7\u00f3\u00f9\u00f6 \u00b4 \u00ba \u00ba \u00e5\u00ea \u00f2 \u00f3\u00f9\u00f6\u00d7\u00b8 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00b8 \u00f8\u00b5\u00ba \u00ec \u00fb \u00f3\u00f0 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00d7 \u00f8 \u00d7\u00f9\u00f1 \u00f3 \u00f8 \u00d7 \u00f6 \u00f1 \u00f3\u00fa \u00f6 \u00d7\u00f8 \u00f8 \u00d7 i \u00f2 j\u00ba \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f2 \u00f6 \u00f0 \u00d7 \u00f8\u00f3 \u00f2 \u00e5\u00ea \u00fb \u00f8 n \u00f2\u00f3 \u00d7 \u00b4\u00fb \u00f8 \u00f2\u00f3 s \u00fa \u00f2 m s \u00d7\u00f8 \u00f8 \u00d7\u00b5 h \u2212\u2192 n s=1 ms i=1 p s i a s \u2020 i ms j=1 a s j \u00b4 \u00b5 \u00fb \u00f2 \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00f9\u00d7 \u00f2 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 t s i,j \u2261 a s \u2020 i a s j \u00f8 \u00f8 \u00f3\u00f4\u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f2 j \u00f8\u00f3 \u00f2 i \u00f8 \u00f2\u00f3 s\u00ba h = n s=1 ms i,j=1 p s i t s i,j \u00b4 \u00b5 \u00e1\u00f2 \u00f4\u00f6 \u00f8 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd p s i \u00f4 \u00f2 \u00d7 \u00b4\u00fa \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00f0 \u00f5\u00f9 \u00b9 \u00f8\u00f3\u00f6\u00d7\u00b8 \u00d7 \u00d7\u00f6 \u00f2 \u00f8 \u00d7\u00f9\u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f2 \u00f8 \u00e0 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bd\u00b5 \u00f3\u00f2 \u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00f3\u00f8 \u00f6 \u00f2\u00f3 \u00d7 \u00f2 \u00f8 \u00e5\u00ea \u00ba \u00ec \u00d7 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f2 \u00f3\u00f1\u00f4\u00f9\u00f8 \u00fd \u00f4\u00f4\u00f0\u00fd \u00f2 \u00f2 \u00be \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f0\u00fd \u00d7 \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8\u00f3 \u00f8 \u00e5\u00ea \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00d7\u00ba \u00ec \u00f9\u00d7 \u00f9\u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f2 k \u00f8 \u00f2\u00f3 t \u00b4\u00fb \u00d7 n t k \u2261 a t \u2020 k a t k \u00b5 \u00fb \u00f8 \u00fd p s,t i,k \u00f8\u00f3 \u00f8 \u00f6\u00b9 \u00f1 \u00f2 \u00f8 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00b4 \u00ba \u00ba \u00f4 \u00f6\u00fb \u00d7 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00fb \u00f2 \u00f2\u00f3 \u00d7 \u00f3 \u00f8 \u00e5\u00ea \u00b5 \u00f3\u00f6 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2 i \u00f8 \u00f2\u00f3 s \u00f9 \u00f8\u00f3 \u00f2 k \u00f8 \u00f2\u00f3 t \u00f2 \u00f3\u00f9\u00f4 \u00ba \u00ec \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00d7 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00f3\u00f6 \u00f2\u00fd \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00f2 k \u00f8 \u00f2\u00f3 t\u00b8 \u00f9\u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 n t k \u00f9\u00f8\u00f3\u00f1 \u00f8 \u00f0\u00f0\u00fd \u00f8 \u00f6\u00f1 \u00f2 \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00f2 \u00b8 \u00f2 \u00f8 \u00f2 \u00f9\u00d7 \u00d7 \u00f8 \u00d7 \u00f2\u00f9\u00f1 \u00f6 \u00f8\u00f3 \u00fb \u00f8 \u00f2\u00fd \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6 \u00f8 \u00f8 \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00f8 \u00d7 \u00f2\u00f3 \u00ba \u00ec \u00d7 \u00f9\u00d7 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f8\u00f3 \u00fb \u00f8 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00d7 \u00d7 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8 \u00f9\u00d7 \u00f8 \u00f9 \u00f6 \u00f2\u00f8 \u00d7 \u00f8 \u00f8 \u00d7 \u00f2 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f2\u00f3 \u00b4 \u00ba \u00ba \u00d7\u00f8 \u00f2 \u00f6 \u00e0 \u00b5 \u00d7 \u00f4 \u00fd\u00d7 \u00f0\u00f0\u00fd \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8 \u00f8\u00f3 \u00f8 \u00d7 \u00f8\u00f9 \u00f8 \u00f3\u00f2 \u00fb \u00f6 \u00f3 \u00f8 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00f9\u00f8 \u00f2\u00f8\u00f3 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f5\u00f9 \u00f0\u00b9\u00d7 \u00fe \u00d7\u00f9 \u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b8 \u00f9\u00d7 \u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f2 \u00f2 \u00f6 \u00f8 \u00fd \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f8 \u00d7 \u00d7\u00f9 \u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6 \u00fc \u00f8\u00f0\u00fd \u00f2 \u00f0\u00f0 \u00fd \u00f8 \u00f8 \u00f3\u00f2 \u00f0 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f2 \u00f2 \u00f6 \u00f8 \u00fd \u00f8 \u00f8 \u00f8 \u00f8 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00fb \u00f2 \u00d7\u00f9 \u00b9 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6 \u00f4\u00f6\u00f3\u00f4\u00f3\u00f6\u00f8 \u00f3\u00f2 \u00f0\u00f0\u00fd \u00fb \u00f6 \u00f8 \u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00fb \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00ba \u00ec \u00d7 \u00f0\u00f0\u00f3\u00fb\u00d7 p s i \u00f8\u00f3 \u00f6 \u00f4\u00f0 \u00fd \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 p s i \u00b8\u00fb \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 p s i \u00d7 \u00f3\u00f2 \u00fb \u00f8 \u00fa \u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f2 \u00d7 \u00f2 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f2 \u00f8 \u00f2 \u00f3\u00f9\u00f6 \u00f3\u00f3 c(s) \u00f3 \u00f2\u00f3 s \u00f3 \u00f8 \u00e5\u00ea \u00ba p s i \u2212\u2192 p s i \u2261 t\u2208c(s) mt k=1 p s,t i,k n t k \u00b4 \u00b5 \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 \u00f3\u00f9\u00f0 \u00f3\u00f1\u00f4 \u00f6 \u00fb \u00f8 \u00f8 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3\u00f6\u00f1 \u00f3 \u00f8 \u00e0 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00fb \u00f6 \u00f8 t\u2208c(s) (\u2022 \u2022 \u2022 ) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f8 c (\u2022 \u2022 \u2022 ) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00b8 \u00f2 \u00f8 \u00d7\u00f9\u00f1 \u00f3\u00fa \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 mt k=1 (\u2022 \u2022 \u2022 ) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00f2 \u00f8\u00f3 \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f8 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8 \u00d7 \u00f8 \u00f8 \u00f1 \u00f8 \u00f4\u00f4 \u00f6 \u00f2 \u00f8 (\u2022 \u2022 \u2022 ) \u00f2\u00d7 c (\u2022 \u2022 \u2022 ) \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd\u00ba \u00e5\u00f3\u00f6 \u00f2 \u00f6 \u00f0\u00f0\u00fd \u00f3\u00f6 \u00bf\u00b9\u00f0 \u00f5\u00f9 \u00d7 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 p s i \u00d7 \u00fa \u00f2 \u00fd p s i \u2212\u2192 p s i \u2261 t1,t2\u2208c(s) mt 1 k1=1 mt 2 k2=1 p s,t1,t2 i,k1,k2 n t1 k1 n t2 k2 \u00b4 \u00b5 \u00fb \u00f1 \u00fd \u00d7\u00f8\u00f6 \u00f8 \u00f3\u00f6\u00fb \u00f6 \u00f0\u00fd \u00f2 \u00f6 \u00f0 \u00d7 \u00f8\u00f3 \u00f6 \u00f3\u00f6 \u00f6 \u00f0 \u00f5\u00f9 \u00d7\u00ba \u00e1\u00f2\u00d7 \u00f6\u00f8 \u00f2 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00b9\u00fa \u00f0\u00f9 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f3 p s i \u00f2\u00f8\u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b8\u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f3\u00f1 \u00d7 \u00b4\u00f9\u00d7 \u00f2 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00d7 \u00f3\u00f2\u00f0\u00fd\u00b5 h \u2212\u2192 n s=1 ms i,j=1 t s i,j \uf8eb \uf8ed t\u2208c(s) mt k=1 p s,t i,k n t k \uf8f6 \uf8f8 \u00b4 \u00b5 \u00fb \u00f8 \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2\u00d7 \u00f3\u00f6 \u00f6 \u00f3\u00f6 \u00f6 \u00f0 \u00f5\u00f9 \u00d7\u00ba \u00ec \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00b9\u00fa \u00f0\u00f9 \u00f3 \u00b9 \u00f8 h \u00f2 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f2\u00fd \u00e5\u00ea \u00d7\u00f8 \u00f8 \u00b8\u00fb \u00f8 \u00f6 \u00f8 \u00d7 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00d7 \u00f2 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00f4 \u00f6 \u00f2\u00f3 \u00d7\u00f8 \u00f8 \u00b8\u00f3\u00f6 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f4 \u00f6 \u00f2\u00f3 \u00ba \u00ec \u00d7 \u00d7 \u00f8 \u00fd \u00b9 \u00fa \u00f2\u00f8 \u00f3 \u00f9\u00d7 \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00b8 \u00f9\u00d7 \u00f8 \u00fd \u00f6 \u00f8 \u00fa \u00f0\u00fd \u00f2 \u00f6 \u00f0 \u00f4\u00f6\u00f3 \u00f9\u00f6 \u00d7 \u00b4 \u00ba \u00ba \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00b5 \u00f8 \u00f8 \u00f2 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f2\u00fd \u00d7\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00ec \u00f0 \u00f6 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f4\u00f6\u00f3\u00fa \u00d7 \u00f9\u00f2 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00f2 \u00f2 \u00f0\u00f0 \u00f3 \u00f8 \u00d7 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8 \u00d7 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8\u00f0\u00fd\u00ba \u00be \u00ec \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f6\u00f1 \u00f9\u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00f2 \u00f3\u00f6 \u00fd \u00fb \u00f6 \u00f3\u00f1\u00f4 \u00f8\u00b9 \u00f0 \u00f8\u00fd \u00fb \u00f8 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6 \u00f2 \u00e5\u00ea \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00fb \u00f6 \u00f8 \u00f8\u00f3\u00f6 p s i \u00d7 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f2\u00f8 \u00f6\u00d7 \u00f8 \u00fb \u00f8 \u00f2\u00f3 s \u00b4 \u00ba \u00ba \u00f3\u00f6 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00d7 \u00f3\u00f2\u00f0\u00fd\u00b8 \u00f8 \u00d7 \u00f2 \u00f6 \u00f8 \u00fd \u00f8 t\u2208c(s) mt k=1 p s,t i,k n t k \u00f8\u00f3\u00f6 \u00f2 \u00f5\u00f9 \u00b9 \u00f8 \u00f3\u00f2 \u00b5\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8\u00f8 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00fa \u00f0\u00f3\u00f4 \u00f6 \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f3\u00f6 \u00f2\u00fd \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f6\u00f1 \u00f9 \u00f0\u00f8 \u00f3\u00f9\u00f8 \u00f3 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00b8\u00d7\u00f3 \u00fa \u00f6\u00fd \u00f0 \u00f6 \u00f0 \u00d7\u00d7 \u00f3 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 h \u00f2 \u00f3\u00f2\u00d7\u00f8\u00f6\u00f9\u00f8 \u00d7\u00f9 \u00d7 \u00bd\u00ba \u00ec \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f8 \u00f2 \u00f6 \u00f8 \u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00d7 t\u2208c(s) mt k=1 p s,t i,k n t k \u00f2 \u00f6 \u00f4\u00f0 \u00fd \u00d7\u00f3\u00f1 \u00f3\u00f8 \u00f6 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f6\u00f1\u00b8\u00d7\u00f9 \u00d7 \u00f2\u00f3\u00f2\u00b9\u00f0 \u00f2 \u00f6 \u00d7 \u00b9 \u00f1\u00f3 \u00d7\u00f5\u00f9 \u00d7 \u00f2 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u03c3( t\u2208c(s) mt k=1 p s,t i,k n t k )\u00b8 \u00d7 \u00d7 \u00f8\u00fd\u00f4 \u00f0\u00f0\u00fd \u00f3\u00f2 \u00f2 \u00f2 \u00f9\u00f6 \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00f1\u00f4\u00f0 \u00f1 \u00f2\u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f6 \u00f9\u00f6\u00f6 \u00f2\u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00ba \u00e7\u00f2 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00fb \u00fd \u00f3 \u00fa \u00fb \u00f2 \u00f8 \u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f4 \u00f8\u00fb \u00f2 \u00f8 \u00d7 \u00f2\u00f3\u00f2\u00b9\u00f0 \u00f2 \u00f6 \u00d7 \u00f1\u00f3 \u00f0 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00f2 \u00f8 \u00f0 \u00f5\u00f9 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f2 \u00f3 \u00f8 \u00f2 \u00fd \u00f4 \u00f6\u00f8\u00f9\u00f6 \u00f8 \u00fa \u00f0\u00fd \u00fc\u00f4 \u00f2 \u00f2 \u00f8 \u00d7 \u00f1\u00f3 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f4\u00f3\u00fb \u00f6\u00d7 \u00f3 \u00f8\u00d7 \u00f6 \u00f9\u00f1 \u00f2\u00f8 t\u2208c(s) mt k=1 p s,t i,k n t k \u00fb \u00f2\u00f0\u00f9 \u00d7 \u00f8 \u00f6\u00f1\u00d7 \u00f8 \u00f8 \u00f0\u00f3\u00f3 \u00f0 \u00f8 \u00f3\u00f6 \u00f2 \u00f0 \u00f0 \u00f5\u00f9 \u00f4\u00f6\u00f3 \u00f9\u00f8 t\u2208c(s) mt k=1 p s,t i,k n t k \u00f4\u00f0\u00f9\u00d7 \u00f3\u00f8 \u00f6 \u00f6 \u00f3\u00f6 \u00f6 \u00f8 \u00f6\u00f1\u00d7\u00ba \u00be\u00ba \u00ec \u00f3\u00f4\u00f4 \u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 t s i,j = a s \u2020 i a s j \u00f2 \u00f6 \u00f4\u00f0 \u00fd \u00d7\u00f3\u00f1 \u00f3\u00f8 \u00f6 \u00f9\u00f2\u00b9 \u00f8 \u00f3\u00f2 \u00f0 \u00f3\u00f6\u00f1\u00b8\u00d7\u00f9 \u00d7 \u00f3\u00f2 \u00f8 \u00f8 \u00f2\u00f6 \u00d7 \u00d7 \u00b4 \u00ba \u00ba \u00f6\u00f8 \u00b5 \u00f3\u00f6 \u00f6 \u00d7 \u00d7 \u00b4 \u00ba \u00ba \u00f8 \u00b5 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b8\u00fb \u00f1 \u00fd \u00f9\u00d7 \u00f8\u00f3 \u00f0\u00f0\u00f3\u00fb \u00f8 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f8\u00f3 \u00fc\u00f4\u00f0\u00f3\u00f6 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f8 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f3\u00f9\u00f4 \u00f2 \u00d7\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00d7 \u00f9\u00d7 \u00f0\u00f3\u00f2 \u00d7 \u00f8 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00b4 \u00ba \u00ba \u00fb \u00f8 \u00f3\u00f9\u00f8 \u00f8 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6 \u00f4 \u00f3\u00fa \u00b5\u00b8\u00f8 \u00f2 \u00f8 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00f8 \u00f4\u00f6 \u00f3\u00f6 \u00fa \u00f3\u00f9\u00f6 \u00f8 \u00f8 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00f3\u00f6 \u00f2\u00fd \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f6 \u00f2\u00f0\u00f9 \u00ba \u00ec \u00f8 \u00f3 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f2 \u00fa \u00fb \u00f2 \u00f8 \u00f6\u00f1\u00d7 \u00f3 \u00f0 \u00f1 \u00f2\u00f8 \u00f6\u00fd \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00b4 \u00d7 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00b5\u00b8 \u00f2 \u00f8 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f0 \u00f6 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f3 \u00f0\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f2 \u00fb h \u00d7 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7\u00ba \u00e1\u00f8 \u00d7 \u00f0\u00d7\u00f3 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00f3 \u00f9\u00d7 \u00d7\u00fd\u00f1 \u00f3\u00f0 \u00f0 \u00f6 \u00f8\u00f3 \u00f3 \u00f8 \u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f9\u00f8\u00f3\u00f1 \u00f8 \u00f0\u00f0\u00fd\u00ba \u00e1\u00f2 \u00f2 \u00f6 \u00f0\u00b8\u00f8 \u00f8 \u00f3 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f3\u00f2 \u00d7 \u00f8 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7\u00f8 \u00f8 \u00d7 \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00d7 \u00f8\u00fd\u00f4 \u00f3 \u00fd\u00f2\u00f1 \u00f2 \u00f6 \u00f1\u00b8 \u00f2 \u00fb \u00fa \u00f6\u00f8 \u00fc \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f2 \u00f3\u00f2 \u00f2 \u00f2\u00f3\u00f1 \u00f2 \u00d7\u00f8 \u00f8 \u00f8\u00f3 \u00f4\u00f6\u00f3 \u00f9 \u00f2 \u00f3\u00f9\u00f8 \u00f3 \u00f2 \u00d7\u00f8 \u00f8 \u00b4 \u00f2\u00fd\u00b5\u00b8 \u00f2 \u00b4\u00fb \u00f8 \u00b5 \u00d7\u00f9\u00f1 \u00f3 \u00d7\u00f9 \u00f6 \u00f1\u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00b4\u00fb \u00f8 \u00b5 \u00d7\u00f9\u00f1 \u00f3 \u00f4\u00f6\u00f3 \u00f9\u00f8\u00d7 \u00f3 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00b4\u00f2\u00f3\u00f8 \u00f8 \u00f8 \u00f6 \u00f8 \u00fb \u00f8\u00d7 \u00f6 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f1\u00f4\u00f0 \u00f8\u00f9 \u00d7\u00b5\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00f2\u00f9\u00f1 \u00f6\u00b9\u00f3\u00f2\u00d7 \u00f6\u00fa \u00f2 \u00f2 \u00f8 \u00d7 \u00f2\u00d7 \u00f8 \u00f8 \u00f8\u00d7 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 t s i,j \u2261 a s \u2020 i a s j \u00f9\u00d7 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8\u00f3 \u00f3\u00f4 \u00f6\u00f3\u00f1 \u00f2 j \u00f8\u00f3 \u00f2 i \u00f8 \u00f2\u00f3 s\u00b8\u00fb \u00f8 \u00f3\u00f9\u00f8 \u00f2 \u00f3\u00f6 \u00f0\u00f3\u00d7\u00d7 \u00f3 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00b9 \u00f4\u00f0 \u00d7 \u00f8 \u00f2\u00f3 s\u00ba \u00f3\u00f6\u00f1 \u00f0\u00f0\u00fd\u00b8\u00f8 \u00d7 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8\u00fd \u00f1 \u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 [h, n s ] = 0 \u00fb \u00f6 n s \u2261 ms i=1 n s i \u00d7 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8 \u00f2\u00f3 s\u00ba \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00d7 \u00f2 \u00f2\u00f8\u00f9 \u00f8 \u00fa \u00f0\u00fd \u00f9\u00d7 \u00f8 \u00f1 \u00fd \u00fb\u00f6 \u00f8\u00f8 \u00f2 \u00d7 hn s = n s h\u00b8\u00fb \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f8 \u00fb \u00f2 \u00fd\u00f3\u00f9 \u00f1 \u00d7\u00f9\u00f6 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f2\u00f3 s \u00f8 \u00f2 \u00f3 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00fd\u00f3\u00f9 \u00f8 \u00f8 \u00d7 \u00f1 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 \u00fb \u00f2 \u00fd\u00f3\u00f9 \u00f3 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f8 \u00f2 \u00f1 \u00d7\u00f9\u00f6 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f2\u00f3 s\u00b8\u00d7\u00f3 \u00f8 \u00f6 \u00f1\u00f9\u00d7\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f2\u00d7 \u00f6\u00fa \u00f8 \u00f3\u00f2\u00ba \u00be \u00ec \u00d7\u00f8 \u00f4\u00d7 \u00f2 \u00f8 \u00f6 \u00fa \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f2\u00d7 \u00f6\u00fa \u00f8 \u00f3\u00f2 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8\u00fd [h, n u ] = 0 \u00f6 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 [h, n u ] = n s=1 ms i,j=1 t s i,j t\u2208c(s) mt k=1 p s,t i,k n t k , n u = n s=1 ms i,j=1 \uf8eb \uf8ed t s i,j t\u2208c(s) mt k=1 p s,t i,k n t k n u \u2212n u t s i,j t\u2208c(s) mt k=1 p s,t i,k n t k \uf8f6 \uf8f8 = n s=1 ms i,j=1 t s i,j t\u2208c(s) mt k=1 p s,t i,k n t k n u \u2212t s i,j n u ( t\u2208c(s) mt k=1 p s,t i,k n t k ) = n s=1 ms i,j=1 \uf8eb \uf8ed t s i,j t\u2208c(s) mt k=1 p s,t i,k n t k n u \u2212t s i,j t\u2208c(s) mt k=1 p s,t i,k n t k n u \uf8f6 \uf8f8 = 0 \u00b4 \u00b5 \u00f9\u00d7 \u00f2 [n u , t s i,j ] = 0 \u00b4t s i,j \u00f9\u00d7 \u00d7 \u00f3\u00f4\u00f4 \u00f2 \u00f8 \u00f2\u00f3 s \u00f9\u00f8 \u00f3\u00f2\u00d7 \u00f6\u00fa \u00d7 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1\u00b9 \u00f6 \u00f8 \u00f2\u00f3 s\u00b8 \u00f2 \u00f0\u00d7\u00f3 \u00f8\u00f6 \u00fa \u00f0\u00f0\u00fd \u00f3\u00f2\u00d7 \u00f6\u00fa \u00d7 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f8 \u00f0\u00f0 \u00f3\u00f8 \u00f6 \u00f2\u00f3 \u00d7\u00b5 \u00f8\u00f3 \u00f1 \u00f8 \u00f6 \u00f4\u00f0 \u00f1 \u00f2\u00f8 n u t s i,j \u2212\u2192 t s i,j n u \u00b8 \u00f2 [n u , n t k ] = 0 \u00b4\u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00b9 \u00f8\u00f3\u00f6\u00d7 \u00f0\u00fb \u00fd\u00d7 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00b5 \u00f8\u00f3 \u00f1 \u00f8 \u00f6 \u00f4\u00f0 \u00f1 \u00f2\u00f8 n u ( t\u2208c(s) mt k=1 p s,t i,k n t k ) \u2212\u2192 ( t\u2208c(s) mt k=1 p s,t i,k n t k )n u \u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 [n u , t s i,j ] = 0 \u00f2 [n u , n t k ] = 0 \u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00f8\u00f3 \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00f8 \u00d7 \u00f6 \u00f8 \u00f3\u00f2\u00bb \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f2\u00f8 \u00f2\u00f8 \u00f3 \u00f8 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7\u00ba \u00ec \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f8 \u00f3 \u00f9\u00d7 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00d7 \u00f8\u00f3 \u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f8 \u00f3 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00b8\u00d7\u00f3 \u00f8 \u00f8 \u00f8 \u00d7 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f6 \u00f2\u00f3\u00fb \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f0 \u00f6 \u00f0\u00f0\u00fd\u00ba \u00e7\u00f2 \u00f3\u00f9\u00f0 \u00fa\u00f3 \u00f8 \u00f9\u00d7 \u00f3 \u00f8 \u00d7 \u00f0 \u00f6 \u00f4\u00f4\u00f6\u00f3 \u00b4 \u00d7\u00f4 \u00f0\u00f0\u00fd \u00fb \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00d7 \u00f3\u00f2\u00f0\u00fd \u00d7 \u00f2 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00b8 \u00d7 \u00f2 \u00d7\u00f8 \u00f2 \u00f6 \u00e5\u00ea \u00b5\u00b8 \u00f9\u00f8 \u00d7 \u00f8 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f1 \u00f1\u00f3\u00f6 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00b4 \u00ba \u00ba \u00d7\u00f9 \u00f8\u00f0 \u00f2\u00f8 \u00f6 \u00f4 \u00f2 \u00f2 \u00d7 \u00f8\u00fb \u00f2 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00b5 \u00f8 \u00d7 \u00f8\u00f8 \u00f6 \u00f8\u00f3 \u00f3 \u00f8 \u00f1 \u00fd \u00f9\u00d7 \u00f2 \u00f8 \u00d7 \u00f0 \u00f6 \u00f4\u00f4\u00f6\u00f3 \u00ba \u00bf\u00ba \u00f6 \u00f1\u00f1 \u00f8 \u00ea \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 \u00b4 \u00ba \u00ba \u00d7 \u00eb \u00f8 \u00f3\u00f2 \u00be\u00ba\u00be\u00b5 \u00f2 \u00fb \u00fc \u00f2 \u00fd \u00f6 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00f0\u00fd \u00f9\u00f4 \u00f8 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f6\u00f3\u00f1 pr(\u00fc , \u00fd) \u00d7 \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00f0\u00f3\u00fb \u00fb \u00f6 \u00f6\u00f6\u00f3\u00fb \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f4 \u00f2 \u00f2\u00fd\u00ba \u00ec \u00f6 \u00f4 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8 \u00f8 \u00f9\u00f4 \u00f8 \u00d7 \u00f6 \u00f1 \u00f1\u00f3\u00f6\u00fd\u00f0 \u00d7\u00d7\u00ba \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00b8\u00fc 2 \u00f4 \u00f2 \u00d7 \u00f3\u00f2 \u00fd 1 \u00fa pr(\u00fc 2 |\u00fd 1 )\u00b8 \u00f9\u00f8 \u00f8 \u00f3 \u00d7 \u00f2\u00f3\u00f8 \u00f4 \u00f2 \u00f3\u00f2 \u00fc 1 \u00ba \u00fc 1 \u00fc 2 \u2212\u2192 \u00fc 2 \u00fc 3 \u2212\u2192 \u00fc 3 \u2022 \u2022 \u2022 \u0580 \u0580 \u0580 \u0581 \u0581 \u0581 \u0580 \u0580 \u0580 \u0581 \u0581 \u0581 \u2022 \u2022 \u2022 \u00fd 1 \u2212\u2192 \u00fd 1 \u00fd 2 \u2212\u2192 \u00fd 2 \u00fd 3 \u2022 \u2022 \u2022 pr(\u00fc 2 |\u00fd 1 ) pr(\u00fd 2 |\u00fc 2 ) pr(\u00fc 3 |\u00fd 2 ) pr(\u00fd 3 |\u00fc 3 ) \u00be \u00ec \u00f3\u00fa \u00f6 \u00f1 \u00f2 \u00d7 \u00f0 \u00f8\u00f3\u00f2 \u00d7 \u00fd \u00f3\u00f1 \u00f8\u00f8 \u00f2 \u00f0\u00f0 \u00f2 \u00d7\u00d7 \u00f2\u00f8 \u00f0 \u00f0 \u00f0\u00f0 \u00f2 \u00f2 \u00f3\u00f6 \u00f6 \u00f8\u00f3 \u00f1\u00f4 \u00d7 \u00d7 \u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f3\u00fb\u00b8 \u00f2 \u00fb \u00d7 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f0\u00f3\u00f3 \u00d7 \u00f0 \u00f8 \u00d7 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u0580 \u0581 \u0580 \u0581 \u2022 \u2022 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u2022 \u00e1 \u00f8 \u00d7 \u00d7 \u00f0 \u00f8\u00f3\u00f2 \u00d7 \u00f8 \u00f3\u00f2 \u00d7 \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00fb \u00f2 \u00f2 \u00f3\u00f6\u00f1 \u00f8 \u00f3\u00f2 \u00f3\u00fb \u00f6 \u00f1 \u00f3\u00f6 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 \u00f3 \u00f2\u00f3 \u00e5 \u00f6 \u00f3\u00fa \u00f2\u00b8\u00f8 \u00f2 \u00f8\u00fd\u00f4 \u00f0 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f0\u00f3\u00f3 \u00d7 \u00f0 \u00f8 \u00f6 \u00f1 \u00f0\u00f3\u00fb\u00ba \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u00b11 \u0581 \u0580 \u0581 \u2022 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u00b12 \u0581 \u0580 \u0580 \u0581 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u00b13 \u0580 \u0580 \u0580 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 +1 +2 \u22123 \u22121 \u22122 \u22122 +1 \u22123 +2 \u22123 \u00f3\u00f6 \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00fa \u00f4\u00f9\u00f6\u00f4\u00f3\u00d7 \u00d7 \u00f8 \u00e5 \u00f6 \u00f3\u00fa \u00f2 \u00d7 \u00f6 \u00fb\u00f2 \u00f2 \u00f8 \u00f9\u00f4\u00b9 \u00f3\u00fb\u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f6 \u00f1\u00b8\u00fb \u00f8 \u00f8 \u00f3\u00f6 \u00fe\u00f3\u00f2\u00f8 \u00f0 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f9\u00d7 \u00f3\u00f6 \u00f8 \u00d7\u00f6 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f4\u00d7 \u00f8 \u00f8 \u00f6 \u00f2 \u00f6 \u00f8 \u00fd \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f4\u00f6\u00f3 \u00f9\u00f6 \u00ba \u00ec \u00b1n \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f0 \u00f8 \u00f2 \u00d7 \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f0 \u00f0\u00f0 \u00f2 \u00f3\u00f2\u00fa \u00f2\u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00d7 \u00f9\u00d7 \u00f3\u00f6 \u00f8 \u00f9\u00f4 \u00f8 \u00f8 \u00f8 \u00f3\u00f9\u00f6\u00d7 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f4\u00b8\u00fb \u00f6 +n \u00f2 \u00f8 \u00d7 \u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f8\u00fb \u00f2 \u00f2\u00f3 \u00f2 \u00f8\u00d7 \u00f6 \u00f8 \u00f2 \u00f2 \u00f3\u00f9\u00f6 \u00b4\u00f6 \u00f8 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f8 \u00f6 \u00f1\u00b5\u00b8 \u00f2 \u2212n \u00d7 \u00f8 \u00f2 \u00f0\u00f3 \u00f3\u00f9\u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f8 \u00f0 \u00f8 \u00f2 \u00f2 \u00f3\u00f9\u00f6\u00ba \u00ec \u00b1n \u00f2\u00f3\u00f8 \u00f8 \u00f3\u00f2 \u00f0\u00f3\u00f2 \u00f8 \u00f3\u00f8\u00f8\u00f3\u00f1 \u00f3 \u00f8 \u00f6 \u00f1 \u00d7 \u00f3\u00fb\u00d7 \u00f8 \u00f8\u00f9 \u00f0 \u00f9\u00f4 \u00f8 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f3\u00f9\u00f6\u00d7 \u00f8 \u00f8 \u00f1 \u00d7\u00f8 \u00f4\u00ba \u00ec \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 \u00f8 \u00f8 \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00f6 \u00f1 \u00f3\u00fa \u00d7 \u00f9\u00f2 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00f9\u00d7 \u00f8 \u00d7 \u00f6 \u00f2 \u00f3\u00f1\u00ba \u00ec \u00f6 \u00f6 \u00d7 \u00f4 \u00f6 \u00f8 \u00d7 \u00f6 \u00f1\u00d7 \u00f8 \u00f8 \u00f6 \u00f9\u00d7 \u00f8\u00f3 \u00f9 \u00f0 \u00f8 \u00f3\u00fa \u00f6 \u00f1 \u00fb \u00f6 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f8 \u00f6 \u00f1 \u00f0\u00f3\u00fb\u00ba \u00ed\u00d7\u00f9 \u00f0\u00f0\u00fd \u00f6 \u00f2 \u00f3\u00f1\u00f0\u00fd \u00d7 \u00f0 \u00f8 \u00d7 \u00f5\u00f9 \u00f2 \u00f3 \u00f8 \u00d7 \u00f6 \u00f1\u00d7 \u00f3\u00f6\u00f1\u00d7 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00b8 \u00f9\u00f8 \u00f3\u00f8 \u00f6 \u00f3 \u00d7 \u00f6 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00ba \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u0581 \u0580 \u2022 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u0581 \u0580 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2022 \u2022 \u2022 \u0581 \u0580 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 \u2022 \u2212\u2192 \u2022 +1 \u22121 +2 \u22122 +3 \u22123 \u00ec \u00d7 \u00f0 \u00f8\u00f3\u00f2 \u00d7 \u00d7\u00f8\u00f6\u00f9\u00f8\u00f9\u00f6 \u00f3 \u00f8 \u00f6 \u00f1\u00d7 \u00f2 \u00f2\u00f3\u00fb \u00d7 \u00f1\u00f4\u00f0 \u00f9\u00f6\u00f8 \u00f6 \u00f8\u00f3 \u00f1 \u00f8 \u00f0\u00f3\u00f3 \u00f1\u00f3\u00f6 \u00d7\u00fd\u00f1\u00f1 \u00f8\u00f6 \u00f0 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f8 \u00f6 \u00f1 \u00f0\u00f3\u00fb\u00b8\u00fb \u00f6 \u00f8 \u00f4 \u00d7 \u00f3 \u00f8 \u00f3\u00fa \u00f6 \u00f1\u00d7 \u00f6 \u00f6 \u00fb\u00f2 \u00f2 \u00fa \u00f9 \u00f0\u00f0\u00fd \u00f2 \u00f1\u00f3\u00f6 \u00d7\u00fd\u00f1\u00f1 \u00f8\u00f6 \u00f0 \u00d7 \u00f3\u00f2\u00ba \u00be \u2022 \u2212\u2192 \u2022 =\u21d2 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u0581 \u2022 \u2022 =\u21d2 \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u0580 \u2022 \u2022 =\u21d2 \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u2212\u2192 \u2022 \u2212\u2192 \u00ec \u00d7 \u00f6 \u00f9 \u00d7 \u00f8 \u00d7\u00f6 \u00f4\u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f8\u00f3 \u00d7 \u00f8 \u00f3 \u00d7 \u00f6 \u00f1\u00d7 \u00f2 \u00fb \u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f2\u00f3 \u00fa\u00f3\u00f0\u00fa \u00d7 \u00f6 \u00f0\u00fd \u00b4 \u00ba \u00ba \u2212\u2192 \u2022 \u2212\u2192 \u00b5 \u00f3\u00f6 \u00d7 \u00f2\u00fa\u00f3\u00f0\u00fa \u00f2 \u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00b4 \u00ba \u00ba \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u00f2 \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u00b5\u00ba \u00ec \u00d7 \u00f6 \u00f1\u00d7 \u00f0\u00f0\u00f3\u00fb \u00f3\u00f6 \u00f8 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f8\u00fd \u00f8 \u00f8 \u00f2\u00f3 \u00d7 \u00f1 \u00f1\u00f3\u00f6\u00fd \u00f3 \u00f8\u00d7 \u00f4\u00f6 \u00fa \u00f3\u00f9\u00d7 \u00d7\u00f8 \u00f8 \u00b4 \u00ba \u00ba \u00f2 \u00f6\u00f6\u00f3\u00fb \u00f3\u00f1 \u00d7 \u00f2 \u00f6\u00f3\u00f1 \u00f8 \u00f0 \u00f8\u00b5\u00b8\u00d7\u00f3 \u00f8 \u00e5 \u00e5 \u00f6 \u00f1\u00d7 \u00f3\u00fa \u00f6 \u00d7\u00f4 \u00f0 \u00d7 \u00f2 \u00fb \u00f8 \u00d7 \u00f1 \u00f1\u00f3\u00f6\u00fd \u00d7 \u00d7 \u00f6 \u00ba \u00ec \u00d7 \u00f6 \u00f1\u00d7 \u00f2 \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f6 \u00f3\u00f6 \u00f6 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00fb \u00f1 \u00f0 \u00f1 \u00f8 \u00f8 \u00f8 \u00f3 \u00d7 \u00fa \u00f6 \u00f0 \u00d7 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7\u00ba \u00ec \u00f9\u00d7\u00b8\u00d7\u00f8 \u00f6\u00f8 \u00fd \u00f2 \u00f2 \u00f2 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h\u00ba \u00f3\u00f6 \u00f4 \u00f6 \u00f3 \u00e5\u00ea \u00f2\u00f3 \u00d7 \u00f8 \u00d7 \u00d7 \u00f0\u00b9 \u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bc\u00b8\u00fb \u00d7 \u00f3 \u00f8 \u00f3\u00f6\u00f1 h \u2261 i + h 1 + h 2 \u00ba \u00ec i \u00d7 \u00f8 \u00f2\u00f8 \u00f8\u00fd \u00fb \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f2\u00f3 \u00f9\u00f4 \u00f8 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00b8 \u00f2 \u00f8 h 1 \u00f2 h 2 \u00f4 \u00d7 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f8\u00f3 \u00f9\u00f4 \u00f8 \u00d7 \u00f8 \u00f8 \u00f3\u00f9\u00f6 \u00f3\u00f2 \u00f3\u00f2 \u00f3\u00f6 \u00f8 \u00f3\u00f8 \u00f6 \u00f3 \u00f8 \u00f8\u00fb\u00f3 \u00f2\u00f3 \u00d7\u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd\u00ba h \u2261 \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 \u00b4 \u00bc\u00b5 \u00e5\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 \u00f1 \u00fd \u00f8 \u00f2 \u00f2 \u00f6 \u00f8 \u00fd \u00f8 \u00f6 \u00f8 \u00f2 h \u00f8\u00f3 \u00f6 \u00f8 \u00f4\u00f3\u00fb \u00f6\u00d7 \u00f3 h\u00ba \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2 \u00b8h2 \u00f1 \u00fd \u00f6 \u00fa \u00d7 \u00fd \u00fc\u00f4 \u00f2 \u00f2 \u00f3\u00f9\u00f8 {i + h 1 + h 2 } 2 \u00f2 \u00f3\u00f0\u00f0 \u00f8 \u00f2 \u00f8\u00f3 \u00f8 \u00f6 \u00d7 \u00f1 \u00f0 \u00f6 \u00f8 \u00f6\u00f1\u00d7\u00b8 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be\u00ba h 2 = a 0 + a 1 + a 2 \u00b4 \u00bd\u00b5 \u00be \u00fb \u00f6 a 0 \u2261 \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 a 1 \u2261 \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 a 2 \u2261 \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u2193 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u2191 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u2191 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u2193 \u2212\u2192 \u2022 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 \u00b4 \u00be\u00b5 \u00ec \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bd \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f1 \u00fd \u00d7 \u00f1\u00f4\u00f0 \u00f8\u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b4\u00f9\u00d7 \u00f2 i 2 = i \u00f2 ih i = h i i = h i \u00b5\u00ba h 2 = b 0 + b 1 + a 2 \u00b4 \u00bf\u00b5 \u00fb \u00f6 b 0 \u2261 \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 b 1 \u2261 2 \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2193 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 + 2 \uf8eb \uf8ed \u2212\u2192 \u2022 \u2212\u2192 \u2191 \u2212\u2192 \u2022 \u2212\u2192 \uf8f6 \uf8f8 \u00b4 \u00b5 \u00e1\u00f2 \u00f8 \u00f6 \u00f1\u00f1 \u00f8 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f3\u00f6 h 2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f8 \u00f6\u00d7\u00f8 \u00f6\u00f3\u00fb \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f2\u00f3 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00b8\u00f8 \u00d7 \u00f3\u00f2 \u00f6\u00f3\u00fb \u00f3\u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00b8 \u00f2 \u00f8 \u00f8 \u00f6 \u00f6\u00f3\u00fb \u00f8\u00fb\u00f3 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00f3\u00f6 \u00f6 \u00f2 \u00fb \u00f8 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f3\u00f9\u00f6 \u00d7 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00b4 \u00ba \u00ba h 1 h 2 = h 2 h 1 \u00f2 \u00f2 \u00f6 \u00f0\u00b5 \u00d7\u00f3 \u00f8 \u00f6 \u00f1\u00d7 \u00f2 \u00f8 \u00f8 \u00f6 \u00f6\u00f3\u00fb \u00f2\u00f2\u00f3\u00f8 \u00f3\u00f1 \u00f2 \u00ba \u00e7\u00f2 \u00f8 \u00f3\u00f8 \u00f6 \u00f2 ih i = h i i = h i \u00d7\u00f3 \u00f8 \u00f6 \u00f1\u00d7 \u00f2 \u00f8 \u00d7 \u00f3\u00f2 \u00f6\u00f3\u00fb \u00f2 \u00f3\u00f1 \u00f2 \u00ba \u00ec \u00d7 \u00f6 \u00f1\u00d7 \u00f6 \u00f8\u00f9 \u00f0\u00f0\u00fd \u00fd\u00f2\u00f1 \u00f2 \u00f6 \u00f1\u00d7\u00b8\u00fb \u00d7\u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2\u00d7 \u00f2 \u00f2 \u00fa \u00d7\u00f9 \u00f0\u00f0\u00fd \u00f4\u00f4 \u00f0 \u00f2 \u00fb \u00fd\u00ba \u00e1\u00f2 \u00f8 \u00d7 \u00d7 \u00f8 \u00fd \u00d7 \u00f3\u00fb \u00f3\u00fb \u00f8 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00f2\u00fa\u00f3 \u00fd \u00f8 \u00f4 \u00d7 \u00f3 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f8 \u00f8\u00f3 \u00f8 \u00f6 \u00f2 \u00fa \u00f6 \u00f3\u00f9\u00d7 \u00fb \u00fd\u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00f8 \u00f6 \u00f1\u00f1 \u00f8 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f6 \u00f3\u00f6 \u00f6 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h 2 \u00ba \u00ec \u00d7 \u00fc \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00f1\u00f4\u00f0 \u00f2\u00f3\u00f9 \u00f8 \u00f8 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f6 \u00f3 \u00fa \u00f3\u00f9\u00d7\u00b8 \u00f9\u00f8 \u00f8 \u00f6 \u00f1\u00f1 \u00f8 \u00f8 \u00f2 \u00f5\u00f9 \u00f2 \u00f6 \u00f0 \u00d7 \u00d7 \u00f8\u00f3 \u00f6 \u00f8\u00f6 \u00f6 \u00f0\u00fd \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00d7 \u00d7\u00ba \u00bf\u00bc \u00ec \u00f1 \u00f3 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00d7 \u00f3\u00fb \u00d7\u00f3\u00f1 \u00d7 \u00f1\u00f4\u00f0 \u00f4\u00f6 \u00f8 \u00f0 \u00f9\u00d7 \u00d7 \u00f3 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f4\u00f4\u00f6\u00f3 \u00f8 \u00f8 \u00d7 \u00d7\u00f6 \u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba ae\u00f3 \u00f8\u00f8 \u00f1\u00f4\u00f8 \u00fb \u00f0\u00f0 \u00f1 \u00f8\u00f3 \u00f3 \u00fc\u00f8 \u00f2\u00d7 \u00fa \u00f3\u00f1\u00f4\u00f9\u00f8 \u00f8 \u00f3\u00f2\u00d7\u00b8 \u00f9\u00d7 \u00f8 \u00d7 \u00fb \u00f0\u00f0 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f9\u00f8\u00f9\u00f6 \u00f4 \u00f4 \u00f6\u00d7 \u00f2 \u00f8 \u00d7 \u00d7\u00f6 \u00f8 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00fd\u00f2 \u00f1 \u00d7 \u00d7 \u00f6 \u00d7 \u00f3 \u00f4 \u00f4 \u00f6\u00d7\u00ba \u00eb \u00f8 \u00f3\u00f2 \u00ba\u00bd \u00f0\u00f0\u00f9\u00d7\u00f8\u00f6 \u00f8 \u00d7 \u00f3\u00fb \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6\u00f6 \u00f8\u00f0\u00fd \u00f2 \u00f6 \u00f8 \u00d7 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00d7 \u00f3\u00f6 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f8 \u00f8 \u00f6 \u00f3\u00f9\u00f4 \u00fd \u00d7 \u00f2 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00b8\u00f8 \u00f9\u00d7 \u00f2\u00d7\u00f9\u00f6 \u00f2 \u00fb \u00f6 \u00d7 \u00f3\u00f1\u00f4 \u00f8 \u00f0 \u00f8\u00fd \u00f8\u00fb \u00f2 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f4\u00f4\u00f6\u00f3 \u00f2 \u00f8 \u00d7\u00f8 \u00f2\u00b9 \u00f6 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f3\u00f6 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00e5\u00ea \u00d7\u00ba \u00eb \u00f8 \u00f3\u00f2 \u00ba\u00be \u00f2 \u00f6 \u00f0 \u00d7 \u00d7 \u00f8 \u00d7 \u00f8\u00f3 \u00f8 \u00d7 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00d7\u00f8 \u00f8 \u00d7\u00b8 \u00f2 \u00f6 \u00fa \u00d7 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00f3 \u00d7 \u00f2 \u00f0 \u00f2\u00f3 \u00e5\u00ea \u00fb \u00d7 \u00f8 \u00d7 \u00f1 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00d7 \u00f2 \u00f8 \u2104\u00ba \u00ba\u00bd \u00ed\u00f4 \u00f8 \u00f3 \u00eb \u00f2 \u00f0 \u00b9\u00eb \u00f1\u00f4\u00f0 \u00eb\u00f8 \u00f8 \u00d7 \u00d7 \u00f3\u00f2 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f3\u00f6 h \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00fa \u00f6 \u00fd \u00f8 \u00f8 \u00f8 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3 h \u00f8\u00f3 \u00d7\u00f8 \u00f2 \u00f6 \u00e5\u00ea \u00d7\u00f8 \u00f8 \u00b4 \u00ba \u00ba \u00f3\u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f4 \u00f6 \u00f2\u00f3 \u00b5 \u00f0 \u00d7 \u00f8\u00f3 \u00f8 \u00fc\u00f4 \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00f3\u00f6\u00f1 \u00f3 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00ba \u00e1\u00f2 \u00d7\u00f8 \u00f2 \u00f6 \u00e5\u00ea \u00f3\u00f2\u00f0\u00fd \u00d7 \u00f2 \u00f0 \u00f2 i u \u00d7 \u00f3\u00f9\u00f4 \u00f8 \u00f2\u00f3 u\u00ba \u00f3\u00f6 \u00f2 n \u00b9\u00f2\u00f3 \u00e5\u00ea \u00f8 \u00d7 \u00f2 \u00d7 \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00f8 \u00f8 \u00d7 \u00f8 \u00f3\u00f6\u00f1 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u2261 n u=1 a u \u2020 iu |0 \u00b4 \u00b5 \u00ec \u00f6\u00d7\u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f8\u00f3 \u00f3\u00f2\u00d7 \u00f6 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 n t k \u00b4 \u00f3\u00f6 \u00f1 \u00d7\u00f9\u00f6 \u00f2 \u00f3\u00fb \u00f1 \u00f2\u00fd \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6 \u00f2 \u00f2 k \u00f8 \u00f2\u00f3 t\u00b5\u00ba \u00ef \u00f2 n t k \u00d7 \u00f4\u00f4\u00f0 \u00f8\u00f3 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00f8 \u00fa \u00d7 n t k \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) = n t k n u=1 a u \u2020 iu |0 = \u03b4 it,k \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00b4 \u00b5 \u00d7\u00f3 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u03b4 it,k \u00d7 \u00bd \u00f8 \u00f2 \u00f8 \u00f2\u00f3 t \u00f2 \u00fc \u00f1 \u00f2 \u00b4 \u00ba \u00ba k\u00b5 \u00f1 \u00f8 \u00d7 \u00f8 \u00f2 \u00f2 \u00fb \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f2\u00f3 t \u00d7 \u00f8\u00f3 \u00f3\u00f9\u00f2 \u00b4 \u00ba \u00ba i t \u00b5\u00b8 \u00f2 \u00d7 \u00bc \u00f3\u00f8 \u00f6\u00fb \u00d7 \u00ba \u00e1\u00f2\u00d7 \u00f6\u00f8 \u00f8 \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f2\u00f8\u00f3 \u00f8 t\u2208c(s) mt k=1 p s,t i,k n t k \u00f4 \u00f6\u00f8 \u00f3 h \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f3\u00f2 t\u2208c(s) mt k=1 p s,t i,k n t k \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) = t\u2208c(s) mt k=1 p s,t i,k n t k n u=1 a u \u2020 iu |0 = t\u2208c(s) mt k=1 p s,t i,k \u03b4 it,k \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) = t\u2208c(s) p s,t i,it \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00b4 \u00b5 \u00fb \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00fb \u00f8 \u00fd \u00f8 \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00f8 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00d7 \u00f8 \u00f8 \u00f2\u00fa\u00f3\u00f0\u00fa \u00f2\u00f3 s\u00ba \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00f3\u00f6\u00f6 \u00f8\u00f0\u00fd \u00f3\u00f1\u00f4\u00f9\u00f8 \u00d7 \u00f8 \u00be\u00b9\u00f0 \u00f5\u00f9 \u00f2 \u00f9 \u00f2 \u00f3 \u00f8 \u00f2 \u00f3\u00f9\u00f6\u00d7 \u00f3 \u00f2\u00f3 s \u00f8 \u00f8 \u00d7 \u00fc\u00f4 \u00f8 \u00f2 \u00d7\u00f8 \u00f2 \u00f6 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00ba \u00bf\u00bd h \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f0\u00d7\u00f3 \u00f2\u00fa\u00f3\u00f0\u00fa \u00d7 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 t s i,j \u00ba \u00f4\u00f4\u00f0\u00fd t s i,j \u00f8\u00f3 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00f8\u00f3 \u00f3 \u00f8 \u00f2 t s i,j \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) = t s i,j n u=1 a u \u2020 iu |0 = a s \u2020 i a s j a 1 \u2020 i1 a 2 \u2020 i2 \u2022 \u2022 \u2022 a s \u2020 is \u2022 \u2022 \u2022 a n \u2020 in |0 = a s \u2020 i a 1 \u2020 i1 a 2 \u2020 i2 \u2022 \u2022 \u2022 a s \u2020 is a s j + \u03b4 is,j \u2022 \u2022 \u2022 a n \u2020 in |0 = a s \u2020 i a 1 \u2020 i1 a 2 \u2020 i2 \u2022 \u2022 \u2022 a s \u2020 is \u2022 \u2022 \u2022 a n \u2020 in a s j |0 +\u03b4 is,j a 1 \u2020 i1 a 2 \u2020 i2 \u2022 \u2022 \u2022 a s \u2020 i \u2022 \u2022 \u2022 a n \u2020 in |0 = \u03b4 is,j \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i s\u22121 , i, i s+1 , \u2022 \u2022 \u2022 , i n ) \u00b4 \u00b5 \u00fb \u00f6 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a s j \u00d7 \u00f1\u00f3\u00fa \u00f8\u00f3 \u00f8 \u00f6 \u00f8\u00b8\u00f4 \u00f2 \u00f9\u00f4 \u00f2\u00f3\u00f2\u00b9\u00fe \u00f6\u00f3 \u00f3\u00f1\u00f1\u00f9\u00f8 \u00f8\u00f3\u00f6 \u00f3\u00f2\u00f0\u00fd \u00fb \u00f2 \u00f8 \u00f1\u00f3\u00fa \u00d7 \u00f4 \u00d7\u00f8 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a s \u2020 is \u00b4 \u00ba \u00ba \u00f3\u00f8 \u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f6 \u00f8 \u00f8 \u00d7 \u00f1 \u00f2\u00f3 \u00d7\u00f3 \u00f8 \u00fd \u00f3 \u00f2\u00f3\u00f8 \u00f3\u00f1\u00f1\u00f9\u00f8 i s = j\u00b5\u00b8 \u00f2 \u00f2 \u00f0\u00f0\u00fd \u00f1 \u00f8\u00d7 \u00f8 \u00f1\u00f4\u00f8\u00fd \u00d7\u00f8 \u00f8 |0 \u00fb \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00d7\u00ba \u00ec \u00d7 \u00f6 \u00d7\u00f9\u00f0\u00f8 \u00d7 \u00f5\u00f9 \u00f0 \u00f8\u00f3 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i s\u22121 , i, i s+1 , \u2022 \u2022 \u2022 , i n ) \u00fb \u00f8 \u00fd \u00f8\u00f3\u00f6 \u03b4 is,j \u00b8\u00fb \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f2 \u00fb \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u00f2 \u00fb \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f2\u00f3 s \u00d7 \u00f3\u00f4\u00f4 \u00f8\u00f3 \u00f2 i\u00b8\u00fb \u00f8 \u00fd \u00bd \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f2\u00f3 s \u00d7\u00f8 \u00f6\u00f8 \u00f3 \u00f2 \u00f2 j\u00b8 \u00f2 \u00bc \u00f3\u00f8 \u00f6\u00fb \u00d7 \u00ba \u00ec \u00d7 \u00d7 \u00fc \u00f8\u00f0\u00fd \u00f8 \u00fa \u00f3\u00f9\u00f6 \u00f8 \u00f8 \u00d7 \u00fc\u00f4 \u00f8 \u00f3 \u00f8 \u00f8\u00f6 \u00f2\u00d7 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 t s i,j \u00ba \u00f2 \u00f0\u00f0\u00fd\u00b8 \u00f2\u00d7 \u00f6\u00f8 \u00f2 \u00f8 \u00f6 \u00d7\u00f9\u00f0\u00f8\u00d7 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f2\u00f8\u00f3 h \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00fa \u00d7 h\u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) = n s=1 ms i,j=1 t s i,j t\u2208c(s) mt k=1 p s,t i,k n t k \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) = n s=1 ms i,j=1 \u03b4 is,j t\u2208c(s) p s,t i,it \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i s\u22121 , i, i s+1 , \u2022 \u2022 \u2022 , i n ) = n s=1 ms i=1 t\u2208c(s) p s,t i,it \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i s\u22121 , i, i s+1 , \u2022 \u2022 \u2022 , i n ) \u00b4 \u00b5 \u00ec \u00f8 \u00f3\u00f2 \u00f3 h \u00f3\u00f2 \u00f8 \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00f4\u00f6\u00f3 \u00f9 \u00d7 \u00fb \u00f8 \u00d7\u00f9\u00f1 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00b4\u00f3\u00f6 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00b5\u00b8 \u00f9\u00d7 \u00f8 \u00f8 \u00f3 h \u00f8 \u00f2\u00f3 s \u00d7 \u00f8\u00f3 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f2 \u00b9 \u00f3\u00f9\u00d7\u00f0\u00fd \u00f6 \u00f8 m s \u00d7\u00f8 \u00f8 \u00d7 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i s\u22121 , i, i s+1 , \u2022 \u2022 \u2022 , i n ) \u00b4 \u00f3\u00f6 i = 1, 2, \u2022 \u2022 \u2022 , m s \u00b5\u00b8 \u00f3 \u00fb \u00d7 \u00f8\u00d7 \u00f3\u00fb\u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6 t\u2208c(s) p s,t i,it \u00b4 \u00ba \u00ba \u00f4\u00f6\u00f3 \u00f9\u00f8 \u00f3 \u00be\u00b9 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00d7\u00b5\u00b8\u00fb \u00d7 \u00f8\u00f3\u00f8 \u00f0 \u00f3 m 1 m 2 \u2022 \u2022 \u2022 m n \u00d7\u00f8 \u00f8 \u00d7 \u00fb \u00f8 \u00f8 \u00f6 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6\u00d7\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f2\u00d7 \u00f1 \u00f0 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00d7 \u00f3\u00f9\u00f0 \u00f6 \u00f6\u00f3\u00f9\u00f4 \u00d7\u00f3 \u00f8 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3\u00f4 \u00d7 \u00f3 \u00f2\u00f8 \u00f0 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7 \u00f6 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00d7 \u00d7 \u00f2 \u00f0 \u00f3\u00f4\u00fd \u00fb \u00f8 \u00f2 \u00f4\u00f4\u00f6\u00f3\u00f4\u00f6 \u00f8 \u00fb \u00f8 \u00f2 \u00f8\u00f3\u00f6\u00ba \u00ec \u00f9\u00d7 h\u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00d7 \u00f4\u00f6 \u00d7 \u00f0\u00fd \u00f8 \u00f2\u00d7 \u00f1 \u00f0 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00f6\u00f3\u00f1 \u00fb \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f6 \u00fb\u00d7 \u00f8\u00d7 \u00f9\u00f4 \u00f8 \u00d7\u00f8 \u00f8 \u00ba \u00ec \u00d7 \u00fa \u00f6 \u00d7 \u00f8 \u00f8 \u00f8 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f2 \u00f6 \u00f8 \u00d7 \u00f8 \u00f3\u00f6\u00f6 \u00f8 \u00fa \u00f3\u00f9\u00f6 \u00fb \u00f2 \u00f3\u00f2\u00f0\u00fd \u00d7 \u00f2 \u00f0 \u00f2 i u \u00d7 \u00f3\u00f9\u00f4 \u00f8 \u00f2\u00f3 u\u00b8 \u00d7 \u00d7 \u00f8 \u00d7 \u00f2 \u00d7\u00f8 \u00f2\u00b9 \u00f6 \u00e5 \u00e5 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00e5\u00ea \u00d7\u00ba \u00eb \u00f1 \u00f0 \u00f6\u00f0\u00fd\u00b8 \u00f6 \u00f3\u00f6 \u00f6 \u00f0 \u00f5\u00f9 \u00d7 \u00f4\u00f6\u00f3 \u00f9 \u00f8 \u00d7 \u00f1 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00fd \u00f8\u00fb \u00f2 \u00fb \u00f8 \u00f8 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f2 \u00f6 \u00f8 \u00d7 \u00f2 \u00fb \u00f8 \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00f2 \u00f6 \u00f8 \u00d7\u00b8\u00d7\u00f3 \u00f8 \u00d7\u00d7\u00f9\u00f1 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f3\u00f6\u00f1 \u00f3 h \u00d7 \u00fb \u00f6 \u00f0\u00fd \u00f3\u00f1\u00f4 \u00f8 \u00f0 \u00fb \u00f8 \u00e5 \u00e5 \u00d7 \u00f1\u00f9\u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00d7\u00f8 \u00f2 \u00f6 \u00e5\u00ea \u00d7 \u00fb \u00f8 \u00d7 \u00f2\u00b9 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00f4 \u00f6 \u00f2\u00f3 \u00ba \u00eb\u00f8 \u00f2 \u00f6 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f6 \u00f2 \u00f3\u00f1\u00f0\u00fd \u00d7 \u00f0 \u00f8 \u00d7 \u00f2 \u00f0 \u00d7\u00f8 \u00f8 \u00f6\u00f3\u00f1 \u00f8 \u00f3\u00fa \u00f2\u00d7 \u00f1 \u00f0 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 \u00f2 \u00f6 \u00f8 \u00fd \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f8 \u00f4\u00f6\u00f3 \u00b9 \u00bf\u00be \u00f0 \u00f8\u00fd \u00f3 \u00f4 \u00f6\u00f8 \u00f9\u00f0 \u00f6 \u00d7\u00f8 \u00f8 \u00f2 \u00d7 \u00f0 \u00f8 \u00d7 \u00fa \u00f2 \u00fd \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6 \u00f8 \u00f8 \u00fb \u00f8\u00d7 \u00f8 \u00f8 \u00d7\u00f8 \u00f8 \u00f2 \u00f8 \u00f2\u00d7 \u00f1 \u00f0 \u00ba \u00e5\u00f3\u00f6 \u00d7\u00f3\u00f4 \u00d7\u00f8 \u00f8 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7\u00b8 \u00f2\u00f3\u00fb\u00f2 \u00d7 \u00f4 \u00f6\u00f8 \u00f0 \u00f0\u00f8 \u00f6 \u00f2 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00bf\u2104\u00b8\u00d7 \u00f0 \u00f8 \u00d7 \u00fa \u00f6 \u00f0 \u00d7\u00f8 \u00f8 \u00d7 \u00f6\u00f3\u00f1 \u00f8 \u00f2\u00d7 \u00f1 \u00f0 \u00fb \u00f0\u00f0\u00f3\u00fb\u00d7 \u00d7 \u00fa \u00f6 \u00f0 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00f9\u00f4 \u00f8 \u00d7 \u00f8\u00f3 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f2 \u00f3\u00f9\u00d7\u00f0\u00fd \u00f3\u00f0\u00f0\u00f3\u00fb \u00b8\u00fb \u00f0\u00f0\u00f3\u00fb\u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3\u00fa \u00f6 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00d7 \u00f8\u00f3 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f3\u00f6\u00f1\u00ba \u00e0\u00f3\u00fb \u00fa \u00f6\u00b8 \u00f0\u00f0 \u00f3 \u00f8 \u00d7 \u00f4\u00f4\u00f6\u00f3 \u00d7 \u00f8 \u00f2\u00f8\u00f3 \u00f8 \u00d7 \u00f1 \u00f8 \u00f3\u00f6 \u00f8 \u00f0 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00fb \u00f6 \u00f8 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u00f2 \u00f6 \u00f8 \u00d7 \u00f8 \u00f9\u00f0\u00f0 \u00f2\u00d7 \u00f1 \u00f0 \u00f3 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00d7\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u00d7 \u00f2 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00d7 \u00f6 \u00f6 \u00f0 \u00f8 \u00f8\u00f3 \u00f3\u00f9 \u00f0\u00fd \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f3\u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00d7 \u2104\u00ba \u00ec \u00f9\u00d7 \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00d7 \u00d7 \u00f2 \u00f0 \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00f3 \u00f8 \u00e5\u00ea \u00f2\u00f3 \u00d7\u00b8\u00fb \u00f6 \u00d7 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00d7 \u00f6 \u00f2 \u00f3 \u00f0\u00f8 \u00f6\u00f2 \u00f8 \u00fa \u00f3 \u00f2\u00f8 \u00d7\u00f8 \u00f8 \u00d7 \u00f3 \u00f8 \u00e5\u00ea \u00f2\u00f3 \u00d7\u00ba \u00ec \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f0 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00f4\u00f6\u00f3\u00fa \u00d7 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00f2 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8 \u00f6 \u00f1 \u00fb\u00f3\u00f6 \u00f3\u00f6 \u00f9\u00d7 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00f8\u00f3 \u00f1 \u00f2 \u00f4\u00f9\u00f0 \u00f8 \u00f8 \u00d7 \u00f4\u00f9\u00f6 \u00f2 \u00f1 \u00fc \u00e5\u00ea \u00d7\u00f8 \u00f8 \u00d7\u00b8\u00f3\u00f6 \u00f5\u00f9 \u00fa \u00f0 \u00f2\u00f8\u00f0\u00fd \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f3\u00f9 \u00f0\u00fd \u00d7\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f3\u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00d7\u00ba \u00ba\u00be \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00e5\u00f9\u00f0\u00f8 \u00b9\u00eb \u00f1\u00f4\u00f0 \u00eb\u00f8 \u00f8 \u00ec \u00f1 \u00f3 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f1\u00f3\u00f2\u00d7\u00f8\u00f6 \u00f8 \u00f2 \u00f8 \u00f0 \u00f8 \u00f8 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 h \u2261 m i=1 p i a i \u2020 m j=1 a j \u00d7 \u00f2 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00fb \u00d7 \u00f8 \u00d7 \u00f1 \u00f4\u00f6\u00f3\u00f4 \u00f6\u00f8 \u00d7 \u00d7 \u00f2 \u00f8 \u2104\u00ba \u00e1\u00f2 \u00eb \u00f8 \u00f3\u00f2 \u00ba\u00bd \u00f8 \u00f4\u00f4\u00f0 \u00f8 \u00f3\u00f2 \u00f3 h \u00f8\u00f3 \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u03c8(i 1 , i 2 , \u2022 \u2022 \u2022 , i n ) \u00f3\u00f2\u00fa \u00f6\u00f8\u00d7 \u00f8 \u00f2\u00f8\u00f3 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b5\u00ba \u00ec \u00f1 \u00f2\u00f3\u00fb \u00d7 \u00f8\u00f3 \u00f6 \u00fa \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f0 \u00b9\u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8\u00f0\u00fd \u00f1 \u00f4\u00d7 \u00f8\u00f3 \u00f8\u00d7 \u00f0 \u00f9\u00f2 \u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 h\u00ba \u00ec \u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f8\u00f3 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00f8 \u00f8 \u00f3\u00f2\u00f8 \u00f2\u00d7 \u00fc \u00f8\u00f0\u00fd \u00f8 \u00f6 \u00f8 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00f3 \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u00d7 \u00f8\u00f3 \u00f0 \u00f2 \u00f8 \u00f3\u00f4\u00f4 \u00f2 \u00f6 \u00f8 \u00d7 \u00f2 \u00f6 \u00f8 \u00fd h\u00ba \u00e1\u00f2 \u00f4 \u00fd\u00d7 \u00d7 \u00f8 \u00d7 \u00d7 \u00f2\u00f3\u00fb\u00f2 \u00d7 \u00f8 \u00f8 \u00f0 \u00f0 \u00f2 \u00f3\u00f2 \u00f8 \u00f3\u00f2\u00ba \u00ef \u00f2 \u00f8 \u00f6 \u00d7 \u00d7 \u00f2 \u00f0 \u00d7 \u00f1\u00f4\u00f0 \u00f4 \u00f6 \u00f2\u00f3 \u00f8 \u00d7 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00f2\u00d7 \u00f1 \u00f0 \u00f8 \u00f8 \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f0 \u00f3\u00f6 \u00f8 \u00f1 \u00d7 \u00d7 \u00f8\u00f3 \u00f2 \u00f6 \u00f8 \u00ba \u00e1\u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f2 \u00f2 \u00f6 \u00f0 \u00f8\u00f3 \u00f2 \u00f0\u00fd\u00f8 \u00f0\u00f0\u00fd \u00f6 \u00fa \u00f8 \u00d7 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u00f8 \u00fb \u00f6 \u00f8 \u00f2 \u00e5 \u00e5 \u00f0 \u00f3\u00f6 \u00f8 \u00f1\u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f2\u00f3\u00f8 \u00f2 \u00ba \u00ec \u00d7 \u00f2\u00f8\u00f6 \u00f8 \u00f0\u00b9 \u00f8\u00fd \u00f6 \u00d7 \u00d7 \u00f9\u00d7 \u00f8 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00d7 \u00f9\u00d7 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f2 \u00f3\u00f9\u00f6 \u00f2 \u00f2\u00f3 \u00d7 \u00b4 \u00ba \u00ba \u00f2\u00f3 \u00d7 \u00f2 \u00f8 \u00d7 \u00f1 \u00f0 \u00f5\u00f9 \u00b5 \u00f8\u00f3 \u00f2\u00f8 \u00f6 \u00f8 \u00fb \u00f8 \u00f3\u00f8 \u00f6\u00b8\u00fb \u00f0 \u00d7 \u00f8\u00f3 \u00f8 \u00fa \u00f0\u00b9 \u00f3\u00f4\u00f1 \u00f2\u00f8 \u00f3 \u00f2 \u00f6 \u00f8 \u00f0\u00f3\u00f2 \u00b9\u00f6 \u00f2 \u00f3\u00f6\u00f6 \u00f0 \u00f8 \u00f3\u00f2\u00d7 \u00f8\u00fb \u00f2 \u00f2\u00f3 \u00d7 \u00fd \u00d7 \u00f2 \u00f8\u00f3 \u00f8 \u00f6 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f6 \u00f8 \u00d7 \u00f3\u00f6\u00f8\u00b9\u00f6 \u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7 \u00b4 \u00ba \u00ba \u00f4 \u00f8 \u00d7 \u00f3 \u00f2 \u00f9 \u00f2 \u00f6 \u00f9 \u00f0\u00f8 \u00f3\u00f9\u00f8 \u00f3 \u00f2\u00f8 \u00f6\u00f0 \u00f2 \u00f0 \u00f5\u00f9 \u00f8\u00f3\u00f6\u00d7\u00b5\u00ba \u00ec \u00d7\u00f9\u00f1\u00f1 \u00f8 \u00f3\u00f2 \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f4 \u00f8 \u00d7 \u00fa \u00fb \u00f8 \u00f2\u00f3 \u00d7 \u00f2 \u00f2\u00f8 \u00f6 \u00f8 \u00f2 \u00f6 \u00f8\u00f0\u00fd \u00fb \u00f8 \u00f3\u00f8 \u00f6 \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00f0\u00fd\u00f8 \u00f0\u00f0\u00fd \u00f8\u00f6 \u00f8 \u00f0 \u00b8 \u00fc \u00f4\u00f8 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00d7\u00f9 \u00d7 \u00fb \u00f2 \u00f8 \u00f2\u00f3 \u00d7 \u00f2\u00f8 \u00f6 \u00f8 \u00f0\u00f3\u00f2 \u00bd\u00b9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00f2 \u00b4\u00f3\u00f6 \u00f2\u00fd \u00fd\u00f0 \u00f6 \u00f4 \u00f3 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00b5\u00ba \u00e5\u00f3\u00f6 \u00f2\u00f8 \u00f6 \u00d7\u00f8 \u00f2 \u00d7 \u00d7\u00b8\u00d7\u00f9 \u00d7 \u00be\u00b9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00d7 \u00f8\u00d7 \u00f3 \u00f2\u00f3 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2\u00d7\u00b8 \u00f6 \u00f2\u00f3\u00f8 \u00f2 \u00f0\u00fd\u00f8 \u00f0\u00f0\u00fd \u00f8\u00f6 \u00f8 \u00f0 \u00f2 \u00f2 \u00f6 \u00f0 \u00b4 \u00f0\u00f8 \u00f3\u00f9 \u00f8 \u00f6 \u00f6 \u00d7\u00f4 \u00f0 \u00d7 \u00d7 \u00f8 \u00f8 \u00f6 \u00fc \u00f4\u00f8 \u00f3\u00f2\u00d7\u00b8\u00d7\u00f9 \u00d7 \u00f8 \u00be\u00b9 \u00f1 \u00f2\u00d7 \u00f3\u00f2 \u00f0 \u00e1\u00d7 \u00f2 \u00f1\u00f3 \u00f0\u00b5\u00ba \u00e7\u00f2 \u00d7 \u00fb \u00f2 \u00d7\u00f3\u00f0\u00fa \u00f2 \u00f0\u00fd\u00f8 \u00f0\u00f0\u00fd \u00d7 \u00f8 \u00d7 \u00f3 \u00f2 \u00e5\u00ea \u00fb \u00f8 \u00d7 \u00f2 \u00f0 \u00f2\u00f3 \u00f8 \u00f8 \u00f2\u00f8 \u00f6 \u00f8\u00d7 \u00fb \u00f8 \u00fc \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00ba \u00e1\u00f2 \u00f8\u00b8\u00f8 \u00d7 \u00d7 \u00f2 n \u00b9\u00f2\u00f3 \u00e5\u00ea \u00f2 \u00fb n \u2212 1 \u00f3 \u00f8 \u00f2\u00f3 \u00d7 \u00f6 \u00f6\u00f3\u00fe \u00f2\u00b8 \u00f2 \u00f8 \u00f6 \u00f2 \u00f9 \u00f2 \u00f3\u00f2 \u00f8 \u00d7 \u00f2 \u00f0 \u00f6 \u00f1 \u00f2 \u00f2 \u00b4\u00f9\u00f2 \u00f6\u00f3\u00fe \u00f2\u00b5 \u00f2\u00f3 \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00fd \u00f8 \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00ba \u00ec \u00d7 \u00d7 \u00d7 \u00f2\u00f8 \u00f6 \u00d7\u00f8 \u00f2 \u00f9\u00d7 \u00f8 \u00d7 \u00f8 \u00f1\u00f3 \u00f0 \u00f8 \u00f8 \u00d7 \u00f9\u00d7 \u00f2 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7\u00f8 \u00fa \u00f6\u00d7 \u00f3\u00f2 \u00b4 \u00ba \u00ba \u00d7 \u00f2 \u00f0 \u00bf\u00bf \u00f3 \u00f2 \u00f0 \u00fd \u00f6\u00b5 \u00f3 \u00f2 \u00f8 \u2104 \u00f8 \u00d7 \u00f8 \u00f6 \u00f3\u00f6 \u00f4\u00f6\u00f9 \u00f2\u00f8 \u00f8\u00f3 \u00f9\u00d7 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f1 \u00f8 \u00f3 \u00d7 \u00fa \u00f0\u00f3\u00f4 \u00f2 \u00f8 \u00d7 \u00f4 \u00f4 \u00f6 \u00f8\u00f3 \u00fa \u00f6 \u00fd \u00f8 \u00f8 \u00f8 \u00e5 \u00e5 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f8 \u00fa \u00f3\u00f9\u00f6 \u00f8 \u00f8 \u00d7 \u00f3 \u00d7 \u00f6\u00fa \u00f2 \u00f2 \u00f8\u00ba \u00ec \u00d7\u00f8 \u00f8 \u00d7\u00f4 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0\u00fd \u00f3\u00f9\u00f4 \u00bd\u00b9\u00f2\u00f3 \u00e5\u00ea \u00d7 \u00f2 n\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b9 \u00f8\u00f3 \u00f6 \u00f1\u00ba \u00ec \u00f1 \u00f2\u00f3\u00fb \u00d7 \u00f8\u00f3 \u00f6 \u00fa \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00f3 \u00f2 n\u00b9\u00d7 \u00f1\u00f4\u00f0 \u00d7\u00b9 \u00f8\u00f3 \u00f6 \u00f1 \u00f9\u00f2 \u00f6 \u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f6 \u00f4 \u00f8 \u00e5 \u00e5 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00d7 \u00f2 \u00f6 \u00f8 \u00fd h = m i=1 p i a i \u2020 m j=1 a j \u00b4\u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf\u00b5\u00b8\u00fb \u00f6 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 p i \u00f6 \u00f6 \u00fa \u00f6\u00f3\u00f1 \u00fc \u00fc\u00f8 \u00f6\u00f2 \u00f0 \u00d7\u00f3\u00f9\u00f6 \u00ba \u00ec \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u03c8 \u00f1\u00f9\u00d7\u00f8 \u00d7 \u00f8 \u00d7 \u00fd \u00f8 \u00d7 \u00f0 \u00b9\u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00f8 \u00f3\u00f9\u00f2 \u00d7\u00f8 \u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \uf8eb \uf8ed m j=1 p j a j \u2020 \uf8f6 \uf8f8 m i=1 a i \u03c8 = \u03bb\u03c8 \u00b4 \u00bc\u00b5 \u00fb \u00f6 \u03bb \u00d7 \u00f2 \u00f2\u00fa \u00f0\u00f9 \u00ba \u00e1\u00f2 \u00f3\u00f8 \u00f6 \u00fb\u00f3\u00f6 \u00d7 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 \u00f1\u00f9\u00d7\u00f8 \u00f1 \u00f4 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00f2\u00f8\u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f3 \u00f8\u00d7 \u00f0 \u00b8 \u00d7 \u00d7 \u00fc\u00f4 \u00f8 \u00f3 \u00f2 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u00ba \u00f9\u00d7 \u00f3\u00f6\u00f6 \u00f8 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f3 \u00f8 \u00d7\u00f8 \u00f8 \u00f2 \u00f3 \u00f8 \u00e5 \u00e5 \u00f9\u00f4 \u00f8 \u00f3\u00f4\u00b9 \u00f6 \u00f8\u00f3\u00f6 \u00fa \u00f2\u00f3\u00f8 \u00f2 \u00f1\u00f4\u00f3\u00d7 \u00b4\u00f8\u00f3 \u00fa\u00f3 \u00f0\u00f3\u00f8\u00d7 \u00f3 \u00d7\u00f8\u00f6 \u00f8 \u00f2 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f8 \u00f3\u00f2 \u00f8\u00f3\u00f6\u00d7 \u00f4\u00f4 \u00f6 \u00f2 \u00f2 \u00f8 \u00f1 \u00f8 \u00f1 \u00f8 \u00d7\u00b5\u00b8\u00f8 \u00f2\u00fa \u00f0\u00f9 \u00d7 \u00f2\u00f3\u00f8 \u00f8 \u00fc\u00f4 \u00f8 \u03bb = 1\u00b8 \u00f9\u00f8 \u00f2 \u00fa \u00f6\u00f8 \u00f0 \u00d7\u00d7 \u00f8 \u00fa \u00f0\u00f9 \u00f3 \u03bb \u00f1 \u00fd \u00f6 \u00f0\u00fd \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00b4\u00d7 \u00f8 \u00f6 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b5\u00ba \u00ec \u00f1 \u00fc \u00d7\u00f8 \u00f8 \u03c8 \u00f2 \u00fc\u00f4 \u00f2 \u00d7 \u00fb \u00f8 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00f3 \u00f4\u00f9\u00f6 \u00d7\u00f8 \u00f8 \u00d7 \u00f8 \u00f9\u00d7 \u03c8 = n1,n2,\u2022\u2022\u2022 ,nm \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) m k=1 a k \u2020 n k |0 \u00b4 \u00bd\u00b5 \u00fb \u00f6 (a k \u2020 ) n k |0 \u00d7 \u00b4\u00f9\u00f4 \u00f8\u00f3 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f2 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8\u00b5 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 n k \u00d7 \u00f1\u00b9 \u00f4\u00f0 \u00d7 \u00f2 \u00f2 k\u00b8 m k=1 (a k \u2020 ) n k |0 \u00d7 \u00b4\u00f9\u00f4 \u00f8\u00f3 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f2 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8\u00b5 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00fb \u00f8 \u00f3\u00f9\u00f4 \u00f2\u00fd (n 1 , n 2 , \u2022 \u2022 \u2022 , n m )\u00b8\u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00b4\u00f9\u00f4 \u00f8\u00f3 \u00f2\u00f3\u00f6\u00f1 \u00f0 \u00d7 \u00f2 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8\u00b5 \u00f3 \u00f8 \u00d7 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00b8 \u00f2 n1,n2,\u2022\u2022\u2022 ,nm (\u2022 \u2022 \u2022 ) \u00d7 \u00f1 \u00fc\u00f8\u00f9\u00f6 \u00f3 \u00d7\u00f9 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00d7\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f2\u00f3\u00f8 \u00f2 \u00d7\u00d7 \u00f6\u00fd \u00f8\u00f3 \u00f2\u00f8\u00f6\u00f3 \u00f9 \u00f8 \u00f2\u00f3\u00f6\u00b9 \u00f1 \u00f0 \u00d7 \u00f2 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8\u00d7 \u00fc\u00f4\u00f0 \u00f8\u00f0\u00fd \u00f9\u00d7 \u00f0\u00f0 \u00fb \u00f6 \u00f8\u00f6\u00fd \u00f2 \u00f8\u00f3 \u00f3 \u00d7 \u00f8\u00f3 \u00f1\u00f3\u00f2\u00d7\u00f8\u00f6 \u00f8 \u00f8 \u00f8 \u03c8 \u00d7 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bc\u00ba \u00f6\u00d7\u00f8 \u00f3 \u00f0\u00f0\u00b8 \u00f3\u00f6 \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8\u00f3 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2 \u00ba \u00e1\u00f2 \u00f4 \u00fd\u00d7 \u00d7\u00f8\u00d7\u00b3 \u00f8 \u00f6\u00f1 \u00f2\u00f3\u00f0\u00f3 \u00fd\u00b8\u00f8 \u00d7 \u00fb \u00f8 \u00fc \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00d7 \u00f2\u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f1 \u00f0 \u00f6 \u00f8 \u00f6 \u00f8 \u00f2 \u00f6 \u00f2 \u00f2\u00f3\u00f2 \u00f0 \u00f2\u00d7 \u00f1 \u00f0 \u00f2 \u00fb \u00f8 \u00f8\u00f3\u00f8 \u00f0 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00fb\u00f3\u00f9\u00f0 \u00f0\u00f0\u00f3\u00fb \u00f8\u00f3 \u00fa \u00f6\u00fd\u00ba \u00ec \u00f9\u00d7 \u00fb\u00f6 \u00f8 \u03c8 \u00d7 \u03c8 = n1,n2,\u2022\u2022\u2022 ,nm \u03b4 n,n1+n2+\u2022\u2022\u2022+nm \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) m k=1 a k \u2020 n k |0 \u00b4 \u00be\u00b5 \u00fb \u00f6 \u00f8 \u00e3\u00f6\u00f3\u00f2 \u00f6 \u00f0\u00f8 \u03b4 n,n1+n2+\u2022\u2022\u2022+nm \u00f2\u00d7\u00f9\u00f6 \u00d7 \u00f8 \u00f8 \u00f3\u00f2\u00f0\u00fd \u00f8 \u00f6\u00f1\u00d7 \u00f2 n1,n2,\u2022\u2022\u2022 ,nm (\u2022 \u2022 \u2022 ) \u00f8 \u00f8 \u00d7 \u00f8 \u00d7 \u00fd \u00f8 \u00f3\u00f2 \u00f8 \u00f3\u00f2 n = n 1 + n 2 + \u2022 \u2022 \u2022 + n m \u00f2 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00ba ae\u00f3\u00fb \u00f2 \u00f8 \u00d7\u00f8 \u00f8 \u03c8 \u00f8 \u00f8 \u00d7 \u00f8 \u00d7 \u00d7 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00fd \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bc\u00ba \u00bf \u00f6\u00d7\u00f8 \u00d7\u00f9 \u00d7\u00f8 \u00f8\u00f9\u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00be \u00f2\u00f8\u00f3 \u00f8 \u00f0 \u00f8 \u00f2 \u00d7 \u00f3 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bc \u00f8\u00f3 \u00f3 \u00f8 \u00f2 n1,n2,\u2022\u2022\u2022 ,nm \u03b4 n,n1+n2+\u2022\u2022\u2022+nm \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \uf8eb \uf8ed m j=1 p j a j \u2020 \uf8f6 \uf8f8 m i=1 a i m k=1 a k \u2020 n k |0 \u00b4 \u00bf\u00b5 ae\u00f3\u00fb \u00f9\u00d7 \u00f8 \u00f8 a i (a j \u2020 ) n |0 = n\u03b4 i,j (a j \u2020 ) n\u22121 |0 \u00f8\u00f3 \u00f1\u00f3\u00fa \u00f0\u00f0 \u00f3 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6\u00d7 \u00f8\u00f3 \u00f8 \u00f6 \u00f8 \u00f2 \u00f8 ( m j=1 p j a j \u2020 )( m i=1 a i ) m k=1 (a k \u2020 ) n k |0 \u00f4 \u00f6\u00f8 \u00f3 \u00f8 \u00fc\u00f4\u00f6 \u00d7\u00d7 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bf \u00f8\u00f3 \u00f3 \u00f8 \u00f2 \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f8 \u00f3\u00f2 (\u2022 \u2022 \u2022 ) |0 = m j=1 p j a j \u2020 m i=1 n i a 1 \u2020 n1 \u2022 \u2022 \u2022 a i \u2020 ni\u22121 \u2022 \u2022 \u2022 a m \u2020 nm |0 = m j=1 p j \uf8eb \uf8ec \uf8ed n j a 1 \u2020 n1 \u2022 \u2022 \u2022 a m \u2020 nm |0 + m i = 1, i = j n i a 1 \u2020 n1 \u2022 \u2022 \u2022 a i \u2020 ni\u22121 \u2022 \u2022 \u2022 a j \u2020 nj +1 \u2022 \u2022 \u2022 a m \u2020 nm |0 \uf8f6 \uf8f7 \uf8f8 \u00b4 \u00b5 \u00fb \u00f6 \u00f8 \u00d7 \u00d7 i = j \u00b4 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00fb \u00f8 \u00f2 \u00d7 \u00f2 \u00f0 \u00f2\u00b5 \u00f2 i = j \u00b4 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f2 \u00f3\u00f2 \u00f2 \u00f2 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f2\u00f3\u00f8 \u00f6 \u00f2\u00b8 \u00ba \u00ba \u00f3\u00f4\u00f4 \u00f2 \u00b5 \u00fa \u00f8\u00f3 \u00f3\u00f2\u00d7 \u00f6 \u00d7 \u00f4 \u00f6 \u00f8 \u00f0\u00fd\u00ba \u00ec \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00fa \u00f2 \u00f2 \u00f0 \u00d7\u00f8 \u00f8 j \u00b4 \u00f9\u00f8 \u00d7\u00f9\u00f1\u00f1 \u00f2 \u00f3\u00fa \u00f6 \u00f8 \u00f2 \u00f8 \u00f0 \u00d7\u00f8 \u00f8 i\u00b5 \u00f2 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f6 \u00f1\u00f1 \u00f8 \u00f0\u00f0\u00fd \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7 p j n j \uf8eb \uf8ec \uf8ed i (= j) ai \u2212\u2192 \u2022 aj \u2020 \u2212\u2192 j \u21d1 source \uf8f6 \uf8f7 \uf8f8 + p j m i = 1, i = j n i \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed i ( = j) ai \u0581 \u2022 aj \u2020 \u2212\u2192 j \u21d1 source \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 \u00fb \u00d7 \u00d7\u00f9\u00f1 \u00f3 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2\u00d7 \u00f3 \u00f8 \u00f3\u00f6\u00f1 p j n i \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed i ai \u0581 \u2022 aj \u2020 \u2212\u2192 j \u21d1 source \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 \u00fb \u00f6 \u00f8 \u00f3\u00fa \u00f6 \u00f0\u00f0 \u00f8\u00f3\u00f6 \u00f3 n i \u00f3\u00f1 \u00d7 \u00f6\u00f3\u00f1 \u00f8 \u00f8 \u00f8 \u00f8 \u00f8 \u00f2\u00f2 \u00f0 \u00f8 \u00f3\u00f2 \u00f3\u00f4 \u00f6 \u00f8\u00f3\u00f6 a i \u00d7 n i \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8\u00f3 \u00f3\u00f3\u00d7 \u00f6\u00f3\u00f1 \u00f2 \u00f8 \u00f2 \u00f8 \u00f0 \u00d7\u00f8 \u00f8 \u00ba \u00ec \u00f3 \u00f2\u00f8\u00d7 \u00f3 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f2 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2\u00d7 \u00f8\u00f3 \u00f8 \u00f0 \u00f8 \u00f2 \u00d7 \u00f2 \u00f6 \u00f8 \u00f2 \u00d7 \u00f3 \u00f8 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00f3\u00f2 \u00f8 \u00f3\u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bc \u00f2 \u00f2\u00f3\u00fb \u00f1 \u00f8 \u00f9\u00f4\u00ba ae\u00f3\u00f8 \u00f8 \u00f8 \u00f8 \u00d7 \u00f1 \u00f8 \u00f2 \u00f3 \u00f3 \u00f2\u00f8\u00d7 \u00d7 \u00f0\u00f0\u00f3\u00fb \u00f9\u00d7 \u00f8 \u00d7 \u00f8 \u00f3 \u00d7\u00f8 \u00f8 \u00d7 m k=1 (a k \u2020 ) n k |0 \u00d7 \u00f3\u00f6\u00f8 \u00f3 \u00f3\u00f2 \u00f0 \u00f2 \u00f3\u00f1\u00f4\u00f0 \u00f8 \u00b4\u00d7 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00ba\u00be\u00ba \u00b5\u00ba \u00ec \u00d7 \u00f0 \u00d7 \u00f8\u00f3 \u00bf \u00f8 \u00f3\u00f0\u00f0\u00f3\u00fb \u00f2 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00fd \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f8 \u00f8 \u00f2\u00f8 \u00f6\u00f6 \u00f0 \u00f8 \u00d7 \u00f8 \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m )\u00ba m j=1 p j \uf8eb \uf8ec \uf8ed n j \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) + m i = 1, i = j (n i + 1) \u03c8(n 1 , \u2022 \u2022 \u2022 , n i + 1, \u2022 \u2022 \u2022 , n j \u2212 1, \u2022 \u2022 \u2022 , n m ) \uf8f6 \uf8f7 \uf8f8 = \u03bb\u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u00b4 \u00b5 ae\u00f3\u00fb \u00f2 \u00f8\u00f6 \u00f0 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f8 \u00d7 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b4\u00fb \u00f6 n = n 1 + n 2 + \u2022 \u2022 \u2022 + n m \u00b5 \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) = n! n 1 !n 2 ! \u2022 \u2022 \u2022 n m ! p 1 n1 p 2 n2 \u2022 \u2022 \u2022 p m nm \u00b4 \u00b5 \u00ec \u00d7 \u00f8\u00f6 \u00f0 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00d7 \u00f8\u00f3 \u00f4\u00f0 \u00f2 n \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f6 \u00f2 \u00f3\u00f1 \u00f2\u00f8\u00f3 \u00f8 \u00d7\u00b9 \u00f8\u00f3 \u00f6 \u00f1\u00b8\u00f9\u00d7 \u00f2 \u00d7 \u00f1\u00f4\u00f0 \u00f2 \u00f4\u00f6\u00f3 \u00f0 \u00f8 \u00d7 (p 1 , p 2 , \u2022 \u2022 \u2022 , p m ) \u00f3\u00f6 \u00f3 \u00f8 m \u00f2\u00d7\u00ba \u00ec \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6 p 1 n1 p 2 n2 \u2022 \u2022 \u2022 p m nm \u00d7 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f3 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00fb \u00fd \u00f3 \u00f4\u00f0 \u00f2 n \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00b4\u00f8 \u00f2 \u00f3\u00f9\u00f2\u00f8 \u00f3 \u00f8 \u00f3\u00f6 \u00f6 \u00f2 \u00fb \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f6 \u00f4\u00f0 \u00b5\u00b8 \u00f2 \u00f8 \u00f1\u00f9\u00f0\u00f8 \u00f2\u00f3\u00f1 \u00f0 \u00f8\u00f3\u00f6 n! n1!n2!\u2022\u2022\u2022nm! \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4\u00f3\u00d7\u00d7 \u00f0 \u00f3\u00f6 \u00f6\u00b9 \u00f2 \u00d7 \u00f3 \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f8 \u00f8 \u00f0 \u00fa \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f9\u00f2 \u00f2 \u00b4 \u00ba \u00ba \u00f4 \u00f6\u00f1\u00f9\u00f8 \u00fb \u00f8 \u00f2 \u00f2\u00d7 \u00f9\u00f8 \u00f2\u00f3\u00f8 \u00f8\u00fb \u00f2 \u00f2\u00d7\u00b5\u00ba \u00e1\u00f8 \u00d7 \u00f6 \u00d7\u00f3\u00f2 \u00f0 \u00f8\u00f3 \u00fc\u00f4 \u00f8 \u00f8 \u00d7 \u00f8\u00f3 \u00f8 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f9\u00d7 \u00f8 \u00f8 \u00f3 h \u00b4 \u00ba \u00ba m i=1 p i a i \u2020 m j=1 a j \u00b5 \u00d7 \u00f8\u00f3 \u00f6 \u00f2 \u00f3\u00f1\u00f0\u00fd \u00f2\u00f2 \u00f0 \u00f8 \u00d7 \u00f1\u00f4\u00f0 \u00f6\u00f3\u00f1 \u00f8 \u00d7\u00f8\u00f3 \u00f6 \u00f1\u00b8 \u00f2 \u00f8 \u00f2 \u00f8\u00f3 \u00f6 \u00f8 \u00f8 \u00f2 \u00fb \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd p i \u00f2 \u00f2 i \u00b4\u00fb \u00d7 \u00f1 \u00f1\u00f3\u00f6\u00fd\u00f0 \u00d7\u00d7 \u00f3\u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00b5\u00b8\u00d7\u00f3 \u00f8 \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u00fa \u00f2 \u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00f3\u00f9\u00f0 \u00f2 \u00f5\u00f9 \u00f0 \u00f6 \u00f9\u00f1 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f9\u00f4 \u00f8 \u00d7 \u00f2 \u00f6 \u00f8 \u00fd h\u00ba \u00eb\u00f9 \u00d7\u00f8 \u00f8\u00f9\u00f8 \u00f8 \u00d7 \u00f8\u00f6 \u00f0 \u00d7\u00f3\u00f0\u00f9\u00f8 \u00f3\u00f2 \u00f2\u00f8\u00f3 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00fd \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00f8\u00f3 \u00f3 \u00f8 \u00f2 m j=1 p j \uf8eb \uf8ec \uf8ed n j n! n1!\u2022\u2022\u2022nm! p 1 n1 \u2022 \u2022 \u2022 p m nm + m i = 1, i = j (n i + 1) n! n1!\u2022\u2022\u2022(ni+1)!\u2022\u2022\u2022(nj \u22121)!\u2022\u2022\u2022nm! p 1 n1 \u2022 \u2022 \u2022 p i ni+1 \u2022 \u2022 \u2022 p j nj \u22121 \u2022 \u2022 \u2022 p m nm \uf8f6 \uf8f7 \uf8f8 = \u03bb n! n 1 ! \u2022 \u2022 \u2022 n m ! p 1 n1 \u2022 \u2022 \u2022 p m nm \u00b4 \u00b5 \u00f2 \u00f0 \u00f8 \u00f8\u00f3\u00f6 \u00f0\u00d7 \u00f2 \u00f8 \u00f4\u00f6\u00f3 \u00f0 \u00f8\u00fd \u00f8\u00f3\u00f6\u00d7\u00ba m j=1 p j \uf8eb \uf8ec \uf8ec \uf8ec \uf8ec \uf8ec \uf8ed n j + m i = 1, i = j n j p i p j \uf8f6 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f7 \uf8f8 = \u03bb \u00b4  \u00e5\u00ea m j=1 a j \u00f2 \u00f6 \u00f8 \u00d7 m j=1 n j = n \u00d7 \u00f4 \u00f6 \u00f8 \u00f3\u00f2\u00f8\u00f6 \u00f9\u00f8 \u00f3\u00f2\u00d7\u00ba \u00ec \u00f8 \u00f8 \u00f8 \u03bb \u00d7 \u00f3\u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f1 \u00f2\u00d7 \u00f8 \u00f8 \u00f8 \u00f3\u00f2\u00d7 \u00d7\u00f8 \u00f2\u00fd \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b4 \u00ba \u00ba \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00b5 \u00d7 \u00f2 \u00f2\u00fa \u00f0\u00f9 \u03bb \u00f8 \u00f8 \u00d7 \u00f2 \u00f4 \u00f2 \u00f2\u00f8 \u00f3 \u00f8 \u00f3 \u00f3 (n 1 , n 2 , \u2022 \u2022 \u2022 , n m )\u00b8\u00fb \u00f1 \u00f9\u00f1 \u00d7\u00f8 \u00f8 \u03c8 \u00b4 \u00d7 \u00d7 \u00f6 \u00f5\u00f9 \u00f6 \u00f2 \u00f3\u00f6 \u00f6 \u00f3\u00f6 \u03c8 \u00f8\u00f3 \u00d7 \u00f8 \u00d7 \u00fd \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00bc\u00b5\u00ba n1,n2,\u2022\u2022\u2022 ,nm \u03b4 n,n1+n2+\u2022\u2022\u2022+nm \u03c8(n 1 , n 2 , \u2022 \u2022 \u2022 , n m ) \u00f1 \u00f2\u00f8 \u00f3 n \u00d7 \u00f1\u00f4\u00f0 \u00d7 \u00f2\u00f8\u00f3 \u00d7 \u00f8 \u00f3 \u00d7\u00f8\u00f3 \u00f6 \u00f1 \u00f2\u00d7\u00ba \u00f0\u00d7\u00f3\u00b8\u00f0 \u00f6 \u00f6 \u00eb\u00e7ae\u00d7 \u00f2 \u00f9 \u00f0\u00f8 \u00f3\u00f9\u00f8 \u00f3 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f0 \u00f2 \u00f2 \u00f8 \u00f1\u00f3 \u00f9\u00f0 \u00d7\u00b8 \u00f2 \u00f8 \u00d7 \u00f3\u00f6\u00f6 \u00d7\u00f4\u00f3\u00f2 \u00f8\u00f3 \u00bf \u00b5\u00ba \u00e8\u00f6\u00f3 \u00f0 \u00f8\u00fd\u00b8 \u00f6 \u00f5\u00f9 \u00f2\u00fd \u00f2 \u00f6 \u00d7\u00f3\u00f2 \u00f0 \u00fc\u00f4 \u00f8 \u00f8 \u00f3\u00f2\u00ba \u00f1\u00ba \u00e2\u00ba \u00e8 \u00fd\u00d7\u00ba\u00b8\u00bd \u00b4\u00bd\u00b5\u00b8\u00bd \u00bd\u00bf\u00ba \u00be\u2104 \u00eb\u00f1\u00fd\u00f8 \u00b8\u00e8\u00ba \u00b4\u00bd \u00b5\u00ba \u00f0 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00d7\u00b8 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00f1\u00f3 \u00f0\u00d7\u00b8 \u00f2 \u00e5 \u00f6 \u00f3\u00fa \u00f6 \u00f2 \u00f3\u00f1 \u00f0 \u00d7 \u00f9\u00f2 \u00fd \u00f2 \u00fa \u00fb\u00ba \u00e8 \u00f8\u00f8 \u00f6\u00f2 \u00ea \u00f3 \u00f2\u00ba \u00e4 \u00f8\u00f8\u00ba\u00b8\u00bd \u00b4\u00bd\u00bd\u00b9\u00bd\u00bf\u00b5\u00b8\u00bd\u00be \u00f2\u00d7 \u00f3\u00f2 \u00f2 \u00f8\u00fb\u00f3\u00f6 \u00ba ae \u00f8\u00fb\u00f3\u00f6 \u00b9 \u00f3\u00f1\u00f4\u00ba ae \u00f9\u00f6 \u00f0\u00b8 \u00b4\u00be\u00b5\u00b8\u00be \u00be \u00bc\u00ba \u2104 \u00d7 \u00b8\u00e2\u00ba \u00b4\u00bd \u00b5\u00ba \u00eb\u00f4 \u00f8 \u00f0 \u00f2\u00f8 \u00f6 \u00f8 \u00f3\u00f2 \u00f2 \u00f8 \u00d7\u00f8 \u00f8 \u00d7\u00f8 \u00f0 \u00f2 \u00f0\u00fd\u00d7 \u00d7 \u00f3 \u00f0 \u00f8\u00f8 \u00d7\u00fd\u00d7\u00f8 \u00f1\u00d7\u00ba \u00e2\u00ba \u00ea\u00f3\u00fd\u00ba \u00eb\u00f8 \u00f8\u00ba \u00eb\u00f3\u00ba \u00b8\u00bf \u00b4\u00be\u00b5\u00b8\u00bd \u00be \u00be\u00bf \u00ba \u00f9\u00f8 \u00f3\u00f2 \u00f0 \u00f4\u00f3\u00f4\u00f9\u00f0 \u00f8 \u00f3\u00f2 \u00f3 \u00d7 \u00d7 \u00f1\u00f9\u00f0\u00f8 \u00f2 \u00f3\u00f9\u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00f8 \u00f3\u00f2 \u00f3 \u00f9\u00f2 \u00f6\u00f8 \u00f2\u00f8\u00fd \u00f2 \u00f1\u00f9\u00f0\u00f8 \u00f4\u00f0 \u00f8\u00fd\u00ba ae \u00f9\u00f6 \u00f0 \u00f3\u00f1\u00b9 \u00f4\u00f9\u00f8\u00ba\u00b8\u00bd \u00b4\u00bd\u00bc\u00b5\u00b8\u00be\u00be \u00be\u00be \u00ba",
        "prob": 0.6787341772151899
    }, {
        "ID": 5953,
        "phrase": " proof: since the ideal ml decoder decodes y to 0, we have y + e = 0 or e = y",
        "prob": 0.21000000000000002
    }, {
        "ID": 6100,
        "phrase": " from now on we will work in ml + , unless otherwise specified",
        "prob": 0.34444444444444444
    }, {
        "ID": 6101,
        "phrase": " from now on we will work in ml + , unless otherwise specified",
        "prob": 0.3444444444444444
    }, {
        "ID": 6102,
        "phrase": " from now on we will work in ml + , unless otherwise specified",
        "prob": 0.34444444444444444
    }, {
        "ID": 6103,
        "phrase": " from now on we will work in ml + , unless otherwise specified",
        "prob": 0.3444444444444444
    }, {
        "ID": 6122,
        "phrase": "5 is such that each finite fragment of \u03c3, \u03d5 f = s ij\u22121 \u03c4 * \u2192 s ij \u22121 ai j \u2192 s ij is a prefix of a computation of a refinement based part such as, either \u2022 \u03c3 \u2032 = s ij\u22121 \u03c4 * \u2192 s ij \u22121 ai j \u2192 s ij c * \u2192 s c \u03c4 * \u2192 s ij \u22121 ai j \u2192 s ij c * \u2192 s c ",
        "prob": 0.45499999999999996
    }, {
        "ID": 6177,
        "phrase": " matrices; ai denotes the i-th element of a; ai, aij denote the ith column, respectively ij-th element of a; h, t, \u2022, \u2022 denote (complex conjugated) transposition and inner product, log denotes base-2 logarithm, unless otherwise specified",
        "prob": 0.2793103448275862
    }, {
        "ID": 6190,
        "phrase": " for this setup, when studying the ml decoder in (1) or (2), we can without loss of generality assume that the zero codeword was sent, because all decision regions are congruent",
        "prob": 0.44999999999999996
    }, {
        "ID": 6274,
        "phrase": " there exists homogeneous relations fulfilling ai but not aj for all i and j excepted the two implications of proposition 6",
        "prob": 0.23846153846153847
    }, {
        "ID": 6308,
        "phrase": ") let event \u03c8 (a i ) be defined as \u03c8 (a i ) : \u03c8 i \u03b8 \u2212 \u03b8 i \u2265 \u2206 (\u03c4 b i ) 2 , ( 42 ) where \u03c8 i \u03b8 denotes the ith ordered component of the ml estimate of \u03b8, where the components are ordered in non-decreasing order",
        "prob": 0.33888888888888885
    }, {
        "ID": 6603,
        "phrase": " more common words than others (for example consider two topics, basketball and machine learning)",
        "prob": 0.2928571428571428
    }, {
        "ID": 6862,
        "phrase": " hence there is no loss of generality to consider only joint distributions of the form p(t i , x ai , x 1ai )p(x bi , x 1bi ) for (t i , x ai , x 1ai , x bi , x 1bi )",
        "prob": 0.3153846153846154
    }, {
        "ID": 6892,
        "phrase": " , x as for the boolean combination of linear (in)equalities \u03c6 = \u03c6 1 \u2227 \u00ac\u03c6 2 , where \u2022 \u03c6 1 states that w \u2032 \u2261 \u03c6 w, that is, \u03c6 1 = \u2113 i=1 (x ai > k) \u2227 s j=\u2113+1 x aj = # aj (w) ; and  \u2022 \u03c6 2 states that z 0 q 1 (w \u2032 )z 1 \u2022 \u2022 \u2022 q n (w \u2032 )z n |= d out (b), that is, \u03c6 2 is (k c j \u00d7 x aj ) + k c \u2265 i, respectively",
        "prob": 0.43571428571428567
    }, {
        "ID": 7362,
        "phrase": " ,\u223cb m = w bm ) = i|=ai w ai + i|=\u223cbj w bj \u00b4 \u00b5 \u00f1\u00f4\u00f0 \u00d7 i |= h\u00ba \u00ba \u00f3\u00f1\u00f4\u00f9\u00f8 \u00d7\u00f8 \u00f8 \u00f1 \u00f2\u00f8 s \u00f3 \u00f8 \u00f3\u00f6\u00f1 \u00b4 \u00b5 \u00d7 \u00d7 \u00f8 \u00d7 \u00f2 i \u00b4 \u00f2\u00f3\u00f8 i |= s\u00b5 \u21d0\u21d2 i |= {a 1 , ",
        "prob": 0.2625
    }, {
        "ID": 7362,
        "phrase": " , \u223cb m = w bm } \u2264 u, \u00b4\u00bd\u00bc\u00b5 \u00fb \u00f6 a i \u00b3\u00d7 \u00f2 b j \u00b3\u00d7 \u00f6 \u00f8\u00f3\u00f1\u00d7\u00b8 \u00f2 l\u00b8u\u00b8w ai \u00b3\u00d7\u00b8 \u00f2 w bj \u00b3\u00d7 \u00f6 \u00f2 \u00f8\u00f9\u00f6 \u00f0 \u00f2\u00f9\u00f1 \u00f6\u00d7\u00ba 8 \u00eb \u00f2 \u00f0\u00f4 \u00f6\u00d7 \u00d7 \u00f6 \u00d7\u00f4\u00f3\u00f2\u00d7 \u00f0 \u00f3\u00f6 \u00f2\u00d7\u00f8 \u00f2\u00f8 \u00f8 \u00f2 \u00fa \u00f6 \u00f0 \u00d7 \u00f2 \u00f4\u00f6 \u00b9 \u00f2\u00f8 \u00f6\u00f4\u00f6 \u00f8 \u00f2 \u00f6\u00f8 \u00f2 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u00d7\u00fd\u00f1 \u00f3\u00f0\u00d7 \u00f8 \u00f2\u00f4\u00f9\u00f8 \u00f0 \u00f2 \u00f9 \u00d7 \u00f8\u00f9 \u00f0\u00f0\u00fd \u00f1\u00f9 \u00f1\u00f3\u00f6 \u00f2 \u00f6 \u00f0\u00ba \u00be \u00ec\u00ba \u00e2 \u00f2 \u00f9\u00f2 \u00f2 \u00f2 \u00ba \u00e7 \u00f6 \u00f2 \u00f2 \u00d7 \u00f3\u00f6 \u00b8\u00fb \u00f9\u00d7 \u00d7 \u00f3\u00f6\u00f8 \u00f2 l \u2264 {a = w a , \u223cb = w b } \u2264 u \u00f3\u00f6 \u00fb \u00f8 \u00f3\u00f2\u00d7\u00f8\u00f6 \u00f2\u00f8 \u00b4\u00bd\u00bc\u00b5 \u00fb \u00f6 a = {a 1 , ",
        "prob": 0.4428571428571429
    }, {
        "ID": 7408,
        "phrase": " the join rewrite relation induced by r is usually defined as \u2192 a = i\u22650 \u2192 ai  [21]  where \u2192 a0 = \u2205 and for all i \u2265 0, \u2192 ai+1 is the smallest rewrite relation such that for all rule d = c \u2283 l \u2192 r \u2208 r, for all substitution \u03c3, if d\u03c3 \u2193 ai c\u03c3 then l\u03c3 \u2192 ai+1 r\u03c3",
        "prob": 0.6733333333333333
    }, {
        "ID": 7408,
        "phrase": " for any rule d = c \u2283 l \u2192 r \u2208 r and substitution \u03c3, if u \u2701 \u03b2 l\u03c3 \u2192 ai r\u03c3, then there exists \u03c3 \u2032 such that u = l\u03c3 \u2032 \u2192 ai r\u03c3 \u2032 \u2701 \u03b2 r\u03c3",
        "prob": 0.3
    }, {
        "ID": 7408,
        "phrase": " first, we show by induction on the definition of the parallel rewrite relation \u2704 \u03b2 that if u \u2701 \u03b2 s \u2192 ai t then there exists v such that u \u2192 * ai v \u2701 \u03b2 t",
        "prob": 0.3416666666666666
    }, {
        "ID": 7408,
        "phrase": " for all i \u2265 0, let \u2704 ai be the smallest parallel rewrite relation closed by: (rule) d = c \u2283 l \u2192 r \u2208 r l\u03c3 \u2192 ai r\u03c3 \u03c3 \u2704 ai \u03b8 l\u03c3 \u2704 ai r\u03b8 recall that l\u03c3 \u2192 ai r\u03c3 is ensured by d\u03c3 \u2193 ai\u22121 c\u03c3",
        "prob": 0.46923076923076923
    }, {
        "ID": 7408,
        "phrase": " the definition of \u2704 bi follows the same scheme as the one of \u2704 ai ; the only difference is that b i is used everywhere in place of a i ",
        "prob": 0.4636363636363636
    }, {
        "ID": 7408,
        "phrase": " since \u2192 ai is a rewrite relation, we have l\u03c3{x \u2192 s} \u2704 ai r\u03c3{x \u2192 s}",
        "prob": 0.5666666666666667
    }, {
        "ID": 7408,
        "phrase": " therefore l\u03c3{x \u2192 s} \u2704 ai r\u03b8{x \u2192 t}",
        "prob": 0.4428571428571429
    }, {
        "ID": 7409,
        "phrase": " the join rewrite relation induced by r is usually defined as \u2192 a = i\u22650 \u2192 ai  [21]  where \u2192 a0 = \u2205 and for all i \u2265 0, \u2192 ai+1 is the smallest rewrite relation such that for all rule d = c \u2283 l \u2192 r \u2208 r, for all substitution \u03c3, if d\u03c3 \u2193 ai c\u03c3 then l\u03c3 \u2192 ai+1 r\u03c3",
        "prob": 0.74
    }, {
        "ID": 7409,
        "phrase": " for any rule d = c \u2283 l \u2192 r \u2208 r and substitution \u03c3, if u \u2701 \u03b2 l\u03c3 \u2192 ai r\u03c3, then there exists \u03c3 \u2032 such that u = l\u03c3 \u2032 \u2192 ai r\u03c3 \u2032 \u2701 \u03b2 r\u03c3",
        "prob": 0.4428571428571429
    }, {
        "ID": 7409,
        "phrase": " first, we show by induction on the definition of the parallel rewrite relation \u2704 \u03b2 that if u \u2701 \u03b2 s \u2192 ai t then there exists v such that u \u2192 * ai v \u2701 \u03b2 t",
        "prob": 0.3416666666666666
    }, {
        "ID": 7409,
        "phrase": " for all i \u2265 0, let \u2704 ai be the smallest parallel rewrite relation closed by: (rule) d = c \u2283 l \u2192 r \u2208 r l\u03c3 \u2192 ai r\u03c3 \u03c3 \u2704 ai \u03b8 l\u03c3 \u2704 ai r\u03b8 recall that l\u03c3 \u2192 ai r\u03c3 is ensured by d\u03c3 \u2193 ai\u22121 c\u03c3",
        "prob": 0.46923076923076923
    }, {
        "ID": 7409,
        "phrase": " the definition of \u2704 bi follows the same scheme as the one of \u2704 ai ; the only difference is that b i is used everywhere in place of a i ",
        "prob": 0.3727272727272727
    }, {
        "ID": 7409,
        "phrase": " since \u2192 ai is a rewrite relation, we have l\u03c3{x \u2192 s} \u2704 ai r\u03c3{x \u2192 s}",
        "prob": 0.5666666666666667
    }, {
        "ID": 7409,
        "phrase": " therefore l\u03c3{x \u2192 s} \u2704 ai r\u03b8{x \u2192 t}",
        "prob": 0.3
    }, {
        "ID": 7519,
        "phrase": " let \u03b8 i be the angle between t ai and the x-axis",
        "prob": 0.3
    }, {
        "ID": 7526,
        "phrase": " 2 \n ml ) is equal to the function q l\u2212m defined in (22) for the orthonormal polynomials on [\u22121, 1] for the weight w defined byw(x) = (1 \u2212 x) m (1 + x) m ",
        "prob": 0.36428571428571427
    }, {
        "ID": 7900,
        "phrase": " therefore, the total number of searches for selecting the desired set is equal to m m=1 (l \u2212 m + 1) = ml \u2212 m (m \u22121) \n 2 , which is linear in l",
        "prob": 0.22142857142857145
    }, {
        "ID": 8172,
        "phrase": " \n 14 \n development of cbr systems the main ai questions for cbr assistance systems might also be organised at the two levels distinguished by  newell (1982)  (see  trousse & visser, 1993) ",
        "prob": 0.24285714285714283
    }, {
        "ID": 8433,
        "phrase": " each a i chooses secret key * q ai z x \u2208 and computes public key p x y ai ai = ",
        "prob": 0.51
    }, {
        "ID": 8433,
        "phrase": " each of the original signcrypters computes ) ( 2 w ai ai m h x s = and broadcasts it all the proxy signcrypter",
        "prob": 0.61
    }, {
        "ID": 8433,
        "phrase": " each ai computes ) ( 1 w id ai m h s s ai = and broadcasts ai s to the each proxy signcrypter",
        "prob": 0.5666666666666667
    }, {
        "ID": 8433,
        "phrase": " 23 the proxy signcrypter group verifies the correctness of each ai s by the equation if each ai s is verified, then each proxy signcrypter p j computes \n w m , s, c, r p , u p ) to the b unsigncrypter c as multi-proxy multi-signcryption of m",
        "prob": 0.3736842105263158
    }, {
        "ID": 8555,
        "phrase": "y n , is therefore \u00b5 ai (y 1 x 1 ",
        "prob": 0.22000000000000003
    }, {
        "ID": 8765,
        "phrase": " also the i-th row of these matrices are equal, and therefore according to the definition of the inner product, these rows are orthogonal to each other, and thus, w g and w g * ai are locally equivalent",
        "prob": 0.22777777777777775
    }, {
        "ID": 8856,
        "phrase": " assume a ai \u2282 g a aj holds",
        "prob": 0.4428571428571429
    }, {
        "ID": 8856,
        "phrase": " since a ai \u2282 g a aj and a bi \u2282 g a bj holds, it follows that a ai was generated from a sub graph of g aj and a bi from a sub graph of g bj ",
        "prob": 0.65
    }, {
        "ID": 8906,
        "phrase": " comments on the proof of theorem 1 in here is an outline of the original proof of theorem 1 in  [1] : (a) \"since the transmitted bit associated with variable node v i has uniform a priori probability, an ml estimator is equal to a maximum a posterior estimation,which is known to yield the minimum probability of error of all estimators based on the same observation\"; (b) the maximum a posterior estimator based on the received observation r by sending a randomly chosen codeword through the channel w is superior to the maximum a posterior estimator based on the received observation r \u2032 by sending r through an auxiliary channel q; (c) \"the claim now follows by observing that for a belief-propagation decoder decoder, the sign of the message sent along edge e in the \u2113th decoding iteration is equal to the estimate of an ml estimator based on the observation in n 2\u2113 e [2]\" however, two of these claims are inherently flawed",
        "prob": 0.29753086419753083
    }, {
        "ID": 8906,
        "phrase": " (a) with a local tree-like neighborhood,we do not necessarily have uniform prior probability for the transmitted bit v i and the sign of the message sent along edge e of belief-propagation decoder is not necessarily equal to maximum a posterior estimator even if we assume that \"the sign of the message sent along edge e in the \u2113th decoding iteration is equal to the estimate of an ml estimator based on the observation in n 2\u2113 e  [2] \"",
        "prob": 0.3511627906976744
    }, {
        "ID": 9131,
        "phrase": " we define a subset \u03c6 m of z 2 0 as \u03c6 m := {(i, j) \u2208 z 2 0 | i < q \u2212 1, j < a, ai + bj \u2264 m}, where ai + bj is equal to the pole order o(x i y j ) of x i y j at p \u221e ",
        "prob": 0.6749999999999999
    }, {
        "ID": 9131,
        "phrase": " the condition {c(\u03b1 i , \u03b1 j ) = 0} in (1) is equivalent to the ordinary linear system (c h ) 0\u2264h<n [z h (q l )] 0\u2264h<n, 0\u2264l<n\u2212k = 0, (2) where q l := (\u03b1 i , \u03b1 j ) for (i, j) \u2208 \u03c6 m with order l \u2264 l \u2032 \u21d4 ai + bj \u2264 ai \u2032 + bj \u2032 ",
        "prob": 0.5399999999999999
    }, {
        "ID": 9132,
        "phrase": " we define a subset \u03c6 m of z 2 0 as \u03c6 m := {(i, j) \u2208 z 2 0 | i < q \u2212 1, j < a, ai + bj \u2264 m}, where ai + bj is equal to the pole order o(x i y j ) of x i y j at p \u221e ",
        "prob": 0.6749999999999999
    }, {
        "ID": 9132,
        "phrase": " elementary encoding: the condition {c(\u03b1 i , \u03b1 j ) = 0} in (1) is equivalent to the ordinary linear system (c h ) 0\u2264h<n [z h (q l )] 0\u2264h<n, 0\u2264l<n\u2212k = 0, (2) where q l := (\u03b1 i , \u03b1 j ) for (i, j) \u2208 \u03c6 m with order l \u2264 l \u2032 \u21d4 ai+ bj \u2264 ai \u2032 + bj \u2032 ",
        "prob": 0.5941176470588235
    }, {
        "ID": 9228,
        "phrase": " let us bind some ml identifiers to terms for use in later terminal sessions",
        "prob": 0.22142857142857145
    }, {
        "ID": 9250,
        "phrase": " elements of e will be written hn 1 ; n 2 ; ai where n 1 and n 2 are nodes and a is an attribute name",
        "prob": 0.23333333333333334
    }, {
        "ID": 9250,
        "phrase": " for all hn 1 ; n 2 ; ai 2 e we have h (n 1 ); (n 2 )i 2 a i , (which is equivalent to (n 2 ) = a i ( (n 1 )), since a i is a function)",
        "prob": 0.2625
    }, {
        "ID": 9250,
        "phrase": " to merge two a-edges hn; n 1 ; ai and hn; n 2 ; ai, replace them with a single new edge hn; n 0 ; ai, where n 0 results from merging n 1 and n 2 , i",
        "prob": 0.56875
    }, {
        "ID": 9250,
        "phrase": " proof: let the two edges be hn; n 1 ; ai and hn; n 2 ; ai and the new node n 0 be n 1 n 2 ",
        "prob": 0.5916666666666667
    }, {
        "ID": 9250,
        "phrase": " modify the resulting world so that for each hn 1 ; n 2 ; ai 2 e the a-ller for the distinguished node of the graphical world from n 1 is the distinguished node of the graphical world from n 2 ",
        "prob": 0.3588235294117647
    }, {
        "ID": 9250,
        "phrase": " the converse is satis ed by the requirement in de nition 3 thatfor each a-edge hn 1 ; n 2 ; ai 2 e, we have (n 2 ) = a i ( (n 1 ))",
        "prob": 0.2818181818181818
    }, {
        "ID": 9380,
        "phrase": " for example, the join predicate ai \u2229 bj = \u2205 may be changed to t (ai) \u2229 t (bj) = \u2205 where t is a transformation and ai and bj are members of two spatial sets",
        "prob": 0.6529411764705882
    }, {
        "ID": 9381,
        "phrase": " for example, the join predicate ai \u2229 bj = \u2205 may be changed to t (ai) \u2229 t (bj) = \u2205 where t is a transformation and ai and bj are members of two spatial sets",
        "prob": 0.5941176470588235
    }, {
        "ID": 9448,
        "phrase": " ti m e -c ons t r ai ne d appl i c at i ons s uch as voi c e and r e al -t i me t r a c u s e t h e s y nchr onous mode",
        "prob": 0.23333333333333334
    }, {
        "ID": 9449,
        "phrase": " t h u s,w e n eed at l east two n oi se event sc h angi ng t w o d at a sym bo l s t o a t rp ai r and creat e a f al se endi n g d e l i m i t e r ",
        "prob": 0.24117647058823527
    }, {
        "ID": 9572,
        "phrase": " consider the edge {v ai , v bi }",
        "prob": 0.35000000000000003
    }, {
        "ID": 9572,
        "phrase": " since v ci is connected via a z i -path to v ai , but z i does not occur in var(v bi ), it holds that v ci is contained in t a ",
        "prob": 0.425
    }, {
        "ID": 9572,
        "phrase": " since var(v ai ) \u2229 bigvars = \u2205, \u03c0 does not traverse v ai ",
        "prob": 0.3875
    }, {
        "ID": 9572,
        "phrase": " therefore by the connectedness condition it holds that var(v ci ) \u2229 var(v cj ) \u2286 var(v ai )",
        "prob": 0.5083333333333333
    }, {
        "ID": 9572,
        "phrase": " moreover, by fact 6, no variable from var(v ai ) \u2212 s is contained in both var(v ci ) and var(v cj )",
        "prob": 0.425
    }]
}, {
    "topic_id": 26,
    "top_words": ["planning", "problem", "model", "whether", "process", "question", "used", "domain", "approach", "system", "address", "strategy", "since", "long", "kind"],
    "phrases": [{
        "ID": 8,
        "phrase": " this is the traditional machine learning problem",
        "prob": 0.26249999999999996
    }, {
        "ID": 73,
        "phrase": " but although the utility of abduction for formulating such problems in ai is well proven there has been little work (see though  (menzies 1996) ) to address the question of whether these abductive formulations can form the basis for computationally effective solutions to realistic problems",
        "prob": 0.325
    }, {
        "ID": 74,
        "phrase": " but although the utility of abduction for formulating such problems in ai is well proven there has been little work (see though  (menzies 1996) ) to address the question of whether these abductive formulations can form the basis for computationally effective solutions to realistic problems",
        "prob": 0.4321428571428571
    }, {
        "ID": 141,
        "phrase": " we are not sure whether the choice of m k is of marginal importance, as long as m k is chosen sufficiently large and of low complexity, m k = 2 2 16 for instance, or whether the choice of m k will turn out to be a central topic for the ai\u03be model or for the planning aspect of any ai system in general",
        "prob": 0.8115384615384614
    }, {
        "ID": 141,
        "phrase": " if \u00b5 ai is the true prior probability, the question now is, what is the behaviour \u1e8fai k of the ai\u00b5 system",
        "prob": 0.21000000000000002
    }, {
        "ID": 141,
        "phrase": " eventually \u03be ai will converge to the minimax strategy \u00b5 ai ",
        "prob": 0.5125000000000001
    }, {
        "ID": 252,
        "phrase": " acronyms are generally three or more characters in length, although two-character acronyms exist (for example ai for artificial intelligence)",
        "prob": 0.4764705882352941
    }, {
        "ID": 252,
        "phrase": " because of the small number of combinations, two-character acronyms exhibit far greater scope for ambiguity (for instance artificial intelligence versus artificial insemination)",
        "prob": 0.29047619047619044
    }, {
        "ID": 253,
        "phrase": " 5 this is different from traditional ai planning, since the output of the algorithm is not a complete plan to achieve a goal, but steps (set of actions) to reduce the distance between the agent and its goal",
        "prob": 0.24285714285714283
    }, {
        "ID": 392,
        "phrase": "introduction an important question in the study of machine learning is: \"what kinds of functions can be learned efficiently from noisy, imperfect data?\" the statistical query (sq) framework of kearns  [8]  was designed as a useful, elegant model for addressing this issue",
        "prob": 0.18214285714285716
    }, {
        "ID": 449,
        "phrase": " an example of this is a machine learning technique that is used to spider the web efficiently for a specific topic  [104; 86]  that emphasize on planning the best path that is going to be traversed next",
        "prob": 0.2904761904761905
    }, {
        "ID": 477,
        "phrase": " we are not sure whether the choice of m k is of marginal importance, as long as m k is chosen sufficiently large and of low complexity, m k = 2 2 16 for instance, or whether the choice of m k will turn out to be a central topic for the ai\u03be model or for the planning aspect of any universal ai system in general",
        "prob": 0.8555555555555555
    }, {
        "ID": 658,
        "phrase": " (53) assertion: involve(s,c, a) \u2227 demand(a) meanwhile, a microplanning task might begin with goals to convey two specific instances about the ai class, c1; its assignments, a1; and an eventuality, s1, as in (  54 )",
        "prob": 0.205
    }, {
        "ID": 661,
        "phrase": " what that study did not address, however, was the cost of the human labor and/or machine cycles involved to construct such a system, nor the relative cost of obtaining the training data for the machine learning system",
        "prob": 0.2958333333333334
    }, {
        "ID": 692,
        "phrase": " one obvious strategy would be to have each agent perform the same gradient-descent algorithm in parallel to adapt the parameters of its own local policy \u00b5 ai ",
        "prob": 0.24117647058823527
    }, {
        "ID": 725,
        "phrase": " whirl  [49]  combines techniques from information retrieval and ai to address this problem through an appropriate similarity measure",
        "prob": 0.2928571428571428
    }, {
        "ID": 1034,
        "phrase": " the advantages of the ml approach over the ke approach are evident",
        "prob": 0.34444444444444444
    }, {
        "ID": 1134,
        "phrase": " and/or trees have a long history in the ai community and we adapt them here for our purposes",
        "prob": 0.2818181818181818
    }, {
        "ID": 1220,
        "phrase": ", 1998) , this power has been used to model the ai planning problem  (brogi et al",
        "prob": 0.31
    }, {
        "ID": 1241,
        "phrase": " in the setting of combinatorial auctions, ai authors (  [20, 3] ) like to consider bidders as placing bids",
        "prob": 0.16153846153846155
    }, {
        "ID": 1251,
        "phrase": " , n \u2212 1 be elements of a nonstandard model r+ such that a = n\u22121 i=0 \u03bbiai and a ai for any i = 0, ",
        "prob": 0.5125000000000001
    }, {
        "ID": 1251,
        "phrase": " , n \u2212 1 be elements of a nonstandard model r+ such that a = n\u22121 i=0 \u03bbiai and a ai for any i = 0, ",
        "prob": 0.3875
    }, {
        "ID": 1252,
        "phrase": " , n \u2212 1 be elements of a nonstandard model r+ such that a = n\u22121 i=0 \u03bbiai and a ai for any i = 0, ",
        "prob": 0.3875
    }, {
        "ID": 1252,
        "phrase": " , n \u2212 1 be elements of a nonstandard model r+ such that a = n\u22121 i=0 \u03bbiai and a ai for any i = 0, ",
        "prob": 0.5125000000000001
    }, {
        "ID": 1291,
        "phrase": " a key motivation for the hybrid approach is the assumption that handling the complexity of ai tasks is beyond the reach of a single paradigm",
        "prob": 0.25625
    }, {
        "ID": 1342,
        "phrase": " thus, the best correct approximation of f p,p(x) with respect to an abstract domain \u03c1 \u2208 uco(\u2118(sub)) is inductively defined as follows for any \u03c6 \u2208 \u03c1(\u2118(sub)): s \u03c1 \u03b8 (\u03c6) = \u03c1(\u03b8 \u2297 \u03c6) s \u03c1 a1\u00d7a2 (\u03c6) = \u03c1(s \u03c1 a1 (\u03c6) \u2297 s \u03c1 a2 (\u03c6)) s \u03c1 n i=1 ai (\u03c6) = \u03c1( n i=1 s \u03c1 ai (\u03c6)) s \u03c1 p(x) (\u03c6) = s \u03c1 a (\u03c6) where p(x) \u2190 a \u226a p ",
        "prob": 0.2157894736842105
    }, {
        "ID": 1342,
        "phrase": " \u2022 -consider s \u03c1 n i=1 ai ",
        "prob": 0.22000000000000003
    }, {
        "ID": 1398,
        "phrase": " of course, most present day work in applied proof theory is not aimed directly at the ai problem",
        "prob": 0.22142857142857142
    }, {
        "ID": 1398,
        "phrase": " thirdly, reasoning in mathematics requires both creativity and a significant semantic understanding of the subject matter, and thus represents a significant challenge for an ai system",
        "prob": 0.2157894736842105
    }, {
        "ID": 1422,
        "phrase": " consider how a person can communicate the homepage of ai magazine to another",
        "prob": 0.41
    }, {
        "ID": 1422,
        "phrase": "com, type ai magazine, and click the 'i'm feeling lucky' button",
        "prob": 0.21000000000000002
    }, {
        "ID": 1617,
        "phrase": " here's another example which shows how the head noun nato determines question type qorganisational: nato \u2208 {nato; world organization; international organization} \u2192 {alliance; coalition; alignment; alinement} \u2192 {organization; organisation} \n \u2192 {social group} if the question classifier is switched on, then the determined question type t q will be compared against all answer candidate types t ai , and in the case of incompatibility, the respective candidates are discarded",
        "prob": 0.36590909090909096
    }, {
        "ID": 1635,
        "phrase": " \n artificial intelligence classical logic has always played a prominent role in artificial intelligence (ai), where a typical problem would be to form a plan or to solve a problem, given a complete description of the \"world\" in question",
        "prob": 0.23461538461538461
    }, {
        "ID": 1806,
        "phrase": " these experiments are relevant, as they compare the systems in the important domain of ai planning on benchmark instances which are really used to compare planning systems",
        "prob": 0.33888888888888885
    }, {
        "ID": 1881,
        "phrase": " in machine learning we are often interested in choosing a single model h ; the obvious choice is then the model that is most probable, i",
        "prob": 0.33999999999999997
    }, {
        "ID": 1882,
        "phrase": " as a central problem of classical ai research, effective algorithms have been developed to solve planning problems",
        "prob": 0.22142857142857145
    }, {
        "ID": 1923,
        "phrase": " since planning is admired as a mainstay of artificial intelligence, attempts were made to extend classical ai planning methods to handle uncertainty",
        "prob": 0.33888888888888885
    }, {
        "ID": 1923,
        "phrase": "  1  classical ai planning usually determines the goal as a subset of the state space",
        "prob": 0.25833333333333336
    }, {
        "ID": 2121,
        "phrase": "introduction and/or graphs  [chang and slagle 1971; montanari 1973, 1978 ;  levi and sirovich 1976; nilsson 1980; bagchi and mahanti 1983; pearl 1984; mahanti and bagchi 1985 ;  kumar 1991 ] are generalizations of directed graphs used in the problem-decomposition approach in artificial intelligence",
        "prob": 0.325
    }, {
        "ID": 2301,
        "phrase": "005 indicate that the observed differences in accuracy between baselines and ml schemes are statistically significant; the only exception is the selection of the 2 nd fact, where there is no significant difference between the base planner and 1-nn",
        "prob": 0.2318181818181818
    }, {
        "ID": 2333,
        "phrase": " the ai problem",
        "prob": 0.22000000000000003
    }, {
        "ID": 2333,
        "phrase": " we are not sure whether the choice of the horizon is of marginal importance, as long as it is chosen sufficiently large, or whether the choice will turn out to be a central topic for the aixi model or for the planning aspect of any universal ai system in general",
        "prob": 0.6576923076923077
    }, {
        "ID": 2333,
        "phrase": " rigorous proofs of value bounds for the ai\u03be theory are the major theoretical challenge -general ones as well as tighter bounds for special environments \u00b5 ai ",
        "prob": 0.26842105263157895
    }, {
        "ID": 2333,
        "phrase": " of special importance are suitable (and acceptable) conditions to \u00b5 ai , under which \u1e8fk and finite value bounds exist for infinite y, x and m",
        "prob": 0.2928571428571428
    }, {
        "ID": 2333,
        "phrase": " we are not sure whether the choice of m k is of marginal importance, as long as m k is chosen sufficiently large and of low complexity, m k =2 2 16 for instance, or whether the choice of m k will turn out to be a central topic for the ai\u03be model or for the planning aspect of any ai system in general",
        "prob": 0.8115384615384614
    }, {
        "ID": 2333,
        "phrase": " the major problem with this approach is that \u03be ai alt is not enumerable",
        "prob": 0.3875
    }, {
        "ID": 2333,
        "phrase": " whether \u03be ai alt \u00d7 = \u03be ai is also an open problem (cf",
        "prob": 0.2625
    }, {
        "ID": 2333,
        "phrase": " \n using the ai\u03be model for game playing when going from the specific ai\u00b5 model, where the rules of the game have been explicitly modeled into the prior probability \u00b5 ai , to the universal model ai\u03be we have to ask whether these rules can be learned from the assigned rewards r k ",
        "prob": 0.324
    }, {
        "ID": 2333,
        "phrase": " eventually \u03be ai will converge to the minimax strategy \u00b5 ai ",
        "prob": 0.5125000000000001
    }, {
        "ID": 2333,
        "phrase": "2 (notation and emphasis in ai versus control theory) ",
        "prob": 0.23333333333333334
    }, {
        "ID": 2390,
        "phrase": " awesome concludes that the actions are drawn from the equilibrium strategy if and only if the distance between the two distributions is small: max ai\u2208ai |p ai hi \u2212 p ai \u03c0 * i | < \u01eb e , where p a \u03c6 is the percentage of time that action a is played in \u03c6",
        "prob": 0.1952380952380952
    }, {
        "ID": 2669,
        "phrase": " in particular, we consider the classical travelling salesman problem from optimization theory, (a new version of) the strategic companies problem, the planning problem blocks world, from artificial intelligence",
        "prob": 0.3521739130434782
    }, {
        "ID": 2760,
        "phrase": " \n parity functions another outstanding challenge in machine learning is to determine whether there exist attribute efficient algorithms for learning parity functions",
        "prob": 0.255
    }, {
        "ID": 2850,
        "phrase": " it is generally accepted (at least in artificial intelligence) that this kind of operation is a form of 'planning' but this is no guarantee that methods for solving this kind of problem will transfer without modification to other kinds of 'planning' such as deciding what to do on holiday or planning a major construction project",
        "prob": 0.2793103448275862
    }, {
        "ID": 3208,
        "phrase": " it is the fastest algorithm at present; we can run the algorithm nearly in complete parallel; it is scalable and can adapt to the changing world efficiently; perform this algorithm twice, both complete attribute reduction and value reduction are at hand; and the result of knowledge reduction are two different kinds of classifiers; it is easy to combine with any heuristic information (but demarcation information measure is recommended); it can integrate user preference to find a local optimal attribute subset; it can also be used in feature selection and knowledge reduction and it can also be regarded as a process of selective inductive machine learning",
        "prob": 0.235
    }, {
        "ID": 3335,
        "phrase": " that is, p \u2032 ml is equivalent to the maximum likelihood estimate calculated as follows,  p \u2032 ml(n) (w i |w i\u22121 i\u2212n+1 ) = c \u2032 n (w i i\u2212n+1 ) wi c \u2032 n (w i i\u2212 \n question answering engine \n question answering as a search problem the question answering process is often seen as the sequence of the question analysis, the relevant document (or passage) retrieval, answer extraction and answer selection processes",
        "prob": 0.327027027027027
    }, {
        "ID": 3382,
        "phrase": " our approach to the els task is to treat it as a classical supervised machine learning problem",
        "prob": 0.46923076923076923
    }, {
        "ID": 3443,
        "phrase": " machine learning is then used to learn which reviewers accurately represent the views of the journal's readers and thus deserve to have their opinions carry more weight",
        "prob": 0.32105263157894737
    }, {
        "ID": 3443,
        "phrase": " machine learning is used to decide which reviewers accurately represent the views of the journal's readers and thus deserve to have their opinions carry more weight",
        "prob": 0.3736842105263158
    }, {
        "ID": 3873,
        "phrase": " the ai planner that is integrated in the planning system is referred to as \"ai planner\" or \"planning algorithm\"",
        "prob": 0.5083333333333333
    }, {
        "ID": 3873,
        "phrase": " \n world model and goals the world model and goals need to be understood by the ai planner",
        "prob": 0.7
    }, {
        "ID": 3873,
        "phrase": " so goals and world model are parsed to the correct syntax of pddl since this is the syntax understood by the ai planner used in the robot's planning system",
        "prob": 0.5842105263157894
    }, {
        "ID": 3873,
        "phrase": " \n the ai planner and the output (symbolic plan) the ai planner first parses the world model and goals before calculating a route for the robot",
        "prob": 0.5941176470588235
    }, {
        "ID": 3873,
        "phrase": " \n third party software the ai planning algorithm used in the robot is from the ff planner version 2",
        "prob": 0.2928571428571428
    }, {
        "ID": 3873,
        "phrase": " a good ai planning algorithm should be able to generate a sequence of actions so that the robot will reach its specified goals",
        "prob": 0.20666666666666667
    }, {
        "ID": 4435,
        "phrase": " in the terminology used in research on preference reasoning in ai  [boutilier et al",
        "prob": 0.21000000000000002
    }, {
        "ID": 4694,
        "phrase": " therefore, as we are able to process this kind of data together efficiently using ml algorithms, we can be sure to obtain better results than any of the three sources alone",
        "prob": 0.3857142857142857
    }, {
        "ID": 5829,
        "phrase": " \n representation the problem at hand is an abstract ai planning problem as described in the introduction",
        "prob": 0.3416666666666666
    }, {
        "ID": 5925,
        "phrase": " 2001] ) (3) stochastic requests, anticipated changes (in oil platform supply  [fowler and  first author's address and current affiliation: artificial intelligence center, sri international, menlo park, ca 94025, u",
        "prob": 0.6291666666666667
    }, {
        "ID": 5926,
        "phrase": " 2001] ) (3) stochastic requests, anticipated changes (in oil platform supply  [fowler and  first author's address and current affiliation: artificial intelligence center, sri international, menlo park, ca 94025, u",
        "prob": 0.6291666666666667
    }, {
        "ID": 5927,
        "phrase": " 2001] ) (3) stochastic requests, anticipated changes (oil platform supply  [fowler and brown 2000] , vehicle routing  [bent and hentenryck 2004] ) first author's address and current affiliation: artificial intelligence center, sri international, menlo park, ca 94025, u",
        "prob": 0.6241379310344828
    }, {
        "ID": 6624,
        "phrase": " these dominant error events will be both code and decoder dependent, consisting of low-weight codewords as well as non-codeword events if ml decoding is not used",
        "prob": 0.1952380952380952
    }, {
        "ID": 6724,
        "phrase": " when confronted with the problem, a machine learning approach (a topic that i was delving in the master's classes) emerged as the right move",
        "prob": 0.38125
    }, {
        "ID": 6785,
        "phrase": " we should address this issue with respect to the problem of creating artificial intelligence",
        "prob": 0.2818181818181818
    }, {
        "ID": 7144,
        "phrase": " this strategy can also be used with the ml estimator, but, having a greater variance, it is more likely to result in a spuriously low estimate of z t and early stops",
        "prob": 0.3
    }, {
        "ID": 7408,
        "phrase": " since l\u03c3 \u2192 ai r\u03c3, there is v such that d\u03c3 \u2192 * ai\u22121 v \u2190 * ai\u22121 c\u03c3",
        "prob": 0.22000000000000003
    }, {
        "ID": 7408,
        "phrase": " we now turn to the commutation of \u2704 ai and \u2192 h ",
        "prob": 0.18333333333333335
    }, {
        "ID": 7409,
        "phrase": " we now turn to the commutation of \u2704 ai and \u2192 h ",
        "prob": 0.18333333333333335
    }, {
        "ID": 8231,
        "phrase": " in af, the source encodes its messages into codewords with length ml each, and divides each codeword into l sub-blocks each with m symbols, where l is chosen to be sufficiently large",
        "prob": 0.22777777777777775
    }, {
        "ID": 8247,
        "phrase": " we find that to reach human levels, ai entities may need to be something more than the learning machines they are now",
        "prob": 0.22142857142857145
    }, {
        "ID": 8248,
        "phrase": " we can see that to speak and think like humans, ai entities also need the kind of self-sentience that humans have",
        "prob": 0.2733333333333333
    }, {
        "ID": 8462,
        "phrase": " however, when puncturing occurs, we need to explore whether the performance of the iterative decoder eventually converges to the ml bound",
        "prob": 0.3
    }, {
        "ID": 8555,
        "phrase": " we are not sure whether the choice of m k is of marginal importance, as long as m k is chosen sufficiently large and of low complexity, m k =2 2 16 for instance, or whether the choice of m k will turn out to be a central topic for the ai\u03be model or for the planning aspect of any ai system in general",
        "prob": 0.85
    }, {
        "ID": 8555,
        "phrase": " when going from the specific ai\u00b5 model, where the rules of the game are explicitly modeled into the prior probability \u00b5 ai , to the universal model ai\u03be, we have to ask whether these rules can be learned from the assigned rewards r k ",
        "prob": 0.3857142857142857
    }, {
        "ID": 8555,
        "phrase": " eventually \u03be ai will converge to the minimax strategy \u00b5 ai ",
        "prob": 0.5125000000000001
    }, {
        "ID": 8622,
        "phrase": " we note that that our approach is also related more to the conventional ai planning approach as opposed to the operations research approach  (boutilier, 1999) , since we do not associate rewards with any intermediate actions and since we treat students equally in terms of goal states, regardless of how long they take to graduate",
        "prob": 0.4033333333333333
    }, {
        "ID": 8623,
        "phrase": " we note that our approach is more related to conventional ai planning as opposed to the operations research approach, since we do not associate rewards with any intermediate actions and since we treat students equally in terms of goals, regardless of how long they take to graduate",
        "prob": 0.4111111111111111
    }, {
        "ID": 8638,
        "phrase": " herein, we address this question in the context of ai planning",
        "prob": 0.4555555555555555
    }, {
        "ID": 8638,
        "phrase": " \n\t\t\t note that this is a problem of present-day optimal ai planning in general, not only of our research",
        "prob": 0.425
    }, {
        "ID": 8639,
        "phrase": " herein, we address this question in the context of ai planning",
        "prob": 0.4555555555555555
    }, {
        "ID": 8639,
        "phrase": " \n\t\t\t note that this is a problem of present-day optimal ai planning in general, not only of our research",
        "prob": 0.3416666666666666
    }, {
        "ID": 8706,
        "phrase": " hence the problem of ml decoding reduces to the problem of minimizing, t r (y \u2212 s i h) h (y \u2212 s i h \u2200 1 \u2264 i \u2264 k",
        "prob": 0.2818181818181818
    }, {
        "ID": 9221,
        "phrase": " by writing more ml you extend and tailor lcf to the task at hand, perhaps producing a system as large as mulmuley's  [20] ",
        "prob": 0.25625
    }, {
        "ID": 9241,
        "phrase": " self-customizing software eliminates the need for user customization by starting with partially-specified software and applying machine learning methods to complete any remaining customization",
        "prob": 0.3227272727272727
    }, {
        "ID": 9256,
        "phrase": " ttg used machine learning techniques to acquire much of the needed domain knowledge, but still required hand-coded heuristics to turn this acquired knowledge into a fully functioning discourse analyzer",
        "prob": 0.19615384615384618
    }, {
        "ID": 9266,
        "phrase": " the model we adopt has the avor of models used in distributed ai and organization theory",
        "prob": 0.425
    }, {
        "ID": 9303,
        "phrase": "a fundamental assumption made by classical ai planners is that there is no uncertainty in the world: the planner has full knowledge of the conditions under which the plan will be executed and the outcome of every action is fully predictable",
        "prob": 0.3227272727272727
    }, {
        "ID": 9305,
        "phrase": " our work uses a control-theoretic approach to the related problem, while applying it to two basic ai contexts",
        "prob": 0.2733333333333333
    }, {
        "ID": 9332,
        "phrase": " de nition 2 (mergeability) a plan p 1 for achieving goal g 1 is mergeable with a plan p 2 for the goal g 2 with respect to a problem, hi 0 ; g 0 ; ai , if there is a plan p 0 which is correct for hi 0 ; g 0 ; ai and hhp 0 ii hhp 1 ii\\hhp 2 ii",
        "prob": 0.4809523809523809
    }, {
        "ID": 9338,
        "phrase": " usual machine learning research, however, strives for using the results from one problem instance for solving subsequent instances, which we did not attempt",
        "prob": 0.33888888888888885
    }, {
        "ID": 9342,
        "phrase": " the planners are characterized by the domain for which they are developed (\\bw\" for blocks world, \\log\" for logistics, and \\tyr\" for tyre world { all of which are benchmark domains in ai planning); the type of (state-space) re nement used (\\p\" for progression and \\r\" for regression), and the type of domain speci c control knowledge used (h1 that limits useless moves, h2 which moves blocks via table, etc",
        "prob": 0.3275
    }, {
        "ID": 9445,
        "phrase": " o t h er m anuf a c t u r e r sla t e rfo u n d w a y s t o t r a n s m i t 100 m bps o n u n s h i e l d edtw is t e dp ai r ( utp) , w h i c h i s u sedintelep h one w i r i n g, up t o 5 0 m ",
        "prob": 0.3416666666666666
    }, {
        "ID": 9504,
        "phrase": " there are several papers  [chapman 1987 , joslin and roach 1989 , bylander 1992 ] that provide in-depth discussions on the complexity of ai planning, and it is generally accepted that most non-trivial planning problems are at least np-complete",
        "prob": 0.284
    }, {
        "ID": 9504,
        "phrase": " this new approach to ai planning trades in the completeness of the planner for the speed up of the search process",
        "prob": 0.46923076923076923
    }, {
        "ID": 9504,
        "phrase": " in  [koza 1992 , spector 1994 , handley 1994 ], the authors used gp to solve several problems that are similar to the ones encountered in ai planning (e",
        "prob": 0.24117647058823527
    }, {
        "ID": 9504,
        "phrase": " even though their domain-specific solutions cannot be considered general-purpose planning systems, the experimental results showed that gp has great potential for solving large instances of traditional ai planning problems",
        "prob": 0.4269230769230769
    }, {
        "ID": 9504,
        "phrase": " based on the encouraging results obtained by both stochastic planners and gpbased problem solving techniques, we decided to formalize and fully-implement a general-purpose ai planner that relies on the genetic programming paradigm",
        "prob": 0.364
    }, {
        "ID": 9504,
        "phrase": " in terms of ai planning, the in-values represent the initial world status, while the desired-out-values can be seen as the goals to be achieved",
        "prob": 0.22777777777777775
    }, {
        "ID": 9504,
        "phrase": ", noah  [sacerdoti 1975] ), the vast majority of the ai planners define their planning actions in a declarative manner that is based on the one used by strips  [fikes and nilsson 1971] ",
        "prob": 0.4789473684210526
    }, {
        "ID": 9504,
        "phrase": " in order to find a solution for the problem at hand, sinergy uses an approach resembling the one described in  [kautz and selman 1996] : it converts an ai planning problem p 1 to a problem p 2 of a different nature, it solves p 2 based on a stochastic approach, and it converts the result to a solution for p 1 ",
        "prob": 0.4862068965517241
    }, {
        "ID": 9504,
        "phrase": " however, while kautz and selman turned the ai planning problem to an equivalent satisfiability problem, sinergy converts the ai planning problem to a gp problem (figure  1 )",
        "prob": 0.655
    }, {
        "ID": 9504,
        "phrase": " the sinergy approach to ai planning the sinergy approach to solving ai planning problems has three main advantages",
        "prob": 0.6733333333333333
    }, {
        "ID": 9504,
        "phrase": " second, the sinergy approach to ai planning facilitates problem solving in dynamic environments",
        "prob": 0.3923076923076923
    }, {
        "ID": 9504,
        "phrase": " gp-based problem solvers rarely find optimal solutions for the problems at hand, but the above mentioned advantages together with sinergy's ability to find closeto-optimal solutions for large, complex problem instances makes the gp-based approach to ai planning an alternative to be taken into account and a serious candidate for further research investigations",
        "prob": 0.4641025641025641
    }, {
        "ID": 9504,
        "phrase": " sinergy also provides a domain-independent solution to a major problem related to the different nature of ai planning and gp: planning operators are \"strongly typed\" (i",
        "prob": 0.40499999999999997
    }, {
        "ID": 9504,
        "phrase": " \n conclusions the major contribution of this paper consists of providing a domain-independent mapping of any ai planning problem into an equivalent gp problem",
        "prob": 0.5611111111111111
    }, {
        "ID": 9504,
        "phrase": " in final analysis, we can conclude that sinergy is a general-purpose ai planning system that is capable of solving large, complex problem instances",
        "prob": 0.39444444444444443
    }, {
        "ID": 9504,
        "phrase": " sinergy traditional ai planners sinergy input -initial state -initial state -set of goals -set of goals -set of operators -set of operators -additional information (search -additional information (fitness control rules, memory of plans, etc",
        "prob": 0.253125
    }, {
        "ID": 9504,
        "phrase": " gp-generated programs gp functions executed during plan simulation equivalent linear ai plans \n table 4 ",
        "prob": 0.38125
    }, {
        "ID": 9552,
        "phrase": " \n approach in general, a machine learning process consists of three elements: model, strategy (criterion), and algorithm",
        "prob": 0.63125
    }, {
        "ID": 9552,
        "phrase": " that is, when we conduct machine learning, we need consider  (1)  what kind of model we are to use to represent the problem,  (2)  what kind of strategy we should adopt to control the learning process, and  (3)  what kind of algorithm we should employ to perform the learning task",
        "prob": 0.6961538461538462
    }, {
        "ID": 9553,
        "phrase": " \n approach in general, a machine learning process consists of three elements: model, strategy (criterion), and algorithm",
        "prob": 0.50625
    }, {
        "ID": 9553,
        "phrase": " that is, when we conduct machine learning, we need consider  (1)  what kind of model we are to use to represent the problem,  (2)  what kind of strategy we should adopt to control the learning process, and  (3)  what kind of algorithm we should employ to perform the learning task",
        "prob": 0.6576923076923077
    }, {
        "ID": 9554,
        "phrase": " \n approach in general, a machine learning process consists of three elements: model, strategy (criterion), and algorithm",
        "prob": 0.63125
    }, {
        "ID": 9554,
        "phrase": " that is, when we conduct machine learning, we need consider  (1)  what kind of model we are to use to represent the problem,  (2)  what kind of strategy we should adopt to control the learning process, and  (3)  what kind of algorithm we should employ to perform the learning task",
        "prob": 0.5807692307692307
    }, {
        "ID": 9679,
        "phrase": " the main vehicles that carry the present solutions are machine learning and probability theory",
        "prob": 0.3153846153846154
    }, {
        "ID": 9680,
        "phrase": " the main vehicles that carry the present solutions are machine learning and probability theory",
        "prob": 0.23846153846153847
    }, {
        "ID": 9779,
        "phrase": " to facilitate the analysis we modified arthur's original problem to be more general, and since we were not interested in directly comparing our results to those in the literature, we used a more conventional (and arguably \"dumber\") machine learning algorithm than the ones investigated in  [4, 47, 50, 64] ",
        "prob": 0.38846153846153847
    }, {
        "ID": 9799,
        "phrase": " we can conceptually think of ps as consisting of a choice of j \u2208 s, a plan p r s for accessing aj, and, if |s| > 1, a plan p l s for computing bj = \u22b2\u22b3i\u2208s j ai and a plan p \u22b2\u22b3 s for computing bj \u22b2\u22b3 aj",
        "prob": 0.26842105263157895
    }, {
        "ID": 9874,
        "phrase": " however, the intended reading requires bracketing 11c: 11b) (natural (((language question) answering) systems)) 11c) ((natural language) ((question answering) systems)) however, a suitable preference rule operating on the level of word categories would have to prefer the bracketing ((adj-n)-((n-gerund)-n)) over any other, which would give the wrong prediction for 15) specific preference rules preferring sentences since, in this case, the intended reading requires the bracketing 15a) (((specific (preference rules)) preferring) sentence) the reason why 11b is the intended reading turns out to be much simpler: the sequences of lexical items ''natural language'' and ''question answering systems'', respectively, almost always belong together, at least in the context of artificial intelligence, i",
        "prob": 0.2813333333333334
    }]
}, {
    "topic_id": 27,
    "top_words": ["ml", "st", "function", "value", "first", "list", "values", "terms", "type", "threshold", "variable", "standard", "curve", "term", "line"],
    "phrases": [{
        "ID": 424,
        "phrase": " moreover, since the value of ml 2 required for ac2(a) is the same as its current value (i",
        "prob": 0.3416666666666666
    }, {
        "ID": 612,
        "phrase": " summarising, if a time slice represents a qubit line swap no commands are sent to the quantum device; instead, for each address pair (ai, bi), where ai is the i-th element of t \u2113 (0) (r) and bi is the i-th element of t \u2113 (1) (r) , the elements pa i and p b i are transposed in the list p",
        "prob": 0.644
    }, {
        "ID": 613,
        "phrase": " summarising, if a time slice represents a qubit line swap no commands are sent to the quantum device; instead, for each address pair (ai, bi), where ai is the i-th element of t \u2113 (0) (r) and bi is the i-th element of t \u2113 (1) (r) , the elements pa i and p b i are transposed in the list p",
        "prob": 0.644
    }, {
        "ID": 615,
        "phrase": " we felt that the reason for this low accuracy in estimating the \"generic\" category is that the frequency of \"generic\" terms is low and machine learning is biased toward \"definite\" terms, which have higher frequency than \"generic\" terms",
        "prob": 0.40399999999999997
    }, {
        "ID": 615,
        "phrase": " in each of the rules in the list, (i) the condition parts, (ii) values assigned by hand, and (iii) values assigned by machine learning 2 are included",
        "prob": 0.41764705882352937
    }, {
        "ID": 777,
        "phrase": " we can write t as t |u [t ai (a, i) , b], where t ai is boolean; similarly we can write z as z |u [a, z ib (i, b)]",
        "prob": 0.23333333333333334
    }, {
        "ID": 1028,
        "phrase": "   [srinivasan, 2001]  from the oxford university machine learning laboratory",
        "prob": 0.21000000000000002
    }, {
        "ID": 1028,
        "phrase": "5 g sodium borohydride was dissolved in 450 ml phosphate buffered saline to which 133 ml of 100% ethanol was added immediately prior to use",
        "prob": 0.41764705882352937
    }, {
        "ID": 1060,
        "phrase": " notice that linus could have arrived at the phrase 'sir, i was wondering if' himself (without the above example), but that would have required a lot of imagination (computation, for an ai system  [56] ) on his part",
        "prob": 0.205
    }, {
        "ID": 1464,
        "phrase": " the recursive splitting with the mdl cost function is clearly superior to the sequential splitting with ml cost, which in turn is superior to linguistica",
        "prob": 0.22777777777777775
    }, {
        "ID": 1464,
        "phrase": " the sequential ml method comes second and linguistica third with a share of 43% correctly segmented words",
        "prob": 0.20666666666666667
    }, {
        "ID": 1464,
        "phrase": " mdl), sequential segmentation and ml cost (seq",
        "prob": 0.41
    }, {
        "ID": 1475,
        "phrase": " \n process given an instance of a: 1) for each element a i in a in indexed order: for each variable in p ai and pair of variables in p ai determine respective constraints: a",
        "prob": 0.75625
    }, {
        "ID": 1476,
        "phrase": " \n process given an instance of a: 1) for each element a i in a in indexed order: for each variable in p ai and pair of variables in p ai determine respective constraints: a",
        "prob": 0.69375
    }, {
        "ID": 1477,
        "phrase": " \n process given an instance of a: 1) for each element a i in a in indexed order: for each variable in p ai and pair of variables in p ai determine respective constraints: a",
        "prob": 0.69375
    }, {
        "ID": 1512,
        "phrase": " \n kernel distance sigmoidal functions in artificial neural network and machine learning, each node has a transfer function which consists of an activation function (a summation of inputs) and an output function",
        "prob": 0.3521739130434782
    }, {
        "ID": 1704,
        "phrase": " the diagram emphasizes that the value of f b is determined by the values of ml 1 and ml 2 (which in turn are determined by the value of the exogenous variable u",
        "prob": 0.69375
    }, {
        "ID": 1705,
        "phrase": " the diagram emphasizes that the value of f b is determined by the values of ml 1 and ml 2 (which in turn are determined by the value of the exogenous variable u",
        "prob": 0.69375
    }, {
        "ID": 1706,
        "phrase": " the diagram emphasizes that the value of f b is determined by the values of ml 1 and ml 2 (which in turn are determined by the value of the exogenous variable u",
        "prob": 0.75625
    }, {
        "ID": 1826,
        "phrase": "m] remove the element ai from the domain of zi",
        "prob": 0.3
    }, {
        "ID": 1907,
        "phrase": " here, the spoiler chooses an element ai in a r and the duplicator answers with a bi in b r ",
        "prob": 0.23333333333333334
    }, {
        "ID": 2053,
        "phrase": " this is followed by the content hash stage of round i, which computes the hash h(si ai content \u2212 block i ), where denotes bit string concatenation, h is our cryptographic hash function, and content \u2212 block i denotes the portion of the content that we hash during round i (to be determined in section a",
        "prob": 0.6033333333333333
    }, {
        "ID": 2053,
        "phrase": " specifically, it computes the hash of its appropriate local content blocks: h \u2032 i = h(si ai content \u2212 block i )",
        "prob": 0.36428571428571427
    }, {
        "ID": 2197,
        "phrase": " , a n ) of a joint instance is given by p 0 (c|\u03c0 c ) n i=1 p 0 (a i |\u03c0 ai ), where the values of the parent variables are those consistent with (c, a 1 , ",
        "prob": 0.2818181818181818
    }, {
        "ID": 2197,
        "phrase": " , m, are not constants in general but functions of some attribute variables, as the minimisation does not always involve all the attributes of which the argument of \u00b5 ai is function",
        "prob": 0.34
    }, {
        "ID": 2333,
        "phrase": "3 convergence of \u03be ai to \u00b5 ai ",
        "prob": 0.22000000000000003
    }, {
        "ID": 2742,
        "phrase": " \n situation calculus the situation calculus  (mccarthy 1963 ) is well-known in ai research",
        "prob": 0.3416666666666666
    }, {
        "ID": 2941,
        "phrase": " in the same line of reasoning, contrasting conflicting hypotheses is a common situation in many ml algorithms",
        "prob": 0.2928571428571428
    }, {
        "ID": 2942,
        "phrase": " in the same line of reasoning, contrasting conflicting hypotheses is a common situation in many ml algorithms",
        "prob": 0.36428571428571427
    }, {
        "ID": 2996,
        "phrase": "m] remove the element ai from the domain of zi",
        "prob": 0.3
    }, {
        "ID": 2997,
        "phrase": "m] remove the element ai from the domain of zi",
        "prob": 0.3
    }, {
        "ID": 2998,
        "phrase": "m] remove the element ai from the domain of zi",
        "prob": 0.3
    }, {
        "ID": 3031,
        "phrase": " finally, to support the creation of bound variables, represented using indices in the de bruijn scheme, the following instructions in which n is a positive number, are included in our abstract machine: put index ai,n unify index n the first instruction writes a bound variable with index n on the heap and makes the register ai a reference to this location",
        "prob": 0.41944444444444445
    }, {
        "ID": 3298,
        "phrase": " hence, we can create for every attribute name a i thus used a variable x ai with type single(atom)",
        "prob": 0.3923076923076923
    }, {
        "ID": 3298,
        "phrase": " hence, we can create for every attribute name a i thus used a variable x ai with type single(atom)",
        "prob": 0.3923076923076923
    }, {
        "ID": 3329,
        "phrase": " our preconditioner k is the laplacian of a graph with ml edges, where m is the number of elements and l is the number of nodes in the reference element (refer to lemma 6",
        "prob": 0.3
    }, {
        "ID": 3549,
        "phrase": " an m-ary constraint is of the form r(xi 1 , \u2022 \u2022 \u2022 , xi m ), and asserts that the values ai 1 , ",
        "prob": 0.3727272727272727
    }, {
        "ID": 3549,
        "phrase": " , ai m assigned to the variables xi 1 , ",
        "prob": 0.3
    }, {
        "ID": 3601,
        "phrase": " its main characteristics (for a regular ensemble with left degree at least 3) are as follows: the function is zero below the ml threshold \u01ebml",
        "prob": 0.3
    }, {
        "ID": 3601,
        "phrase": " first, the it and the ml curve coincide above \u01ebml",
        "prob": 0.4555555555555555
    }, {
        "ID": 3601,
        "phrase": " second, the ml curve can be constructed from the iterative curve in the following way",
        "prob": 0.425
    }, {
        "ID": 3601,
        "phrase": " to determine the ml threshold take a straight vertical line at \u01eb = \u01ebit and shift it to the right until the area which lies to the left of this straight line and is enclosed by the line and the iterative curve is equal to the area which lies to the right of the line and is enclosed by the line and the iterative curve (these areas are indicated in dark gray in the picture)",
        "prob": 0.7742857142857144
    }, {
        "ID": 3601,
        "phrase": " the ml exit curve is now the curve which is zero to the left of the threshold and equals the iterative curve to the right of this threshold",
        "prob": 0.69375
    }, {
        "ID": 3601,
        "phrase": " other words, the ml threshold is determined by a balance between two areas  3  ",
        "prob": 0.5545454545454546
    }, {
        "ID": 3601,
        "phrase": " 0 1 1 \u01eb it \u01eb ml exit(\u01eb) 0 1 1 \u01eb it \u01eb ml exit(\u01eb) figure  1 : left: the exit curve of the ml decoder for the degree distribution pair (\u03bb(x) = x 2 , \u03c1(x) = x 5 )",
        "prob": 0.5941176470588235
    }, {
        "ID": 3601,
        "phrase": " the curve is zero until \u01eb ml at which point it jumps",
        "prob": 0.34444444444444444
    }, {
        "ID": 3601,
        "phrase": " the ml threshold is determined by the balance of the two dark gray areas",
        "prob": 0.5916666666666667
    }, {
        "ID": 3601,
        "phrase": " inspired by the statistical mechanics analogy, we shall explain the balance condition determining the ml threshold by analyzing an algorithm which moves from the non zeroentropy branch to the zero-entropy branch of the exit curve",
        "prob": 0.604
    }, {
        "ID": 3601,
        "phrase": " 1 1 \u01eb it \u01eb ml exit(\u01eb) 0 1 1 \u01eb it \u01eb ml exit(\u01eb) in fig",
        "prob": 0.4555555555555555
    }, {
        "ID": 3601,
        "phrase": "  2  and to explain why these areas should be in balance at the ml threshold",
        "prob": 0.5666666666666667
    }, {
        "ID": 3601,
        "phrase": " \n\t\t\t the ml threshold was first determine by the replica method in [6] ",
        "prob": 0.51
    }, {
        "ID": 3602,
        "phrase": " we show that an area theorem holds for such a function, implying, among other things, an upper bound on the ml threshold",
        "prob": 0.25625
    }, {
        "ID": 3602,
        "phrase": " first, the it and the ml curve coincide above \u01ebml",
        "prob": 0.5666666666666667
    }, {
        "ID": 3602,
        "phrase": " second, the ml curve can be constructed from the iterative curve in the following way",
        "prob": 0.3416666666666666
    }, {
        "ID": 3602,
        "phrase": " to determine the ml threshold take a straight vertical line at \u01eb = \u01ebit and shift it to the right until the area which lies to the left of this straight line and is enclosed by the line and the iterative curve is equal to the area which lies to the right of the line and is enclosed by the line and the iterative curve (these areas are indicated in dark gray in the picture)",
        "prob": 0.7742857142857141
    }, {
        "ID": 3602,
        "phrase": " the ml exit curve is  2  the exit function is the function 1 n n i=1 h(x i |y [n]\\{i} ), see [2]",
        "prob": 0.425
    }, {
        "ID": 3602,
        "phrase": " in other words, the ml threshold is determined by a balance between two areas  3  ",
        "prob": 0.4636363636363636
    }, {
        "ID": 3602,
        "phrase": " 0 1 1 \u01eb it \u01eb ml exit(\u01eb) 0 1 1 \u01eb it \u01eb ml exit(\u01eb) figure  1 : left: the exit curve of the ml decoder for the degree distribution pair (\u03bb(x) = x 2 , \u03c1(x) = x 5 )",
        "prob": 0.5352941176470588
    }, {
        "ID": 3602,
        "phrase": " the curve is zero until \u01eb ml at which point it jumps",
        "prob": 0.4555555555555555
    }, {
        "ID": 3602,
        "phrase": " the ml threshold is determined by the balance of the two dark gray areas",
        "prob": 0.5083333333333333
    }, {
        "ID": 3602,
        "phrase": " inspired by the statistical mechanics analogy, we shall explain the balance condition determining the ml threshold by analyzing an algorithm which moves from the non zeroentropy branch to the zero-entropy branch of the exit curve",
        "prob": 0.6839999999999999
    }, {
        "ID": 3602,
        "phrase": "  2  and to explain why these areas should be in balance at the ml threshold",
        "prob": 0.5666666666666667
    }, {
        "ID": 3602,
        "phrase": " \n\t\t\t the ml threshold was first determine by the replica method in [6] ",
        "prob": 0.51
    }, {
        "ID": 3896,
        "phrase": " 2 reduced variable setc, e, f, l, w, x, y, ab, ae, af, ag, ai process",
        "prob": 0.2818181818181818
    }, {
        "ID": 4020,
        "phrase": " , x j and \u03bc(x j i ) to indicate which outcomes determine the ml estimator, finally we abbreviate s n = x 1 +",
        "prob": 0.3727272727272727
    }, {
        "ID": 4026,
        "phrase": " here, we shall show (at type bool) how the control operator call-cc of scheme or standard ml is interpreted as a sequential algorithm of type ((bool \u2192 b) \u2192 bool) \u2192 bool",
        "prob": 0.41363636363636364
    }, {
        "ID": 4311,
        "phrase": " the lists rl, wl and ml (lines 9, 10) store transaction operations in order to detect conflicts with other transactions",
        "prob": 0.69375
    }, {
        "ID": 4312,
        "phrase": " the lists rl, wl and ml \u2022 25 (lines 9, 10) store transaction operations in order to detect conflicts with other transactions",
        "prob": 0.56875
    }, {
        "ID": 4698,
        "phrase": " this bound coincides with the ml threshold determined by montanari et al",
        "prob": 0.51
    }, {
        "ID": 4727,
        "phrase": " this bound coincides with the ml threshold determined by montanari et al",
        "prob": 0.61
    }, {
        "ID": 4727,
        "phrase": " this bound coincides with the ml threshold determined by montanari et al",
        "prob": 0.61
    }, {
        "ID": 4868,
        "phrase": " we will use an informal \"internal language\" to denote uniform maps which when formalised would amount to an extension of lfpl with indexed type dependency in the style of dependent ml  [15] ",
        "prob": 0.18636363636363634
    }, {
        "ID": 4900,
        "phrase": " in other words, \u2206(s , s ai ) \u2265 2, i = 1, 2",
        "prob": 0.22000000000000003
    }, {
        "ID": 4900,
        "phrase": " finally, in case 5c, s has three children in t t , s ai , i = 1, 2, 3, and \u00b5(s ai ) \u2264 \u00b5(s ) \u2212 3, i = 1, 2, 3",
        "prob": 0.2625
    }, {
        "ID": 5076,
        "phrase": " , l m , q (nm) ml = b m(l\u22121) \u2212b ml , where b m0 (\u03c4 ) := n m for all \u03c4 \u2265 0",
        "prob": 0.2625
    }, {
        "ID": 5177,
        "phrase": "  w(i) j=1 k\u22122 l=0 2 mc j,l +i j = w(i) j=1 2 i j k\u22122 l=0 2 mc j,l \u2264 w(i) j=1 2 i j k\u22121 l=1 2 ml \u2264 (2 m \u2212 1) \u2022 2 mk \u2212 2 m 2 m \u2212 1 < 2 mk \u2212 1",
        "prob": 0.5071428571428571
    }, {
        "ID": 5178,
        "phrase": "  w(i) j=1 k\u22122 l=0 2 mc j,l +i j = w(i) j=1 2 i j k\u22122 l=0 2 mc j,l \u2264 w(i) j=1 2 i j k\u22121 l=1 2 ml \u2264 (2 m \u2212 1) \u2022 2 mk \u2212 2 m 2 m \u2212 1 < 2 mk \u2212 1",
        "prob": 0.5785714285714285
    }, {
        "ID": 5344,
        "phrase": " for example p1,1 is given by p1,1 = (a h 1,1 \u2022a 1,2 +b h 1,1 \u2022b 1,2 +b t 2,1 \u2022b * 2,2 \u2212a t 2,1 \u2022a * 2,2 )\u2212(a h 1,1 \u2022a 1,2 +b h 1,1 \u2022b 1,2 +b t 2,1 \u2022b * 2,2 \u2212a t 2,1 \u2022a * 2,2 ) h = = same generating function a h 1,1 dependent on [h 1 ,\u2022\u2022\u2022 ,h k/4 ] \u2022a 1,2 \u2212a 1,1 \u2022a h 1,2 dependent on [h k/4+1 ,\u2022\u2022\u2022 ,h k/2 ] + \u2022 \u2022 \u2022 = \u00e3h 1 \u2022 b1 \u2212 b1 \u2022 \u00e3h 1 same structure as p1 + \u2022 \u2022 \u2022 (36) ultimately, this structure propagates to each of the scalar elements p1(n,m) of p1 , yielding p1(n,m) = k/2 i=1 (h * ai h bi +h ai h * bi )\u2212(h * ai h bi +h ai h * bi ) * = 0, (37) where the set of pairs {(h a1 , h b1 ), \u2022 \u2022 \u2022 , (h a k/2 , h b k/2 )} are different for each (n, m)-th element of the matrix",
        "prob": 0.204
    }, {
        "ID": 5379,
        "phrase": " this curve is close to ml performance",
        "prob": 0.2625
    }, {
        "ID": 5413,
        "phrase": " first the data, made of f : x \u2192 y and a : u \u2192 x, with the same type x, is represented as a span sp in the category g: x on ml hi jk \u2192 u a g g x on ml hi jk \u2193 x f g g y on ml hi jk then the pushout with base sp is built in the category g: x on ml hi jk \u2192 u a g g x on ml hi jk x f g g y on ml hi jk u a g g x f g g y on ml hi jk the vertex of the pushout is an instance of the premises of the rule for composition",
        "prob": 0.5704545454545454
    }, {
        "ID": 5518,
        "phrase": " pr[a + b = w] = a+b=w pr[a = a] \u2022 pr[b = b] = (a+b) +i =w +i e ai pr[a = a +i ] \u2022 e bi pr[b = b +i ] = e wi a +i +b +i =w +i pr[a = a +i ] \u2022 pr[b = b +i ] = e wi pr[a + b = w +i ] f",
        "prob": 0.63125
    }, {
        "ID": 5818,
        "phrase": " since 0 is the ml codeword m i (f i ) > m 0 (f 0 ) implying that m i (a) > m 0 (f 0 )",
        "prob": 0.2625
    }, {
        "ID": 5914,
        "phrase": " the next step consists of estimating h i=1 1 ai ",
        "prob": 0.2625
    }, {
        "ID": 5914,
        "phrase": "2] that h i=1 1 ai \u2208 o(log 2 |d|)",
        "prob": 0.22000000000000003
    }, {
        "ID": 6100,
        "phrase": " the formulae of ml are translated into l 1 by means of the following standard translation function, st(\u2022, \u2022), which takes as arguments an m l-formula together with a variable from var: st(p i , x) := p i (x) for every p i \u2208 prop; st(\u00ac\u03d5, x) := \u00acst(\u03d5, x); st(\u03d5 \u2228 \u03c8, x) := st(\u03d5, x) \u2228 st(\u03c8, x); st(\u03d5 \u2227 \u03c8, x) := st(\u03d5, x) \u2227 st(\u03c8, x); st (\u2738\u03d5, x) := \u2203y(rxy \u2227 st(\u03d5, y)), st (\u2737\u03d5, x) := \u2200y(rxy \u2192 st(\u03d5, y)), where y is the first variable in var not appearing in st (\u03d5, x)",
        "prob": 0.8743589743589744
    }, {
        "ID": 6101,
        "phrase": " the formulae of ml are translated into l 1 by means of the following standard translation function, st(\u2022, \u2022), which takes as arguments an m l-formula together with a variable from var: st(p i , x) := p i (x) for every p i \u2208 prop; st(\u00ac\u03d5, x) := \u00acst(\u03d5, x); st(\u03d5 \u2228 \u03c8, x) := st(\u03d5, x) \u2228 st(\u03c8, x); st(\u03d5 \u2227 \u03c8, x) := st(\u03d5, x) \u2227 st(\u03c8, x); st (\u2738\u03d5, x) := \u2203y(rxy \u2227 st(\u03d5, y)), st (\u2737\u03d5, x) := \u2200y(rxy \u2192 st(\u03d5, y)), where y is the first variable in var not appearing in st (\u03d5, x)",
        "prob": 0.9
    }, {
        "ID": 6102,
        "phrase": " the formulae of ml are translated into l 1 by means of the following standard translation function, st(\u2022, \u2022), which takes as arguments an m l-formula together with a variable from var: st(p i , x) := p i (x) for every p i \u2208 prop; st(\u00ac\u03d5, x) := \u00acst(\u03d5, x); st(\u03d5 \u2228 \u03c8, x) := st(\u03d5, x) \u2228 st(\u03c8, x); st(\u03d5 \u2227 \u03c8, x) := st(\u03d5, x) \u2227 st(\u03c8, x); st (\u2738\u03d5, x) := \u2203y(rxy \u2227 st(\u03d5, y)), st (\u2737\u03d5, x) := \u2200y(rxy \u2192 st(\u03d5, y)), where y is the first variable in var not appearing in st (\u03d5, x)",
        "prob": 0.9
    }, {
        "ID": 6103,
        "phrase": " the formulae of ml are translated into l 1 by means of the following standard translation function, st(\u2022, \u2022), which takes as arguments an m l-formula together with a variable from var: st(p i , x) := p i (x) for every p i \u2208 prop; st(\u00ac\u03d5, x) := \u00acst(\u03d5, x); st(\u03d5 \u2228 \u03c8, x) := st(\u03d5, x) \u2228 st(\u03c8, x); st(\u03d5 \u2227 \u03c8, x) := st(\u03d5, x) \u2227 st(\u03c8, x); st (3\u03d5, x) := \u2203y(rxy \u2227 st(\u03d5, y)), st (2\u03d5, x) := \u2200y(rxy \u2192 st(\u03d5, y)), where y is the first variable in var not appearing in st (\u03d5, x)",
        "prob": 0.9
    }, {
        "ID": 6109,
        "phrase": " this is because the ml metric can be written as a sum of several square terms, each depending on at-most one variable for od",
        "prob": 0.47333333333333333
    }, {
        "ID": 6165,
        "phrase": " the gap between the tub and the near ml performance curve at moderate-to-high values of \u01eb is due to the fact that only a limited number of codewords are taken into account in the summation of the union bound",
        "prob": 0.29583333333333334
    }, {
        "ID": 6435,
        "phrase": " assume that the constellation consists of the zero symbol, which is transmitted with probability x y p 0 1 1 = -e , and symbols x x x 1 2 , , , k k { } of the form x x x 1 2 1 0 0 0 1 0 0 0 1 = ( ) = ( ) = ( ) e e e , , , , , , , , , , , , k k m ( )\u2265 [ ] - + - ( ) + ( ) \u25ca \u00e8 \u00ee \u00ed \u00ed \u00ed - - + - - + ( ) - + + ( ) b b + ( ) [ ] \u25ca ( ) [ ] + - ( ) + - ( ) + - - + ( ) [ ] + + ( ) [ ] \u2022 -- + + + + \u00fa m e x e k e y k ml m y ml ml m m k x x m m l ml m l m ln ln \u02c6\u00e2 a a a a a a a f ( ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 -\u2022 \u2022 \u00fa l dxdy , where f x ( ) represents the standard normal cumulative distribution function",
        "prob": 0.35000000000000003
    }, {
        "ID": 6435,
        "phrase": " = + + ( ) - ( ) + ( ) + - ( ) + ( ) - + ( ) - + + ( ) - + ( ) - + + ( ) 2 2 2 1 2 1 1 2 1 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 m l m m l k ml m e k ml m e l ml u m l m m l l ml u m l m m l 2 f f u du y k e k ml m e k m m l l m l m m x l l ( ) + - - - ( ) - - ( ) + ( ) - \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ed + + - + + \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 -\u2022 \u2022 \u00fa s b b b b b b b \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 - + - ( ) + ( ) \u00ea \u00eb \u00e1 \u00e8 \u00ee \u00ed \u00ed \u2022 \u00fa k y k ml m e dx l l 1 1 1 2 1 2 1 2 2 ln \u015d b b a a \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u02c6( ) \u2022 \u00fa p y dy y 0 now, using integration by parts on the first integral and making a change of variable in the second followed again by integration by parts, we get     + + + -\u2022 \u2022 \u2022 - - + ( ) - + + ( ) \u00fa \u00fa \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ed \u02d8( ) = + - ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed ln a a a a a a -\u2022 -\u2022 \u2022 -- + + + + - -\u2022 \u2022 \u00fa \u00fa + - ( ) [ ] + - ( ) + - ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u02c6( k u e k e ye k ml m du p y k u u m m l ml m l m l l y 1 2 1 1 2 1 2 1 2 2 2 2 1 2 2 1 ( )= + + \u00ea \u00eb \u00e1 \u02c6- - + + \u00ea \u00eb \u00e1 \u00e8 \u00ee \u00ed \u00ed + + \u00ea \u00eb \u00e1 1 2 2 1 2 1 2 2 2 2 1 2 1 2 8 1 2 + - + + \u00ea \u00eb \u00e1 \u00e8 \u00ee \u00ed \u00ed + + \u00ea \u00eb \u00e1 \u2022 -- + \u00fa f 1 1 2 2 1 2 2 2 2 2 2 2 1 2 1 1 2 2 1 2 m l ml m l m l y k ml m dxdy ml k ml b b b s b s s p + + + -\u2022 \u2022 + - ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 = [ ] - \u00fa ( ) [ ] + - ( ) - + + ( ) [ ] \u2022 -- + + + + -\u2022 \u2022 \u00fa \u00fa \u25ca ( ) [ ] + - ( ) + - ( ) + ( ) \u00e8 \u00ee \u00ed \u00ed \u00ed \u00ed \u00ea \u00eb \u00e1 \u00e1 \u00e1 \u00e1 2 2 2 2 2 2 2 8 2 1 0 2 2 2 2 1 2 2 1 2 1 1 2 1 2 1 ml m m k x x m m l ml m l m l x e k e y k ml m dxdy b b b b b b s b ln a a a a f \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u00e1 \u02c6, which establishes the bound given in lemma 3",
        "prob": 0.4113636363636364
    }, {
        "ID": 6676,
        "phrase": " thus, by applying theorems 1 and 2, we conclude that our low-density scheme saturates the gelfand-pinsker bound under ml encoding/decoding",
        "prob": 0.3588235294117647
    }, {
        "ID": 6785,
        "phrase": " let's go through the list of features that should be implemented in an ai as a base",
        "prob": 0.20999999999999996
    }, {
        "ID": 6798,
        "phrase": " , a k )) = (\u03c3, i, 1) \u00fb \u00f6 \u03c3 \u00d7 \u00f4 \u00f6\u00f8 \u00f0 \u00f9\u00f2\u00f8 \u00f3\u00f2 \u03c3 : x \u2192 t l \u00f2 \u03c3(a j ) = a j 1 \u2264 j \u2264 k \u03c3(x j ai ) = n(a i , j, s) j \u2208 n \u00ef \u00f6 \u00f0\u00f0 \u00f8 \u00f8 \u00f8 \u00f4\u00f6 \u00f2 \u00f4 \u00f0 \u00fc \u00f9\u00f8 \u00f2 \u00f8 \u00f6\u00f3\u00f0 \u03c0(i) \u00d7 \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8 \u00fd a i \u00f8 \u00f9\u00d7\u00b8 \u00f2 \u00f8 \u00f8 \u00f6\u00f3\u00f0 \u00b8 \u00fa \u00f6\u00fd \u00fa \u00f6 \u00f0 \u00f3 \u00f8 \u00f3\u00f6\u00f1 x j ai \u00f6 \u00f4\u00f6 \u00d7 \u00f2\u00f8\u00d7 \u00f2\u00f3\u00f2 \u00f2 \u00f6 \u00f8 \u00fd a i \u00ba \u00ec \u00fa \u00f6\u00d7 \u00f6\u00fd \u00f2 \u00d7 \u00f2 \u00f1 \u00d7\u00d7 \u00d7 (sid, f, h) send(sid,m) \u2212\u2212\u2212\u2212\u2212\u2212\u2212\u2192 (sid, f \u2032 , h \u2032 ) \u00fb \u00f6 sid \u2208 sid\u00b8m \u2208 t l \u00b8h\u2032 \u00b8 \u00f2 f \u2032 \u00f6 \u00f2 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7\u00ba \u00ef \u00f2 f \u2032 (sid \u2032 ) = f (sid \u2032 ) \u00f3\u00f6 \u00fa \u00f6\u00fd sid \u2032 = sid\u00ba \u00ef \u00f2\u00f3\u00f8 \u03c0(j) = ((l j 1 , r j 1 ), ",
        "prob": 0.6230769230769231
    }, {
        "ID": 6876,
        "phrase": " = p (\u015d ml = s) ",
        "prob": 0.22000000000000003
    }, {
        "ID": 6990,
        "phrase": " the ml estimator will assign probability 1/n to the n symbols that appear in the string and zero probability to the rest",
        "prob": 0.22142857142857142
    }, {
        "ID": 7232,
        "phrase": " in contrast, the ml decoder can go down this list, and determine the first vertex which has integral coordinates",
        "prob": 0.36428571428571427
    }, {
        "ID": 7232,
        "phrase": " therefore if we could guess the right facet f 1 we can determine the ml codeword for this case",
        "prob": 0.3153846153846154
    }, {
        "ID": 7233,
        "phrase": " in contrast, the ml decoder can go down this list, and determine the first vertex which has integral coordinates",
        "prob": 0.36428571428571427
    }, {
        "ID": 7233,
        "phrase": " therefore if we could guess the right facet f 1 we can determine the ml codeword for this case",
        "prob": 0.3153846153846154
    }, {
        "ID": 7394,
        "phrase": " \n \u27a2 the actor model, \u27a2 process calculi such as \u27a2 -calculus, ambient calculus \u03c0 \u27a2 calculus of communicating systems \u27a2 communicating sequential processes \n \u27a2 alice -extension to standard ml (supports concurrency through futures)",
        "prob": 0.6708333333333333
    }, {
        "ID": 7395,
        "phrase": " \n \u27a2 calculus of communicating systems\u27a2 communicating sequential processes \n \u27a2 alice -extension to standard ml (supports concurrency through futures)",
        "prob": 0.5941176470588235
    }, {
        "ID": 7396,
        "phrase": " \n \u27a2 calculus of communicating systems\u27a2 communicating sequential processes \n \u27a2 alice -extension to standard ml (supports concurrency through futures)",
        "prob": 0.711764705882353
    }, {
        "ID": 7397,
        "phrase": " \n \u27a2 calculus of communicating systems\u27a2 communicating sequential processes \n \u27a2 alice -extension to standard ml (supports concurrency through futures)",
        "prob": 0.7705882352941176
    }, {
        "ID": 7517,
        "phrase": " in this case, (88) is equal to \uf8f1 \uf8f2 \uf8f3 e \uf8eb \uf8ed a1 \u03b1(1)=1 c (p1,\u03b1(1)) w c (q1,\u03b1(1)) w b1 \u03b3(1)=1 c (r1,\u03b3(1)) w c (s1,\u03b3(1)) w \uf8f6 \uf8f8 (89) \u2212 e \uf8eb \uf8ed a1 \u03b1(1)=1 c (p1,\u03b1(1)) w c (q1,\u03b1(1)) w \uf8f6 \uf8f8 e \uf8eb \uf8ed b1 \u03b3(1)=1 c (r1,\u03b3(1)) w c (s1,\u03b3(1)) w \uf8f6 \uf8f8 \uf8fc \uf8fd \uf8fe \u00d7 j i=2 e \uf8eb \uf8ed ai \u03b1(i)=1 c (pi,\u03b1(i)) ui c (qi,\u03b1(i)) ui \uf8f6 \uf8f8 \u2022 l i=2 e \uf8eb \uf8ed bi \u03b3(i)=1 c (ri,\u03b3(i)) vi c (si,\u03b3(i)) vi \uf8f6 \uf8f8 \u00d7 product of \u03b4 functions, where, for given i and \u03b1(i), p i,\u03b1(i) and q i,\u03b1(i) are edge variables touching the same vertex within a cycle of the k-graph, and so do r i,\u03b3(i) and s i,\u03b3(i) with given i and \u03b3(i)",
        "prob": 0.2652173913043478
    }, {
        "ID": 7539,
        "phrase": " now run the ml algorithm with m = poly(nl/\u01eb) log(m/\u03b4) on this list of hypothesis distributions using z m as the target distribution",
        "prob": 0.20666666666666667
    }, {
        "ID": 7592,
        "phrase": " //generalised segments for each \u03c3 j of \u03c3 \n table 1 : 1 corpus profiles monographs collections li ai ke01 ke04 \n table 2 : 2 segmentation results \n\t\t\t in the following, the term index is always used with the same meaning",
        "prob": 0.305
    }, {
        "ID": 7858,
        "phrase": " write the function inside the sup argument as e ml x (r x , r y , \u03b3, \u03c1)",
        "prob": 0.31
    }, {
        "ID": 7995,
        "phrase": " for each ei, 1 \u2264 i \u2264 k + 1, build a set ai of disjoint augmentations by deleting every (k + 1) th link starting with ei: i",
        "prob": 0.23846153846153847
    }, {
        "ID": 8462,
        "phrase": " (5) the iowef coefficients b p w,d can be used to determine a tight upper bound on the bep for ml soft decoding for the case of an awgn channel, as follows p b \u2264 1 n d w wb p w,d q 2r p e b n 0 \u2022 d , (6) where r p is the rate of the turbo code, which in our case is equal to 1/3",
        "prob": 0.3
    }, {
        "ID": 8462,
        "phrase": " the upper bound on the bep for ml soft decoding for the case of an awgn channel takes the form p b \u2264 w p \u2032 (w), (15) where p \u2032 (w) is given by p \u2032 (w) = d \u2032 w n b p \u2032 w,d \u2032 q 2r p \u2032 e b n 0 \u2022 d \u2032 (16) and r p \u2032 = 1/2",
        "prob": 0.3588235294117647
    }, {
        "ID": 8907,
        "phrase": " new ml certificate algorithm 1) if there is a variable that is in more unsatisfied than satisfied constraints (only the constraints in the expander graph), flip the value of that variable 2) repeat 1) until no such variable remains",
        "prob": 0.33809523809523806
    }, {
        "ID": 9221,
        "phrase": " ml data types include the usual int and bool , and also term, form, and thm, whose values are pplambda terms, formulas, and theorems",
        "prob": 0.45499999999999996
    }, {
        "ID": 9221,
        "phrase": " it fails if the first argument is not an implication, or if the second argument is not the antecedent of the first: p =\u21d2 q p q lcf is programmable: all commands can be invoked as ml functions",
        "prob": 0.39444444444444443
    }, {
        "ID": 9221,
        "phrase": " nearly any tactic can be expressed in terms of other tactics and tacticals, without requiring low-level ml code that explicitly builds lists of subgoals",
        "prob": 0.255
    }, {
        "ID": 9221,
        "phrase": " by the ml function conj, which has type thm \u2192 thm \u2192 thm",
        "prob": 0.6454545454545454
    }, {
        "ID": 9223,
        "phrase": " the following program, written in standard ml  [6] , defines the data structure exp and the normalize function norm",
        "prob": 0.38125
    }, {
        "ID": 9223,
        "phrase": " the structural induction tactic is instantiated to handle expressions and bound to the ml identifier exp tac",
        "prob": 0.33999999999999997
    }, {
        "ID": 9224,
        "phrase": " x x, which is bound to the ml identifier less refl of type thm",
        "prob": 0.4636363636363636
    }, {
        "ID": 9224,
        "phrase": " the rule of conjunction introduction, \u03b3 a \u2206 b \u03b3, \u2206 a \u2227 b is bound to the ml identifier conj of type thm \u2192 thm \u2192 thm",
        "prob": 0.5399999999999999
    }, {
        "ID": 9224,
        "phrase": " the conjunction elimination rules are \u03b3 a \u2227 b \u03b3 a \u03b3 a \u2227 b \u03b3 b they are implemented by ml functions of type thm \u2192 thm that fail if the argument is not a conjunction",
        "prob": 0.25625
    }, {
        "ID": 9224,
        "phrase": " the ml function disj1 has type thm \u2192 form \u2192 thm",
        "prob": 0.6454545454545454
    }, {
        "ID": 9224,
        "phrase": " edinburgh lcf executed ml slowly",
        "prob": 0.34444444444444444
    }, {
        "ID": 9224,
        "phrase": " \n the implementation isabelle consists of 3200 lines of the new standard ml  [26] , compiled by david matthew's poly/ml on a vax/750 running berkeley unix",
        "prob": 0.32105263157894737
    }, {
        "ID": 9224,
        "phrase": " for the typed \u03bb-calculus, the ml type arity represents types and the ml type term represents \u03bb-expressions",
        "prob": 0.69375
    }, {
        "ID": 9224,
        "phrase": " the premises are an ml list of strings; each variable is indicated by a prefixed question mark; skolem subscripts are in square brackets: val prodintrrl = read_rule ( [ \"?h |-?a type\", \"?h, pri[?b1,?b1]: ?a |-?b1(pri[?b1,?b1]) : ?b1(pri[?b1,?b1])\" ] ,  { -------------------------------------------------------------------}  \"?h |-lambda(?b1) : prod(?a,?b1)\" ); the horizontal line is simply an ml comment",
        "prob": 0.6483870967741935
    }, {
        "ID": 9225,
        "phrase": " by 1986, edinburgh lcf's techniques had spread to several systems  [29] , standard ml had become a language in its own right, and isabelle reached a usable form",
        "prob": 0.4789473684210526
    }, {
        "ID": 9226,
        "phrase": " another aim was to write the entire system in standard ml -which had grown out of lcf's meta-language -to show it was a practical alternative to lisp",
        "prob": 0.24285714285714283
    }, {
        "ID": 9228,
        "phrase": " ml treats the terms and formulas of pplambda as data values, providing functions to build them and take them apart",
        "prob": 0.2733333333333333
    }, {
        "ID": 9228,
        "phrase": " the ml expression for constructing a pplambda object (term or formula) consists of that object enclosed in quotation marks",
        "prob": 0.38125
    }, {
        "ID": 9228,
        "phrase": " the theorems of pplambda, which denote proved formulas, are elements of the ml type thm",
        "prob": 0.3923076923076923
    }, {
        "ID": 9228,
        "phrase": " we bind a complex term, a conditional, to the ml identifier tm_obj",
        "prob": 0.3727272727272727
    }, {
        "ID": 9228,
        "phrase": " ml responds by printing the value and its type",
        "prob": 0.5666666666666667
    }, {
        "ID": 9228,
        "phrase": " conversion functions have many advantages over edinburgh lcf's simplifier, a large and inscrutable ml program",
        "prob": 0.2733333333333333
    }, {
        "ID": 9228,
        "phrase": " because ml treats functions as first-class data, we can implement rewriting tools as functions and write operators to combine them",
        "prob": 0.3
    }, {
        "ID": 9228,
        "phrase": " manipulating pplambda abstract syntax the terms of pplambda, which denote computable values, are elements of the ml type term",
        "prob": 0.5352941176470588
    }, {
        "ID": 9228,
        "phrase": " (f o g)x ---> f(g x) the formulas of pplambda, which denote logical statements, are elements of the ml type form",
        "prob": 0.47333333333333333
    }, {
        "ID": 9230,
        "phrase": " \n the ml code for unification the unification code has a lot of nested functions",
        "prob": 0.425
    }, {
        "ID": 9230,
        "phrase": ") the user could write ml functions to process terms, formulae, and theorems",
        "prob": 0.46923076923076923
    }, {
        "ID": 9230,
        "phrase": "the discussion leads to the ml type definitions: datatype term = var of string | param of string * string list | bound of int | fun of string * term list; datatype form = pred of string * term list | conn of string * form list | quant of string * string * form; \n\t\t\t but once we introduce unification, we have to be careful",
        "prob": 0.7921052631578946
    }, {
        "ID": 9242,
        "phrase": " the parser and pretty printer need approximately 100 lines of ml to specify the translation of set theory's binding operators and other notation shown in figure  2 ",
        "prob": 0.305
    }, {
        "ID": 9242,
        "phrase": " isabelle's parser and pretty printer handle these conventions, using an ml function to search for occurrences of the bound variable",
        "prob": 0.4764705882352941
    }, {
        "ID": 9242,
        "phrase": "  4  finally, we declare the resulting theorem as the ml identifier doubleton_iff: val doubleton_iff = result(); now we prove the main theorem, that ordered pairing is injective",
        "prob": 0.305
    }, {
        "ID": 9242,
        "phrase": " first we state the goal, binding the definition of homomorphism to the ml identifier hom_def: val [hom_def] = goal perm",
        "prob": 0.41764705882352937
    }, {
        "ID": 9243,
        "phrase": " an alcnr-knowledge base = ht ; ai can be translated into a constraint system s by replacing every inclusion c v d 2 t with the constraint 8x",
        "prob": 0.20666666666666664
    }, {
        "ID": 9265,
        "phrase": " a binary constraint cij is row convex i for any ai 2 di, all its supports are consecutive in dj, provided there exists an (implicit) ordering of the domains",
        "prob": 0.1823529411764706
    }, {
        "ID": 9265,
        "phrase": " a binary constraintcij is m-tight i every value ai 2 di is supported by either at most m values in dj, or all values of dj, and, conversely, every value aj 2 dj either has at most m supports in di or is supported by all values of di",
        "prob": 0.42083333333333334
    }, {
        "ID": 9336,
        "phrase": " we direct isabelle via the ml top level: goal hol",
        "prob": 0.17500000000000002
    }, {
        "ID": 9336,
        "phrase": " it returns an ml function, contract",
        "prob": 0.3875
    }, {
        "ID": 9336,
        "phrase": " to apply it to the combinator k, we type a val declaration at the ml top level: val k_contracte = contract",
        "prob": 0.4066666666666666
    }, {
        "ID": 9336,
        "phrase": "simps \"k -1-> z\"; val k_contracte = \"k -1-> ?z ==> ?q\" : thm the ml identifier k_contracte is now bound to the derived rule k 1 \u2212\u2192 z q ",
        "prob": 0.43571428571428567
    }, {
        "ID": 9336,
        "phrase": " the ml function parcontract",
        "prob": 0.3
    }, {
        "ID": 9615,
        "phrase": " i then turn to the semantic rules that pustejovsky uses and argue first that, although they have novel features, they are in a well-established artificial intelligence tradition of explaining meaning by reference to structures that mention other structures assigned to words that may occur in close proximity to the first",
        "prob": 0.253125
    }, {
        "ID": 9665,
        "phrase": " second, it joins each pair of adjacent words in the ml segmentation of the current block and increments the frequency of the resulting words by one",
        "prob": 0.5941176470588235
    }, {
        "ID": 9748,
        "phrase": " , xi\u22121) to realize the value ai\u22121, has the following expression: p(ai|ai\u22121)dai = 1 v \u03b4 (1) \u2022 s \u03b4\u2212i+1 ai ai\u22121 \u2022 vi\u22121 \uf8eb \uf8ed 1 \u2212 ai ai\u22121 2 \uf8f6 \uf8f8 \u2022 dai ai\u22121 therefore, since vi(r) = vi(1) \u2022 r i and si(r) = i \u2022 vi(1) \u2022 r i\u22121 , we have p(a 1 ) \u03b4 i=2 p(a i |a i\u22121 )da i = \u03b4v \u03b4 (1)a \u03b4\u22121 1 v \u03b4 (1) \u03b4 i=2 1 v \u03b4 (1) \u2022 (\u03b4 \u2212 i + 1)v \u03b4\u2212i+1 (1) \u2022 a i a i\u22121 \u03b4\u2212i \u2022 v i\u22121 (1) \u2022 \uf8eb \uf8ed 1 \u2212 a i a i\u22121 2 \uf8f6 \uf8f8 i\u22121 \u2022 da i a i\u22121 = \u03b4!a \u03b4\u22121 1 v \u03b4 (1) \u03b4\u22121 \u03b4 i=2 v \u03b4\u2212i+1 (1)v i\u22121 (1) \uf8eb \uf8ed \u03b4 i=2 a i \u03b4\u2212i a i\u22121 \u03b4\u2212i+1 \uf8eb \uf8ed 1 \u2212 a i a i\u22121 2 \uf8f6 \uf8f8 i\u22121 da i \uf8f6 \uf8f8 in the rightmost term above the product of the powers of the a i 's simplifies to 1 a1 \u03b4\u22121 , so that = \u03b4! \u03b4\u22121 i=1 v i (1) 2 v \u03b4 (1) \u03b4\u22121 \u03b4 i=2 \uf8eb \uf8ed 1 \u2212 a i a i\u22121 2 \uf8f6 \uf8f8 i\u22121 da i the last expression contains a constant depending only on \u03b4, which will be denoted k \u03b4 \u2206 = \u03b4! \u03b4\u22121 i=1 vi(1) 2 v \u03b4 (1) \u03b4\u22121 now we can write the probability for the absolute value of the determinant to be no larger than v p rob(|p 1 , p 2 ",
        "prob": 0.284375
    }]
}, {
    "topic_id": 28,
    "top_words": ["learning", "machine", "data", "mining", "techniques", "algorithms", "applied", "web", "several", "information", "different", "use", "based", "analysis", "structure"],
    "phrases": [{
        "ID": 128,
        "phrase": " this feature distinguishes moo from the vast literature in machine learning and database mining; it is also different from applying algorithms for online learning to online optimization  [bb] , from using data collected online to make decisions  [kmmo, fm] , and from mining database access histories for buffer management  [fltt] ",
        "prob": 0.3361111111111111
    }, {
        "ID": 128,
        "phrase": ") by offering a database perspective on online optimization, moo has the potential of facilitating a mutually enriching interaction among database management, machine learning and algorithm analysis",
        "prob": 0.3227272727272727
    }, {
        "ID": 173,
        "phrase": " after this we introduce the different data representations we use and our machine learning algorithms",
        "prob": 0.3416666666666666
    }, {
        "ID": 209,
        "phrase": " several machine learning algorithms have been applied to text categorization (e",
        "prob": 0.5545454545454546
    }, {
        "ID": 317,
        "phrase": " although machine learning algorithms have been applied to several text categorization tasks (e",
        "prob": 0.5461538461538461
    }, {
        "ID": 449,
        "phrase": " the web mining research is a converging research area from several research communities, such as database, ir, and ai research communities especially from machine learning and nlp",
        "prob": 0.6714285714285714
    }, {
        "ID": 449,
        "phrase": " there is a close relationship between data mining, machine learning and advanced data analysis  [89] ",
        "prob": 0.46923076923076923
    }, {
        "ID": 449,
        "phrase": " however, throughout the paper, we discuss the web mining research where machine learning techniques are used",
        "prob": 0.2733333333333333
    }, {
        "ID": 449,
        "phrase": " others use machine learning or data mining techniques to learn the extraction patterns or rules for web documents semi-automatically or automatically  [76] ",
        "prob": 0.505
    }, {
        "ID": 449,
        "phrase": " \n web mining and machine learning applied on the web web mining is not the same as learning from the web or machine learning techniques applied on the web",
        "prob": 0.7947368421052632
    }, {
        "ID": 449,
        "phrase": " on the one hand, there are some applications of machine learning applied on the web that are not instances of web mining",
        "prob": 0.3923076923076923
    }, {
        "ID": 449,
        "phrase": " machine learning techniques support and help web mining as they could be applied to the processes in web mining",
        "prob": 0.56875
    }, {
        "ID": 449,
        "phrase": " in short, web mining intersects with the application of machine learning on the web",
        "prob": 0.5083333333333333
    }, {
        "ID": 449,
        "phrase": " this is due to the absence of the machine learning or data mining techniques in the process",
        "prob": 0.5083333333333333
    }, {
        "ID": 449,
        "phrase": " she also surveys research on machine learning applied to text data, which is broader than but similar to our discussion in section 3",
        "prob": 0.20666666666666667
    }, {
        "ID": 449,
        "phrase": " at least this is the area where database and other research communities such as ir, ai, and machine learning met recently",
        "prob": 0.3923076923076923
    }, {
        "ID": 449,
        "phrase": " table 2 : 2 the association between the categories of web mining and the agent paradigm content-based filters \u2194 content mining reputation-based filters \u2194 structure (and content) mining collaborative or social-based \u2194 usage mining filters event-based filters \u2194 usage mining hybrid filters \u2194 combination of the categories \n table 1 : 1 web mining categories web mining web content mining web structure mining web usage mining ir view db view view of data -unstructured -semi structured -links structure -interactivity -semi structured -web site as db main data -text documents -hypertext documents -links structure -server logs -hypertext documents -browser logs representation -bag of words, n-grams -edge-labeled graph (oem) -graph -relational table -terms, phrases -relational -graph -concepts or ontology -relational method -tfidf and variants -proprietary algorithms -proprietary algorithms -machine learning -machine learning -ilp -statistical -statistical (including nlp) -(modified) association rules -(modified) association rules application -categorization -finding frequent sub- -categorization -site construction, adapta- categories structures tion, and management -clustering -web site schema discovery -clustering -marketing -finding extraction rules -user modeling -finding patterns in text -user modeling \n table 3 : 3 an ir view on web content mining for unstructured documents author document representa- process method application tion ahonen, et al",
        "prob": 0.6159763313609468
    }, {
        "ID": 449,
        "phrase": " the web mining research is at the cross road of research from several research communities, such as database, information retrieval, and within ai, especially the sub-areas of machine learning and natural language processing",
        "prob": 0.40399999999999997
    }, {
        "ID": 682,
        "phrase": " these observations would account for the fact that rule learning or discovery has become a major topic in both machine learning and data mining research",
        "prob": 0.32105263157894737
    }, {
        "ID": 682,
        "phrase": " \n conclusions if global optimization is a main issue for automated rule discovery from data, then current machine learning theories do not seem adequate",
        "prob": 0.2157894736842105
    }, {
        "ID": 682,
        "phrase": " in light of its significance, this theory would hopefully point out a new direction for machine learning and data mining",
        "prob": 0.25625
    }, {
        "ID": 713,
        "phrase": " he felt importance of collaborative efforts with different participating organizations to cooperate in order to explore the possible and actual ways in which the technical systems of artificial intelligence can be done",
        "prob": 0.3227272727272727
    }, {
        "ID": 721,
        "phrase": " \n advance: the central computational proposal is to generate actual individuals as the different families of d, ai \u2286 d for i \u2208 i",
        "prob": 0.3153846153846154
    }, {
        "ID": 725,
        "phrase": " there are several places where machine learning can help in the automation of information integration",
        "prob": 0.425
    }, {
        "ID": 815,
        "phrase": " finally, we conclude with a short discussion of how these results can be applied to other machine learning techniques and to other problems",
        "prob": 0.43571428571428567
    }, {
        "ID": 1028,
        "phrase": " \n microarray data analysis several algorithms from data mining, machine learning, and parametric and nonparametric statistics have entered microarray data analysis  [aharoni et al",
        "prob": 0.6238095238095238
    }, {
        "ID": 1281,
        "phrase": "5) (someone,machine learning,1",
        "prob": 0.35000000000000003
    }, {
        "ID": 1282,
        "phrase": " machine learning techniques proved particularly adept at identifying patterns in user behaviour",
        "prob": 0.36428571428571427
    }, {
        "ID": 1282,
        "phrase": " the question is: how do current systems measure up to the challenges previously identified within the interface agent field? \n knowing the user supervised machine learning techniques require large (in the order of 100,000's) labelled document corpuses to be effective",
        "prob": 0.28928571428571426
    }, {
        "ID": 1333,
        "phrase": "  [36, 46] ), machine learning and data mining (e",
        "prob": 0.5125000000000001
    }, {
        "ID": 1334,
        "phrase": "  [38, 49] ), machine learning and data mining (e",
        "prob": 0.2625
    }, {
        "ID": 1370,
        "phrase": " relation to classical statistics and learning theory: in statistics and machine learning one wants to find the meaning of the data provided",
        "prob": 0.3588235294117647
    }, {
        "ID": 1384,
        "phrase": ", microarray bioinformatics) and a complementary role in others, by augmenting traditional techniques from numerical analysis, statistics, and machine learning",
        "prob": 0.5352941176470588
    }, {
        "ID": 1385,
        "phrase": ", microarray bioinformatics) and a complementary role in others, by augmenting traditional techniques from numerical analysis, statistics, and machine learning",
        "prob": 0.5352941176470588
    }, {
        "ID": 1387,
        "phrase": " \n system combination when different machine learning systems are applied to the same task, they will make different errors",
        "prob": 0.2733333333333333
    }, {
        "ID": 1430,
        "phrase": " the other eight pages, the brooks series and the lambda series, are from the mit ai lab's technical document collection and are scanned at 300 dpi",
        "prob": 0.38125
    }, {
        "ID": 1467,
        "phrase": " most of the techniques for implicitly gathering and exploiting user information are based on methods and algorithms from machine learning  [117, 74, 75]  and data mining, which attempt to discover interesting patterns or trends from large and diverse data sources",
        "prob": 0.5423076923076923
    }, {
        "ID": 1483,
        "phrase": " so, apart from presenting our results obtained via machine learning techniques, we also analyze the problem to gain a better understanding of how difficult it is",
        "prob": 0.33888888888888885
    }, {
        "ID": 1483,
        "phrase": " \n discussion the results produced via machine learning techniques are quite good in comparison to the humangenerated baselines discussed in section 4",
        "prob": 0.33888888888888885
    }, {
        "ID": 1500,
        "phrase": " an alternative approach is to collect sample summaries and apply machine learning techniques to identify what types of information are included in a summary, and identify their stylistic, grammatical, and lexical choice characteristics and to generate or regenerate a summary based on these characteristics",
        "prob": 0.38275862068965516
    }, {
        "ID": 1500,
        "phrase": " amitay describes strategies for locating and extracting snippets from various types of web pages, and applies machine learning to rank different snippet description of the same document for fitness as a document summary",
        "prob": 0.484
    }, {
        "ID": 1500,
        "phrase": " our goal is not to analyze what makes one summary better than another, but to learn how to generate a suitable summary of a resource based on machine learning over a compiled corpus",
        "prob": 0.205
    }, {
        "ID": 1691,
        "phrase": " it was stated in these publications that the results obtained with relational methods using real industrial or environmental data are better than with any other known approach, with or without machine learning",
        "prob": 0.1952380952380952
    }, {
        "ID": 1748,
        "phrase": " note that a large class of data mining and machine learning algorithms based on information gains (id3, c4",
        "prob": 0.38125
    }, {
        "ID": 1867,
        "phrase": " a feature vector is calculated for each candidate phrase and machine learning techniques are used to learn a model that can classify a phrase as a keyphrase or non-keyphrase",
        "prob": 0.40499999999999997
    }, {
        "ID": 1877,
        "phrase": "5, using nine different configurations, is more significant and interesting than a cursory examination of several alternative machine learning algorithms",
        "prob": 0.5352941176470588
    }, {
        "ID": 1880,
        "phrase": "introduction the most common learning paradigm in machine learning research is known as supervised learning from examples",
        "prob": 0.20666666666666664
    }, {
        "ID": 1885,
        "phrase": "introduction a significant area of research in machine learning involves empirical tests of algorithms that learn to classify",
        "prob": 0.31875
    }, {
        "ID": 1888,
        "phrase": " other researchers have applied machine learning techniques to jet engine diagnosis",
        "prob": 0.425
    }, {
        "ID": 1888,
        "phrase": " montgomery  [12]  has applied machine learning techniques to the diagnosis of aircraft gas turbine engine faults",
        "prob": 0.33999999999999997
    }, {
        "ID": 1893,
        "phrase": " a strongly biased machine learning system is like an organism that emphasizes instinctive behaviors",
        "prob": 0.2928571428571428
    }, {
        "ID": 1893,
        "phrase": " a weakly biased machine learning system is like an organism that emphasizes learned behaviors",
        "prob": 0.2928571428571428
    }, {
        "ID": 1893,
        "phrase": " for example, in machine learning, the problem of learning to classify accurately is simpler than the problem of learning to classify with low cost",
        "prob": 0.3588235294117647
    }, {
        "ID": 2124,
        "phrase": " generating p-cfg's by machine learning) \n table ",
        "prob": 0.34444444444444444
    }, {
        "ID": 2128,
        "phrase": " with help of a machine learning techniques, this method will give a classification of developmental biological data as well as any varying data during a certain period and the classification can be applied for diagnosis of a disease",
        "prob": 0.4826086956521739
    }, {
        "ID": 2333,
        "phrase": " what can be said about machine learning? in machine learning one tries to build and understand systems which learn from past data and make good prediction, which are able to generalize, act intelligently, ",
        "prob": 0.39565217391304347
    }, {
        "ID": 2333,
        "phrase": "1 on the foundations of machine learning ",
        "prob": 0.3
    }, {
        "ID": 2468,
        "phrase": " logged information could be used for machine learning, which could occur offline or online, depending on the agent business logic",
        "prob": 0.33888888888888885
    }, {
        "ID": 2481,
        "phrase": " ignoring negative interactions may cause several problems in machine learning and statistics",
        "prob": 0.2928571428571428
    }, {
        "ID": 2482,
        "phrase": " ignoring negative interactions may cause several problems in machine learning and statistics",
        "prob": 0.2928571428571428
    }, {
        "ID": 2521,
        "phrase": " since these agents also learn using machine learning algorithms we are left with some hope that we might someday be able to understand the complex dynamics of these type of systems",
        "prob": 0.29047619047619044
    }, {
        "ID": 2747,
        "phrase": " mixed-initiative interaction (mii) has been well studied by the speech interfaces, artificial intelligence planning, and discourse analysis communities  [2]  but has only recently begun to be investigated in web interactions  [34] ",
        "prob": 0.2652173913043479
    }, {
        "ID": 2795,
        "phrase": " in what follows, we will use arxiv data to illustrate how machine learning methods can be used to analyze, structure, maintain, and evolve a large online corpus of academic literature",
        "prob": 0.5499999999999999
    }, {
        "ID": 2795,
        "phrase": " \n arxiv benchmarks before using the machine learning framework to identify new subject area content, we first assessed its performance on the existing (author-provided) category classifications",
        "prob": 0.2652173913043478
    }, {
        "ID": 2795,
        "phrase": " we see further that machine learning tools can characterize a subdomain and thereby help accelerate its growth, via the interaction of an information resource with the social system of its practitioners",
        "prob": 0.3857142857142857
    }, {
        "ID": 2795,
        "phrase": "we illustrate the use of machine learning techniques to analyze, structure, maintain, and evolve a large online corpus of academic literature",
        "prob": 0.6722222222222222
    }, {
        "ID": 2941,
        "phrase": " although ml algorithms allow the detection and extraction of interesting patterns of data for several kinds of problems, most of these algorithms provide an output based on quantitative evidence (i",
        "prob": 0.6409090909090909
    }, {
        "ID": 2941,
        "phrase": " although ml algorithms allow the detection and extraction of interesting patterns of data for several kinds of problems, most of these algorithms are based on quantitative reasoning, as they rely on training data in order to infer so-called target functions",
        "prob": 0.6586206896551724
    }, {
        "ID": 2942,
        "phrase": " although ml algorithms allow the detection and extraction of interesting patterns of data for several kinds of problems, most of these algorithms provide an output based on quantitative evidence (i",
        "prob": 0.6863636363636364
    }, {
        "ID": 2942,
        "phrase": " although ml algorithms allow the detection and extraction of interesting patterns of data for several kinds of problems, most of these algorithms are based on quantitative reasoning, as they rely on training data in order to infer so-called target functions",
        "prob": 0.6241379310344828
    }, {
        "ID": 3095,
        "phrase": " in machine learning terms, spammers have a strong interest in making the \"spam\" and \"legitimate\" classes indistinguishable",
        "prob": 0.20666666666666667
    }, {
        "ID": 3208,
        "phrase": " it is also closely relevant to other fields, such as machine learning and data mining",
        "prob": 0.2818181818181818
    }, {
        "ID": 3249,
        "phrase": " second, machine learning techniques can be used to predict further refactorings based on those already applied",
        "prob": 0.43571428571428567
    }, {
        "ID": 3418,
        "phrase": " beyond that, dbmss have a framework for data mining and machine learning algorithms",
        "prob": 0.3416666666666666
    }, {
        "ID": 3443,
        "phrase": " machine learning algorithms that are trying to become reviewers have the difficult, but interesting, task of trying to analyze an article's content to predict if it should be accepted",
        "prob": 0.4789473684210526
    }, {
        "ID": 3474,
        "phrase": " the tracking data from the pda is integrated with previous tracking data, and the machine learning routines use time and location information to 1) determine the user's significant places, 2) calculate travel times between these places, and 3) to generate a probabilistic schedule (mschedule) for the user",
        "prob": 0.4225806451612903
    }, {
        "ID": 3499,
        "phrase": " \n outlier detection from data outlier detection problems come in several different flavors within different applicative settings, mainly investigated in the area of statistics, machine learning and knowledge discovery in databases",
        "prob": 0.5807692307692307
    }, {
        "ID": 3500,
        "phrase": " \n outlier detection from data outlier detection problems come in several different varieties within different settings, mainly investigated in the area of statistics, machine learning and knowledge discovery in databases",
        "prob": 0.604
    }, {
        "ID": 3600,
        "phrase": " in each case, the communication system uses machine learning techniques to model the state of social interaction in the voice channel, and then adapts the channel to facilitate interaction",
        "prob": 0.29047619047619044
    }, {
        "ID": 3708,
        "phrase": " there may be more than one plan that accomplishes a task, but a posterior decision system should be able to determine, eventually based on machine learning, the one that achieves the best performance, based on the available information and prediction horizon",
        "prob": 0.284
    }, {
        "ID": 3959,
        "phrase": " ist -2001-37574 12 \n data mining techniques for textual data in the most general sense, data mining is an analytical process performed on a dataset and using techniques based on statistics, machine learning, information theory and artificial intelligence  [berthold99]   \n clustering techniques clustering is one of the core data mining techniques",
        "prob": 0.6028571428571429
    }, {
        "ID": 3959,
        "phrase": " [keim02] prompts for an integration of existing visualization techniques and other techniques of statistics, machine learning, operations research and simulation",
        "prob": 0.5352941176470588
    }, {
        "ID": 3971,
        "phrase": " \n voting algorithms and the context the areas of social choice theory and machine learning are full of algorithms by which a collective can aggregate the individual perspectives of its members in order to yield a collective perspective  [1] ",
        "prob": 0.2125
    }, {
        "ID": 4111,
        "phrase": " relevant for the analysis of implicit information is the interpretation of the internal structure of web pages: which pieces of information are embedded in which  1  xdoc stands for x ml based document processing",
        "prob": 0.2772727272727273
    }, {
        "ID": 4123,
        "phrase": " the tools would do data mining and machine learning on the data, and would make it easy to script workflows that analyze the data",
        "prob": 0.5055555555555555
    }, {
        "ID": 4123,
        "phrase": " in addition, data analysis using data cubes has made huge advances, and now efforts are focused on integrating machine learning algorithms that infer trends, do data clustering, and detect anomalies",
        "prob": 0.444
    }, {
        "ID": 4126,
        "phrase": " tools that encapsulate the best statistical algorithms, the best machine learning algorithms and the best data visualization are at your disposal to make you more productive and a better scientist",
        "prob": 0.6238095238095238
    }, {
        "ID": 4126,
        "phrase": " (2) data analysis experts who are skilled at statistical analysis, data mining algorithms, and machine learning algorithms, or just algorithms in general",
        "prob": 0.5611111111111111
    }, {
        "ID": 4407,
        "phrase": " how about the commutator of the covariant derivative on a vector field? here it is: (\u2207 k \u2207 l \u2212 \u2207 l \u2207 k ) x j = \u2202 \u2202x k \u2207 l x j + \u03b3 mk j (\u2207 l x m ) \u2212 \u03b3 lk m \u2207 m x j \u2212 \u2202 \u2202x l \u2207 k x j \u2212 \u03b3 ml j (\u2207 k x m ) + \u03b3 kl m \u2207 m x j = \u2202 2 \u2202x k \u2202x l \u2212 \u2202 2 \u2202x l \u2202x k x j + \u2202 \u2202x k \u03b3 hl j x h \u2212 \u2202 \u2202x l \u03b3 hk j x h + \u03b3 mk j \u2202x m \u2202x l \u2212 \u03b3 ml j \u2202x m \u2202x k + \u03b3 mk j \u03b3 hl m x h \u2212 \u03b3 ml j \u03b3 hk m x h + (\u03b3 kl m \u2212 \u03b3 lk m ) \u2207 m x j = \u2202\u03b3 hl j \u2202x k x h + \u03b3 hl j \u2202x h \u2202x k \u2212 \u2202\u03b3 j hk \u2202x l x h \u2212 \u03b3 hk j \u2202x h \u2202x l + \u03b3 mk j \u2202x m \u2202x l \u2212 \u03b3 ml j \u2202x m \u2202x k + \u03b3 mk j \u03b3 hl m x h \u2212 \u03b3 ml j \u03b3 hk m x h + (\u03b3 kl m \u2212 \u03b3 lk m ) \u2207 m x j = \u2202\u03b3 hl j \u2202x k \u2212 \u2202\u03b3 hk j \u2202x l + \u03b3 mk j \u03b3 hl m \u2212 \u03b3 ml j \u03b3 hk m x h + (\u03b3 kl m \u2212 \u03b3 lk m ) \u2207 m x j (36) the second part of this result we already recognize: it's the torsion again",
        "prob": 0.6346938775510205
    }, {
        "ID": 4408,
        "phrase": " how about the commutator of the covariant derivative on a vector field? here it is: (\u2207 k \u2207 l \u2212 \u2207 l \u2207 k ) x j = \u2202 \u2202x k \u2207 l x j + \u03b3 mk j (\u2207 l x m ) \u2212 \u03b3 lk m \u2207 m x j \u2212 \u2202 \u2202x l \u2207 k x j \u2212 \u03b3 ml j (\u2207 k x m ) + \u03b3 kl m \u2207 m x j = \u2202 2 \u2202x k \u2202x l \u2212 \u2202 2 \u2202x l \u2202x k x j + \u2202 \u2202x k \u03b3 hl j x h \u2212 \u2202 \u2202x l \u03b3 hk j x h + \u03b3 mk j \u2202x m \u2202x l \u2212 \u03b3 ml j \u2202x m \u2202x k + \u03b3 mk j \u03b3 hl m x h \u2212 \u03b3 ml j \u03b3 hk m x h + (\u03b3 kl m \u2212 \u03b3 lk m ) \u2207 m x j = \u2202\u03b3 hl j \u2202x k x h + \u03b3 hl j \u2202x h \u2202x k \u2212 \u2202\u03b3 j hk \u2202x l x h \u2212 \u03b3 hk j \u2202x h \u2202x l + \u03b3 mk j \u2202x m \u2202x l \u2212 \u03b3 ml j \u2202x m \u2202x k + \u03b3 mk j \u03b3 hl m x h \u2212 \u03b3 ml j \u03b3 hk m x h + (\u03b3 kl m \u2212 \u03b3 lk m ) \u2207 m x j = \u2202\u03b3 hl j \u2202x k \u2212 \u2202\u03b3 hk j \u2202x l + \u03b3 mk j \u03b3 hl m \u2212 \u03b3 ml j \u03b3 hk m x h + (\u03b3 kl m \u2212 \u03b3 lk m ) \u2207 m x j (36) the second part of this result we already recognize: it's the torsion again",
        "prob": 0.6346938775510205
    }, {
        "ID": 4552,
        "phrase": " studies comparing rdr to machine learning techniques have shown that rdr systems converge and end up with similar sized knowledge bases as those created by machine learning techniques  [4, 22]  and that they cannot be compressed much by simple reorganisation  [23] ",
        "prob": 0.19615384615384615
    }, {
        "ID": 4552,
        "phrase": " data mining -practical machine learning tools and techniques with java implementations",
        "prob": 0.3923076923076923
    }, {
        "ID": 4716,
        "phrase": " due to the weakness of the current techniques to exploit large data repositories and the complexity of the data being collected, a new discipline known as data mining is emerging in the intersection of artificial intelligence, databases and statistics",
        "prob": 0.4653846153846154
    }, {
        "ID": 5130,
        "phrase": " on the other hand, principles and ideas from universal learning can be of immediate use, and of course machine learning research aims at exploring and establishing more and more general concepts and algorithms",
        "prob": 0.3857142857142857
    }, {
        "ID": 5568,
        "phrase": " third, machine learning techniques could in principle be applied to find simplified approximate or reduced models of emergent phenomena within complex domain models",
        "prob": 0.18636363636363634
    }, {
        "ID": 5768,
        "phrase": " to better understand human intellectual activity (thinking, decisionmaking, and learning) and to build artificial intelligence, we have to be able to work with a variety of schema types",
        "prob": 0.255
    }, {
        "ID": 5843,
        "phrase": " \n experimental results a previous version of seamless included generic methods for synthesis and machine learning which were devised independently of the data structure used for knowledge encoding",
        "prob": 0.2318181818181818
    }, {
        "ID": 5845,
        "phrase": " another concern of the ml and pr communities is to develop learning algorithms that generate simple solutions",
        "prob": 0.2733333333333333
    }, {
        "ID": 6398,
        "phrase": " what is the source of purposes then? are they preset a priori or do they appear during vital activities of an organism? what is the mechanism of their appearance in the latter case? the notion of \"learning\" has been formalized most in the theory of the artificial intelligence",
        "prob": 0.18636363636363634
    }, {
        "ID": 6572,
        "phrase": " machine learning, the computer science branch of statistics, often deals with very large model classes",
        "prob": 0.4066666666666666
    }, {
        "ID": 6603,
        "phrase": " appearing in w4: learning in web search, at the 22 nd international conference on machine learning, bonn, germany, 2005",
        "prob": 0.20666666666666667
    }, {
        "ID": 6604,
        "phrase": " in a web-based search engine, we view the presentation of results to users as part of an interactive process that can also be designed to provide unbiased data for machine learning purposes",
        "prob": 0.41363636363636364
    }, {
        "ID": 6635,
        "phrase": " \n ontological representation there are various meanings that the term ontology can have in ai  [13] ",
        "prob": 0.31
    }, {
        "ID": 6954,
        "phrase": " in order to assist the biologists in their daily bibliographical work, the extraplodocs project 1 develops the natural language processing and machine learning tools that enable to build focused information extraction systems in genomics (geneprotein interaction, gene fonctionalities, gene homologies, etc",
        "prob": 0.396969696969697
    }, {
        "ID": 7286,
        "phrase": "  [29]  applied machine learning tools to whois and bgp data to classify ass into several different classes, such as tier-1 isps, tier-2 isps, ixps, universities, customer ass, and so on",
        "prob": 0.8374999999999999
    }, {
        "ID": 7287,
        "phrase": "  [18]  applied machine learning tools to whois and bgp data to classify ass into several different classes, such as tier-1 isps, tier-2 isps, ixps, universities, customer ass, and so on",
        "prob": 0.7958333333333333
    }, {
        "ID": 7288,
        "phrase": "  [28]  applied machine learning tools to the best available data from the internet registry (whois) and routing (border gateway protocol (bgp)) systems to classify ass into several different classes, such as tier-1 isps, tier-2 isps, internet exchange points, universities, customer ass, and so on",
        "prob": 0.6885714285714286
    }, {
        "ID": 7333,
        "phrase": " the care taken in the technical aspects of data collection is meant to facilitate its use as machine learning training data, not the collection of reportable descriptive statistics, for which we do not have a sufficiently large or diverse corpus",
        "prob": 0.7958333333333333
    }, {
        "ID": 7334,
        "phrase": " the care taken in the technical aspects of data collection is meant to facilitate its use as machine learning training data, not the collection of reportable descriptive statistics, for which we do not have a sufficiently large or diverse corpus",
        "prob": 0.7541666666666667
    }, {
        "ID": 7593,
        "phrase": " the caderige project aims at designing and integrating natural language processing (nlp) and machine learning (ml) techniques to explore, analyze and extract targeted information in biological textual databases",
        "prob": 0.244
    }, {
        "ID": 7593,
        "phrase": " the extraction patterns are thus easier to acquire or learn, more abstract and easier to maintain beyond extraction patterns, it is also possible to acquire from the corpus, via ml methods, a part of the knowledge necessary for text normalization as shown here",
        "prob": 0.3964285714285714
    }, {
        "ID": 7593,
        "phrase": " the aim here is to build training corpus to which various techniques of nlp and ml are applied in order to acquire efficient event-based extraction patterns",
        "prob": 0.45499999999999996
    }, {
        "ID": 7593,
        "phrase": " this project involves teams from different areas (biology, machine learning, natural language processing) in order to develop highlevel analysis tools for extracting structured information from biological bibliographical databases, especially medline",
        "prob": 0.3964285714285714
    }, {
        "ID": 7606,
        "phrase": " 2005 ] that uses machine learning techniques to combine the results of several aspect mining techniques",
        "prob": 0.36428571428571427
    }, {
        "ID": 7607,
        "phrase": " 2005 ] which uses machine learning techniques to combine the results of several aspect mining techniques",
        "prob": 0.65
    }, {
        "ID": 8111,
        "phrase": " spatio-temporal machine learning mostly focuses on clustering, outlier detection, denoising, and trend analysis",
        "prob": 0.56875
    }, {
        "ID": 8166,
        "phrase": " we have concluded that while most of the fundamental ai arsenal needed is already available significant applied research is required for the establishment of tools that will streamline the experimentation process",
        "prob": 0.4263157894736842
    }, {
        "ID": 8247,
        "phrase": " the resultant learning aims and response demands placed on a natural entity are thus different from what is generally provided to an artificial intelligence mechanism or entity, static or mobile",
        "prob": 0.2772727272727273
    }, {
        "ID": 8248,
        "phrase": " the other reason is that ai entities find it easier to infer than cognize, which is in itself a reflection of their design sources and its aims",
        "prob": 0.22142857142857145
    }, {
        "ID": 9078,
        "phrase": " few advanced audio browsers use either shortcut commands or machine learning to identify sections in web pages and probable interaction workflows",
        "prob": 0.755
    }, {
        "ID": 9078,
        "phrase": "tremendous research effort was invested in audio browsers and machine learning techniques to decode the structure of web pages in order to put them into an audio format",
        "prob": 0.8142857142857142
    }, {
        "ID": 9079,
        "phrase": " few advanced audio browsers use either shortcut commands or machine learning to identify sections in web pages and probable interaction workflows",
        "prob": 0.755
    }, {
        "ID": 9079,
        "phrase": "tremendous research effort was invested in audio browsers and machine learning techniques to decode the structure of web pages in order to put them into an audio format",
        "prob": 0.8142857142857142
    }, {
        "ID": 9080,
        "phrase": " few advanced audio browsers use either shortcut commands or machine learning to identify sections in web pages and the most probable interaction workflows",
        "prob": 0.755
    }, {
        "ID": 9080,
        "phrase": "tremendous research effort was invested in audio browsers and machine learning techniques to decode the structure of web pages in order to put them into an audio format",
        "prob": 0.8142857142857142
    }, {
        "ID": 9081,
        "phrase": " few advanced browsers use machine learning algorithms to classify objects on the web page and learn browsing behaviors, have multimodal input and outputs and are able to synchronize between the graphical and audio modalities to interact with the web page",
        "prob": 0.7535714285714286
    }, {
        "ID": 9082,
        "phrase": " few advanced browsers use machine learning algorithms to classify objects on the web page and learn browsing behaviors, have multimodal input and outputs and are able to synchronize between the graphical and audio modalities to interact with the web page",
        "prob": 0.7892857142857143
    }, {
        "ID": 9083,
        "phrase": " few advanced browsers use machine learning algorithms to classify objects on the web page and learn browsing behaviors, have multimodal input and outputs and are able to synchronize between the graphical and audio modalities to interact with the web page",
        "prob": 0.7535714285714286
    }, {
        "ID": 9254,
        "phrase": "introduction current data collection technology provides a unique challenge and opportunity for automated machine learning techniques",
        "prob": 0.41764705882352937
    }, {
        "ID": 9254,
        "phrase": " this is fisher's famous iris data, which has been extensively studied in the statistics and machine learning literature",
        "prob": 0.36428571428571427
    }, {
        "ID": 9294,
        "phrase": " most machine learning research, however, treats the learner as a passive recipient of data to be processed",
        "prob": 0.36428571428571427
    }, {
        "ID": 9298,
        "phrase": " `real-world' learning tasks are de ned by people for use with machine learning systems",
        "prob": 0.23846153846153847
    }, {
        "ID": 9310,
        "phrase": " machine learning has also been used in several other areas of discourse analysis",
        "prob": 0.3727272727272727
    }, {
        "ID": 9312,
        "phrase": "introduction empirical learning is the sub eld of ai that develops algorithms for constructing theories from data",
        "prob": 0.23846153846153847
    }, {
        "ID": 9323,
        "phrase": " analogous to anytime planning techniques  (dean & boddy, 1988) , we believe machine learning researchers should create better anytime learning algorithms",
        "prob": 0.2157894736842105
    }, {
        "ID": 9323,
        "phrase": ")  these domains are available at the university of wisconsin machine learning (uw-ml) site via the world wide web (ftp://ftp",
        "prob": 0.2833333333333333
    }, {
        "ID": 9331,
        "phrase": " we anticipate that this and other machine learning/discovery techniques (e",
        "prob": 0.3875
    }, {
        "ID": 9343,
        "phrase": " this would doubtless best be achieved by integrating the machine learning algorithms with current database management tools|a topic of considerable interest in the data mining community  (fayyad et al",
        "prob": 0.30869565217391304
    }, {
        "ID": 9553,
        "phrase": " this problem has already been investigated in the area of machine learning and related fields",
        "prob": 0.3416666666666666
    }, {
        "ID": 9565,
        "phrase": " using ai techniques, adaptive agents are able to judge their results, then modify their behavior (and thus their internal structure) to improve their perceived fitness",
        "prob": 0.3736842105263158
    }, {
        "ID": 9566,
        "phrase": " using ai techniques, adaptive agents are able to judge their results, then modify their behavior (and thus their internal structure) to improve their perceived fitness",
        "prob": 0.3736842105263158
    }, {
        "ID": 9599,
        "phrase": " machine learning for text-categorization has been applied to content-based recommending of web pages  [25]  and newsgroup messages  [15] ; however, to our knowledge has not previously been applied to book recommending",
        "prob": 0.5954545454545455
    }, {
        "ID": 9602,
        "phrase": " \n trilogy ontology \n ontology description the word \"ontology\" seems to generate a lot of controversy in the ai world",
        "prob": 0.4066666666666666
    }]
}, {
    "topic_id": 29,
    "top_words": ["functions", "probability", "boolean", "model", "universal", "prior", "symmetric", "possible", "distribution", "environment", "functional", "true", "form", "lower", "function"],
    "phrases": [{
        "ID": 141,
        "phrase": " the intention of this work is to introduce the universal ai model and give an in breadth analysis",
        "prob": 0.425
    }, {
        "ID": 141,
        "phrase": " ai model for known deterministic environment: let us define for the chronological turing machine p a partial function also named p : x * \u2192 y * with y 1:k = p(x <k ) where y 1:k is the output of turing machine p on input x <k in cycle k, i",
        "prob": 0.6565217391304348
    }, {
        "ID": 141,
        "phrase": " \n ai model for known prior probability: let us now weaken our assumptions by replacing the environment q with a probability distribution \u00b5(q) over chronological functions",
        "prob": 0.7833333333333333
    }, {
        "ID": 141,
        "phrase": " to get our final universal ai model the idea is to replace \u00b5 by the universal probability \u03be, defined later",
        "prob": 0.7214285714285714
    }, {
        "ID": 141,
        "phrase": " equivalence of functional and iterative ai model: the iterative environmental probability \u00b5 is given by the functional form in the following way, \u00b5(yx 1:k ) = q:q(y 1:k )=x 1:k \u00b5(q) (10) as is easy to see",
        "prob": 0.655
    }, {
        "ID": 141,
        "phrase": " all we have to do is to suitably generalize the universal semimeasure \u03be from the last subsection and replace the true but unknown prior probability \u00b5 ai in the ai\u00b5 model by this generalized \u03be ai ",
        "prob": 0.7705882352941176
    }, {
        "ID": 141,
        "phrase": " in the functional formulation we define the universal probability \u03be ai of an environment q just as 2 \u2212l(q) \u03be(q) := 2 \u2212l(q) the definition could not be easier 10 ! 11 collecting the formulas of section 2 and replacing \u00b5(q) by \u03be(q) we get the definition of the ai\u03be system in functional form",
        "prob": 0.6291666666666667
    }, {
        "ID": 141,
        "phrase": " the equivalence of the functional and iterative ai model proven in section 3 is true for every chronological semimeasure \u03c1, esp",
        "prob": 0.5399999999999999
    }, {
        "ID": 141,
        "phrase": " the prior probability \u00b5 ai of the ai\u00b5 model is \u00b5 ai (y 1 x 1 ",
        "prob": 0.4428571428571429
    }, {
        "ID": 141,
        "phrase": " so ai\u03be should allow good sequence prediction for some universal choice of m k and not only for m k = k, which definitely does not suffice for more complicated ai problems",
        "prob": 0.5785714285714285
    }, {
        "ID": 141,
        "phrase": " so the number of wrong predictions e ai n\u03be of system (48) is bounded by e ai n\u03be < 1 \u03b1 = 2 k( \u017c)+o(1) < \u221e (50) for a computable deterministic environment string \u017c1 \u017c2 ",
        "prob": 0.23846153846153847
    }, {
        "ID": 141,
        "phrase": " the environmental prior probability is therefore \u00b5 ai (y 1 x 1 ",
        "prob": 0.3875
    }, {
        "ID": 141,
        "phrase": " the prior probability then is \u00b5 ai (yx 1 ",
        "prob": 0.4428571428571429
    }, {
        "ID": 141,
        "phrase": "yx (r+1)n ) ( 56 ) where we have renamed the prior probability (54) for one game to \u00b5 ai 1 ",
        "prob": 0.31
    }, {
        "ID": 141,
        "phrase": " using the ai\u03be model for game playing: when going from the specific ai\u00b5 model, where the rules of the game have been explicitly modeled into the prior probability \u00b5 ai , to the universal model ai\u03be we have to ask whether these rules can be learned from the assigned credits c k ",
        "prob": 0.364
    }, {
        "ID": 141,
        "phrase": " \u00b5 ai should still be sufficiently separable allowing to formulate and prove good credit bounds for ai\u03be",
        "prob": 0.5461538461538461
    }, {
        "ID": 141,
        "phrase": " more importantly, we want to parallel the other ai classes, like in the sp\u00b5 model, where we always started with a probability distribution \u00b5 that was finally replaced by \u03be to get the universal solomonoff prediction sp\u03be",
        "prob": 0.6714285714285714
    }, {
        "ID": 141,
        "phrase": " if we keep x \u2032 k the ai prior probability is has been defined in (59)",
        "prob": 0.5125000000000001
    }, {
        "ID": 141,
        "phrase": " \u03be tl (yx 1:n ) := \u03c1 : l(\u03c1)\u2264 l \u2227 t(\u03c1)\u2264 t 2 \u2212l(\u03c1) \u03c1(yx 1:n ) (63) let us assume that the true environmental prior probability \u00b5 ai is equal to or sufficiently accurately approximated by a \u03c1 with l(\u03c1) \u2264 l and t(\u03c1) \u2264 t with t and l of reasonable size",
        "prob": 0.8049999999999999
    }, {
        "ID": 141,
        "phrase": " roughly speaking, the theorem says, that if there exists a computable solution to some ai problem at all, the explicitly constructed algorithm p * is such a solution",
        "prob": 0.63125
    }, {
        "ID": 141,
        "phrase": " the main remaining problem is the unknown prior probability distribution \u00b5 ai of the environment(s)",
        "prob": 0.5916666666666667
    }, {
        "ID": 141,
        "phrase": " we unified the theory of universal sequence prediction with the decision theoretic agent by replacing the unknown true prior \u00b5 ai by an appropriately generalized universal semimeasure \u03be ai ",
        "prob": 0.705
    }, {
        "ID": 141,
        "phrase": " this form, introduced in section 2, is general enough to include any ai system (and also less intelligent systems)",
        "prob": 0.2928571428571428
    }, {
        "ID": 141,
        "phrase": " we combine both ideas and get a parameterless theory of universal artificial intelligence",
        "prob": 0.425
    }, {
        "ID": 477,
        "phrase": " we define the generalized universal probability \u03be ai as the 2 \u2212l(q) weighted sum over all chronological programs (environments) q which output x 1:k , similar to (4) but with y 1:k provided on the \"input\" tape: \u03be(yx 1:k ) := q:q(y 1:k )=x 1:k 2 \u2212l(q) ",
        "prob": 0.41363636363636364
    }, {
        "ID": 477,
        "phrase": " \u03be ai dominates all chronological enumerable semimeasures \u03be(yx 1:n ) \u2265 2 \u2212k(\u03c1)\u2212o(1) \u03c1(yx 1:n )",
        "prob": 0.61
    }, {
        "ID": 477,
        "phrase": " roughly speaking, this means that if there exists a computable solution to some ai problem at all, then the explicitly constructed algorithm p * is such a solution",
        "prob": 0.5399999999999999
    }, {
        "ID": 477,
        "phrase": " the ai\u03be tl algorithm should be regarded only as the first step toward a computable universal ai model",
        "prob": 0.3923076923076923
    }, {
        "ID": 1011,
        "phrase": " k m=1 (a mj b mj + a mj b mj ) = 0 1 \u2264 j \u2264 2k (8) equating the coefficients of x j x l , 1 \u2264 j < l \u2264 2k we get k m=1 (a mj b ml + a ml b mj ) = 1 1 \u2264 j < l \u2264 2k (9) let us define vectors y j \u2208 f 2k , 1 \u2264 j \u2264 2k as follows y t j \u2206 = (a 1j , b 1j , a 2j , b 2j , ",
        "prob": 0.505
    }, {
        "ID": 1250,
        "phrase": " we do not know how people generally handle this and, even if we knew, it is not clear that ai systems should react in exactly the same way: people are, after all, notoriously bad with statistical information",
        "prob": 0.355
    }, {
        "ID": 1342,
        "phrase": "p a ::= \u03b8 | a \u2297 a | n i=1 a i | p(x) the forward semantics p(x), {\u03d1} p of a procedure call p(x)\u03d1 in a program p is defined as s p(x) ({\u03d1}), as given by the following function on \u2118(sub), which is recursively defined on program's structure for any \u03c6 \u2208 \u2118(sub): s \u03b8 (\u03c6) = \u03b8 \u2297 \u03c6 s a1\u2297a2 (\u03c6) = s a1 (\u03c6) \u2297 s a2 (\u03c6) s n i=1 ai (\u03c6) = n i=1 s ai (\u03c6) s p(x) (\u03c6) = s a (\u03c6) where p(x) \u2190 a \u226a p ",
        "prob": 0.46249999999999997
    }, {
        "ID": 1894,
        "phrase": " we assume the standard machine learning framework, where examples are represented as vectors in a multidimensional feature space (also known as the attribute-value representation)",
        "prob": 0.2157894736842105
    }, {
        "ID": 2333,
        "phrase": " \u03be ai is not a computable but only an enumerable semimeasure",
        "prob": 0.4428571428571429
    }, {
        "ID": 2333,
        "phrase": " furthermore, the replacement of \u03be ai by time-limited versions  [lv91, lv97] , which is suitable for sequence prediction, has been shown to fail for the ai\u03be model",
        "prob": 0.3588235294117647
    }, {
        "ID": 2333,
        "phrase": " roughly speaking, this means that if there exists a computable solution to some ai problem at all, then the explicitly constructed algorithm p * is such a solution",
        "prob": 0.5399999999999999
    }, {
        "ID": 2333,
        "phrase": " then, the consequences of replacing \u00b5 ai by \u03be ai are considered",
        "prob": 0.3
    }, {
        "ID": 2333,
        "phrase": " the ai\u03be tl algorithm should be regarded only as the first step toward a computable universal ai model",
        "prob": 0.3923076923076923
    }, {
        "ID": 2333,
        "phrase": " if the environment \u00b5 ai is complicated but extra knowledge z makes k(\u00b5 ai |z) small, one can show that a bound for \u03be ai similarly to (1",
        "prob": 0.23846153846153847
    }, {
        "ID": 2333,
        "phrase": " \n ai model for known deterministic environment let us define for the chronological turing machine p a partial function also named p : x * \u2192 y * with y 1:k = p(x <k ) where y 1:k is the output of turing machine p on input x <k in cycle k, i",
        "prob": 0.6565217391304348
    }, {
        "ID": 2333,
        "phrase": " \n ai model for known prior probability let us now weaken our assumptions by replacing the environment q with a probability distribution \u00b5(q) over chronological functions",
        "prob": 0.7833333333333333
    }, {
        "ID": 2333,
        "phrase": " to get our final universal ai model the idea is to replace \u00b5 by the universal probability \u03be, defined later",
        "prob": 0.7214285714285714
    }, {
        "ID": 2333,
        "phrase": "18) \n equivalence of functional and explicit ai model as is clear from their interpretations, the iterative environmental probability \u00b5 relates to the functional form in the following way: proof",
        "prob": 0.6894736842105263
    }, {
        "ID": 2333,
        "phrase": " all we have to do is to suitably generalize the universal semimeasure \u03be = \u03be u from the last subsection and replace the true but unknown prior probability \u00b5 ai in the ai\u00b5 model by this generalized \u03be ai = \u03be ai u ",
        "prob": 0.7705882352941176
    }, {
        "ID": 2333,
        "phrase": " in the functional formulation we define the universal probability \u03be ai of an environment q just as 2 \u2212l(q) \u03be(q) := 2 \u2212l(q) the definition could not be easier 1 ! 2 collecting the formulas of section 4",
        "prob": 0.6722222222222222
    }, {
        "ID": 2333,
        "phrase": " the equivalence of the functional and iterative ai model proven in section 4",
        "prob": 0.51
    }, {
        "ID": 2333,
        "phrase": " the main remaining problem is the unknown prior probability distribution \u00b5 ai of the environment(s)",
        "prob": 0.5916666666666667
    }, {
        "ID": 2333,
        "phrase": " we unified the theory of universal sequence prediction with the decision theoretic agent by replacing the unknown true prior \u00b5 ai by an appropriately generalized universal semimeasure \u03be ai ",
        "prob": 0.8049999999999999
    }, {
        "ID": 2333,
        "phrase": " \u03be ai alt (yx 1:n ):=m(yx 1:n )/ x 1:n m(yx 1:n ), where m is solomonoff's prior (2",
        "prob": 0.5666666666666667
    }, {
        "ID": 2333,
        "phrase": " \n repetition of the ai\u00b5/\u03be models in the last chapter we unified sequential decision theory with the theory of universal induction to a model of artificial intelligence, which we claimed to be universal and superior to any other model in various senses",
        "prob": 0.25416666666666665
    }, {
        "ID": 2333,
        "phrase": " the main remaining problem is the unknown prior probability distribution \u00b5 ai of the environment(s)",
        "prob": 0.5916666666666667
    }, {
        "ID": 2333,
        "phrase": " we unified the theory of universal sequence prediction with the decision theoretic agent by replacing the unknown true prior \u00b5 ai by an appropriately generalized universal semimeasure \u03be ai ",
        "prob": 0.755
    }, {
        "ID": 2333,
        "phrase": " the prior probability \u00b5 ai of the ai\u00b5 model is \u00b5 ai (y 1 x 1 ",
        "prob": 0.4428571428571429
    }, {
        "ID": 2333,
        "phrase": " so ai\u03be should allow good sequence prediction for some universal choice of m k and not only for m k = k, which definitely does not suffice for more complicated ai problems",
        "prob": 0.5071428571428571
    }, {
        "ID": 2333,
        "phrase": " the environmental prior probability is therefore  \u00b5 ai (y 1 x 1 ",
        "prob": 0.3875
    }, {
        "ID": 2333,
        "phrase": " \u00b5 ai should still be sufficiently separable allowing us to formulate and prove good reward bounds for ai\u03be",
        "prob": 0.5785714285714285
    }, {
        "ID": 2333,
        "phrase": " more importantly, we want to parallel the other ai classes, like in the sp\u00b5 model, where we always started with a probability distribution \u00b5 that was finally replaced by \u03be to get the universal solomonoff prediction sp\u03be",
        "prob": 0.5761904761904761
    }, {
        "ID": 2333,
        "phrase": " if we keep x \u2032 k the ai prior probability is where \u1e8ff m k has been defined in (6",
        "prob": 0.3875
    }, {
        "ID": 2333,
        "phrase": " \n (posterization of prediction errors) [c20u/40o] show \u03be ai (yx 1:n ) \u00d7 \u2265 \u03be sp (z 1:n ), where z k = \u03b4 y k x k , based on a similar idea we construct in section 7",
        "prob": 0.38125
    }, {
        "ID": 2333,
        "phrase": "3) let us assume that the true environmental prior probability \u00b5 ai is equal to or sufficiently accurately approximated by a \u03c1 with l(\u03c1) \u2264 l and t(\u03c1) \u2264 t with t and l of reasonable size",
        "prob": 0.7705882352941176
    }, {
        "ID": 2333,
        "phrase": " roughly speaking, the theorem says, that if there exists a computable solution to some (or all) ai problem(s) at all, the explicitly constructed algorithm p * is such a solution",
        "prob": 0.56875
    }, {
        "ID": 2333,
        "phrase": " \n universal prior knowledge there are people who believe universal ai is not possible, that one has to incorporate some/sufficient prior knowledge",
        "prob": 0.5399999999999999
    }, {
        "ID": 2333,
        "phrase": " after all this one should not forget that most other approaches to ai implicitly or explicitly make the same, and usually even more, assumptions",
        "prob": 0.25833333333333336
    }, {
        "ID": 2333,
        "phrase": "3 equivalence of functional and explicit ai model ",
        "prob": 0.5125000000000001
    }, {
        "ID": 2333,
        "phrase": "3 ai model for known deterministic environment ",
        "prob": 0.5125000000000001
    }, {
        "ID": 2333,
        "phrase": "4 ai model for known prior probability ",
        "prob": 0.5125000000000001
    }, {
        "ID": 2333,
        "phrase": " if \u00b5 ai is the true prior probability, the question now is, what is the behavior \u1e8fai k of the ai\u00b5 agent",
        "prob": 0.31
    }, {
        "ID": 2333,
        "phrase": " \n the number of interesting applications makes this restricted class of ai problems, with time and space bounded environment \u00b5 tl as prior probability, is universal, relative to all ai\u00b5 tl models in the same way as ai\u03be is universal to ai\u00b5 for all enumerable chronological semimeasures \u00b5",
        "prob": 0.37407407407407406
    }, {
        "ID": 2333,
        "phrase": " the intention of this work is to introduce the universal ai model and give an in breadth analysis",
        "prob": 0.425
    }, {
        "ID": 2744,
        "phrase": " \n so far we have shown that ai represents pi with respect to \u03c0 i , for i \u2208 {1a, 1b, ",
        "prob": 0.2333333333333333
    }, {
        "ID": 4115,
        "phrase": " ( 10 ) note that if the (unmodified) ml estimator \u03b8(z n ) exists, then this is equal to l u (z n ) + ln m \u03b8(z n ) (z n )",
        "prob": 0.19090909090909086
    }, {
        "ID": 4389,
        "phrase": " the lower bound proofs for sets work without modifications on lists and bags -we actually do not compare collections except in the definition of ai of the proof of theorem 4",
        "prob": 0.4333333333333333
    }, {
        "ID": 4390,
        "phrase": " the lower bound proofs for sets work without modifications on lists and bags -we actually do not compare collections except in the definition of ai of the proof of theorem 4",
        "prob": 0.5285714285714286
    }, {
        "ID": 5288,
        "phrase": " the ml performance bound given in  [9]  is then used to prove our main result",
        "prob": 0.425
    }, {
        "ID": 5289,
        "phrase": " the ml performance bound given in  [9]  is then used to prove our main result",
        "prob": 0.425
    }, {
        "ID": 5738,
        "phrase": " choosing the ml estimator (183) for \u03bb * , we get c(x (i)|s i\u22121 ) def = \u2212(n \u2212 d + 2) |x (i)| x 2 2 \u2212 x 2 2 \u2212 \u2202 \u2202|x (i)| log \u03c0(\u03b8 * |\u03bb * ) |\u03c8 \u03bb\u03bb (\u03b8 * , \u03bb * )| 1 2 = \u2212(n \u2212 d + 2) |x (i)| x 2 2 \u2212 x 2 2 + (d + 2) |\u03b8 * i | \u03bd\u22121 d j=1 |\u03b8 * j | \u03bd \u2202|\u03b8 * i (x (i))| \u2202|x (i)| , 1 \u2264 i \u2264 d (196) it is easy to see that with a possible exception for the derivative term, all terms in (196) are decreasing functions of |x (i)|",
        "prob": 0.205
    }, {
        "ID": 6308,
        "phrase": ", q (x n ) \u25b3 = p m l (x n ) y n p m l (y n ) , (16) where p m l (x n ) is the ml probability of x n , and the summation is over all possible sequences y n of length n",
        "prob": 0.21000000000000002
    }, {
        "ID": 6502,
        "phrase": " given the constraint (  4 )-(  5 ), the total number 1 of valid inputs for k users with amplitude distribution a and spreading factor n is given as a function of the channel state s : ( ) ( ) { } ( ) 1 1 1 1 , ; , , d k k k k \u03b2 \u03b2 \u03bb \u03b4 \u03b2 \u2212 \u2212 \u2212 \u2212 \u2212 \u221e = = \u2212 \u2212 \u2211 \u222b + i s a s s a ai \u03bbi ",
        "prob": 0.1631578947368421
    }, {
        "ID": 6658,
        "phrase": " q t k is the ml estimator in \u03b8 \u03b4 k k based on z m i( finally, we take as our sequence of universal filtering schemes, indexed by k and \u01eb, x\u01eb univ,k = { x\u01eb q t k ,t }",
        "prob": 0.22142857142857145
    }, {
        "ID": 6676,
        "phrase": " it builds on our previous work  [7] , in which we proved that low-density constructions and ml decoding can saturate the rate-distortion bound for a symmetric bernoulli source",
        "prob": 0.255
    }, {
        "ID": 6676,
        "phrase": " proof of theorem 2 as described in the previous sections, theorems 1 and 2 allow us to establish that the wyner-ziv and gelfand-pinsker bounds can be saturated under ml encoding/decoding",
        "prob": 0.24285714285714283
    }, {
        "ID": 6862,
        "phrase": " substituting (84), (85), and (86) into (83), we obtain nr 0 + nr 1 \u2264 n i=1 i(x ai ; y 1ai |t i , x 1ai ) + i(t i , x 1ai ; y 2ai ) + i(x bi , x 1bi ; y 2bi ) + n\u03b4 1 + n\u03b4 2 (87) finally, we note that all the terms in the bounds (80), (81) and (87) are determined either by the distribution p(t i , x ai , x 1ai , y 1ai , y 2ai ) or by the distribution p(x bi , x 1bi , y 1bi , y 2bi )",
        "prob": 0.205
    }, {
        "ID": 6872,
        "phrase": " \n universal but incomputable ai solomonoff's theoretically optimal universal predictors and their bayesian learning algorithms  [104, 105, 42, 36]  only assume that the reactions of the environment are sampled from an unknown probability distribution \u00b5 contained in a set m of all enumerable distributions-compare text after equation  (1) ",
        "prob": 0.6107142857142858
    }, {
        "ID": 6873,
        "phrase": " \n universal but incomputable ai solomonoff's theoretically optimal universal predictors and their bayesian learning algorithms  [104, 105, 42, 36]  only assume that the reactions of the environment are sampled from an unknown probability distribution \u00b5 contained in a set m of all enumerable distributions-compare text after equation  (1) ",
        "prob": 0.6107142857142857
    }, {
        "ID": 6874,
        "phrase": " \n universal but incomputable ai solomonoff's theoretically optimal universal predictors and their bayesian learning algorithms  [104, 105, 42, 36]  only assume that the reactions of the environment are sampled from an unknown probability distribution \u00b5 contained in a set m of all enumerable distributions-compare text after equation  (1) ",
        "prob": 0.6107142857142858
    }, {
        "ID": 6999,
        "phrase": " for a symmetric distribution q given by q ln ai an\u22121\u2212i = a i , i = 0, 1, \u2022 \u2022 \u2022 , n \u2212 1, where a i \u2208 (0, 1] and n\u22121 i=0 a i = 1, we can compute all source distributions for which the induced initial message distribution p (0) is equal to q",
        "prob": 0.3588235294117647
    }, {
        "ID": 7209,
        "phrase": " (aiii, 8) it complicated to deduce the closed form for ml case when receiver does not know the kind of noise realization, i",
        "prob": 0.25625
    }, {
        "ID": 7210,
        "phrase": " 8) it is complicated to deduce the closed form for the ml case when the receiver does not know the kind of noise realization, i",
        "prob": 0.20666666666666667
    }, {
        "ID": 7326,
        "phrase": " because of the successful algebraic attack to several keystream generators, now it is interested to understand the algebraic immunity ai(f ) of a boolean function f , which is introduced in  [6]  and the general properties of ai of boolean functions are proved in  [6] [7] [8] [9] ",
        "prob": 0.5695652173913043
    }, {
        "ID": 7326,
        "phrase": " it is known that the ai of a n variable boolean function is less than or equal to \u2308 n 2 \u2309",
        "prob": 0.61
    }, {
        "ID": 7326,
        "phrase": " the ai of elementary symmetric boolean functions is explicitly determined and some symmetric functions of maximum possible ai are constructed",
        "prob": 0.74
    }, {
        "ID": 7326,
        "phrase": " all symmetric boolean functions of maximum ai with 6,10,12,14,16 variables are explicitly given",
        "prob": 0.6454545454545454
    }, {
        "ID": 7326,
        "phrase": " some general properties about the ai(f ) and non-linearity n l(f ) of a boolean function f is proved in  [11] [12] [13] [14]  and some general constructions of boolean functions with maximum possible ai based on  [10]  are given in  [14] ",
        "prob": 0.5285714285714286
    }, {
        "ID": 7326,
        "phrase": " we need to recall the following known results about ai of boolean functions",
        "prob": 0.3727272727272727
    }, {
        "ID": 7326,
        "phrase": " as far as our knowledge, there are quite few explicitly given boolean functions with maximal possible ai and people do not know much about the conditions of lower bounds for algebraic immunity of boolean functions",
        "prob": 0.6565217391304348
    }, {
        "ID": 7326,
        "phrase": " \n iii lower bound of ai for symmetric and rotation symmetric boolean functions in this section we use the main result to prove some lower bounds for algebraic immunity of symmetric and rotation symmetric boolean functions",
        "prob": 0.7346153846153846
    }, {
        "ID": 7326,
        "phrase": " from  [10]  and  [14]  we know the following balanced symmetric boolean function of n (n is odd) variables have the maximal possible ai \u2308 n 2 \u2309",
        "prob": 0.7214285714285714
    }, {
        "ID": 7326,
        "phrase": " f (x) = 1, wt(x) < n 2 f (x) = 0, wt(x) < n 2 f (x) = b \u2208 f 2 , wt(x) = n 2 it is clear that the sets s 0 (f ) and s 1 (f ) consist of orbits under all permutations, if we exchange the same elements in these two sets which are the union of orbits under circular actions, we get some rotation symmetric boolean functions and the lower bounds on their ai can be proved by applying theorem 3",
        "prob": 0.7366666666666666
    }, {
        "ID": 7326,
        "phrase": " some rotation symmetric boolean functions with their ai near the maximal possible value \u2308 n 2 \u2309 are constructed",
        "prob": 0.7
    }, {
        "ID": 7326,
        "phrase": " the results are applied to give lower bounds on ai of symmetric boolean functions and rotation symmetric boolean functions, etc",
        "prob": 0.4764705882352941
    }, {
        "ID": 7326,
        "phrase": " some balanced rotation symmetric boolean functions with their ai near the maximum possible value \u2308 n 2 \u2309 are constructed",
        "prob": 0.7214285714285714
    }, {
        "ID": 7327,
        "phrase": " it was proved that the ai of a n variable boolean function is less than or equal to \u2308 n 2 \u2309 (see  [21] ) ",
        "prob": 0.4636363636363636
    }, {
        "ID": 7327,
        "phrase": " however it is also known that there are boolean functions of n variables with their ai equal to the maximal possible value \u2308 n 2 \u2309 (see  [5, 10, 12, 18] )",
        "prob": 0.5785714285714285
    }, {
        "ID": 7327,
        "phrase": " thus it is interesting to know more boolean functions with their ai equal to or near the upper bound \u2308 n 2 \u2309",
        "prob": 0.46923076923076923
    }, {
        "ID": 7327,
        "phrase": " thus it is interested to know the properties of ai of symmetric boolean functions",
        "prob": 0.3727272727272727
    }, {
        "ID": 7327,
        "phrase": " the ai of elementary symmetric boolean functions was explicitly determined and some symmetric functions of maximum possible ai have been constructed",
        "prob": 0.6733333333333333
    }, {
        "ID": 7327,
        "phrase": " we note that theorem 2 can not be applied directly to balanced boolean functions when lower bounding the ai of boolean functions",
        "prob": 0.5399999999999999
    }, {
        "ID": 7327,
        "phrase": " as far as our knowledge, there are quite few explicitly given boolean functions with the maximal possible ai and people do not know much about how to lower bound the algebraic immunity of boolean functions (see  [10, 12, 17, 18] )",
        "prob": 0.7869565217391303
    }, {
        "ID": 7327,
        "phrase": " however if the affine subspaces are taken sufficiently many, this consideration leads to some useful results on the lower bound for the ai of boolean functions",
        "prob": 0.5055555555555555
    }, {
        "ID": 7327,
        "phrase": " \n iii lower bound for ai of symmetric and rotation symmetric boolean functions in this section we use the main result to prove some lower bounds on the algebraic immunity of symmetric and rotation symmetric boolean functions",
        "prob": 0.7346153846153846
    }, {
        "ID": 7327,
        "phrase": " it is observed from corollary 4 and example 2, for a symmetric boolean function f with the property that most vectors in s 1 (f ) have their weight less than \u2308 n 2 \u2309 and most vectors in s 0 (f ) have their weight larger than \u2308 n 2 \u2309, its ai is relatively high",
        "prob": 0.32105263157894737
    }, {
        "ID": 7327,
        "phrase": " from  [5]  and  [8]  we know the following balanced symmetric boolean function f of n (n is odd) variables has the maximal possible ai \u2308 n 2 \u2309",
        "prob": 0.7214285714285714
    }, {
        "ID": 7327,
        "phrase": " f (x) = 1, wt(x) < n 2 f (x) = 0, wt(x) < n 2 f (x) = b \u2208 f 2 , wt(x) = n 2 if we exchange some orbits under circular actions in the two sets s 0 (f ) and s 1 (f ), we get some rotation symmetric boolean functions and the lower bound on their ai can be proved by applying theorem 3",
        "prob": 0.7434782608695651
    }, {
        "ID": 7327,
        "phrase": " some rotation symmetric boolean functions with their ai near the maximal possible value \u2308 n 2 \u2309 are constructed",
        "prob": 0.7
    }, {
        "ID": 7327,
        "phrase": " the results are applied to give lower bounds on the ai of symmetric boolean functions and rotation symmetric boolean functions",
        "prob": 0.69375
    }, {
        "ID": 7327,
        "phrase": " some balanced rotation symmetric boolean functions with their ai near the maximum possible value \u2308 n 2 \u2309 are constructed",
        "prob": 0.7214285714285714
    }, {
        "ID": 7328,
        "phrase": " it was proved that the ai of a n variable boolean function is less than or equal to \u2308 n 2 \u2309 (see  [21] ) ",
        "prob": 0.5545454545454546
    }, {
        "ID": 7328,
        "phrase": " however it is also known that there are boolean functions of n variables with their ai equal to the maximal possible value \u2308 n 2 \u2309 (see  [5] ,  [10] ,  [12] ,  [18] )",
        "prob": 0.43571428571428567
    }, {
        "ID": 7328,
        "phrase": " thus it is interesting to know more boolean functions with their ai equal to or near the upper bound \u2308 n 2 \u2309",
        "prob": 0.3923076923076923
    }, {
        "ID": 7328,
        "phrase": " thus it is interested to know the properties of ai of symmetric boolean functions",
        "prob": 0.3727272727272727
    }, {
        "ID": 7328,
        "phrase": " the ai of elementary symmetric boolean functions was explicitly determined and some symmetric functions of maximum possible ai have been constructed",
        "prob": 0.74
    }, {
        "ID": 7328,
        "phrase": " we note that theorem 2 can not be applied directly to balanced boolean functions when lower bounding the ai of boolean functions",
        "prob": 0.6066666666666667
    }, {
        "ID": 7328,
        "phrase": " as far as our knowledge, there are quite few explicitly given boolean functions with the maximal possible ai and people do not know much about how to lower bound the algebraic immunity of boolean functions (see  [10] ,  [12] ,  [17] ,  [18] )",
        "prob": 0.7434782608695651
    }, {
        "ID": 7328,
        "phrase": " however if the affine subspaces are taken sufficiently many, this consideration leads to some useful results on the lower bound for the ai of boolean functions",
        "prob": 0.5611111111111111
    }, {
        "ID": 7328,
        "phrase": " lower bound for ai of symmetric and rotation symmetric boolean functions in this section we use the main result to prove some lower bounds on the algebraic immunity of symmetric and rotation symmetric boolean functions",
        "prob": 0.8039999999999999
    }, {
        "ID": 7328,
        "phrase": " it is observed from corollary 4 and example 2, for a symmetric boolean function f with the property that most vectors in s 1 (f ) have their weight less than \u2308 n 2 \u2309 and most vectors in s 0 (f ) have their weight larger than \u2308 n 2 \u2309, its ai is relatively high",
        "prob": 0.32105263157894737
    }, {
        "ID": 7328,
        "phrase": " from  [5]  and  [8]  we know the following balanced symmetric boolean function f of n (n is odd) variables has the maximal possible ai \u2308 n 2 \u2309",
        "prob": 0.7214285714285714
    }, {
        "ID": 7328,
        "phrase": " f (x) = 1, wt(x) < n 2 f (x) = 0, wt(x) < n 2 f (x) = b \u2208 f 2 , wt(x) = n 2 if we exchange some orbits under circular actions in the two sets s 0 (f ) and s 1 (f ), we get some rotation symmetric boolean functions and the lower bound on their ai can be proved by applying theorem 3",
        "prob": 0.7869565217391303
    }, {
        "ID": 7328,
        "phrase": " some rotation symmetric boolean functions with their ai near the maximal possible value \u2308 n 2 \u2309 are constructed",
        "prob": 0.7
    }, {
        "ID": 7328,
        "phrase": " the results are applied to give lower bounds on the ai of symmetric boolean functions and rotation symmetric boolean functions",
        "prob": 0.56875
    }, {
        "ID": 7328,
        "phrase": " some balanced rotation symmetric boolean functions with their ai near the maximum possible value \u2308 n 2 \u2309 are constructed",
        "prob": 0.7214285714285714
    }, {
        "ID": 7408,
        "phrase": " because \u03c3 \u2032 \u2704 ai \u03b8 \u2032 , it suffices to prove that l\u03c3 \u2032 \u2192 ai r\u03c3 \u2032 ",
        "prob": 0.35000000000000003
    }, {
        "ID": 7856,
        "phrase": " alternatively, this can be seen from first principles for ml decoding by observing that any false path bi 1 can be divided into a true prefix b j\u22121 1 and a false suffix bi j ",
        "prob": 0.17222222222222222
    }, {
        "ID": 7858,
        "phrase": " further, since the ml and universal exponents are the same for the whole rate region we can define e sw,x (r x , r y ) as e sw,x (r x , r y ) = e ml,sw,x (r x , r y ) = e un,sw,x (r x , r y ), and can similarly define e sw,y (r x , r y )",
        "prob": 0.2157894736842105
    }, {
        "ID": 7870,
        "phrase": " since no prior distribution over the b i is assumed, the following ml strategy is used: \u2022 for every possible bit-sequence bi+d 1 , compute the log-likelihood ln p(y ([0, (i + d)\u03c4 ]) = y([0, (i + d)\u03c4 ])|b i+d 1 = bi+d 1 ) ",
        "prob": 0.2541666666666667
    }, {
        "ID": 7921,
        "phrase": " let us start with the most successful recent development in machine learning, support vector machines (  [18, 19] , with a key idea going back to the generalized portrait method  [20] )",
        "prob": 0.2318181818181818
    }, {
        "ID": 8247,
        "phrase": " patterns, an idea familiar to ai people, arise from and are endemic to stable environments",
        "prob": 0.25833333333333336
    }, {
        "ID": 8555,
        "phrase": " \n ai model for known deterministic environment let us define for the chronological turing machine p a partial function also named p : x * \u2192 y * with y 1:k = p(x <k ), where y 1:k is the output of turing machine p on input x <k in cycle k, i",
        "prob": 0.6130434782608696
    }, {
        "ID": 8555,
        "phrase": " \n ai model for known prior probability let us now weaken our assumptions by replacing the deterministic environment q with a probability distribution \u00b5(q) over chronological functions",
        "prob": 0.7421052631578947
    }, {
        "ID": 8555,
        "phrase": " to get our final universal ai model the idea is to replace \u00b5 by the universal probability \u03be, defined later",
        "prob": 0.7214285714285714
    }, {
        "ID": 8555,
        "phrase": " +r m )\u00b5(yx <k yx k:m ) |y 1:m =p(x<m) (12) as is clear from their interpretations, the iterative environmental probability \u00b5 relates to the functional form in the following way: \u00b5(yx 1:k ) = q:q(y 1:k )=x 1:k \u00b5(q) (13) with this identification one can show  [hut00, hut04]  the following: theorem 5 (equivalence of functional and explicit ai model) the actions of the functional ai model (3) coincide with the actions of the explicit (recursive/iterative) ai model (  9 )-(  11 ) with environments identified by (13)",
        "prob": 0.7525
    }, {
        "ID": 8555,
        "phrase": " all we have to do is to suitably generalize the universal semimeasure \u03be from the last section and replace the true but unknown prior probability \u00b5 ai in the ai\u00b5 model by this generalized \u03be ai ",
        "prob": 0.7705882352941176
    }, {
        "ID": 8555,
        "phrase": " in the functional formulation we define the universal probability \u03be ai of an environment q just as 2 \u2212\u2113(q) \u03be(q) := 2 \u2212\u2113(q) the definition could not be easier 7 ! 8 collecting the formulas of section 2",
        "prob": 0.56875
    }, {
        "ID": 8555,
        "phrase": " the equivalence of the functional and iterative ai model (theorem 5) is true for every chronological semimeasure \u03c1, especially for \u03be, hence we can talk about the ai\u03be model in this respect",
        "prob": 0.5055555555555555
    }, {
        "ID": 8555,
        "phrase": " the main remaining problem is the unknown prior probability distribution \u00b5 ai of the environment(s)",
        "prob": 0.5916666666666667
    }, {
        "ID": 8555,
        "phrase": " we unified the theory of universal sequence prediction with the decision-theoretic agent by replacing the unknown true prior \u00b5 ai by an appropriately generalized universal semimeasure \u03be ai ",
        "prob": 0.755
    }, {
        "ID": 8555,
        "phrase": " the prior probability \u00b5 ai of the ai\u00b5 model is \u00b5 ai (y 1 x 1 ",
        "prob": 0.4428571428571429
    }, {
        "ID": 8555,
        "phrase": " so ai\u03be should allow good sequence prediction for some universal choice of m k and not only for m k =k, which definitely does not suffice for more complicated ai problems",
        "prob": 0.5071428571428571
    }, {
        "ID": 8555,
        "phrase": " the environmental prior probability is therefore \u00b5 ai (y 1 x 1 ",
        "prob": 0.2625
    }, {
        "ID": 8555,
        "phrase": " \u00b5 ai should still be sufficiently separable, allowing us to formulate and prove good reward bounds for ai\u03be",
        "prob": 0.5785714285714285
    }, {
        "ID": 8555,
        "phrase": " what is more important, we want to parallel the other ai classes, like in the sp\u00b5 model, where we always started with a probability distribution \u00b5 that was finally replaced by \u03be to get the universal solomonoff prediction sp\u03be",
        "prob": 0.6238095238095238
    }, {
        "ID": 8555,
        "phrase": " the ai\u00b5 prior probability is \u00b5 ai (y 1 x 1 ",
        "prob": 0.35000000000000003
    }, {
        "ID": 8555,
        "phrase": " \u03be tl (yx 1:n ) := \u03c1 : \u2113(\u03c1)\u2264 l \u2227 t(\u03c1)\u2264 t 2 \u2212\u2113(\u03c1) \u03c1(yx 1:n ) (42) one can show that \u03be tl reduces to \u03be ai defined in (21) for t, l \u2192\u221e",
        "prob": 0.2818181818181818
    }, {
        "ID": 8555,
        "phrase": " let us assume that the true environmental prior probability \u00b5 ai is equal to or sufficiently accurately approximated by a \u03c1 with \u2113(\u03c1) \u2264 l and t(\u03c1) \u2264 t with t and l of reasonable size",
        "prob": 0.7705882352941176
    }, {
        "ID": 8555,
        "phrase": " roughly speaking, the theorem says that if there exists a computable solution to some or all ai problems at all, the explicitly constructed algorithm p * is such a solution",
        "prob": 0.63125
    }, {
        "ID": 8555,
        "phrase": " we combine both ideas and get a parameter-free theory of universal artificial intelligence",
        "prob": 0.3153846153846154
    }, {
        "ID": 8638,
        "phrase": " on the other hand, many unsatisfiable formulas from verification and ai planning contain well over 100,000 variables and can be proved unsatisfiable within a few minutes (e",
        "prob": 0.3588235294117647
    }, {
        "ID": 8639,
        "phrase": " on the other hand, many unsatisfiable formulas from verification and ai planning contain well over 100,000 variables and can be proved unsatisfiable within a few minutes (e",
        "prob": 0.3588235294117647
    }]
}, {
    "topic_id": 30,
    "top_words": ["decoding", "ml", "codes", "bounds", "bound", "upper", "error", "lower", "probability", "block", "ldpc", "ensembles", "thresholds", "channel", "binary"],
    "phrases": [{
        "ID": 1374,
        "phrase": " all the information in the picture is described by a binary string x of length n = ml as follows",
        "prob": 0.25833333333333336
    }, {
        "ID": 1971,
        "phrase": " the nfa can be at least exponentially larger than p, but this is not abnormal; indeed, the same happens in ml when the input is only allowed to be investigated once  [12, 13] ",
        "prob": 0.2733333333333333
    }, {
        "ID": 2333,
        "phrase": " try to generalize/improve this bound to (a) general loss functions, (b) bounds on e ai n\u03be \u2212e ai n\u00b5 for probabilistic passive environments, (c) the case h k >1, (d) bounds linear or \"polynomial\" in k( \u017c) as in the case of sp\u03be -or -find examples demonstrating the impossibility of such generalizations/improvements",
        "prob": 0.1576923076923077
    }, {
        "ID": 3601,
        "phrase": " ml decoding is bound to fail above this threshold",
        "prob": 0.23333333333333334
    }, {
        "ID": 3601,
        "phrase": " at the ml threshold all guesses have to be resolved at the end of the decoding process",
        "prob": 0.21000000000000002
    }, {
        "ID": 3602,
        "phrase": " ml decoding is bound to fail above this threshold",
        "prob": 0.34444444444444444
    }, {
        "ID": 3602,
        "phrase": " its main characteristics (for a regular ensemble with left degree at least 3) are as follows: the function is zero below the ml threshold \u01ebml",
        "prob": 0.3
    }, {
        "ID": 3602,
        "phrase": " at the ml threshold all guesses have to be resolved at the end of the decoding process",
        "prob": 0.41
    }, {
        "ID": 4459,
        "phrase": " we also observe that for both the bsc and awgn channel,  with ms, sp, and ml decoding",
        "prob": 0.3416666666666666
    }, {
        "ID": 4459,
        "phrase": "3-ldpc code for m = 11, m = 12 with ms and ml decoding over the bsc",
        "prob": 0.41
    }, {
        "ID": 4695,
        "phrase": " in case of harddecision ml decoding of binary linear codes over an additive white gaussian noise (awgn) channel, the poltyrev bound for binary symmetric channels  [13]  is a tight upper bound",
        "prob": 0.524
    }, {
        "ID": 4695,
        "phrase": " tight bounds on the cep of soft-decision ml decoding of binary linear block codes over awgn channels are known (e",
        "prob": 0.5611111111111111
    }, {
        "ID": 4698,
        "phrase": ", ldpc codes with a constant degree (a r ) of the parity-check nodes) cannot achieve the channel capacity on a bsc, even under optimal ml decoding",
        "prob": 0.5842105263157894
    }, {
        "ID": 4698,
        "phrase": "  [1] , and therefore enable to obtain tighter upper bounds on the thresholds of sequences of binary linear block codes under ml decoding",
        "prob": 0.7277777777777777
    }, {
        "ID": 4698,
        "phrase": " \n thresholds of ldpc ensembles under ml decoding the following results (see tables  1-3 ) provide bounds on the thresholds of ldpc ensembles under ml decoding",
        "prob": 0.655
    }, {
        "ID": 4698,
        "phrase": " no refers to ml decoding, and is based on [1,  theorem 1]  (see also  [13, table ii] )",
        "prob": 0.19090909090909092
    }, {
        "ID": 4698,
        "phrase": " the upper bound on the threshold of e b \n ldpc no holds under 'typical pairs' decoding  [5]  (and hence, also under ml decoding), and the de thresholds are based on density evolution for iterative message-passing decoding  [10] ",
        "prob": 0.4826086956521739
    }, {
        "ID": 4698,
        "phrase": " no thresholds under ml decoding",
        "prob": 0.4428571428571429
    }, {
        "ID": 4698,
        "phrase": " for gallager's regular ldpc ensembles, the gap between the thresholds under ml decoding and the exact thresholds under the sum-product decoding algorithm (which are calculated using density-evolution analysis) are rather large",
        "prob": 0.644
    }, {
        "ID": 4698,
        "phrase": " for this reason, we also compare the lower bounds on the e b no thresholds under ml decoding with upper bounds on the e b no thresholds which rely on \"typical pairs decoding\"  [5] ; an upper bound on the e b no thresholds under an arbitrary sub-optimal decoding algorithm (e",
        "prob": 0.5423076923076923
    }, {
        "ID": 4698,
        "phrase": ", \"typical pairs decoding\") also forms an upper bound on these thresholds under optimal ml decoding",
        "prob": 0.7214285714285714
    }, {
        "ID": 4698,
        "phrase": " it is shown in table  1  that the gap between the thresholds under iterative decoding and the bounds for ml decoding (see the columns referring to the de threshold and the upper bound based on \"typical pairs decoding\") is rather large",
        "prob": 0.844
    }, {
        "ID": 4698,
        "phrase": " on the other hand, it is also demonstrated in table  1  that the gap between the upper and lower bounds on the thresholds under ml decoding is much smaller",
        "prob": 0.56875
    }, {
        "ID": 4698,
        "phrase": " \u03bb(x) \u03c1(x) 2 the plots in figure  2  compare different lower bounds on the e b n 0 -threshold under ml decoding of right-regular ldpc ensembles",
        "prob": 0.7705882352941176
    }, {
        "ID": 4698,
        "phrase": " our bounds on the thresholds of ldpc ensembles under optimal ml decoding depend only on the degree distribution of their parity-check nodes and their design rate",
        "prob": 0.6894736842105263
    }, {
        "ID": 4698,
        "phrase": " these generalized bounds can be applied to the analysis of the ml performance of non-binary ldpc ensembles whose transmission takes place over arbitrary discrete memoryless channels with possibly different types of quantization  [3] ",
        "prob": 0.6192307692307693
    }, {
        "ID": 4698,
        "phrase": "3]  shows that a logarithmic growth rate of the parity-check density is achievable for gallager's regular ldpc ensemble under ml decoding when transmission takes place over an arbitrary mbios channel",
        "prob": 0.8374999999999999
    }, {
        "ID": 4698,
        "phrase": "1 provide lower bounds on the e b \n figure 2 : 2 figure 2: comparison between different lower bounds on the threshold under ml decoding for right-regular ldpc ensembles with a r = 6 (left plot) and a r = 10 (right plot)",
        "prob": 0.8374999999999999
    }, {
        "ID": 4698,
        "phrase": " the 2-level, 4-level, 8-level and un-quantized lower bounds on the threshold refer to ml decoding, and are based on [1, theorem 2], corollaries 3",
        "prob": 0.39444444444444443
    }, {
        "ID": 4698,
        "phrase": " the 2-level, 4-level, 8-level and un-quantized lower bounds on the threshold refer to ml decoding, and are based on [1, theorem 2], corollaries 3",
        "prob": 0.33888888888888885
    }, {
        "ID": 4698,
        "phrase": ", and therefore enable to obtain tighter upper bounds on the thresholds of sequences of binary linear block codes under ml decoding",
        "prob": 0.7833333333333333
    }, {
        "ID": 4727,
        "phrase": ", ldpc codes with a constant degree (a r ) of the parity-check nodes) cannot achieve the channel capacity on a bsc, even under optimal ml decoding",
        "prob": 0.6368421052631579
    }, {
        "ID": 4727,
        "phrase": "  [1] , and therefore enable to obtain tighter upper bounds on the thresholds of sequences of binary linear block codes under ml decoding",
        "prob": 0.7833333333333333
    }, {
        "ID": 4727,
        "phrase": " \n thresholds of ldpc ensembles under ml decoding the following table provides bounds on the thresholds of regular ldpc ensembles under ml decoding",
        "prob": 0.7421052631578947
    }, {
        "ID": 4727,
        "phrase": " no holds under 'typical pairs' decoding  [4]  (and hence, also under ml decoding), and the density evolution (de) thresholds are based on density evolution for iterative message-passing decoding  [9] ",
        "prob": 0.719047619047619
    }, {
        "ID": 4727,
        "phrase": "2 provide lower bounds on the e b n 0 thresholds under ml decoding",
        "prob": 0.41
    }, {
        "ID": 4727,
        "phrase": " for gallager's regular ldpc ensembles, the gap between the thresholds under ml decoding and the exact thresholds under the sum-product decoding algorithm (which are calculated using density-evolution analysis) are rather large",
        "prob": 0.724
    }, {
        "ID": 4727,
        "phrase": " for this reason, we also compare the lower bounds on the e b n 0 thresholds under ml decoding with upper bounds on the e b n 0 thresholds which rely on \"typical pairs decoding\"  [4] ; an upper bound on the e b n 0 thresholds under an arbitrary sub-optimal decoding algorithm (e",
        "prob": 0.6961538461538461
    }, {
        "ID": 4727,
        "phrase": ", \"typical pairs decoding\") also forms an upper bound on these thresholds under optimal ml decoding",
        "prob": 0.5785714285714285
    }, {
        "ID": 4727,
        "phrase": " it is shown in table  1  that the gap between the thresholds under iterative decoding and the bounds for ml decoding (see the columns referring to the de threshold and the upper bound based on \"typical pairs decoding\") is rather large",
        "prob": 0.844
    }, {
        "ID": 4727,
        "phrase": " on the other hand, it is also demonstrated in table  1  that the gap between the upper and lower bounds on the thresholds under ml decoding is much smaller",
        "prob": 0.56875
    }, {
        "ID": 4727,
        "phrase": " the plots in figure  1  compare different lower bounds on the e b n 0 -threshold under ml decoding of right-regular ldpc ensembles",
        "prob": 0.7705882352941176
    }, {
        "ID": 4727,
        "phrase": " the bounds on the thresholds of ldpc ensembles under optimal ml decoding depend only on the degree distribution of their parity-check nodes and their design rate",
        "prob": 0.6368421052631579
    }, {
        "ID": 4727,
        "phrase": " these generalized bounds can be applied to the analysis of the ml performance of non-binary ldpc ensembles transmitted over arbitrary discrete memoryless channels with possibly different types of quantization  [2] ",
        "prob": 0.5260869565217391
    }, {
        "ID": 4727,
        "phrase": "3]  shows that a logarithmic growth rate of the parity-check density is achievable for gallager's regular ldpc ensemble under ml decoding when transmission takes place over an arbitrary mbios channel",
        "prob": 0.8374999999999999
    }, {
        "ID": 4727,
        "phrase": ", ldpc codes with a constant degree (a r ) of the parity-check nodes) cannot achieve the channel capacity on a bsc, even under optimal ml decoding",
        "prob": 0.7421052631578947
    }, {
        "ID": 4727,
        "phrase": "  [1] , and therefore enable to obtain tighter upper bounds on the thresholds of sequences of binary linear block codes under ml decoding",
        "prob": 0.7277777777777777
    }, {
        "ID": 4727,
        "phrase": " \n thresholds of ldpc ensembles under ml decoding the following table provides bounds on the thresholds of regular ldpc ensembles under ml decoding",
        "prob": 0.7421052631578947
    }, {
        "ID": 4727,
        "phrase": " no holds under 'typical pairs' decoding  [4]  (and hence, also under ml decoding), and the density evolution (de) thresholds are based on density evolution for iterative message-passing decoding  [9] ",
        "prob": 0.6238095238095238
    }, {
        "ID": 4727,
        "phrase": "2 provide lower bounds on the e b n 0 thresholds under ml decoding",
        "prob": 0.41
    }, {
        "ID": 4727,
        "phrase": " for gallager's regular ldpc ensembles, the gap between the thresholds under ml decoding and the exact thresholds under the sum-product decoding algorithm (which are calculated using density-evolution analysis) are rather large",
        "prob": 0.604
    }, {
        "ID": 4727,
        "phrase": " for this reason, we also compare the lower bounds on the e b n 0 thresholds under ml decoding with upper bounds on the e b n 0 thresholds which rely on \"typical pairs decoding\"  [4] ; an upper bound on the e b n 0 thresholds under an arbitrary sub-optimal decoding algorithm (e",
        "prob": 0.6192307692307693
    }, {
        "ID": 4727,
        "phrase": ", \"typical pairs decoding\") also forms an upper bound on these thresholds under optimal ml decoding",
        "prob": 0.7214285714285714
    }, {
        "ID": 4727,
        "phrase": " it is shown in table  1  that the gap between the thresholds under iterative decoding and the bounds for ml decoding (see the columns referring to the de threshold and the upper bound based on \"typical pairs decoding\") is rather large",
        "prob": 0.7639999999999999
    }, {
        "ID": 4727,
        "phrase": " on the other hand, it is also demonstrated in table  1  that the gap between the upper and lower bounds on the thresholds under ml decoding is much smaller",
        "prob": 0.56875
    }, {
        "ID": 4727,
        "phrase": " the plots in figure  1  compare different lower bounds on the e b n 0 -threshold under ml decoding of right-regular ldpc ensembles",
        "prob": 0.7705882352941176
    }, {
        "ID": 4727,
        "phrase": " the bounds on the thresholds of ldpc ensembles under optimal ml decoding depend only on the degree distribution of their parity-check nodes and their design rate",
        "prob": 0.6368421052631579
    }, {
        "ID": 4727,
        "phrase": " these generalized bounds can be applied to the analysis of the ml performance of non-binary ldpc ensembles transmitted over arbitrary discrete memoryless channels with possibly different types of quantization  [2] ",
        "prob": 0.6130434782608696
    }, {
        "ID": 4727,
        "phrase": "3]  shows that a logarithmic growth rate of the parity-check density is achievable for gallager's regular ldpc ensemble under ml decoding when transmission takes place over an arbitrary mbios channel",
        "prob": 0.7958333333333333
    }, {
        "ID": 4727,
        "phrase": " \n figure 1 : 1 figure 1: comparison between different lower bounds on the threshold under ml decoding for right-regular ldpc ensembles with a r = 6 (left plot) and a r = 10 (right plot)",
        "prob": 0.8142857142857142
    }, {
        "ID": 4727,
        "phrase": " \n figure 1 : 1 figure 1: comparison between different lower bounds on the threshold under ml decoding for right-regular ldpc ensembles with a r = 6 (left plot) and a r = 10 (right plot)",
        "prob": 0.7666666666666666
    }, {
        "ID": 4727,
        "phrase": " the 2-level lower bound on the threshold of e bno refers to ml decoding, and is based on [1,theorem 1]  (see also[11, table ii])",
        "prob": 0.63125
    }, {
        "ID": 4727,
        "phrase": " the 2-level lower bound on the threshold of e bno refers to ml decoding, and is based on [1,theorem 1]  (see also[11, table ii])",
        "prob": 0.69375
    }, {
        "ID": 4727,
        "phrase": ", and therefore enable to obtain tighter upper bounds on the thresholds of sequences of binary linear block codes under ml decoding",
        "prob": 0.7833333333333333
    }, {
        "ID": 4728,
        "phrase": ", ldpc codes with a constant degree (a r ) of the parity-check nodes) cannot achieve the channel capacity on a bsc, even under optimal ml decoding",
        "prob": 0.6894736842105263
    }, {
        "ID": 4728,
        "phrase": " \n thresholds of ldpc ensembles under ml decoding table  1  provides bounds on the thresholds of gallager's regular ldpc ensembles under ml decoding",
        "prob": 0.7947368421052632
    }, {
        "ID": 4728,
        "phrase": "2 provide lower bounds on the e b n 0 thresholds under ml decoding",
        "prob": 0.41
    }, {
        "ID": 4728,
        "phrase": " for gallager's regular ldpc ensembles, the gap between the thresholds under ml decoding and the exact thresholds under the sum-product decoding algorithm (calculated using density-evolution analysis) are no holds under 'typical pairs' decoding  [3]  (and hence, also under ml decoding), and the density evolution (de) thresholds are based on density evolution for mpi decoding  [9] ",
        "prob": 0.7131578947368421
    }, {
        "ID": 4728,
        "phrase": " for this reason, we also compare the lower bounds on the e b n 0 thresholds under ml decoding with upper bounds on the e b n 0 thresholds which rely on \"typical pairs decoding\"  [3] ; an upper bound on the e b n 0 thresholds under an arbitrary sub-optimal decoding algorithm (e",
        "prob": 0.7346153846153846
    }, {
        "ID": 4728,
        "phrase": ", \"typical pairs decoding\") also forms an upper bound on these thresholds under optimal ml decoding",
        "prob": 0.65
    }, {
        "ID": 4728,
        "phrase": " it is shown in table  1  that the gap between the thresholds under iterative decoding and the bounds for ml decoding (see the columns referring to the de threshold and the upper bound based on \"typical pairs decoding\") is rather large",
        "prob": 0.8039999999999999
    }, {
        "ID": 4728,
        "phrase": " on the other hand, it is also demonstrated in table  1  that the gap between the upper and lower bounds on the thresholds under ml decoding is much smaller",
        "prob": 0.56875
    }, {
        "ID": 4728,
        "phrase": " the plots in figure  1  compare different lower bounds on the e b n 0 -threshold under ml decoding of right-regular ldpc ensembles",
        "prob": 0.711764705882353
    }, {
        "ID": 4728,
        "phrase": " the bounds on the thresholds of ldpc ensembles under optimal ml decoding depend only on the degree distribution of their parity-check nodes and their design rate",
        "prob": 0.6894736842105263
    }, {
        "ID": 4728,
        "phrase": "3]  shows that a logarithmic growth rate of the parity-check density is achievable for gallager's regular ldpc ensemble under ml decoding when transmission takes place over an arbitrary mbios channel",
        "prob": 0.8374999999999999
    }, {
        "ID": 4728,
        "phrase": " \n figure 1 : 1 figure 1: comparison between different lower bounds on the threshold under ml decoding for right-regular ldpc ensembles with a r = 6 (left plot) and a r = 10 (right plot)",
        "prob": 0.8142857142857142
    }, {
        "ID": 4728,
        "phrase": " the 2-level lower bound on the threshold of e bno refers to ml decoding, and is based on [1,theorem 1]  (see also [12,  table ii])",
        "prob": 0.69375
    }, {
        "ID": 4728,
        "phrase": "the paper introduces new bounds on the asymptotic density of parity-check matrices and the achievable rates under ml decoding of binary linear block codes transmitted over memoryless binary-input output-symmetric channels",
        "prob": 0.6107142857142857
    }, {
        "ID": 4728,
        "phrase": ", and therefore enable to obtain tighter upper bounds on the thresholds of sequences of binary linear block codes under ml decoding",
        "prob": 0.6722222222222222
    }, {
        "ID": 4854,
        "phrase": " ml performance of rs averaged ensemble is very close to the capacity of bec, which suggests rs codes are good codes",
        "prob": 0.4764705882352941
    }, {
        "ID": 4855,
        "phrase": " therefore, we will investigate the performance of rs codes under ml decoding averaged over the ensemble of binary expansions  [21]  [17] using a union-type upper bound",
        "prob": 0.40499999999999997
    }, {
        "ID": 4855,
        "phrase": " for comparison, the simulation-based ml lower bound (discussed in section iii, labelled as ml lower bound or ml lb) is also plotted",
        "prob": 0.5549999999999999
    }, {
        "ID": 4855,
        "phrase": " comparison of the ml upper bound, lower bound and hdd performance \n fig",
        "prob": 0.46923076923076923
    }, {
        "ID": 4856,
        "phrase": " though adapting the parity convergence behavior of iterative decoding with and without adaptation of rs  (31, 25)  check matrix based on the channel output does not guarantee convergence to the ml decision for awgn channels, it does avoid iterative decoding getting stuck at pseudo-equilibrium points and thus improves the convergence behavior",
        "prob": 0.24594594594594593
    }, {
        "ID": 4856,
        "phrase": " for comparison, the simulation-based ml lower bounds and analytical ml upper bounds are also plotted in some figures",
        "prob": 0.63125
    }, {
        "ID": 4856,
        "phrase": " in this paper, we study the performance of the averaged ensemble of rs codes  [31]  under ml decoding using the divsalar bound  [32] ",
        "prob": 0.44375
    }, {
        "ID": 4856,
        "phrase": " the ml upper bound over rs averaged ensemble is also plotted for comparison",
        "prob": 0.5083333333333333
    }, {
        "ID": 4856,
        "phrase": " it can be seen that the ml upper bound is 0",
        "prob": 0.3875
    }, {
        "ID": 4856,
        "phrase": "05 ml upper bound ml lower bound \n fig",
        "prob": 0.5545454545454546
    }, {
        "ID": 5037,
        "phrase": "  3  we show various decoding simulation results for data transmission over a binary-input awgnc and lower and upper bounds: h eg(2,4) -based sum-product algorithm decoding, h eg(2,4) -based lp decoding, c eg(2,4) -based ml decoding, an upper bound on lp decoding based on a union of events upper bound, an upper bound on ml decoding based on a union of events upper bound, and a lower bound on ml decoding based on an inequality by de caen as presented by s\u00e9guin  [17] ",
        "prob": 0.5836363636363636
    }, {
        "ID": 5037,
        "phrase": " \n\t\t\t note that during ml decoding, ties between decoding regions can either be resolved in a random or in a systematic fashion",
        "prob": 0.4733333333333334
    }, {
        "ID": 5054,
        "phrase": " next, consider ml decoding over the two subchannels w 1 and w 2 , using independent (2n, 2 n r , q \u2032 ) ensembles, where q \u2032 is uniform",
        "prob": 0.36428571428571427
    }, {
        "ID": 5054,
        "phrase": " then, e r (r, bec) = e r (r, q \u2032 , bec), and the ml complexity and reliability figures are \u03c7 1 + \u03c7 2 \u223c = 2 n r and p e,1 + p e,2 \u223c = 2 \u22122n er(r/2,bec) ",
        "prob": 0.2818181818181818
    }, {
        "ID": 5129,
        "phrase": " the performance of punctured ldpc codes under ml decoding was studied in  [2]  via analyzing the asymptotic growth rate of their average weight distributions and using upper bounds on the decoding error probability under ml decoding",
        "prob": 0.48518518518518516
    }, {
        "ID": 5129,
        "phrase": " for ensembles of punctured ldpc codes, the calculation of bounds on their thresholds under ml decoding and their exact thresholds under iterative decoding (based on density evolution analysis) is of interest in the sense that it enables to assess the degradation in the asymptotic performance which is attributed to the suboptimality of iterative decoding (as compared to ml decoding), and also to assess the inherent loss in the asymptotic performance which is attributed to the structure of these ensembles, even if ml decoding could be applied to decode ldpc codes",
        "prob": 0.45294117647058824
    }, {
        "ID": 5129,
        "phrase": " section 4 relies on the previous bounds and derives an upper bound on the achievable rates of ldpc codes under ml decoding for parallel channels",
        "prob": 0.6368421052631579
    }, {
        "ID": 5129,
        "phrase": " \n bounds on the conditional entropy for parallel channels this section serves as a preparatory step towards the derivation of upper bounds on the achievable rates of ml decoded binary linear block codes whose transmission takes place over statistically independent parallel mbios channels",
        "prob": 0.7088235294117646
    }, {
        "ID": 5129,
        "phrase": " \n an upper bound on the achievable rates of ldpc codes over parallel channels in this section, we derive an upper bound on the design rate of a sequence of ensembles of ldpc codes whose transmission takes place over a set of statistically independent parallel mbios channels, and achieves vanishing bit error probability under ml decoding",
        "prob": 0.8487179487179487
    }, {
        "ID": 5129,
        "phrase": " \n achievable rates of punctured ldpc codes in this section we derive upper bounds on the achievable rates of punctured ldpc codes whose transmission takes place over an mbios channel, and the codes are ml decoded",
        "prob": 0.8555555555555555
    }, {
        "ID": 5129,
        "phrase": " we assume that the transmission of these codes takes place over an mbios channel, and refer to their achievable rates under optimal ml decoding",
        "prob": 0.5352941176470588
    }, {
        "ID": 5129,
        "phrase": " \n numerical results for intentionally punctured ldpc codes in this section, we present a comparison between thresholds under message-passing iterative (mpi) decoding and bounds on thresholds under ml decoding for ensembles of ip-ldpc codes",
        "prob": 0.8555555555555555
    }, {
        "ID": 5129,
        "phrase": " this enables to calculate the capacity limits which refer to the design rates of these ensembles, and to evaluate the gaps to capacity under ml decoding and iterative decoding for these ensembles of punctured ldpc codes",
        "prob": 0.7
    }, {
        "ID": 5129,
        "phrase": " for various ensembles of ip-ldpc codes, tables 1-3 provide lower bounds on the inherent gap to capacity under optimal ml decoding (based on theorem 5",
        "prob": 0.5761904761904761
    }, {
        "ID": 5129,
        "phrase": "2 (which provides a lower bound on e b n0 under ml decoding), and thresholds under iterative message-passing decoding",
        "prob": 0.7214285714285714
    }, {
        "ID": 5129,
        "phrase": "2 (which provides a lower bound on e b n0 under ml decoding), and thresholds under iterative message-passing decoding",
        "prob": 0.36428571428571427
    }, {
        "ID": 5129,
        "phrase": "2 (which provides a lower bound on e b n0 under ml decoding), and thresholds under iterative message-passing decoding",
        "prob": 0.43571428571428567
    }, {
        "ID": 5209,
        "phrase": " using the sphere bound, the error event of ml decoding conditioned on a channel  p e h h h \u2264 prob \u2212w \u2265 \u03b7 ",
        "prob": 0.43571428571428567
    }, {
        "ID": 5220,
        "phrase": " various gallager type bounds on ml decoders for different finite ldpc code ensembles have been established in  [27] ",
        "prob": 0.44375
    }, {
        "ID": 5288,
        "phrase": " in this paper, we introduce a new family of concatenated codes defined on graphs, namely the concatenated low-density parity-check and generator matrix (ldpc-gm) codes, and prove that these codes can achieve capacity using ml decoding on any mbios channels with bounded graphical complexity",
        "prob": 0.46
    }, {
        "ID": 5288,
        "phrase": " first, there are improved iterative decoding algorithms that approach closely the ml performance  [10, 11] ",
        "prob": 0.23846153846153847
    }, {
        "ID": 5288,
        "phrase": " therefore we can define the guaranteed rate of these ldpc-gm codes with asymptotically high probability to be r r o \u2212 max{w ub (0), 0} (13) 5 analysis of the ldpc-gm codes in this section, we will first characterize w ub (a), and then use the derived results to prove that ldpc-gm codes can be capacity-achieving on the mbios channels using ml decoding with bounded graphical complexity",
        "prob": 0.7097560975609757
    }, {
        "ID": 5288,
        "phrase": " \n density evolution for ldpc-gm codes on the bec although the aforementioned ldpc-gm ensembles have finite graphical complexity, the decoding complexity under ml decoding is still exponential",
        "prob": 0.5875
    }, {
        "ID": 5288,
        "phrase": " furthermore, after applying the ml performance bound given in  [9]  to these ldpc-gm codes, we prove that they can achieve capacity on any mbios channels using ml decoding",
        "prob": 0.5285714285714286
    }, {
        "ID": 5289,
        "phrase": " in this paper, we introduce a new family of concatenated codes defined on graphs, namely the concatenated low-density parity-check and generator matrix (ldpc-gm) codes, and prove that these codes can achieve capacity using ml decoding on any mbios channels with bounded graphical complexity",
        "prob": 0.5457142857142857
    }, {
        "ID": 5289,
        "phrase": " first, there are improved iterative decoding algorithms that approach closely the ml performance  [10, 11] ",
        "prob": 0.3923076923076923
    }, {
        "ID": 5289,
        "phrase": " therefore we can define the guaranteed rate of these ldpc-gm codes with asymptotically high probability to be r r o \u2212 max{w ub (0), 0} (13) 5 analysis of the ldpc-gm codes in this section, we will first characterize w ub (a), and then use the derived results to prove that ldpc-gm codes can be capacity-achieving on the mbios channels using ml decoding with bounded graphical complexity",
        "prob": 0.6853658536585366
    }, {
        "ID": 5289,
        "phrase": " \n density evolution for ldpc-gm codes on the bec although the aforementioned ldpc-gm ensembles have finite graphical complexity, the decoding complexity under ml decoding is still exponential",
        "prob": 0.5875
    }, {
        "ID": 5289,
        "phrase": " furthermore, after applying the ml performance bound given in  [9]  to these ldpc-gm codes, we prove that they can achieve capacity on any mbios channels using ml decoding",
        "prob": 0.5761904761904761
    }, {
        "ID": 5290,
        "phrase": " in this paper, we introduce a new family of concatenated codes defined on graphs, namely the concatenated low-density parity-check and generator matrix (ldpc-gm) codes, and prove that these codes can achieve capacity using ml decoding on any mbios channels with bounded graphical complexity",
        "prob": 0.5171428571428572
    }, {
        "ID": 5290,
        "phrase": " therefore we can define the guaranteed rate of these ldpc-gm codes with asymptotically high probability to be r r o \u2212 max{w ub (0), 0} (13) 5 analysis of the ldpc-gm codes in this section, we will first characterize w ub (a), and then use the derived results to prove that ldpc-gm codes can be capacity-achieving on the mbios channels using ml decoding with bounded graphical complexity",
        "prob": 0.7097560975609757
    }, {
        "ID": 5290,
        "phrase": " \n density evolution for ldpc-gm codes on the bec although the aforementioned ldpc-gm ensembles have finite graphical complexity, the decoding complexity under ml decoding is still exponential",
        "prob": 0.6291666666666667
    }, {
        "ID": 5290,
        "phrase": " furthermore, after applying the ml performance bound given in  [10]  to these ldpc-gm codes, we prove that they can achieve capacity on any mbios channels using ml decoding",
        "prob": 0.6714285714285714
    }, {
        "ID": 5334,
        "phrase": " based on the poltyrev tangential sphere bound (tsb)  [34]  and the average binary weight enumerator, average bounds on the ml error probability of rs codes over additive white gaussian noise (awgn) channels were developed in  [33]  and were shown to be tight",
        "prob": 0.4033333333333333
    }, {
        "ID": 5344,
        "phrase": " in particular, the exact bit error rate (ber) probability of gabba codes over uncorrelated memoryless fading channels with unequal powers and arbitrary statistics is derived under the assumption of perfect channel knowledge at the receiver and ml decoding",
        "prob": 0.5206896551724138
    }, {
        "ID": 5344,
        "phrase": " performance of gabba codes with ml decoding: analysis of exact ber probability the ber probability of digitally modulated signals in a fading channel can be computed by averaging the corresponding error probability in the additive white gaussian noise (awgn) channel over the statistics of the fading process  [35] ",
        "prob": 0.41470588235294115
    }, {
        "ID": 5344,
        "phrase": " the exact ber probability of the codes with ml the decoder over generalized (uncorrelated) fading channels was derived analytically, under the assumption of perfect channel knowledge at the receiver (see section v-a)",
        "prob": 0.5260869565217391
    }, {
        "ID": 5404,
        "phrase": " 0 of the 1 note that during ml decoding, ties between decoding regions can either be resolved in a random or in a systematic fashion",
        "prob": 0.4733333333333334
    }, {
        "ID": 5727,
        "phrase": " although maximum-likelihood (ml) decoding is in general prohibitively complex for long codes, the derivation of upper and lower bounds on the ml decoding error probability is of interest, providing an ultimate indication of the system performance",
        "prob": 0.3607142857142857
    }, {
        "ID": 5727,
        "phrase": " in  [22] , we present various reported upper bounds on the ml decoding error probability",
        "prob": 0.7
    }, {
        "ID": 5727,
        "phrase": " the focus of this presentation is directed towards the application of efficient bounding techniques on ml decoding performance, which are not subjected to the deficiencies of the union bounds and therefore provide useful results at rates reasonably higher than the cut-off rate",
        "prob": 0.3482758620689655
    }, {
        "ID": 5727,
        "phrase": " we also address here lower bounds on the ml decoding error probability (see  [22, chapter 3] ), and exemplify these bounds on linear block codes with a special emphasis on ensembles of codes defined on graphs",
        "prob": 0.5875
    }, {
        "ID": 5727,
        "phrase": " \n general approach for the derivation of improved upper bounds in  [22,  chapter 2], we present many improved upper bounds on the ml decoding error probability which are tighter than the union bound",
        "prob": 0.6565217391304348
    }, {
        "ID": 5727,
        "phrase": " the upper bounds on the bit error probability under optimal ml decoding are compared with computer simulations of the iterative sum-product algorithm with up to 10 iterations",
        "prob": 0.40499999999999997
    }, {
        "ID": 5727,
        "phrase": " the tsb  [19]  happens often to be the tightest reported upper bound for block codes which are transmitted over the binary-input awgn channel and ml decoded (see e",
        "prob": 0.8142857142857142
    }, {
        "ID": 5727,
        "phrase": " cohen and merhav relied on (3) for the derivation of improved lower bounds on the decoding error probability of linear codes under optimal ml decoding",
        "prob": 0.6894736842105263
    }, {
        "ID": 5727,
        "phrase": " recently, two lower bounds on the ml decoding error probability of linear binary block codes were derived by behnamfar et al",
        "prob": 0.6166666666666667
    }, {
        "ID": 5727,
        "phrase": "5], sason and urbanke derived an information-theoretic lower bound on the bit error probability for binary linear block codes under ml decoding",
        "prob": 0.655
    }, {
        "ID": 5728,
        "phrase": " referring to the second question, the answer is given in the form of upper bounds on the achievable rates whose derivation is based on performance bounds under ml decoding",
        "prob": 0.5761904761904761
    }, {
        "ID": 5728,
        "phrase": " the derivation of these bounds also allows to derive lower bounds on the bit/block-error probability under ml decoding (see  [21] ,  [26] )",
        "prob": 0.44375
    }, {
        "ID": 5728,
        "phrase": ", ldpc codes with a constant degree (a r ) of the parity-check nodes) which is a necessary condition for achieving reliable communications over a binary symmetric channel (bsc), even under optimal ml decoding",
        "prob": 0.6708333333333333
    }, {
        "ID": 5728,
        "phrase": " this bound shows that right-regular ldpc codes with fixed right degree cannot achieve the channel capacity on a bsc, even under optimal ml decoding",
        "prob": 0.719047619047619
    }, {
        "ID": 5728,
        "phrase": " a natural question arises: question 3: is the logarithmic behavior of the lower bound on the parity-check density true, or is it just an artifact of the bounding technique ? sason and urbanke showed that for any mbios channel, the logarithmic behavior of the parity-check density is achievable under ml decoding  [21, theorem 2",
        "prob": 0.5787878787878789
    }, {
        "ID": 5728,
        "phrase": " the transmission of the codes is assumed to take place over an mbios channel and the bounds refer to ml decoding",
        "prob": 0.65
    }, {
        "ID": 5728,
        "phrase": " numerical results: table  i  provides bounds on the thresholds under ml decoding of several irregular rate  1  2 ensembles taken from  [20] , where the transmission takes place over the binary input awgn channel",
        "prob": 0.6708333333333333
    }, {
        "ID": 5728,
        "phrase": " the upper bounds on the achievable rates provide lower bounds on the eb n0 thresholds under ml decoding",
        "prob": 0.74
    }, {
        "ID": 5728,
        "phrase": " the bound on the achievable rates of ml decoded   ldpc codes transmitted over parallel channels, can be used to find lower bounds on the thresholds which intentionally punctured ldpc codes achieve under ml decoding",
        "prob": 0.773076923076923
    }, {
        "ID": 5728,
        "phrase": " table  ii  presents the lower bound on the threshold under ml decoding of a sequence of ensembles of ldpc codes with various puncturing rates, where the transmission takes place over the binary input awgn channel",
        "prob": 0.7639999999999999
    }, {
        "ID": 5728,
        "phrase": " in  [7] , hsu and anastasopoulos introduced ensembles of codes which achieve the capacity of general mbios channels under ml decoding with bounded number of edges in the tanner graph per information bit, and for the bec, they also achieve bounded complexity per information bit under mpi decoding",
        "prob": 0.5838709677419355
    }, {
        "ID": 5728,
        "phrase": "1 (which provides a lower bound on e b n 0 n 0 under ml decoding), and thresholds under iterative message-",
        "prob": 0.5916666666666667
    }, {
        "ID": 5729,
        "phrase": " an upper bound on the achievable rates of ldpc codes over parallel channels in this section, we present an upper bound on the design rate of a sequence of ensembles of ldpc codes whose transmission takes place over a set of statistically independent parallel mbios channels, and achieves vanishing bit error probability under ml decoding",
        "prob": 0.8230769230769232
    }, {
        "ID": 5729,
        "phrase": " on the achievable rates of punctured ldpc codes in this section we present upper bounds on the achievable rates of punctured ldpc codes whose transmission takes place over an mbios channel, and the codes are ml decoded",
        "prob": 0.8555555555555555
    }, {
        "ID": 5729,
        "phrase": " we assume that the transmission of these codes takes place over an mbios channel, and refer to their achievable rates under optimal ml decoding",
        "prob": 0.5941176470588235
    }, {
        "ID": 5729,
        "phrase": " numerical results for intentionally punctured ldpc codes in this section, we compare between thresholds under message-passing iterative (mpi) decoding and bounds on thresholds under ml decoding for ensembles of ip-ldpc codes",
        "prob": 0.6961538461538461
    }, {
        "ID": 5729,
        "phrase": " table  1  provides lower bounds on the inherent gap to capacity under optimal ml decoding (based on theorem iii",
        "prob": 0.4764705882352941
    }, {
        "ID": 5729,
        "phrase": "1 for the derivation of upper bounds on the achievable rates under ml decoding of (randomly and intentionally) punctured ldpc codes whose transmission takes place over an mbios channel",
        "prob": 0.7772727272727272
    }, {
        "ID": 5903,
        "phrase": " analytical bounds to ml performance are computed and discussed in section viii-b",
        "prob": 0.3416666666666666
    }, {
        "ID": 5903,
        "phrase": " we have depicted: \u2022 the poltyrev bounds on ml performance (p on the plots), obtained by using the combined weight enumerator computed via  (22) ",
        "prob": 0.24117647058823527
    }, {
        "ID": 5903,
        "phrase": " \u2022 the truncated union bound (l on the plots), approximating the ml performance at low error rates, and computed from the minimum distance term via  (7) ",
        "prob": 0.3736842105263158
    }, {
        "ID": 5903,
        "phrase": " with the aid of the poltyrev bound for the bsc channel, hard ml bounds have also been plotted",
        "prob": 0.5461538461538461
    }, {
        "ID": 5903,
        "phrase": " it is shown that soft ml decoding on the awgn channel offers more than 2 db coding gain over hard ml decoding",
        "prob": 0.24117647058823527
    }, {
        "ID": 5903,
        "phrase": " using the combined enumerators, tight bounds on the ml performance of product codes over awgn channels were derived by using the poltyrev bounds",
        "prob": 0.6894736842105263
    }, {
        "ID": 5908,
        "phrase": " with no rpc cut, and a lower bound on the wer of the ml decoder have been included, as well",
        "prob": 0.2384615384615384
    }, {
        "ID": 5908,
        "phrase": " therefore, this estimate gives a lower bound on the wer of ml decoding",
        "prob": 0.3416666666666666
    }, {
        "ID": 6109,
        "phrase": " (6) this ml metric  (6)  results in exponential decoding complexity with the rate of transmission in bits/sec/hz",
        "prob": 0.46923076923076923
    }, {
        "ID": 6131,
        "phrase": " we then state and prove rigorous upper bounds on the effective rate-distortion function of this ensemble under ml encoding",
        "prob": 0.44375
    }, {
        "ID": 6148,
        "phrase": " thus, the ml decoding fer for cooperative turbo coding scheme averaged over all possible reliable sets can be bounded as fer (m ) = all possible f p(f )p [c] w \u03b3 | f \u2264 all possible f p(f ) \u2022 g(m, f , snr)",
        "prob": 0.25416666666666665
    }, {
        "ID": 6149,
        "phrase": " next, we introduce a tighter bhattacharyya distance code threshold c \u22c6 (compared with c 0 ) under ml decoding",
        "prob": 0.22142857142857145
    }, {
        "ID": 6149,
        "phrase": " the punctured code threshold theorem and quasi-static channel assumption imply that reliable nodes can be guaranteed to decode the message successfully under ml decoding",
        "prob": 0.29047619047619044
    }, {
        "ID": 6165,
        "phrase": " recently, some progress has been made towards efficient ml or near ml decoding of ldpc codes over the bec  [2] -  [4] ",
        "prob": 0.19375
    }, {
        "ID": 6165,
        "phrase": " theorem 2: improved turbo decoding is ml decoding on the bec when l max \u2192 \u221e",
        "prob": 0.5083333333333333
    }, {
        "ID": 6165,
        "phrase": " thus, improved turbo decoding is ml decoding",
        "prob": 0.51
    }, {
        "ID": 6165,
        "phrase": " in table  i  we have tabulated, for different values of the channel erasure probability \u01eb, the empirical value of l max such that improved turbo decoding is near ml decoding",
        "prob": 0.40499999999999997
    }, {
        "ID": 6165,
        "phrase": " , n \u2212 1} is a turbo stopping set if and only if there exist two linear subcodes ca \u2286 c a \u2286 {0, 1} na and cb \u2286 c b \u2286 {0, 1} n b of dimension > 0 with support sets \u03c7( ca ) and \u03c7( cb ), respectively, such that \n table i estimated i expected number of iterations e[t ] and empirical lmax such that improved turbo decoding is near ml decoding for the (155, 64, 18) turbo code from section iii-a the estimate is less reliable, since only 6 ml-decodable frame errors have been observed compared to about 50 for \u01eb > 0",
        "prob": 0.20681818181818182
    }, {
        "ID": 6190,
        "phrase": "  3  we show various decoding simulation results for data transmission over a binary-input awgnc and lower and upper bounds: h eg(2,4) -based sum-product algorithm decoding, h eg(2,4) -based lp decoding, c eg(2,4) -based ml decoding, an upper bound on lp decoding based on a union of events upper bound, an upper bound on ml decoding based on a union of events upper bound, and a lower bound on ml decoding based on an inequality by de caen as presented by s\u00e9guin  [27] ",
        "prob": 0.6381818181818182
    }, {
        "ID": 6190,
        "phrase": " \n\t\t\t we assume that during ml decoding ties between decoding regions are resolved randomly",
        "prob": 0.5083333333333333
    }, {
        "ID": 6624,
        "phrase": " since an ml detector is not commonly used (or even feasible) for decoding ldpc codes, most of these error events are a type of non-codeword error called trapping sets (ts)  [4] ",
        "prob": 0.2125
    }, {
        "ID": 6863,
        "phrase": " \u2227 \u03c6m \u21d2 \u03c60, where each \u03c6i(ai) = ai\u03b8ici, for 0 \u2264 i \u2264 m, is a binary operator comparing the value of an attribute ai \u2208 s(r) with a constant ci",
        "prob": 0.23846153846153845
    }, {
        "ID": 6969,
        "phrase": " he found explicit upper and lower bounds on the ml decoding error probability, which decrease exponentially with block length",
        "prob": 0.4764705882352941
    }, {
        "ID": 6969,
        "phrase": " derive upper bounds on the ml decoding error probability of structured ensembles of codes whose transmission takes place over (independent) parallel channels",
        "prob": 0.6714285714285714
    }, {
        "ID": 6969,
        "phrase": " the upper bounds on the ml decoding error probability are applied to ensembles of codes defined on graphs (e",
        "prob": 0.6733333333333333
    }, {
        "ID": 6969,
        "phrase": " the comparison in  [21]  between upper bounds under ml decoding and computer simulations of the performance of such ensembles under iterative decoding shows a good match in several cases",
        "prob": 0.655
    }, {
        "ID": 6969,
        "phrase": " the upper bounds on the block error probability derived in  [21]  enable to derive achievable regions for ensuring reliable communications under ml decoding",
        "prob": 0.7947368421052632
    }, {
        "ID": 6969,
        "phrase": " the new bounds are used to obtain inner bounds on the boundary of the channel regions which are asymptotically (in the limit where we let the block length tend to infinity) attainable under ml decoding, and the results improve on those recently reported in  [21] ",
        "prob": 0.5592592592592592
    }, {
        "ID": 6969,
        "phrase": " these information-theoretic quantities serve as a benchmark for assessing the gap under optimal ml decoding between the achievable channel regions of various ensembles of codes and the achievable channel region which corresponds to the shannon capacity limit",
        "prob": 0.5592592592592592
    }, {
        "ID": 6969,
        "phrase": " due to the outstanding performance of turbo-like codes, our focus is mainly on such ensembles, where we also consider as a reference the ensemble of fully random block codes which achieves capacity under ml decoding",
        "prob": 0.5458333333333333
    }, {
        "ID": 6969,
        "phrase": " bounds on the ml decoding error probability are often based on the distance properties of the considered codes or ensembles (see, e",
        "prob": 0.5352941176470588
    }, {
        "ID": 6969,
        "phrase": " the distance spectrum and the iowe of linear block codes are useful for the analysis of the block and bit error probabilities, respectively, under ml decoding",
        "prob": 0.531578947368421
    }, {
        "ID": 6969,
        "phrase": " as a reference to all ensembles, we will consider the ensemble of fully random block codes which is capacity-achieving under ml decoding (or 'typical pairs') decoding",
        "prob": 0.6894736842105263
    }, {
        "ID": 6969,
        "phrase": " this concept was originally applied to the ml analysis of ensembles of ldpc codes by miller and burshtein  [24] ",
        "prob": 0.36428571428571427
    }, {
        "ID": 6969,
        "phrase": " the computation of these regions follows from the upper bounds on the ml decoding error probability we have obtained in sections 3 and 4 (see theorems 1 and 2), referring here to the asymptotic case where we let the block length tend to infinity",
        "prob": 0.364
    }, {
        "ID": 6969,
        "phrase": " since the exact decoding error probability under ml decoding is in general unknown, then similarly to  [21] , we evaluate inner bounds on the attainable channel regions whose calculation is based on upper bounds on the ml decoding error probability",
        "prob": 0.6586206896551724
    }, {
        "ID": 6969,
        "phrase": "3 ] which relates to typical-pairs decoding over a single channel and the statement in theorem 3 for ml decoding over a set of independent parallel channels lies mainly in the first condition of both theorems",
        "prob": 0.39565217391304347
    }, {
        "ID": 6969,
        "phrase": ",  [24, theorems 3 and 4]  and  [7, section 5] , where the ml decoding error probability of the considered ensembles of turbo-like codes vanish asymptotically like the inverse of a polynomial of the block length)",
        "prob": 0.6409090909090909
    }, {
        "ID": 6969,
        "phrase": " for independent parallel channels, we study their theoretical performance under ml decoding",
        "prob": 0.5083333333333333
    }, {
        "ID": 6969,
        "phrase": " in the former case, we present upper bounds on the ml decoding error probability, and in the latter case, we consider inner bounds on the attainable channel regions of these ensembles and study the gap to the capacity region",
        "prob": 0.5423076923076923
    }, {
        "ID": 6969,
        "phrase": " in order to assess the tightness of the bounds for ensembles of relatively short block lengths, we compare the upper bounds under optimal ml decoding with computer simulations under (sub-optimal) itera-tive decoding",
        "prob": 0.4269230769230769
    }, {
        "ID": 6969,
        "phrase": " in some cases, the upper bounds under ml decoding are more pessimistic than the experimental results of the iterative decoder, thus indicating that there is still room for improving the tightness of the new bounds",
        "prob": 0.23181818181818184
    }, {
        "ID": 6969,
        "phrase": "1 exemplifies performance bounds for ensembles of short to moderate block length by focusing on a uniformly interleaved ensemble of turbo codes, comparing various bounds on the bit error probability under ml decoding and compare the results with computer simulation of the log-map iterative decoding",
        "prob": 0.7970588235294118
    }, {
        "ID": 6969,
        "phrase": " this sub-section analyzes the performance under optimal ml decoding, assuming the communications takes place over parallel channels",
        "prob": 0.3588235294117647
    }, {
        "ID": 6969,
        "phrase": " \n performance bounds for uniformly interleaved turbo codes in this sub-section, we exemplify the tightness of the new bounds by referring to an ensemble of uniformly interleaved turbo codes, and comparing the upper bounds on the bit error probability under ml decoding with computer simulations of an iterative decoder",
        "prob": 0.7676470588235292
    }, {
        "ID": 6969,
        "phrase": " the reader is referred to  [19]  which introduces coding theorems for turbo code ensembles under ml decoding, assuming that the transmission takes place over a single mbios channel (i",
        "prob": 0.5285714285714286
    }, {
        "ID": 6969,
        "phrase": " in the continuation of this section, we compare inner bounds on the attainable channel regions of accumulate-based codes under ml decoding",
        "prob": 0.711764705882353
    }, {
        "ID": 6969,
        "phrase": " in the following, we present the final results related to the finite-length and asymptotic distance properties (where we let n tend to infinity); these results serve later for the calculation of attainable channel regions under ml decoding",
        "prob": 0.4653846153846154
    }, {
        "ID": 6969,
        "phrase": " the improved performance of the ensembles of spara codes under ml decoding is demonstrated by the gallager bounding technique in fig",
        "prob": 0.69375
    }, {
        "ID": 6969,
        "phrase": " it is shown in this figure that for the spara ensemble with the parameters p = 3, q = 6 and \u03b1 =  2  15 , the gap between the inner bound on the attainable channel region under ml decoding and the capacity limit is less than 0",
        "prob": 0.45499999999999996
    }, {
        "ID": 6969,
        "phrase": " we apply this approach in this section for the calculation of inner bounds on the attainable channel regions under ml decoding, referring to the generalizations of the ds2 and 1961 gallager bounds in sections 3 and 4, respectively",
        "prob": 0.5045454545454545
    }, {
        "ID": 6969,
        "phrase": " in the asymptotic case where we let the block length tend to infinity, the new bounds are used to obtain improved inner bounds on the attainable channel regions under ml decoding",
        "prob": 0.5260869565217391
    }, {
        "ID": 6969,
        "phrase": " this distance spectral analysis serves to assess the performance of these codes under ml decoding where we rely on the bounding techniques developed in this paper and in  [21]  for parallel channels",
        "prob": 0.255
    }, {
        "ID": 6969,
        "phrase": " the improved performance of the ensembles of systematic and punctured accumulate-repeat-accumulate (spara) codes under ml decoding is demonstrated by the gallager bounding technique in fig",
        "prob": 0.719047619047619
    }, {
        "ID": 6969,
        "phrase": " however, in some cases, the new bounds under ml decoding happen to be a bit pessimistic as compared to computer simulations of sub-optimal iterative decoding (see, e",
        "prob": 0.29047619047619044
    }, {
        "ID": 6969,
        "phrase": " (b) performance bounds for the bit error probability under ml decoding versus computer simulation results of iterative log-map decoding (with 10 iterations)",
        "prob": 0.505
    }, {
        "ID": 6969,
        "phrase": " in the asymptotic case where we let the block length tend to infinity, the new bounds are used to obtain improved inner bounds on the attainable channel regions under ml decoding",
        "prob": 0.39565217391304347
    }, {
        "ID": 6970,
        "phrase": " the tangential-sphere bound (tsb) of poltyrev often happens to be the tightest upper bound on the ml decoding error probability of block codes whose transmission takes place over a binary-input awgn channel",
        "prob": 0.7892857142857143
    }, {
        "ID": 6970,
        "phrase": " \n the tangential-sphere bound the tangential-sphere bound (tsb) on the block error probability of ml decoding was derived by poltyrev (see  [12, 14] ), and it applies to the case where the transmission takes place over an awgn channel, and the modulated signals have constant energy",
        "prob": 0.7366666666666666
    }, {
        "ID": 6970,
        "phrase": " from the discussion above, it is clear that the combination of the sfb with another upper bound has the potential to tighten the overall upper bound on the ml decoding probability; this improvement is expected to be especially pronounced for ensembles whose average distance spectrum resembles the binomial distribution of fully random block codes over a relatively large range of hamming weights, but deviates significantly from the binomial distribution for relatively low and large hamming weights (e",
        "prob": 0.22653061224489796
    }, {
        "ID": 6970,
        "phrase": " \n applications this section demonstrates some numerical results of the improved upper bounds on the ml decoding error probability of linear block codes",
        "prob": 0.7421052631578947
    }, {
        "ID": 6970,
        "phrase": " the new bounds apply to the bit and block error probabilities of binary linear block codes under ml decoding",
        "prob": 0.6529411764705882
    }, {
        "ID": 6970,
        "phrase": " the compared bounds under ml decoding are the tangential-sphere bound (tsb), and the bounds in theorems 1 and 4",
        "prob": 0.5785714285714285
    }, {
        "ID": 6970,
        "phrase": " \n figure 6 : 6 figure 6: comparison between various upper bounds on the ml decoding block error probability where the comparison refers to the ensemble of uniformly interleaved turbo-hamming codes whose two component codes are (1023, 1013) hamming codes",
        "prob": 0.7275862068965517
    }, {
        "ID": 6970,
        "phrase": " \n figure 7 : 7 figure 7: comparison between various upper bounds on the ml decoding bit error probability of the ensemble of (1033,1013) uniformly interleaved turbo-hamming code",
        "prob": 0.5761904761904761
    }, {
        "ID": 6970,
        "phrase": " \n figure 9 : 9 figure 9: comparison between various upper bounds on the ml decoding error probability, referring to the ensemble of uniformly interleaved multiple turbo-hamming codes where the three component codes are (1023, 1013) hamming codes (see fig",
        "prob": 0.693103448275862
    }, {
        "ID": 6971,
        "phrase": " other performance bounds under ml decoding or 'typical pairs decoding' are derived and applied to ensembles of turbo-like codes by divsalar  [2] , divsalar and biglieri  [3] , jin and mceliece  [10, 11] , miller and burshtein  [12] , sason and shamai  [14, 15, 16]  and viterbi  [22, 23] ",
        "prob": 0.7074074074074074
    }, {
        "ID": 6971,
        "phrase": " the tangential-sphere bound of poltyrev  [13]  forms one of the tightest performance bounds for ml decoded linear block codes transmitted over the binary-input additive white gaussian noise (biawgn) channel",
        "prob": 0.6192307692307693
    }, {
        "ID": 6971,
        "phrase": " the modulation of the transmitted signals is antipodal, and the modulated signals are coherently detected and ml decoded (with soft decision)",
        "prob": 0.50625
    }, {
        "ID": 6971,
        "phrase": " \n tangential-sphere bound (tsb) the tangential-sphere bound (tsb) forms an upper bound on the decoding error probability of ml decoding of linear block code whose transmission takes place over a binary-input awgn channel  [13, 14] ",
        "prob": 0.8096774193548386
    }, {
        "ID": 6971,
        "phrase": " \n improved tangential-sphere bound (itsb) in  [21] , yousefi and mehrabian derive a new upper bound on the block error probability of binary linear block codes whose transmission takes place over a binary-input awgn channel, and which are coherently detected and ml decoded",
        "prob": 0.8558823529411765
    }, {
        "ID": 6971,
        "phrase": " 3 the error exponents of the itsb and ahp bounds the itsb and the ahp bound were originally derived in  [20, 21]  as upper bounds on the ml decoding error probability of specific binary linear block codes",
        "prob": 0.644
    }, {
        "ID": 6971,
        "phrase": " \n summary and conclusions the tangential-sphere bound (tsb) of poltyrev  [13]  often happens to be the tightest upper bound on the ml decoding error probability of block codes whose transmission takes place over a binaryinput awgn channel",
        "prob": 0.7620689655172413
    }, {
        "ID": 6972,
        "phrase": " improved upper and lower bounds on the error probability of linear codes under ml decoding are addressed in  [12]  and references therein, and applied to various codes and ensembles",
        "prob": 0.6714285714285714
    }, {
        "ID": 6972,
        "phrase": " the tangential-sphere bound (tsb)  [9]  forms one of the tightest performance bounds for ml decoded linear block codes whose transmission takes place over the binary-input additive white gaussian noise (biawgn) channel",
        "prob": 0.6931034482758621
    }, {
        "ID": 6972,
        "phrase": " the modulation of the transmitted signals is antipodal, and the modulated signals are coherently detected and ml decoded (with soft decision)",
        "prob": 0.56875
    }, {
        "ID": 6972,
        "phrase": " \n tangential-sphere bound the tsb forms an upper bound on the decoding error probability of ml decoding of linear block code whose transmission takes place over a binary-input awgn channel  [9, 10] ",
        "prob": 0.6703703703703704
    }, {
        "ID": 6972,
        "phrase": " \n improved tangential-sphere bound in  [17] , yousefi and mehrabian derive a new upper bound on the block error probability of binary linear block codes whose transmission takes place over a binary-input awgn channel, and which are coherently detected and ml decoded",
        "prob": 0.8818181818181818
    }, {
        "ID": 6972,
        "phrase": " \n the error exponents of the itsb and ahp bounds the itsb and the ahp bound were originally derived in  [16, 17]  as upper bounds on the ml decoding error probability of specific binary linear block codes",
        "prob": 0.724
    }, {
        "ID": 6972,
        "phrase": " \n summary and conclusions the tangential-sphere bound (tsb) of poltyrev  [9]  often happens to be the tightest upper bound on the ml decoding error probability of block codes whose transmission takes place over a binary-input awgn channel",
        "prob": 0.8033333333333332
    }, {
        "ID": 6997,
        "phrase": " then the symmetry condition (1) becomes g(\u2212m) = e \u2212m g(m), \u2200m \u2208 r (14) define the probability of error p e (m) under ml decoding of the llr m as follows p e (m) = 0 \u2212\u221e g(m)dm",
        "prob": 0.41764705882352937
    }, {
        "ID": 6998,
        "phrase": " then the symmetry condition (1) becomes g(\u2212m) = e \u2212m g(m), \u2200m \u2208 r (14) define the probability of error p e (m) under ml decoding of the llr m as follows p e (m) = 0 \u2212\u221e g(m)dm",
        "prob": 0.5352941176470588
    }, {
        "ID": 7249,
        "phrase": " the lower bounds are also compared to gallager's random-coding upper bound  [5]  and the tangential-sphere upper bound  [10]  on the ml decoding error probability, applied to random block codes",
        "prob": 0.7958333333333333
    }, {
        "ID": 7249,
        "phrase": "2 db for all block error probabilities lower    4 : a comparison between upper and lower bounds on the ml decoding error probability, referring to block codes of length n = 500 bits which are encoded by an information block length of 400 bits",
        "prob": 0.5962962962962963
    }, {
        "ID": 7249,
        "phrase": " for    5 : a comparison between upper and lower bounds on the ml decoding error probability, referring to short block codes which are qpsk modulated and transmitted over the awgn channel",
        "prob": 0.8142857142857142
    }, {
        "ID": 7249,
        "phrase": "    6 : a comparison of upper and lower bounds on the ml decoding error probability for block codes of length n = 5580 bits and information block length of 4092 bits",
        "prob": 0.705
    }, {
        "ID": 7249,
        "phrase": " for an error probability of 10 \u22124 , the gap between the simulated performance of these codes under iterative decoding, and the isp lower bound, which gives an ultimate lower bound on the error probability of optimally designed codes under ml decoding, is approximately 1",
        "prob": 0.8555555555555555
    }, {
        "ID": 7249,
        "phrase": " the tightness of the isp bound is exemplified by comparing it with upper and lower bounds on the ml decoding error probability and also with computer simulations of turbo-like codes under iterative decoding",
        "prob": 0.8304347826086956
    }, {
        "ID": 7249,
        "phrase": " based on numerical results in  [16]  for the ensemble of uniformly interleaved (1144, 1000) turbo-block codes whose components are random systematic linear block codes, the gap in e b n 0 between the isp lower bound and an upper bound under ml decoding is 0",
        "prob": 0.8607142857142857
    }, {
        "ID": 7249,
        "phrase": " \n figure figure4: a comparison between upper and lower bounds on the ml decoding error probability, referring to block codes of length n = 500 bits which are encoded by an information block length of 400 bits",
        "prob": 0.7958333333333333
    }, {
        "ID": 7249,
        "phrase": " \n packing bound valembois\u2212fossorier bound improved sphere\u2212packing bound random coding upper bound tangetial\u2212sphere upper bound \n figure figure5: a comparison between upper and lower bounds on the ml decoding error probability, referring to short block codes which are qpsk modulated and transmitted over the awgn channel",
        "prob": 0.8675675675675676
    }, {
        "ID": 7249,
        "phrase": " \n figure figure6: a comparison of upper and lower bounds on the ml decoding error probability for block codes of length n = 5580 bits and information block length of 4092 bits",
        "prob": 0.7772727272727272
    }, {
        "ID": 7249,
        "phrase": " \n figure 10 : 10 figure 10: a comparison of the improved sphere-packing (isp) lower bound from section 3 and the exact decoding error probability of random binary linear block codes under ml decoding where the transmission takes place over the bec (see [2, eq",
        "prob": 0.8419354838709677
    }, {
        "ID": 7249,
        "phrase": " the tightness of the new bound is exemplified by comparing it with bounds on the ml decoding error probability, and computer simulations of iteratively decoded turbo-like codes",
        "prob": 0.719047619047619
    }, {
        "ID": 7250,
        "phrase": "    5 : a comparison between upper and lower bounds on the ml decoding error probability, referring to short block codes which are qpsk modulated and transmitted over the awgn channel",
        "prob": 0.7666666666666666
    }, {
        "ID": 7250,
        "phrase": " for an error probability of 10 \u22124 , the gap between the simulated performance of these codes under iterative decoding, and the isp lower bound, which gives an ultimate lower bound on the error probability of optimally designed codes under ml decoding, is approximately 1",
        "prob": 0.8185185185185184
    }, {
        "ID": 7250,
        "phrase": " the tightness of the isp bound is exemplified by comparing it with upper and lower bounds on the ml decoding error probability and also with computer simulations of turbo-like codes under iterative decoding",
        "prob": 0.7434782608695651
    }, {
        "ID": 7250,
        "phrase": " based on numerical results in  [17]  for the ensemble of uniformly interleaved (1144, 1000) turbo-block codes whose components are random systematic linear block codes, the gap in e b n 0 between the isp lower bound and an upper bound under ml decoding is 0",
        "prob": 0.8607142857142857
    }, {
        "ID": 7250,
        "phrase": " \n figure 4 : 4 figure4: a comparison between upper and lower bounds on the ml decoding error probability for block codes of length n = 500 bits and code rate of 0",
        "prob": 0.705
    }, {
        "ID": 7250,
        "phrase": " \n packing bound valembois\u2212fossorier bound improved sphere\u2212packing bound random coding upper bound tangetial\u2212sphere upper bound \n figure figure5: a comparison between upper and lower bounds on the ml decoding error probability, referring to short block codes which are qpsk modulated and transmitted over the awgn channel",
        "prob": 0.8945945945945947
    }, {
        "ID": 7250,
        "phrase": " \n figure 6 : 6 figure6: a comparison of upper and lower bounds on the ml decoding error probability for block codes of length n = 5580 bits and information block length of 4092 bits",
        "prob": 0.8227272727272726
    }, {
        "ID": 7250,
        "phrase": " \n figure 10 : 10 figure 10: a comparison of the improved sphere-packing (isp) lower bound from section 3 and the exact decoding error probability of random binary linear block codes under ml decoding where the transmission takes place over the bec (see [2, eq",
        "prob": 0.8741935483870967
    }, {
        "ID": 7250,
        "phrase": " its tightness is studied by comparing it with bounds on the ml decoding error probability, and computer simulations of iteratively decoded turbo-like codes",
        "prob": 0.6368421052631579
    }, {
        "ID": 7251,
        "phrase": " a comparison between upper and lower bounds on the ml decoding error probability for block codes of length n = 500 bits and code rate of 0",
        "prob": 0.7277777777777777
    }, {
        "ID": 7251,
        "phrase": " a comparison between upper and lower bounds on the ml decoding error probability, referring to short block codes which are qpsk modulated and transmitted over the awgn channel",
        "prob": 0.8142857142857142
    }, {
        "ID": 7251,
        "phrase": " for a block error probability of 10 \u22124 , the gap between the simulated performance of these codes under iterative decoding, and the isp lower bound, which gives an ultimate lower bound on the block error probability of optimally designed codes under ml decoding, is approximately 1",
        "prob": 0.8655172413793103
    }, {
        "ID": 7251,
        "phrase": " a comparison of upper and lower bounds on the ml decoding error probability for block codes of length n = 5580 bits and information block length of 4092 bits",
        "prob": 0.755
    }, {
        "ID": 7251,
        "phrase": " it is observed that this code outperforms random coding upper bound for ml decoded random codes with the same block length and code rate",
        "prob": 0.3736842105263158
    }, {
        "ID": 7251,
        "phrase": " based on numerical results in  [31]  for the ensemble of uniformly interleaved (1144, 1000) turbo-block codes whose components are random systematic, binary and linear block codes, the gap in eb n0 between the isp lower bound and an upper bound under ml decoding is 0",
        "prob": 0.8033333333333332
    }, {
        "ID": 7251,
        "phrase": " the tightness of the isp bound is exemplified by comparing it with upper and lower bounds on the ml decoding error probability and also with reported computer simulations of turbo-like codes under iterative decoding",
        "prob": 0.8374999999999999
    }, {
        "ID": 7251,
        "phrase": " a comparison of upper and lower bounds on the ml decoding error probability for block codes of length n = 5580 bits and information block length of 4092 bits",
        "prob": 0.8049999999999999
    }, {
        "ID": 7251,
        "phrase": " a comparison of the improved sphere-packing (isp) lower bound from section iii and the exact decoding error probability of random binary linear block codes under ml decoding where the transmission takes place over the bec (see [5,  eq",
        "prob": 0.7033333333333334
    }, {
        "ID": 7251,
        "phrase": " its tightness is studied by comparing it with bounds on the ml decoding error probability, and computer simulations of iteratively decoded turbo-like codes",
        "prob": 0.7421052631578947
    }, {
        "ID": 7357,
        "phrase": " examples are artificial intelligence  [6]  and physics  [7] , where one often deals with finite and short binary strings",
        "prob": 0.22142857142857145
    }, {
        "ID": 7408,
        "phrase": " using commutation of \u2704 ai and \u2192 h , we obtain a term t \u2032 such that s \u2032 \u2704 ai t \u2032 ",
        "prob": 0.2625
    }, {
        "ID": 7540,
        "phrase": " the particular case where l = 1 clearly provides a lower bound on the decoding error probability under ml decoding",
        "prob": 0.5399999999999999
    }, {
        "ID": 7540,
        "phrase": " a comparison between upper and lower bounds on the ml decoding error probability for block codes of length n = 500 bits and code rate of 0",
        "prob": 0.6722222222222222
    }, {
        "ID": 7540,
        "phrase": " a comparison of upper and lower bounds on the ml decoding error probability for block codes of length n = 5580 bits and information block length of 4092 bits",
        "prob": 0.755
    }, {
        "ID": 7540,
        "phrase": " for an error probability of 10 \u22124 , the gap between the simulated performance of these codes under iterative decoding, and the isp lower bound, which gives an ultimate lower bound on the error probability of optimally designed codes under ml decoding, is approximately 1",
        "prob": 0.8185185185185184
    }, {
        "ID": 7540,
        "phrase": " the tightness of the isp bound is exemplified by comparing it with upper and lower bounds on the ml decoding error probability",
        "prob": 0.75625
    }, {
        "ID": 7540,
        "phrase": " the full paper version  [15]  also presents numerical results for the binary erasure channel (bec); the exact performance of fully random binary linear block codes under ml decoding is compared with the isp bound when the transmission takes place over the bec",
        "prob": 0.6806451612903226
    }, {
        "ID": 7540,
        "phrase": "a comparison between upper and lower bounds on the ml decoding error probability for block codes of length n = 500 bits and code rate of 0",
        "prob": 0.6166666666666667
    }, {
        "ID": 7540,
        "phrase": " its tightness is studied by comparing it with bounds on the ml decoding error probability",
        "prob": 0.5916666666666667
    }, {
        "ID": 7547,
        "phrase": " the upper bounds on the ml decoding error probability enable to derive achievable regions which ensure reliable communications under ml decoding where the block length of the codes (or ensembles) tend to infinity; these regions depend on the asymptotic distance spectrum of the ensemble of binary linear block codes under consideration (to be defined in section ii)",
        "prob": 0.6342105263157896
    }, {
        "ID": 7547,
        "phrase": " they are also exemplified for various ensembles and provide tighter inner bounds on the boundary of the channel regions which are asymptotically attainable under ml decoding",
        "prob": 0.7833333333333333
    }, {
        "ID": 7547,
        "phrase": " in section iii, we derive the improved upper bounds under ml decoding when the transmission takes place over parallel mbios channels",
        "prob": 0.7277777777777777
    }, {
        "ID": 7547,
        "phrase": " distance properties of ensembles of turbo-like codes bounds on the ml decoding error probability of binary linear block codes or ensembles are often based on their distance properties (see, e",
        "prob": 0.564
    }, {
        "ID": 7547,
        "phrase": " improved bounds for independent parallel channels under ml decoding \n a",
        "prob": 0.6454545454545454
    }, {
        "ID": 7547,
        "phrase": " since the exact decoding error probability under ml decoding is in general unknown, we evaluate inner bounds on the attainable channel regions whose calculation is based on upper bounds on the ml decoding error probability",
        "prob": 0.7535714285714286
    }, {
        "ID": 7547,
        "phrase": "3] which relates to typical-pairs decoding over a single channel and the statement in theorem 3 for ml decoding over a set of independent parallel channels lies mainly in the first condition of both theorems",
        "prob": 0.5260869565217391
    }, {
        "ID": 7547,
        "phrase": " this indicates that there is still room for further improvement in the tightness of the analytical bounds under ml decoding",
        "prob": 0.3923076923076924
    }, {
        "ID": 7547,
        "phrase": " attainable channel regions for various ensembles of accumulate-based codes in this section, we compare inner bounds on the attainable channel regions of accumulate-based codes under ml decoding",
        "prob": 0.7541666666666667
    }, {
        "ID": 7547,
        "phrase": " the distance spectra of the spra and spara ensembles considered here were calculated in  [9]  using the techniques introduced in  [   the improved performance of the ensembles of spara codes under ml decoding is demonstrated by the gallager bounding technique (combined with the optimization of the tilting measures) in fig",
        "prob": 0.47
    }, {
        "ID": 7547,
        "phrase": " it is shown in this figure that for the spara ensemble with the parameters p = 3, q = 6 and \u03b1 = 2 15 , the gap between the inner bound on the attainable channel region under ml decoding and the capacity limit is less than 0",
        "prob": 0.5549999999999999
    }, {
        "ID": 7547,
        "phrase": " performance bounds for the bit error probability under ml decoding versus computer simulation results of iterative log-map decoding (with 10 iterations)",
        "prob": 0.505
    }, {
        "ID": 7547,
        "phrase": " the new bounds are used to obtain improved inner bounds on the attainable channel regions under ml decoding",
        "prob": 0.56875
    }, {
        "ID": 7663,
        "phrase": " since only exponential time solutions to the ml decoding problem are known, gallager also developed simple, iterative decoding algorithms for ldpc codes",
        "prob": 0.355
    }, {
        "ID": 7736,
        "phrase": " error probability after inner ml decoding unfortunately, the union bound is not very tight for channels with a bad to moderate signal-to-noise ratio, so that it is not suitable for analyzing our concatenated scheme",
        "prob": 0.5458333333333333
    }, {
        "ID": 7737,
        "phrase": " error probability after inner ml decoding unfortunately, the union bound is not very tight for channels with a bad to moderate signal-to-noise ratio, so that it is not suitable for analyzing our concatenated scheme",
        "prob": 0.5041666666666667
    }, {
        "ID": 7791,
        "phrase": " using this fact and the sphere-packing lower bound on the ml decoding error probability in (19), we get pr m d (e) \u2265 e \u2212n lesp(r 1 ) \u21d2 e m d (r, l) \u2264 le sp (r) , since r \u2192 r 1 as n \u2192 \u221e",
        "prob": 0.32105263157894737
    }, {
        "ID": 7858,
        "phrase": " combining lemmas 6 and 5, and then following the same derivation for ml decoding yields theorem 7",
        "prob": 0.2583333333333333
    }, {
        "ID": 7870,
        "phrase": " our focus is on ml decoding",
        "prob": 0.3
    }, {
        "ID": 8072,
        "phrase": " he showed that on cycle-free graphs they perform exact ml and app decoding, respectively",
        "prob": 0.2928571428571428
    }, {
        "ID": 8462,
        "phrase": " performance analysis before continuing to the derivation of a condition which needs to be met so that a rate-1/2 ns-pccc can achieve a better ml bound than its parent rate-1/3 pccc, we first enumerate a number of results, derived and justified in  [14] : 1) the minimum information weight w min for recursive convolutional encoders is w min = 2",
        "prob": 0.284375
    }, {
        "ID": 8462,
        "phrase": " thus, for small and more practical interleaver sizes, the performance of rate-1/2 ns-pccc does not gradually approach the upper bound for ml decoding",
        "prob": 0.3736842105263158
    }, {
        "ID": 8462,
        "phrase": " in  [9]  we have presented a technique for deriving good punctured codes and we have identified a rate-1/2 ps-pccc that achieves the second best performance bound for ml decoding, after the rate-1/2 ns-pccc",
        "prob": 0.37916666666666665
    }, {
        "ID": 8462,
        "phrase": " conclusion in this paper we have demonstrated that, if a certain condition is met over the awgn channel, puncturing of the systematic output of a rate-1/3 turbo code using a random interleaver leads to a rate-1/2 non-systematic turbo code that achieves a better performance than its parent code, when ml decoding is used",
        "prob": 0.41470588235294115
    }, {
        "ID": 8707,
        "phrase": " originally, lp decoding was introduced as a relaxation of ml decoding  [4] ",
        "prob": 0.3727272727272727
    }, {
        "ID": 8826,
        "phrase": " we concluded that pseudo-random puncturing could be used to obtain rate-1/2 pcccs exhibiting low error floors, while specific puncturing patterns that achieve either a lower error floor or quicker convergence to the ml performance bound, could be determined by a subsequent search",
        "prob": 0.23823529411764705
    }, {
        "ID": 8837,
        "phrase": " to have the same construction as user 1, user 1 needs to transmit (i) the result of the error correction function h, and (ii) u, for a total of \u2308(1 + \u03b7 1 )m(l\u01eb + 1)\u2309 + \u03b7 4 ml bits at most, achievable at a rate r o 1 ",
        "prob": 0.2157894736842105
    }, {
        "ID": 8907,
        "phrase": " finally, we observe that the argument of berlekamp, mceliece and van tilborg  [1]  can be used to show that exact ml decoding of the considered class of codes constructed from ldpc codes with regular left degree, of which the considered expander codes are a special case, remains np-hard",
        "prob": 0.378125
    }, {
        "ID": 8907,
        "phrase": " section iv gives the brief proof of the np-hardness of ml decoding of the considered class of codes constructed from ldpc codes with regular left degree",
        "prob": 0.41363636363636364
    }, {
        "ID": 8907,
        "phrase": " clearly, r ml (p) has the channel capacity 1 \u2212 h(p) as an upper bound",
        "prob": 0.4636363636363636
    }, {
        "ID": 9163,
        "phrase": " for purposes of comparison, the wer of lp decoding with no rpc cut, as well as a lower bound on the wer of the ml decoder have been included in the figure",
        "prob": 0.3736842105263158
    }, {
        "ID": 9163,
        "phrase": " therefore, this estimate gives a lower bound on the wer of ml decoding",
        "prob": 0.5083333333333333
    }, {
        "ID": 9221,
        "phrase": " ml provides simple data structures",
        "prob": 0.23333333333333334
    }, {
        "ID": 9748,
        "phrase": " specifically, referring concretely to the case \u03b4 = 3, due to the assumption of uniform distribution of the points in the unit sphere, the conditional probability density p(ai|ai\u22121)dai of ai given ai\u22121, i = 2, 3, is proportional (through the value of the density in the unit sphere) to the volume of some three-dimensional domain",
        "prob": 0.17586206896551723
    }]
}, {
    "topic_id": 31,
    "top_words": ["known", "well", "state", "type", "languages", "say", "initial", "problem", "ml", "non", "studied", "cs", "another", "literature", "events"],
    "phrases": [{
        "ID": 40,
        "phrase": " in this example, the initial query is j ournal of theoretical biology and artificial intelligence",
        "prob": 0.425
    }, {
        "ID": 360,
        "phrase": " the main conclusions are: lazyboosting algorithm outperforms the other four state-of-the-art supervised ml methods in all domains tested",
        "prob": 0.3736842105263158
    }, {
        "ID": 404,
        "phrase": " priority associativity classical negation (\u00ac) ~1 right assiciative default negation (not ) not 1 cannot be nested conjunction (and, \u2227) & , 2 right associative disjunction (or, \u2228) | ; v 3 right associative implication (then, \u2192) -> 4 not associative implication (if, \u2190) <- :- 4 not associative equivalence (if and only if, \u2194) <-> 4 not associative \n now by the definition of \u03c9 p , there is ai \u2032 not \u2208 n \u22c4 such that i \u2032 = i \u2032 obj \u222a i \u2032not is a minimal model of p ",
        "prob": 0.4862068965517241
    }, {
        "ID": 665,
        "phrase": " in mercury (and also in functional languages such as ml or haskell), this condition is enforced by the syntax",
        "prob": 0.425
    }, {
        "ID": 665,
        "phrase": " in ml for example, it is forbidden, as it breaks the capabilities of the type inference procedure",
        "prob": 0.425
    }, {
        "ID": 784,
        "phrase": "  ejerhed (1988)  described clauses as a natural structure above chunks: it is a hypothesis of the author's current clause-by-clause processing theory, that a unit corresponding to the basic clause is a stable and easily recognizable surface unit and that is is also an important partial result and building block in the construction od a richer linguistic representation that encompasses syntax as well as semantics and discourse structure  (ejerhed, 1988, page 220)  the goal of this shared task is to evaluate automatic methods, especially machine learning methods, for finding clause boundaries in text",
        "prob": 0.19137931034482758
    }, {
        "ID": 1283,
        "phrase": " l :\u227a\u2192 r such that l((x, y)) = max{r : x \u227a ai r y, a i \u2208 a}, and then (\u227a, l) is a's pedigreed belief state",
        "prob": 0.34444444444444444
    }, {
        "ID": 1595,
        "phrase": " as an example, the wumpus cave has been realized, well known from introductory ai texts  [10] ",
        "prob": 0.425
    }, {
        "ID": 1596,
        "phrase": " as an example, the wumpus cave has been realized, well known from introductory ai texts  [10] ",
        "prob": 0.5083333333333333
    }, {
        "ID": 1597,
        "phrase": " as an example, the wumpus cave has been realized, well known from introductory ai texts  [10] ",
        "prob": 0.5083333333333333
    }, {
        "ID": 1598,
        "phrase": " accordingly, several proposals for the use of weighted bases can be found in the ai literature",
        "prob": 0.3416666666666666
    }, {
        "ID": 1786,
        "phrase": " another worth mentioning is the analysis of ai data / knowledge searches, such as the muddy children problem (cf",
        "prob": 0.2733333333333333
    }, {
        "ID": 1792,
        "phrase": " as such it has the structure of a bilattice, a term due to ginsberg  [gin86] , who was the first to note the importance of bilattices for inference in artificial intelligence  [gin92] ",
        "prob": 0.39444444444444443
    }, {
        "ID": 1793,
        "phrase": " as such it has the structure of a bilattice, a term due to ginsberg  (ginsberg 1986) , who was the first to note the importance of bilattices for inference in artificial intelligence  (ginsberg 1992 )",
        "prob": 0.33888888888888885
    }, {
        "ID": 1846,
        "phrase": " continuations were found to be a major tool for the design of interpreters and compilers for many languages, most prominently scheme, ml and haskell",
        "prob": 0.5352941176470588
    }, {
        "ID": 2333,
        "phrase": " the first important observation is that this makes the ai problem not trivial",
        "prob": 0.21000000000000002
    }, {
        "ID": 2333,
        "phrase": "10) if not clear from context, we add superscripts sp and ai to \u03be, to resolve ambiguities between (1",
        "prob": 0.2818181818181818
    }, {
        "ID": 2474,
        "phrase": " does it capture our intuitions about conditionals? in the ai literature, there has been discussion of the right properties of default statements (which are essentially conditionals)",
        "prob": 0.74
    }, {
        "ID": 2475,
        "phrase": " does this semantics capture our intuitions about conditionals? in the ai literature, there has been little consensus on the \"right\" properties for defaults (which are essentially conditionals)",
        "prob": 0.75625
    }, {
        "ID": 2481,
        "phrase": " in machine learning, an instance corresponds to another event, which is described as a set of attributes' events",
        "prob": 0.22142857142857145
    }, {
        "ID": 2601,
        "phrase": " although many theorems of the machine learning literature in particular, and the computer science literature in general, are limited to functional properties that are trivial in the sense of rice, they are widely regarded as non-trivial in an intuitive sense",
        "prob": 0.337037037037037
    }, {
        "ID": 2629,
        "phrase": "html) which declares to \"advance ai and serve as a tool to measure the state of the art\"  (loebner) ",
        "prob": 0.3153846153846154
    }, {
        "ID": 2660,
        "phrase": " these performances are comparable to other debuggers known to be efficient enough, for example the mercury tracer of somogyi and henderson  [sh99]  or the ml tracer of tolmach and appel  [ta95] ",
        "prob": 0.505
    }, {
        "ID": 2913,
        "phrase": " continuations were found to be a major tool for the design of interpreters and compilers for many languages, most prominently scheme, ml and haskell",
        "prob": 0.5352941176470588
    }, {
        "ID": 2944,
        "phrase": "introduction functional languages like ml assist the programmer with prevention of such errors as run-time type errors, thanks to automatic type inference",
        "prob": 0.5761904761904761
    }, {
        "ID": 2945,
        "phrase": "introduction functional languages like ml assist the programmer with prevention of such errors as run-time type errors, thanks to automatic type inference",
        "prob": 0.6238095238095238
    }, {
        "ID": 2991,
        "phrase": "introduction it is well known that traditional type systems, such as the one found in standard ml  [milner, tofte, harper, and macqueen 1997] , with parametric polymorphism and type constructors can be used to capture program properties beyond those naturally associated with a hindley-milner type system  [milner 1978 ]",
        "prob": 0.6393939393939394
    }, {
        "ID": 2992,
        "phrase": "introduction it is well known that traditional type systems, such as the one found in standard ml  [milner, tofte, harper, and macqueen 1997] , with parametric polymorphism and type constructors, can be used to capture program properties beyond those naturally associated with a hindley-milner type system  [milner 1978 ]",
        "prob": 0.6393939393939394
    }, {
        "ID": 2993,
        "phrase": "introduction it is well known that traditional type systems, such as the one found in standard ml  (milner et al",
        "prob": 0.43571428571428567
    }, {
        "ID": 3176,
        "phrase": " the issue has been extensively studied in the context of databases and artificial intelligence (ai) and several different types of updates are studied in the literature",
        "prob": 0.41764705882352937
    }, {
        "ID": 3176,
        "phrase": " this type of updates frequently appears in ai in the context of theory updates or belief updates, e",
        "prob": 0.46923076923076923
    }, {
        "ID": 3183,
        "phrase": " en g\u00e9n\u00e9ral, ce type d'implantation n\u00e9cessite une m\u00e9thode de g\u00e9n\u00e9ration de code-objet \u00e0 l'ex\u00e9cution (runtime code generation), que nous empruntons \u00e0 l'une des ffi existantes de standard ml of new jersey  [4] ",
        "prob": 0.29583333333333334
    }, {
        "ID": 3192,
        "phrase": " the part of the objects that supports these defeasible updates is defined by the programmer and may include slots, tables, global variables or specific data structures such as lists or arrays (defeasible is an ai term that means \"backtrack-able\")",
        "prob": 0.22592592592592592
    }, {
        "ID": 3451,
        "phrase": " dynamic constraint satisfaction (dcs)  (dechter and dechter 1988 ) is a promising field of ai taking into account dynamic changes of the constraint store such as the addition and deletion of values and constraints",
        "prob": 0.3227272727272727
    }, {
        "ID": 3907,
        "phrase": " needless to say that, the present common fear of ai is proportional to his ignorance, as was true for many tools found useful in this century",
        "prob": 0.24117647058823527
    }, {
        "ID": 4034,
        "phrase": " the early days of semantics were concerned with questions such as the completeness of type assignment to untyped terms (as happens in programming languages like ml which have static type inference)  [40, 10] ",
        "prob": 0.36818181818181817
    }, {
        "ID": 4047,
        "phrase": " it is well known that the ml estimation is asymptotically unbiased under some regulation conditions",
        "prob": 0.3416666666666666
    }, {
        "ID": 4876,
        "phrase": " administrators will be unwilling to spend time with ml assistants unless they can adapt to their task very rapidly, responding to correction, asking for help only for boundary conditions and adapting to later policy changes",
        "prob": 0.29583333333333334
    }, {
        "ID": 5069,
        "phrase": " we implemented our procedure as part of the uclid verifier [ucl], which is written in moscow ml  [mos] ",
        "prob": 0.65
    }, {
        "ID": 5070,
        "phrase": " we implemented our procedure as part of the uclid verifier [ucl], which is written in moscow ml  [mos] ",
        "prob": 0.65
    }, {
        "ID": 5071,
        "phrase": " we implemented our procedure as part of the uclid verifier [ucl], which is written in moscow ml  [mos] ",
        "prob": 0.65
    }, {
        "ID": 5072,
        "phrase": " we implemented our procedure as part of the uclid verifier [ucl], which is written in moscow ml  [mos] ",
        "prob": 0.65
    }, {
        "ID": 5073,
        "phrase": " we implemented our procedure as part of the uclid verifier [ucl], which is written in moscow ml  [mos] ",
        "prob": 0.65
    }, {
        "ID": 5244,
        "phrase": " this is quite in a spirit of ml where type information is optional and is mainly used for documentation or in module interfaces",
        "prob": 0.4066666666666666
    }, {
        "ID": 5969,
        "phrase": " m does not implement l ai \u2264 p lnd-t a i (because m does not have the query-decreasing property with respect to a \u2032 )",
        "prob": 0.21000000000000002
    }, {
        "ID": 6134,
        "phrase": " maximal constraint languages have also been studied in the context of machine learning  [24]  and quantified csps  [18] , and they attract a great deal of attention in universal algebra, cf",
        "prob": 0.355
    }, {
        "ID": 6134,
        "phrase": " these classes of languages are well-studied in universal algebra and computer science; they have, for instance, been considered in connection with machine learning and constraint satisfaction",
        "prob": 0.32105263157894737
    }, {
        "ID": 6317,
        "phrase": " for example, languages that rely extensively on parser state, such as c and c++, as well as layout-sensitive languages such as ml and haskell, may prove more difficult for a packrat parser to handle efficiently",
        "prob": 0.3521739130434782
    }, {
        "ID": 6366,
        "phrase": " this tradition will be very comfortable to programmers accustomed to languages in the ml family, but haskell addicts should beware that the conventions, between type information and cons, are inverse to the conventions in haskell",
        "prob": 0.719047619047619
    }, {
        "ID": 6367,
        "phrase": " this tradition will be very comfortable to programmers accustomed to languages in the ml family, but haskell addicts should beware that the conventions, between type information and cons, are inverse to the conventions in haskell",
        "prob": 0.8142857142857142
    }, {
        "ID": 6368,
        "phrase": " this tradition will be very comfortable to programmers accustomed to languages in the ml family, but haskell addicts should beware that the conventions, between type information and cons, are inverse to the conventions in haskell",
        "prob": 0.8142857142857142
    }, {
        "ID": 6724,
        "phrase": " pragmatically, see them as two more tools: only testing will say which is best in a specific machine learning problem",
        "prob": 0.2733333333333333
    }, {
        "ID": 6785,
        "phrase": " not only should the ai be able to categorize cat and dogs, but it should also be able to categorize the sequence of events as a sequence",
        "prob": 0.5083333333333333
    }, {
        "ID": 6990,
        "phrase": " modifications to the ml estimator such as the laplace \"add one\" and the krichevsky-trofimov \"add half\"  [4]  have been proposed as remedies, but these only alleviate the problem  [3] ",
        "prob": 0.3588235294117647
    }, {
        "ID": 7000,
        "phrase": " this is not to say that there isn't some remarkably clever ai software in service today",
        "prob": 0.3727272727272727
    }, {
        "ID": 7025,
        "phrase": " efficient implementation of or-parallelism has also been extensively investigated in the context of  ai systems (32; 33) ",
        "prob": 0.3416666666666666
    }, {
        "ID": 7362,
        "phrase": " ,\u223cb m } \u00b4 \u00b5      \u00fb \u00f6 n \u2265 0\u00b8m \u2265 0\u00b8 \u00f2 l > 0\u00b8 \u00f2 \u00fb \u00f6 h\u00b8 a i \u00b8 b j \u00b8 \u00f2 h k \u00f6 \u00f8\u00f3\u00f1\u00d7 \u00f2 c\u00b8 w ai \u00b8 w bj \u00b8 \u00d7 \u00fb \u00f0\u00f0 \u00d7 w\u00b8 \u00f6 \u00f2 \u00f8\u00f9\u00f6 \u00f0 \u00f2\u00f9\u00f1 \u00f6\u00d7\u00ba \u00ec \u00d7\u00fd\u00f1 \u00f3\u00f0 \u223c \u00f3\u00f9\u00f6\u00f6 \u00f2 \u00f2 \u00f2 \u00f8 \u00f3\u00f2 \u00be\u00ba\u00bd \u00f2\u00f3\u00f8 \u00d7 \u00f9\u00f0\u00f8 \u00f2 \u00f8 \u00f3\u00f2 \u00f3\u00f6 \u00f2 \u00b9 \u00f8 \u00f3\u00f2 \u00d7 \u00f0\u00f9\u00f6 \u00f8\u00f3 \u00f4\u00f6\u00f3\u00fa \u00fb \u00f6\u00d7 \u00f6\u00f3\u00f1 \u00f0 \u00d7\u00d7 \u00f0 \u00f2 \u00f8 \u00f3\u00f2 \u00f2 \u00f2 \u00f1\u00f4\u00f3\u00f6\u00f8 \u00f2\u00f8 \u00fb \u00fd \u00b4 \u00f0 \u00f3\u00f2 \u00f2 \u00e4 \u00d7 \u00f8\u00fe \u00bd \u00bc\u00b5\u00ba \u00ef \u00f2 \u00f4\u00f3\u00d7 \u00f8 \u00fa \u00f2 \u00f2 \u00f8 \u00fa \u00f9\u00f0\u00f8 \u00f0 \u00f8 \u00f6 \u00f0\u00d7 \u00f2 \u00f8 \u00d7\u00f8 \u00f2 \u00f6 \u00fb \u00fd \u00d7 \u00f8\u00f3\u00f1\u00d7 a \u00f3\u00f6 \u00f8 \u00f6 \u00f2 \u00f8 \u00f3\u00f2\u00d7 \u223ca\u00b8\u00f6 \u00d7\u00f4 \u00f8 \u00fa \u00f0\u00fd\u00ba \u00ec \u00fc \u00f8 \u00f1\u00f3 \u00f0\u00b9 \u00f8 \u00f3\u00f6 \u00f8 \u00d7 \u00f1 \u00f2\u00f8 \u00d7 \u00f3 \u00f6\u00f9\u00f0 \u00d7 \u00d7 \u00f6\u00f6 \u00f9\u00f2\u00f8 \u00f0 \u00eb \u00f8 \u00f3\u00f2 \u00bf\u00b8 \u00f9\u00f8 \u00f2 \u00f3\u00f6\u00f1 \u00f0\u00f0\u00fd \u00d7\u00f4 \u00f2 \u00f8 \u00f6\u00f9\u00f0 \u00d7 \u00f0 \u00d7\u00f8 \u00f3\u00fa \u00f6 \u00f9\u00d7 \u00f8\u00f3 \u00f6 \u00fb \u00f3\u00f2\u00f0\u00f9\u00d7 \u00f3\u00f2\u00d7 \u00d7 \u00f3\u00f0\u00f0\u00f3\u00fb\u00d7\u00ba \u2022 \u00ec h \u00f3 \u00d7 \u00f6\u00f9\u00f0 \u00b4\u00bd\u00b5 \u00f2 \u00f2 \u00f6\u00f6 \u00f8 \u00f8\u00f3\u00f1\u00d7 a 1 , ",
        "prob": 0.22000000000000003
    }, {
        "ID": 7368,
        "phrase": " ) 2 for a given set x of node alias pairs, define ai \u03c8 (x) = x p \u2032 is entry , \u03c8 is entry \u2192 p ao \u03c8 \u2032 (x) \u03c8 \u2032 is entry \u2192 ",
        "prob": 0.3153846153846154
    }, {
        "ID": 7770,
        "phrase": " what formulas are still realizable if one restricts the events to those considered suitable for specific problem areas, such as forms of multiagent planning? and given a desirable formula (a 'postcondition' in another sense of the word), what are the initial conditions such that a sequence of events realizes it? this is the relation to ai problems concerning regression as pointed out in the introductory section, on which we think fast progress can now be made",
        "prob": 0.47750000000000004
    }, {
        "ID": 7772,
        "phrase": " what formulas are still realizable if one restricts the events to those considered suitable for specific problem areas, such as forms of multi-agent planning? and given a desirable formula (a 'postcondition' in another sense of the word), what are the initial conditions such that a sequence of events realizes it? this is the relation to ai problems concerning regression as pointed out in the introductory section  [12] , and also to reasoning given specific protocols, such as always has been the emphasis for knowledge-based programs in the interpreted systems community  [7] , and as recently investigated in  [22]  in a dynamic epistemic context",
        "prob": 0.5018518518518519
    }, {
        "ID": 7773,
        "phrase": " what formulas are still realizable if one restricts the events to those considered suitable for specific problem areas, such as forms of multi-agent planning? and given a desirable formula (a 'postcondition' in another sense of the word), what are the initial conditions such that a sequence of events realizes it? this is the relation to ai problems concerning regression as pointed out in the introductory section  [12] , and also to reasoning given specific protocols, such as always has been the emphasis for knowledge-based programs in the interpreted systems community  [7] , and as recently investigated in  [22]  in a dynamic epistemic context",
        "prob": 0.5574074074074075
    }, {
        "ID": 7905,
        "phrase": " several problems in automatic reasoning and artificial intelligence can be naturally encoded as #sat problem",
        "prob": 0.3642857142857144
    }, {
        "ID": 7906,
        "phrase": " several problems in automatic reasoning and artificial intelligence can be naturally encoded as #sat problem",
        "prob": 0.36428571428571427
    }, {
        "ID": 7964,
        "phrase": " generic variables appear in the implementation of ml languages",
        "prob": 0.31
    }, {
        "ID": 8326,
        "phrase": " as atr is based on pcf (a theoretical first-cousin of both ml and haskell), our results suggest that one might be able to craft \"feasible sublanguages\" of ml and haskell that are both theoretically well-supported and tolerable for programmers",
        "prob": 0.8115384615384614
    }, {
        "ID": 8327,
        "phrase": " as atr is based on pcf (a theoretical first-cousin of both ml and haskell), our results suggest that one might be able to craft \"feasible sublanguages\" of ml and haskell that are both theoretically well-supported and tolerable for programmers",
        "prob": 0.8115384615384614
    }, {
        "ID": 8328,
        "phrase": " as atr is based on pcf (a theoretical first-cousin of both ml and haskell), our results suggest that one might be able to craft \"feasible sublanguages\" of ml and haskell that are both theoretically well-supported and tolerable for programmers",
        "prob": 0.8115384615384614
    }, {
        "ID": 8555,
        "phrase": " the first important observation is that this does not make the ai problem trivial",
        "prob": 0.21000000000000002
    }, {
        "ID": 8638,
        "phrase": "in verification and in (optimal) ai planning, a successful method is to formulate the application as boolean satisfiability (sat), and solve it with state-of-the-art dpll-based procedures",
        "prob": 0.36818181818181817
    }, {
        "ID": 8639,
        "phrase": "in verification and in (optimal) ai planning, a successful method is to formulate the application as boolean satisfiability (sat), and solve it with state-of-the-art dpll-based procedures",
        "prob": 0.3227272727272727
    }, {
        "ID": 8855,
        "phrase": " and if there is a path from an initial state, say q ai to another initial state in a aa , say q aj then there is a corresponding path from an initial state, say q bi in a bb (which corresponds to q ai ) to another initial state, say q bj in a bb (which corre-sponds to q aj ) and vice versa since cs a = cs b and for all automata in cs a there is a corresponding automaton in cs b with the same behavior and vice versa",
        "prob": 0.9093023255813953
    }, {
        "ID": 8855,
        "phrase": " and if there is a path from an initial state, say q ai to another initial state in a aa , say q aj then there is a corresponding path from an initial state, say q bi in a bb (which corresponds to q ai ) to another initial state, say q bj in a bb (which corresponds to q aj ) and vice versa since cs a = cs b and for all automata in cs a there is a corresponding automaton in cs b with the same behavior and vice versa",
        "prob": 0.9071428571428571
    }, {
        "ID": 8856,
        "phrase": " let a ai and a aj be two elements of cs a ",
        "prob": 0.23333333333333334
    }, {
        "ID": 8856,
        "phrase": " since cs a = cs b it follows that for automata, say a ai and a aj in cs a there are automata, say a bi and a bj in cs b such that the behaviors of a ai and a bi are the same, and the behaviors of a aj and a bj are also the same",
        "prob": 0.705
    }, {
        "ID": 8856,
        "phrase": " therefore, it follows that if a ai is removed from cs a to get cs aa and a bi from cs b to get cs bb even then for all automaton in cs aa there is an automaton in cs bb with the same behavior and vice versa",
        "prob": 0.7639999999999999
    }, {
        "ID": 8856,
        "phrase": " since all automata in cs aa are tirm, it follows that for every state, say q ai in a aa there is a path from an initial state of a aa to q ai and a path from q ai to a terminal state of a aa , and from every initial state in a aa there is a path from that initial state to a terminal state in a aa and for every terminal state in a aa there is a path from an initial state of a aa to it",
        "prob": 0.7525000000000001
    }, {
        "ID": 8856,
        "phrase": " and again since there is a mapping between the boundary conditions among all the automata in cs aa and cs bb , and for all automaton in cs aa there is an automaton in cs bb with the same behavior and vice versa, it follows that if there is a path from an initial state, say q ai to another initial state in a aa , say q aj then there is a corresponding path from an initial state, say q bi in a bb (which corresponds to q ai ) to another initial state, say q bj in a bb (which corresponds to q aj ) and vice versa",
        "prob": 0.903921568627451
    }, {
        "ID": 8907,
        "phrase": " quite recently, guruswami and vardy  [2]  have shown that ml decoding problem of reed-solomon codes is nphard, the first hardness result for a specific family of codes with non-trivial algebraic architecture",
        "prob": 0.23461538461538461
    }, {
        "ID": 9224,
        "phrase": " they have considered the dynamic semantics of several simple languages, and ml type-checking  [7] ",
        "prob": 0.6230769230769231
    }, {
        "ID": 9228,
        "phrase": " these are syntax trees, not character strings! ml provides destructor functions for taking apart pplambda objects",
        "prob": 0.19375
    }, {
        "ID": 9233,
        "phrase": " the first published discussions of the function appeared in 1970  [7, 9] , after it had been investigated extensively at stanford's ai laboratory during 1968  [8] ",
        "prob": 0.23846153846153847
    }, {
        "ID": 9239,
        "phrase": " in addition, many ai problems can be encoded quite naturally in sat (eg",
        "prob": 0.3727272727272727
    }, {
        "ID": 9272,
        "phrase": " if c a is an abstraction of c c with respect to (d c , d ai ), then there exists a sequence abstraction mapping and a sequence abstraction mapping as required in de nition 5",
        "prob": 0.20666666666666667
    }, {
        "ID": 9278,
        "phrase": " performance on a known hard problem: since learning from tutorial instruction has not been extensively studied in machine learning, there are no standard, di cult problems",
        "prob": 0.3736842105263158
    }, {
        "ID": 9285,
        "phrase": " we also relate these problems to the hypergraph transversal problem, a well known problem which is related to other applications in ai and for which no polynomial time algorithm is known",
        "prob": 0.39444444444444443
    }, {
        "ID": 9339,
        "phrase": " a complementary way of evaluating the e ectiveness of our scheme would be to apply it to well-studied situations and examples in ai in which reasoning in a dynamically updated world is well-known to be challenging, such as reasoning about action",
        "prob": 0.1708333333333333
    }, {
        "ID": 9352,
        "phrase": " does it capture our intuitions about conditionals? in the ai literature, there has been discussion of the right properties of default statements (which are essentially conditionals)",
        "prob": 0.74
    }, {
        "ID": 9449,
        "phrase": " f d d i p h y l a y er w i l lrecogni z e s u ch non-b oundary jk' s a n d establ i s h a n ewsym bol boundary f or t he r e m ai ni n g s t r e a m ",
        "prob": 0.23846153846153847
    }, {
        "ID": 9631,
        "phrase": " does this semantics capture our intuitions about conditionals? in the ai literature, there has been little consensus on the \"right\" properties for defaults (which are essentially conditionals)",
        "prob": 0.75625
    }]
}, {
    "topic_id": 32,
    "top_words": ["ml", "xy", "log", "max", "vec", "hp", "hx", "dp", "hv", "condition", "hy", "xv", "case", "mv", "function"],
    "phrases": [{
        "ID": 141,
        "phrase": " \u00b5 ai satisfies a strong separability condition",
        "prob": 0.2625
    }, {
        "ID": 423,
        "phrase": " it is easy to see that the contingency ml 2 = 0 satisfies the two conditions in ac2",
        "prob": 0.425
    }, {
        "ID": 423,
        "phrase": " (note that we needed to set ml 2 to 0, contrary to facts, in order to reveal the latent dependence of fb on ml 1 ",
        "prob": 0.44375
    }, {
        "ID": 424,
        "phrase": " it is easy to see that the contingency ml 2 = 0 satisfies the two conditions in ac2",
        "prob": 0.3416666666666666
    }, {
        "ID": 424,
        "phrase": " (note that we needed to set ml 2 to 0, contrary to fact, in order to reveal the latent dependence of fb on ml 1 ",
        "prob": 0.44375
    }, {
        "ID": 425,
        "phrase": " it is easy to see that the contingency ml 2 = 0 satisfies the two conditions in ac2",
        "prob": 0.3416666666666666
    }, {
        "ID": 437,
        "phrase": " a's optimal bids maximize w (a) as follows: max ai = 1, 0 \u2264 ai \u2264 2 n w (a) = max ai = 1, 0 \u2264 ai \u2264 2 n f 2 (a 1 ) + f 2 (a 2 ) + \u2022 \u2022 \u2022 + f 2 (a n ) = max ai = 1 0 \u2264 ai \u2264 2 n n 2 \u2022(a 1 + \u2022 \u2022 \u2022 + a n ) = n 2 ",
        "prob": 0.3727272727272727
    }, {
        "ID": 437,
        "phrase": " max ni\u2022ai = 1 1 \u2264 ai \u2264 k n w (a) = max ni\u2022ai = 1 1 \u2264 ai \u2264 k n n 1 \u2022( n k \u2022a 1 ) + n 2 \u2022( n k \u2022a 2 ) + \u2022 \u2022 \u2022 + n m \u2022( n k \u2022a m ) = n k ",
        "prob": 0.5125
    }, {
        "ID": 1464,
        "phrase": " ml 47",
        "prob": 0.22000000000000003
    }, {
        "ID": 1881,
        "phrase": " i generated 10000 strings from this language, and calculated the various quantities discussed above using ml estimates on various strings that i chose rather arbitrarily: the results are summarised in table  7 ",
        "prob": 0.2772727272727273
    }, {
        "ID": 1881,
        "phrase": " initialise grammar to ml repeat gather all frequent strings calculate distributions cluster using k-means for all c in the set of clusters do if c satisfies mi criterion then calculate mdl gain end if end for \n table 7",
        "prob": 0.33749999999999997
    }, {
        "ID": 1971,
        "phrase": "  a = \u03c0((at 1 \u2022 a \u2022 a2) \u2229 ai ) 16: return (a, f ) where f (\u03bb) = (qa, ia, fa), f (1) = (qt 1 , it 1 , ft 1 ) \u00d7 qa i and f (2n) = f2(n) \u00d7 qa i 17: else if p = (p1 \u2022 p2) \u2022 p3 then 18: compute (a \u2032 , f \u2032 ) = h(p1 \u2022 (p2 \u2022 p3), c) and let f \u2032 (n) = (q \u2032 n , i \u2032 n , f \u2032 n )",
        "prob": 0.38125
    }, {
        "ID": 1971,
        "phrase": " \n 1 : 1 if p = \u03b5, p = \u03c3 or p = p * 1 then 2: compute a dfa a, recognizing l(p) \u2229 c 3:return (a, f ) with f (\u03bb) = (qa, ia, fa) 4:else if p = p1 + p2 then 5: compute (a1, f1) = h(p1, c) and (a2, f2) = h(p2, c \u2212 l(p1)) 6: let a = a1 \u222a a2 7: return (a, f ) with f (\u03bb) = (qa, ia, fa), f (1n) = f1(n) and f (2n) = f2(n) 8: else if p = p1 \u2022 p2 with p1 = \u03b5 or p1 = \u03c3 then 9: compute (a1, f1) = h(p1, c/l(p2)) and (a2, f2) = h(p2, l(p1)\\c) 10: let a = a1 \u2022 a2 11: return (a, f ) with f (\u03bb) = (qa, ia, fa), f (1n) = f1(n) and f (2n) = f2(n) 12: else if p = p * 1 \u2022 p2 then 13: compute dfa's ai and at 1 for i and t1 as defined in proposition 4 14: compute (a2, f2) = h(p2, c2) with c2 as in proposition 4 15: let",
        "prob": 0.6302325581395349
    }, {
        "ID": 2333,
        "phrase": " \u00b5 ai satisfies a strong separability condition",
        "prob": 0.2625
    }, {
        "ID": 2390,
        "phrase": " so, awesome maintains the stationarity hypothesis if and only max ai\u2208ai |p ai hi \u2212 p ai h prev i | < \u01eb s ",
        "prob": 0.25833333333333336
    }, {
        "ID": 2744,
        "phrase": " since d \u2208 \u03c0 i j and d satisfies ai j , it follows that (a, geu(d)) satisfies pi j ",
        "prob": 0.31
    }, {
        "ID": 3698,
        "phrase": " by definition of the auxiliary measure t (3), one can inspect that w q (\u2022|x) \u226a t for every x with the density function (obtained from (  4 )) f t,q (y|x) = \u03b2 det \u03c6 x exp \u03b1 2 y p 2 \u2212 vec (y \u2212 hx) \u2032 \u03c6 \u22121 x vec (y \u2212 hx) \u03c3 2 (18) where \u03c6 x 1 \u03c3 2 (x \u2032 \u2297 i m )\u03c3(x \u2297 i m ) + i ml ",
        "prob": 0.5549999999999999
    }, {
        "ID": 3698,
        "phrase": "2, we can deduce that ac f t,q (y|x) |log 2 f t,q (y|x)| dt dp \u2264 ec f t,q (y|x) |log 2 f t,q (y|x)| dt dp \u2264 |log 2 \u03b2| ec 1 \u03c0 ml \u03c3 2ml det \u03c6 x e \u2212 1 \u03c3 2 vec (y\u2212 hx) \u2032 \u03c6 \u22121 x vec (y\u2212 hx) d\u00b5 y dp + log 2 e \u03c3 2 ec 2\u03b1 2 y p 2 \u03c0 ml \u03c3 2ml det \u03c6 x e \u2212 1 \u03c3 2 vec (y\u2212 hx) \u2032 \u03c6 \u22121 x vec (y\u2212 hx) d\u00b5 y dp \u2264 |log 2 \u03b2| \u03c9 2 (c) + 2\u03b1 2 log 2 e \u03c3 2 \u03c9 2\u2212p (c) y 2 2 \u03c0 ml \u03c3 2ml det \u03c6 x e \u2212 1 \u03c3 2 vec (y\u2212 hx) \u2032 \u03c6 \u22121 x vec (y\u2212 hx) d\u00b5 y dp if we take the sup p\u2208p g,\u03b3 (x) of both sides, the second term of the rhs is a finite value",
        "prob": 0.9303571428571429
    }, {
        "ID": 3698,
        "phrase": " we note that w q (\u2022|x) \u226a \u00b5 y with density function f q (y|x) = 1 \u03c0 ml \u03c3 2ml det \u03c6 x e \u2212 1 \u03c3 2 vec (y\u2212 hx) \u2032 \u03c6 \u22121 x vec (y\u2212 hx) , where \u03c6 x is defined as in  (18) ",
        "prob": 0.6733333333333333
    }, {
        "ID": 3698,
        "phrase": " for every fixed y \u2208 y , we have f po,q (y) = 1 \u03c0 ml \u03c3 2ml det \u03c6 e \u2212 1 \u03c3 2 vec (y\u2212 hx) \u2032 \u03c6 \u22121 x vec (y\u2212 hx) dp o \u2265 1 \u03c0 ml \u03c3 2ml det \u03c6 x e \u2212 2 \u03c3 2 vec y \u2032 \u03c6 \u22121 x vec y e \u2212 2 \u03c3 2 vec ( hx) \u2032 \u03c6 \u22121 x vec ( hx) dp o \u2265 e \u2212 2 \u03c3 2 y 2 2 1 \u03c0 ml \u03c3 2ml det \u03c6 x e \u2212 2 \u03c3 2 vec ( hx) \u2032 \u03c6 \u22121 x vec ( hx) dp o this means that \u2212 log 2 f po,q h (y) = o( y 2 2 )",
        "prob": 0.8818181818181818
    }, {
        "ID": 3698,
        "phrase": " case \u03b7 \u2264 2: recalling that \u03c6 x = 1 \u03c3 2 (x \u2032 \u2297 i m )\u03c3(x \u2297 i m ) + i ml , one can verify that for every x \u2208 x, ( \u03bb min \u03c3 2 x \u2032 x + i l ) \u2297 i m \u2264 \u03c6 x \u2264 ( \u03bb max \u03c3 2 x 2 2 + 1)i ml , where \u03bb max and \u03bb min > 0 are the maximum and minimum eigenvalues of \u03c3",
        "prob": 0.5399999999999999
    }, {
        "ID": 3698,
        "phrase": " then, f po,q (y) \u2265 1 \u03c0 ml \u03c3 2ml det \u03c6 x e \u2212 2 \u03c3 2 vec y \u2032 \u03c6 \u22121 x vec y e \u2212 2 \u03c3 2 vec ( hx) \u2032 \u03c6 \u22121 x vec ( hx) dp o \u2265 1 \u03c0 ml (\u03bb max x 2 2 + \u03c3 2 ) ml e \u2212tr(y(\u03bb min x \u2032 x+\u03c3 2 i l ) \u22121 y \u2032 ) e \u2212tr( hx(\u03bb min x \u2032 x+\u03c3 2 i l ) \u22121 x \u2032 h\u2032 ) dp o \u2265 y 2 \u2264 x 2 ,r(y)\u2286r(x) k (\u03bb max x 2 2 + \u03c3 2 ) ml dp o , where k = k( h, \u03c3) is a nonzero constant dependent on h and \u03c3",
        "prob": 0.8250000000000001
    }, {
        "ID": 3698,
        "phrase": " note that w qv (\u2022|x) \u226a t with a density function (obtained from (4)) f t,qv (y|x) = \u03b2 det \u03c6 x,v exp \u03b1 2 y p 2 \u2212 (y \u2212 \u00b5 h|v x) \u2032 \u03c6 \u22121 x,v (y \u2212 \u00b5 h|v x) \u03c3 2 (22) where \u03c6 x,v = 1 \u03c3 2 (x \u2032 \u2297 i m )\u03c3 h|v (x \u2297 i m ) + i ml ",
        "prob": 0.6894736842105263
    }, {
        "ID": 3698,
        "phrase": "2, we can deduce that ac f t,qv (y|x) |log 2 f t,qv (y|x)| dt dp dr \u2264 ec f t,qv (y|x) |log 2 f t,qv (y|x)| dt dp dr \u2264 |log 2 \u03b2| ec 1 \u03c0 ml \u03c3 2ml det \u03c6 x,v e \u2212 1 \u03c3 2 vec (y\u2212\u00b5 h|v x) \u2032 \u03c6 \u22121 x,v vec (y\u2212\u00b5 h|v x) d\u00b5 y dpdr + log 2 e \u03c3 2 ec 2\u03b1 2 y p 2 \u03c0 ml \u03c3 2ml det \u03c6 x,v e \u2212 1 \u03c3 2 vec (y\u2212\u00b5 h|v x) \u2032 \u03c6 \u22121 x vec (y\u2212\u00b5 h|v x) d\u00b5 y dpdr \u2264 |log 2 \u03b2| \u03c9 2 (c) + 2\u03b1 2 log 2 e \u03c3 2 \u03c9 2\u2212p (c) y 2 2 \u03c0 ml \u03c3 2ml det \u03c6 x,v e \u2212 1 \u03c3 2 vec (y\u2212\u00b5 h|v x) \u2032 \u03c6 \u22121 x,v vec (y\u2212\u00b5 h|v x) d\u00b5 y dpdr if we take sup p\u2208p g,\u03b3 (x) of both sides, the second term of the rhs is a finite value",
        "prob": 0.8904761904761905
    }, {
        "ID": 3698,
        "phrase": "we note that w qv (\u2022|x) \u226a \u00b5 y with density functionf qv (y|x) = 1 \u03c0 ml \u03c3 2ml det \u03c6 x,ve \u2212 vec (y\u2212\u00b5 h|v x) \u2032 \u03c6 \u22121x,v vec (y\u2212\u00b5 h|v x) , \n 1 \u03c3 2 2 \u03c3 2 1 x,v vec y e \u2212 2 \u03c3 2 \u2265 e \u2212 2 \u03c3 2 y 2 2 1 2 \u03c3 2 12221222222 d(pow qv ) d\u00b5 y",
        "prob": 0.7772727272727273
    }, {
        "ID": 3698,
        "phrase": " for every fixed y \u2208 y , we havef po,qv (y) = 1 \u03c0 ml \u03c3 2ml det \u03c6 x,v e \u2212 vec (y\u2212\u00b5 h|v x) \u2032 \u03c6 \u22121 x,v vec (y\u2212\u00b5 h|v x) dp o \u2265 1 \u03c0 ml \u03c3 2ml det \u03c6 x,v e \u2212 vec y \u2032 \u03c6 \u2212vec (\u00b5 h|v x) \u2032 \u03c6 \u22121 x vec (\u00b5 h|v x) dp o \u03c0 ml \u03c3 2ml det \u03c6 x,v e \u2212 vec (\u00b5 h|v x) \u2032 \u03c6 \u22121x,v vec (\u00b5 h|v x) dp o this means that \u2212 log 2 f po,qv (y) = o( y 2 2 \n 2 \u03c3 2 vec y \u2032 \u03c6 \u2212 1 x,v vec y e \u2212 2 \u03c3 2 2122 3 , one can deduce that the support of p o has no interior point",
        "prob": 0.8466666666666667
    }, {
        "ID": 3698,
        "phrase": "case \u03b7 \u2264 2: recalling that \u03c6 x,v = 1 \u03c3 2 (x \u2032 \u2297 i m )\u03c3 h|v (x \u2297 i m ) + i ml , one can verify that for every x \u2208 x,( \u03bb min (v) \u03c3 2 x \u2032 x + i l ) \u2297 i m \u2264 \u03c6 x,v \u2264 ( \u03bb max (v) \u03c3 2 x 2 2 + 1)i ml ,where \u03bb max (v) and \u03bb min (v) > 0 are the maximum and minimum eigenvalues of \u03c3 h|v ",
        "prob": 0.6894736842105263
    }, {
        "ID": 3698,
        "phrase": " then,f po,qv (y) \u2265 1 \u03c0 ml \u03c3 2ml det \u03c6 x,v e \u2212 vec (\u00b5 h|v x) \u2032 \u03c6 \u22121 x,v vec (\u00b5 h|v x) dp o \u2265 e \u2212tr(y(\u03bb min (v)x \u2032 x+\u03c3 2 i l ) \u22121 y \u2032 ) \u03c0 ml (\u03bb max (v) x 2 2 + \u03c3 2 ) ml e \u2212tr(\u00b5 h|v x(\u03bb min (v)x \u2032 x+\u03c3 2 i l ) \u22121 x \u2032 \u00b5 \u2032 h|v ) dp o \u2265 y 2 \u2264\u03bb min (v) x 2 ,r(y)\u2286r(x) k(v) (\u03bb max (v) x 2 2 + \u03c3 2 ) ml dp o , where k(v) = k(\u00b5 h|v , \u03c3 h|v ) is a nonzero function from v to r + ",
        "prob": 0.8314285714285715
    }, {
        "ID": 4061,
        "phrase": ",p\u22121 n log \u00e2q rs,q \u00e2h q + \u03c32 n,q i + diag ( \u0175q ) +tr \u00e2q rs,q \u00e2h q + \u03c32 n,q i + diag ( \u0175q ) \u22121 r + 1 2 (q(2p \u2212 q) + p) log n (4) where \u00e2q , rs,q , \u03c32 n,q , \u0175q are the ml estimates of the unknown parameters assuming q sources, that is \u00e2q , rs,q , \u03c32 n,q , \u0175q = arg max aq rs,qa h q \u2208rq,\u03c3 2 n,q >0,wq\u2208w \u2212n log a q r s,q a h q + \u03c3 2 n,q i + diag (w q ) +tr a q r s,q a h q + \u03c3 2 n,q i + diag (w q ) \u22121 r ",
        "prob": 0.5666666666666667
    }, {
        "ID": 4115,
        "phrase": " in lemma 11 we show that r(n) = o(1), giving: r u (n) = o(1) + 1 2var m \u00b5 * (x) n\u22121 i=0 e p (\u03bc i \u2212 \u00b5 * ) 2 (18) note that \u03bci is almost the ml estimator",
        "prob": 0.25833333333333336
    }, {
        "ID": 4407,
        "phrase": " the first part contains the riemann curvature tensor, defined as r hlk j = \u2212r hkl j = \u2202\u03b3 hl j \u2202x k \u2212 \u2202\u03b3 hk j \u2202x l + \u03b3 mk j \u03b3 hl m \u2212 \u03b3 ml j \u03b3 hk m (37) several other quantities are derived from the curvature tensor that are widely used in physics and mathematics",
        "prob": 0.6107142857142858
    }, {
        "ID": 4408,
        "phrase": " the first part contains the riemann curvature tensor, defined as r hlk j = \u2212r hkl j = \u2202\u03b3 hl j \u2202x k \u2212 \u2202\u03b3 hk j \u2202x l + \u03b3 mk j \u03b3 hl m \u2212 \u03b3 ml j \u03b3 hk m (37) several other quantities are derived from the curvature tensor that are widely used in physics and mathematics",
        "prob": 0.5392857142857143
    }, {
        "ID": 4422,
        "phrase": " for 1 \u2264 i = i \u2032 \u2264 k, notice that |f (a i ) \u2212 f (a i \u2032 )| \u2265 # ai (s)/m",
        "prob": 0.18333333333333335
    }, {
        "ID": 4786,
        "phrase": " note that the corresponding expression in  (40)  for ml decoding is pr(|hx| 2 + 2(hx) t z < 0)",
        "prob": 0.2818181818181818
    }, {
        "ID": 5046,
        "phrase": " we shall call x the ml codeword of y",
        "prob": 0.2625
    }, {
        "ID": 5118,
        "phrase": " it solves the ml detection problem: x = arg min x y \u2212 e s 2 hx 2 (5) the algorithms deals only with real quantities, i",
        "prob": 0.43571428571428567
    }, {
        "ID": 5119,
        "phrase": " it solves the ml detection problem: x = arg min x y \u2212 e s 2 hx 2 (5) the algorithms deals only with real quantities, i",
        "prob": 0.43571428571428567
    }, {
        "ID": 5120,
        "phrase": " it solves the ml detection problem: x = arg min x y \u2212 e s 2 hx 2 (4) the algorithms deals only with real quantities, i",
        "prob": 0.3642857142857142
    }, {
        "ID": 5172,
        "phrase": " \u2227 an)t \u00f2\u00f3 \u2192 \u00e9 \u00e1\u00d7 ai \u00fa \u00f9\u00f3\u00f9\u00d7\u00f0\u00fd \u00d7 \u00f8 \u00d7 \u00f0 apply(ai)t , 1 \u2264 i \u2264 n \u00e9 \u00ef \u00fd \u00d7 a1 \u2227 ",
        "prob": 0.18333333333333335
    }, {
        "ID": 5172,
        "phrase": " \u2228 an)t \u00f2\u00f3 \u2192 \u00e9 \u00e1\u00d7 ai \u00fa \u00f9\u00f3\u00f9\u00d7\u00f0\u00fd \u00d7 \u00f8 \u00d7 \u00f0 apply(ai)t , 1 \u2264 i \u2264 n \u00e9 \u00ef \u00fd \u00d7 a1 \u2228 ",
        "prob": 0.18333333333333335
    }, {
        "ID": 5196,
        "phrase": " we denote the mean time to a latent fault by ml and mean time to repair by mrl",
        "prob": 0.36428571428571427
    }, {
        "ID": 5196,
        "phrase": " the probability that another latent fault, l 2 occurs is p (l 2 |v 1 ) = mrv ml (4) where mrv \u226a ml",
        "prob": 0.46923076923076923
    }, {
        "ID": 5196,
        "phrase": " the probability that another visible fault, v 2 occurs is p (v 2 |l 1 ) = mdl + mrl mv (5) and the probability that another latent fault, l 2 , occurs is p (l 2 |l 1 ) = mdl + mrl ml (6) as before, mrl + mdl \u226a mv and mrl + mdl \u226a ml",
        "prob": 0.6961538461538462
    }, {
        "ID": 5196,
        "phrase": " next, we calculate the total double-fault failure rate as follows 1 mttdl = p (v 2 |v 1 ) + p (l 2 |v 1 ) mv + p (v 2 |l 1 ) + p (l 2 |l 1 ) ml (7) where the first term on the right side counts the fraction of the visible faults that result in double-failures, and the second term counts the fraction of latent faults that result in double-failures",
        "prob": 0.46
    }, {
        "ID": 5196,
        "phrase": " combining the previous equations and accounting for correlated faults, mttdl becomes \u03b1 \u2022 ml 2 mv 2 (mv + ml)(mrv \u2022 ml + (mrl + mdl) \u2022 mv) (8) \n implications to understand the implications of equation 8, we investigate its behavior at various operating ranges",
        "prob": 0.3482758620689655
    }, {
        "ID": 5196,
        "phrase": " then, mttdl \u2248 \u03b1 \u2022 mv 2 mrv (9) because mv + ml \u2248 ml and mrv \u2022 ml \u226b (mrl + mdl) \u2022 mv",
        "prob": 0.74
    }, {
        "ID": 5196,
        "phrase": " on the other hand, if the latent fault rate dominates the visible fault rate, {mrl+mdl, mrv} \u226a ml \u226a mv, then mttdl \u2248 \u03b1 \u2022 ml 2 mrl + mdl (10) because mv + ml \u2248 mv and mrv \u2022 ml \u226a (mrl + mdl) \u2022 mv",
        "prob": 0.7892857142857144
    }, {
        "ID": 5196,
        "phrase": " equation 10 indicates that if latent faults are frequent, we must reduce mdl, as it can negate the additional ml factor of reliability, a result of replication",
        "prob": 0.2157894736842105
    }, {
        "ID": 5196,
        "phrase": " as a result, the approximation mttdl \u2248 \u03b1 \u2022 mv 2 mrv + mv 2 ml ( 11 ) holds when latent faults rates are non-negligible, i",
        "prob": 0.41764705882352937
    }, {
        "ID": 5196,
        "phrase": " ml < mv 2 ",
        "prob": 0.35000000000000003
    }, {
        "ID": 5196,
        "phrase": "  [50] ), we assume that latent faults are five times as likely as visible faults, resulting in an ml of 2",
        "prob": 0.43571428571428567
    }, {
        "ID": 5196,
        "phrase": " \n increase mv or ml based on seagate's specifications, a 200gb consumer barracuda drive has a 7% visible fault probability in a 5year service life  [51] , whereas a 146gb enterprise cheetah has a 3% fault probability  [52] ",
        "prob": 0.35
    }, {
        "ID": 5233,
        "phrase": " theorem 4 the ml error probability for a v-blast communication system with m transmit and m receive antennas satisfies 3 lim \u03c1 \u2192 \u221e r \u2208 r vb log p e (r, \u03c1) \u2212 r log \u03c1 = \u2212m, (18) where r vb is given by r vb {r|m > r log \u03c1 > 0}",
        "prob": 0.3375
    }, {
        "ID": 5501,
        "phrase": " , n, can be written as  [38] ,  [39]  \u1ef9k = h h h f x k + wk  (7)  and the ml receiver chooses xk for x k if and only if xk = arg min x\u2208s \u1ef9k \u2212 h h h f x 2 (8) where wk \u223c cn (0, n 0 ) is the gaussian noise after signal combining",
        "prob": 0.5842105263157894
    }, {
        "ID": 5502,
        "phrase": " , n, can be written as  [38] ,  [39]  \u1ef9k = h h h f x k + wk  (7)  and the ml receiver chooses xk for x k if and only if xk = arg min x\u2208s \u1ef9k \u2212 h h h f x 2 (8) where wk \u223c cn (0, n 0 ) is the gaussian noise after signal combining",
        "prob": 0.5842105263157894
    }, {
        "ID": 5789,
        "phrase": "6 message: known in advance streams in delay: prespecified universal error exponent: double-exponential double-exponential channel: known awgn known awgn constraint: average power average power noiseless required required feedback: initialization: 2 nr -pam none + ml feedback ongoing: mmse feedback mmse feedback + small r-pam perturbations channel input: gaussian perturbed gaussian decoding: minimum distance minimum distance equivalent unstable unstable plant: r < log 2 \u03bb < c r < log 2 \u03bb < c initial condition: bounded zero disturbance: zero bounded stability sense: almost-sure [18] exponential tail fig",
        "prob": 0.2546666666666667
    }, {
        "ID": 5913,
        "phrase": " \u00eb\u00f3 \u00f8 \u00f0\u00f3 \u00f6 \u00f8 \u00f1 \u00f8 \u00f3 \u00f8 \u00f3 \u00f2\u00f8 \u00f2 \u00f6\u00f3\u00f2\u00f8 \u00f3 x k \u00d7 \u00f3\u00f9\u00f2 \u00f3\u00fa \u00fd log h k k i=1 (c \u2032 |q \u22121 i |) , \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00f8 \u00f8 a i \u00f6 \u00f2 \u00f2\u00f6 \u00d7 \u00f2 \u00f3\u00f6 \u00f6 \u2264 log 2 h (c \u2032 ) h h i=1 |q \u22121 i | \u2264 log(2c \u2032 )h + \u03c0 |d| h i=1 1 a i = o h + |d| h i=1 1 a i \u00b4 \u00d7 \u00d7 \u00f3\u00fb\u00f2 \u00f0 \u00f8 \u00f6\u00b8\u00f8 \u00f6\u00d7\u00f8 \u00f8 \u00f6\u00f1 \u00f3 \u00f8 \u00d7 \u00f3\u00f9\u00f2 \u00d7 \u00f2 \u00f8 \u00f3\u00f1 \u00f2 \u00f8 \u00fd \u00f8 \u00d7 \u00f3\u00f2 \u00f3\u00f2 \u00ba\u00b5 \u00ec \u00f2 \u00fc\u00f8 \u00d7\u00f8 \u00f4 \u00f3\u00f2\u00d7 \u00d7\u00f8\u00d7 \u00f3 \u00d7\u00f8 \u00f1 \u00f8 \u00f2 h i=1 1 ai \u00ba \u00ec\u00f3 \u00f8 \u00d7 \u00f4\u00f9\u00f6\u00f4\u00f3\u00d7 \u00b8\u00f3\u00f2\u00d7 \u00f6 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4\u00f3\u00d7\u00d7 \u00f0 b\u00b3\u00d7 \u00f3\u00f6 \u00fa \u00f2 a\u00ba \u00ec \u00d7 \u00f2\u00f9\u00f1 \u00f6 \u00d7 \u00f6\u00f8 \u00f2\u00f0\u00fd \u00f3\u00f9\u00f2 \u00f3\u00fa \u00fd \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 b \u2208] \u2212 a, a] \u00f8 \u00f8 \u00d7 \u00f8 \u00d7 \u00fd b = d mod 2 \u00f2 b 2 \u2212d 4 = 0 mod a\u00ba \u00d7\u00d7\u00f9\u00f1 \u00f2 \u00f8 \u00fb\u00f3\u00f6\u00d7\u00f8 \u00d7 \u00f8 \u00f8 \u00f8 \u00f5\u00f9 \u00f6 \u00f8 \u00f5\u00f9 \u00f8 \u00f3\u00f2 \u00d7 \u00f6\u00f3\u00f3\u00f8 \u00f1\u00f3 \u00f9\u00f0\u00f3 \u00f4\u00f6 \u00f1 \u00fa \u00d7\u00f3\u00f6 \u00f3 a \u00f2 \u00f3\u00f2\u00d7 \u00f6 \u00f2 \u00f8 \u00d7 \u00d7 \u00f3 \u00f3 \u00f2 \u00fa \u00f2 a \u00d7 \u00f4 \u00f6 \u00f8 \u00f0\u00fd\u00f3 \u00f2 \u00f3 \u00f8 \u00f2\u00d7 \u00f2 \u00f9\u00f4\u00f4 \u00f6 \u00f3\u00f9\u00f2 \u00f3\u00f2 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 b\u00b3\u00d7 \u00f3 2 \u2022 2 \u03c9(a) \u2264 2\u03c4 (a)\u00b8\u00fb \u00f6 \u03c9(a) \u00f2\u00f3\u00f8 \u00d7 \u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00f4\u00f6 \u00f1 \u00f8\u00f3\u00f6\u00d7 \u00f3 a \u00f2 \u03c4 (a) \u00f8\u00d7 \u00f2\u00f9\u00f1 \u00f6 \u00f3 \u00fa \u00d7\u00f3\u00f6\u00d7\u00ba \u00e0 \u00f2 \u00b8h i=1 1 a i \u2264 2 |d| 3 a=1 \u03c4 (a) a , \u00f2 \u00f8 \u00d7 \u00d7\u00f9\u00f1 \u00f1 \u00fd \u00f3\u00f9\u00f2 \u00fd \u00d7\u00f8 \u00f2 \u00f6 \u00f8 \u00f2 \u00f5\u00f9 \u00d7 \u00f6\u00f3\u00f1 \u00f2 \u00f0\u00fd\u00f8 \u00f2\u00f9\u00f1 \u00f6 \u00f8 \u00f3\u00f6\u00fd\u00ba \u00ef \u00f9\u00d7 \u00f8 \u00d7\u00f8 \u00f1 \u00f8 \u00d7 n n=1 1 n = log n + \u03b3 + o(1/n ) \u00fb \u00f8 \u03b3 = 0",
        "prob": 0.5125
    }, {
        "ID": 6109,
        "phrase": " the ml metric can then be written as m (s) = tr (v \u2212 sh) h (v \u2212 sh) ",
        "prob": 0.31
    }, {
        "ID": 6109,
        "phrase": " theorem 9: for a linear stbc in k variables, s = k\u22121 k=0 x ki a 2k + x kq a 2k+1 , the ml metric, m (s) defined in (6) decomposes as m (s) = k\u22121 k=0 m k (x k ) + m c where m c = \u2212(k \u2212 1)tr v h v is independent of all the variables and m k (x k ) is a function only of the variable x k , iff 6 a h k a l + a h l a k = 0 \u2200l = k, k + 1 if k is even \u2200l = k, k \u2212 1 if k is odd ",
        "prob": 0.29047619047619044
    }, {
        "ID": 6109,
        "phrase": " theorem 9 for this case specializes to: theorem 11: for a linear stbc in k complex variables, s = k\u22121 k=0 x ki a 2k + x kq a 2k+1 satisfying the necessary condition a h 2k a 2k+1 + a h 2k+1 a 2k = 0, 0 \u2264 k \u2264 k \u2212 1, the ml metric, m (s) defined in (6) decomposes as m (s) = k\u22121 k=0 m k (x k ) + m c where m c = \u2212(k \u2212 1)tr v h v , iff a h k a l + a h l a k = 0, 0 \u2264 k = l \u2264 2k \u2212 1",
        "prob": 0.45909090909090905
    }, {
        "ID": 6109,
        "phrase": " (32) we also have proposition 12: for a linear stbc in k complex variables, s = k\u22121 k=0 x ki a 2k + x kq a 2k+1 satisfying the necessary condition a h 2k a 2k+1 +a h 2k+1 a 2k = 0, 0 \u2264 k \u2264 k \u22121, the ml metric, m (s) defined in (6) decomposes as m (s) = k\u22121 k=0 m k (x k ) + m c where m c = \u2212(k \u2212 1)tr v h v , iff tr a k hh h a h l + a l hh h a h k = 0, 0 \u2264 k = l \u2264 2k \u22121",
        "prob": 0.5499999999999999
    }, {
        "ID": 6122,
        "phrase": " we note (r i ai \u2192 ",
        "prob": 0.22000000000000003
    }, {
        "ID": 6177,
        "phrase": " the ml receiver for x\u2295 is given by x \u2295;ml = arg minx \u2295 ||y \u2212 h\u2295x\u2295|| 2 ",
        "prob": 0.2818181818181818
    }, {
        "ID": 6188,
        "phrase": " then, noting that log p y |x (y i |x i ) = \u2212\u03b3 i x i + log p y |x (y i |0), ml decoding can also be written as x(y) = arg min x\u2208c i\u2208i \u03b3 i x i ",
        "prob": 0.3923076923076923
    }, {
        "ID": 6308,
        "phrase": ") this means that the number of bits required to code the pattern is smaller than the negative logarithm of the ml i",
        "prob": 0.22142857142857145
    }, {
        "ID": 6340,
        "phrase": " using (43) in (41), max-log bit llrs can then be written as: ml solution of (2)",
        "prob": 0.3416666666666666
    }, {
        "ID": 6340,
        "phrase": "  2 ); exhaustive-search ml with optimal bit llr computed through the jacobian logarithm (or \"max * \" function)  [30] ",
        "prob": 0.20666666666666667
    }, {
        "ID": 6421,
        "phrase": " however, because pa and inf t are accumulation points, for any such \u03b5 > 0 and \u03b4 > 0, there is an index i such that ai \u2212 pa < \u03b4 and ti \u2208 [inf t, inf t + \u03b5)",
        "prob": 0.3727272727272727
    }, {
        "ID": 6422,
        "phrase": " however, because pa and inf t are accumulation points, for any such \u03b5 > 0 and \u03b4 > 0, there is an index i such that ai \u2212 pa < \u03b4 and ti \u2208 [inf t, inf t + \u03b5)",
        "prob": 0.3727272727272727
    }, {
        "ID": 6490,
        "phrase": " we set plb(a) = 2 max ai\u2208u | ai an | 1/j , which is nearly optimal  [24] , or to be more specific t \u2264 plb(a) < 2t",
        "prob": 0.25833333333333336
    }, {
        "ID": 6862,
        "phrase": " (79) we first bound the common rate r 0 : we now bound the sum rate r 0 + r 1 : nr 0 = h(w 0 ) = i(w 0 ; y n 2a , y n 2b ) + h(w 0 |y n 2a , y n 2b ) (a nr 0 + nr 1 = h(w 0 , w 1 ) = i(w 0 , w 1 ; y n 1a , y n 1b ) + h(w 0 , w 1 |y n 1a , y n 1b ) \u2264 i(w 0 , w 1 ; y n 1a , y n 1b ) + n\u03b4 1 = n i=1 i(w 0 , w 1 ; y 1ai , y 1bi |y i\u22121 1a , y i\u22121 1b ) + n\u03b4 1 (a) = n i=1 i(w 0 , w 1 ; y 1ai |y i\u22121 1a , y i\u22121 1b , x 1ai ) + i(w 0 , w 1 ; y 1bi |y i 1a , y i\u22121 1b , x 1bi ) + n\u03b4 1 (b) \u2264 n i=1 h(y 1ai |x 1ai ) \u2212 h(y 1ai |w 0 , w 1 , y i\u22121 1a , y i\u22121 1b , x 1ai , x ai ) + h(y 1bi |x 1bi ) \u2212 h(y 1bi |w 0 , w 1 , y i 1a , y i\u22121 1b , x 1bi , x bi ) + n\u03b4 1 (c) = n i=1 h(y 1ai |x 1ai ) \u2212 h(y 1ai |x 1ai , x ai ) + h(y 1bi |x 1bi ) \u2212 h(y 1bi |x 1bi , x bi ) + n\u03b4 1 = n i=1 i(x ai ; y 1ai |x 1ai ) + i(x bi ; y 1bi |x 1bi ) + n\u03b4 1 ",
        "prob": 0.7088235294117647
    }, {
        "ID": 6862,
        "phrase": " the first term in the sum in (83) can be bounded as i(w 1 ; y 1ai |t i , x 1ai ) \u2264 h(y 1ai |t i , x 1ai ) \u2212 h(y 1ai |w 1 , t i , x 1ai , x ai ) (a) \u2264 h(y 1ai |t i , x 1ai ) \u2212 h(y 1ai |t i , x 1ai , x ai ) \u2264 i(x ai ; y 1ai |t i , x 1ai ) (84) where (a) follows from the markov chain condition (w 1 , t i ) \u2192 (x ai , x 1ai ) \u2192 y 1ai ",
        "prob": 0.39444444444444443
    }, {
        "ID": 6876,
        "phrase": " = p (\u015d ml = e) ",
        "prob": 0.22000000000000003
    }, {
        "ID": 7311,
        "phrase": " instead, the ml decoder should be arg max m p (y n |m) where n is the block length",
        "prob": 0.2818181818181818
    }, {
        "ID": 7356,
        "phrase": " examples are artificial intelligence  [6]  and physics  [7] , where one often deals with finite and short binary strings",
        "prob": 0.22142857142857145
    }, {
        "ID": 7408,
        "phrase": " using the stratification of \u2192 a , the confluence of \u2192 ai implies that this pair is not feasible",
        "prob": 0.31
    }, {
        "ID": 7409,
        "phrase": " using the stratification of \u2192 a , the confluence of \u2192 ai implies that this pair is not feasible",
        "prob": 0.31
    }, {
        "ID": 7791,
        "phrase": " the ml decoding error exponent (corresponding to the case l = 1) and the feedback exponent e f (r) are also plotted for comparison purposes",
        "prob": 0.33999999999999997
    }, {
        "ID": 7857,
        "phrase": " if noiseless feedback is available, the ai can also have an explicit functional dependence on the c i\u22121 1 that lie to the left on the timeline",
        "prob": 0.23846153846153847
    }, {
        "ID": 7858,
        "phrase": " theorem 2: given a rate r x > h(p x ), there exists a randomized streaming encoder and maximum likelihood decoder pair (per definition 2) such that for all e < e ml (r x ) there is a constant k > 0 such that pr[x n\u2212\u2206 = x n\u2212\u2206 ] \u2264 k exp{\u2212\u2206e ml (r x )} for all n, \u2206 \u2265 0 where e ml (r x ) = sup 0\u2264\u03c1\u22641 \u03c1r x \u2212 (1 + \u03c1) log x p x (x) 1 1+\u03c1 ",
        "prob": 0.444
    }, {
        "ID": 7858,
        "phrase": " (i) for all e < e ml,sw,x (r x , r y ), there is a constant k > 0 such that pr[x n\u2212\u2206 = x n\u2212\u2206 ] \u2264 k exp{\u2212\u2206e} for all n, \u2206 \u2265 0 where e ml,sw,x (r x , r y ) = min inf \u03b3\u2208[0,1] e ml x (r x , r y , \u03b3), inf \u03b3\u2208[0,1] 1 1 \u2212 \u03b3 e ml y (r x , r y , \u03b3) ",
        "prob": 0.7
    }, {
        "ID": 7858,
        "phrase": " (ii) for all e < e ml,sw,y (r x , r y ) there is a constant k > 0 such that pr[\u0177 n\u2212\u2206 = y n\u2212\u2206 ] \u2264 k exp{\u2212\u2206e} for all n, \u2206 \u2265 0 where e ml,sw,y (r x , r y ) = min inf \u03b3\u2208[0,1] 1 1 \u2212 \u03b3 e ml x (r x , r y , \u03b3), inf \u03b3\u2208[0,1] e ml y (r x , r y , \u03b3) ",
        "prob": 0.3923076923076923
    }, {
        "ID": 7858,
        "phrase": " (iii) for all e < e ml,sw,xy (r x , r y ) there is a constant k > 0 such that pr[(x n\u2212\u2206 , \u0177 n\u2212\u2206 ) = (x n\u2212\u2206 , y n\u2212\u2206 )] \u2264 k exp{\u2212\u2206e} for all n, \u2206 \u2265 0 where e ml,sw,xy (r x , r y ) = min inf \u03b3\u2208[0,1] e ml x (r x , r y , \u03b3), inf \u03b3\u2208[0,1] e ml y (r x , r y , \u03b3) ",
        "prob": 0.65
    }, {
        "ID": 7858,
        "phrase": " in definitions (i)-(iii), e ml x (r x , r y , \u03b3) = sup \u03c1\u2208[0,1] [\u03b3e x|y (r x , \u03c1) + (1 \u2212 \u03b3)e xy (r x , r y , \u03c1)] e ml y (r x , r y , \u03b3) = sup \u03c1\u2208[0,1] [\u03b3e y|x (r x , \u03c1) + (1 \u2212 \u03b3)e xy (r x , r y , \u03c1)] (13) and e xy (r x , r y , \u03c1) = \u03c1(r x + r y ) \u2212 log x,y p xy (x, y) 1 1+\u03c1 1+\u03c1 e x|y (r x , \u03c1) = \u03c1r x \u2212 log y x p xy (x, y) 1 1+\u03c1 1+\u03c1 e y|x (r y , \u03c1) = \u03c1r y \u2212 log x y p xy (x, y) 1 1+\u03c1 1+\u03c1 (14) theorem 7: let (r x , r y ) be a rate pair such that r x > h(x|y ), r y > h(y |x), r x + r y > h(x, y )",
        "prob": 0.7774193548387097
    }, {
        "ID": 7858,
        "phrase": " example 1: symmetric source with uniform marginals e sw,x (r x , r y ) = e block sw,x (r x , r y ) = e ml x (r x , r y , 0) = sup \u03c1\u2208[0,1] [e xy (r x , r y , \u03c1)]",
        "prob": 0.3399999999999999
    }, {
        "ID": 7858,
        "phrase": " similarly for source y: e sw,y (r x , r y ) = e block sw,y (r x , r y ) = e ml y (r x , r y , 0) = sup \u03c1\u2208[0,1] [e xy (r x , r y , \u03c1)]",
        "prob": 0.425
    }, {
        "ID": 7858,
        "phrase": " now e ml x (r x , r y , \u03b3) = sup \u03c1\u2208[0,1] [\u03b3e x|y (r x , \u03c1) + (1 \u2212 \u03b3)e xy (r x , r y , \u03c1)] \u2265 sup \u03c1\u2208[0,1] [e xy (r x , r y , \u03c1)] = e ml x (r x , r y , 0) similarly e ml y (r x , r y , \u03b3) \u2265 e ml y (r x , r y , 0) = e ml x (r x , r y , 0)",
        "prob": 0.6066666666666667
    }, {
        "ID": 7858,
        "phrase": " finally, e sw,x (r x , r y ) = min inf \u03b3\u2208[0,1] e x (r x , r y , \u03b3), inf \u03b3\u2208[0,1] 1 1 \u2212 \u03b3 e y (r x , r y , \u03b3) = e ml x (r x , r y , 0) particularly e x (r x , r y , 1) \u2265 e x (r x , r y , 0), so e block sw,x (r x , r y ) = min{e ml x (r x , r y , 0), e ml x (r x , r y , 1)} = e ml x (r x , r y , 0) the same proof holds for source y",
        "prob": 0.5055555555555555
    }, {
        "ID": 7858,
        "phrase": " maximizing (35) over \u03c1 gives p n (l) \u2264 exp{\u2212(n \u2212 l + 1)e ml (r x )} where e ml (r x )} is defined in theorem 2, in particular (9)",
        "prob": 0.25833333333333336
    }, {
        "ID": 7858,
        "phrase": " using  lemma 2 in (27)  gives pr[x n\u2212\u2206 = x n\u2212\u2206 ] \u2264 n\u2212\u2206 l=1 exp{\u2212(n \u2212 l + 1)e ml (r x )} (36) = n\u2212\u2206 l=1 exp{\u2212(n \u2212 l + 1 \u2212 \u2206)e ml (r x )} exp{\u2212\u2206e ml (r x )} \u2264k 0 exp{\u2212\u2206e ml (r x )} (37) in (37) we pull out the exponent in \u2206",
        "prob": 0.5611111111111111
    }, {
        "ID": 7858,
        "phrase": " p x,y (x n , y n ) < p x,y (x n , \u1ef9n )] \u2264 x n ,y n min 1, (x n , \u1ef9n ) \u2208 fn(l, k, x n , y n ) px,y (x n , y n ) < px,y (x n , \u1ef9n ) pr[x n \u2208 b x (x n ), \u1ef9n \u2208 b y (y n )] p x,y (x n , y n ) (53) \u2264 x n l ,y n = e \u2212(n\u2212l+1)\u03c1rx\u2212(n\u2212k+1)\u03c1ry y k\u22121 l x k\u22121 l p x,y (x k\u22121 l , y k\u22121 l ) 1 1+\u03c1 xk\u22121 l p x,y (x k\u22121 l , y k\u22121 l ) 1 1+\u03c1 \u03c1 xn k ,\u1ef9 n k p x,y (x n k , \u1ef9n k ) 1 1+\u03c1 \u03c1 x n k ,y n k p x,y (x n k , y n k ) 1 1+\u03c1 = e \u2212(n\u2212l+1)\u03c1rx\u2212(n\u2212k+1)\u03c1ry y k\u22121 l x k\u22121 l p x,y (x k\u22121 l , y k\u22121 l ) 1 1+\u03c1 1+\u03c1 x n k ,y n k p x,y (x n k , y n k ) 1 1+\u03c1 1+\u03c1 = e \u2212(n\u2212l+1)\u03c1rx\u2212(n\u2212k+1)\u03c1ry y x p x,y (x, y) 1 1+\u03c1 1+\u03c1 k\u2212l x,y p x,y (x, y) 1 1+\u03c1 (1+\u03c1)(n\u2212k+1) (56) = exp \u2212(k \u2212 l) \u03c1r x \u2212 log y x p x,y (x, y) 1 1+\u03c1 1+\u03c1 exp \u2212(n \u2212 k + 1) \u03c1(r x + r y ) \u2212 (1 + \u03c1) log x,y p x,y (x, y) 1 1+\u03c1 = exp \u2212(k \u2212 l)e x|y (r x , \u03c1) \u2212 (n \u2212 k + 1)e xy (r x , r y , \u03c1) (57) = exp \u2212(n \u2212 l + 1) k \u2212 l n \u2212 l + 1 e x|y (r x , \u03c1) + n \u2212 k + 1 n \u2212 l + 1 e xy (r x , r y , \u03c1) (58) \u2264 exp \u2212(n \u2212 l + 1) sup \u03c1\u2208[0,1] k \u2212 l n \u2212 l + 1 e x|y (r x , \u03c1) + n \u2212 k + 1 n \u2212 l + 1 e xy (r x , r y , \u03c1) (59) = exp \u2212(n \u2212 l + 1)e ml x r x , r y , k \u2212 l n \u2212 l + 1 = exp \u2212(n \u2212 l + 1)e x (r x , r y , k \u2212 l n \u2212 l + 1 ) ",
        "prob": 0.8531914893617022
    }, {
        "ID": 7858,
        "phrase": "h s (l, k, xn , \u1ef9n ) \u2264 h s (l, k, (x n , y n ))) note that the p n (l, k) here differs from the p n (l, k) defined in the ml decoding by replacing p xy (x n , y n ) \u2264 p xy (x n , \u1ef9n ) with h s (l, k, xn , \u1ef9n ) \u2264 h s (l, k, (x n , y n ))",
        "prob": 0.22142857142857145
    }, {
        "ID": 7858,
        "phrase": " the universal error exponent: s p xy (s, y) e un x (r x , 1 1+\u03c1 = a(y, \u03c1) b(\u03c1) \u00d7 c(x, y, \u03c1) d(y, \u03c1) where a(y, \u03c1) = [ s p xy (s, y) 1 1+\u03c1 ] 1+\u03c1 = d(y, \u03c1) 1+\u03c1 now we are ready to prove theorem 8: e ml x (r x , r y , \u03b3) = e un x (r x , r y , \u03b3)",
        "prob": 0.38125
    }, {
        "ID": 7858,
        "phrase": " first, from lemma 16 and lemma 17: \u2202e ml x (r x , r y , \u03b3, \u03c1) \u2202\u03c1 = r (\u03b3) \u2212 \u03b3h(p \u03c1 x|y ) \u2212 (1 \u2212 \u03b3)h(p \u03c1 xy ) then, using lemma 7 and lemma 11, we have: \u2202 2 e ml x (r x , r y , \u03b3, \u03c1) \u2202\u03c1 \u2264 0 ",
        "prob": 0.44375
    }, {
        "ID": 7858,
        "phrase": " so \u03c1 maximize e ml x (r x , r y , \u03b3, \u03c1), if and only if: 0 = \u2202e ml x (r x , r y , \u03b3, \u03c1) \u2202\u03c1 = r (\u03b3) \u2212 \u03b3h(p \u03c1 x|y ) \u2212 (1 \u2212 \u03b3)h(p \u03c1 xy ) (91) because r (\u03b3) is in the interval [\u03b3h(p x|y ) + (1 \u2212 \u03b3)h(p xy ), \u03b3h(p 1 x|y ) + (1 \u2212 \u03b3)h(p 1 xy )] and the entropy functions monotonically-increase over \u03c1, we can find \u03c1 * \u2208 (0, 1), s",
        "prob": 0.604
    }, {
        "ID": 7858,
        "phrase": " \n \u03b3h(p \u03c1 * x|y ) + (1 \u2212 \u03b3)h(p \u03c1 * xy ) = r (\u03b3) using lemma 14 and lemma 15 we get: e ml x (r x , r y , \u03b3) = \u03b3d(p \u03c1 * xy p xy ) + (1 \u2212 \u03b3)d(p \u03c1 * xy p xy ) (92) where \u03b3h(p  x y q xy (x, y) = 1 \u03c1 * x|y ) + (1 \u2212 \u03b3)h(p \u03c1 * xy ) = r (\u03b3) , x y o xy (x, y) = 1 b \u2212 \u03b3h(q x|y ) \u2212 (1 \u2212 \u03b3)h(o xy ) \u2264 0 0 \u2264 q xy (x, y) \u2264 1, \u2200(x, y) \u2208 x \u00d7 y 0 \u2264 o xy (x, y) \u2264 1, \u2200(x, y) \u2208 x \u00d7 y (94) the above optimization problem is convex because the objective function and the inequality constraint functions are convex and the equality constraint functions are affine  [17] ",
        "prob": 0.6767441860465117
    }, {
        "ID": 7858,
        "phrase": " q xy (x, y) = [ s p xy (s, y) 1 1+\u03c1 b ] 1+\u03c1 b t [ s p xy (s, t) 1 1+\u03c1 b ] 1+\u03c1 b p xy (x, y) 1 1+\u03c1 b s p xy (s, y) 1 1+\u03c1 b = p\u03c1 b xy (x, y) o xy (x, y) = p xy (x, y) 1 1+\u03c1 b t s p xy (s, t) 1 1+\u03c1 b = p \u03c1 b xy (x, y) \u03bd i (x, y) = 0 \u2200x, y, i = 1, 2, 3, 4 \u03c1 = \u03c1 b (98) again, e ml x (r x , r y , \u03b3) = e un x (r x , r y , \u03b3), thus we finish the proof",
        "prob": 0.6722222222222222
    }, {
        "ID": 7858,
        "phrase": " substituting (100) and (101) into (99), we get e un x (r x , r y , \u03b3) = \u03b3d(p \u03c1 * xy ||p xy ) + (1 \u2212 \u03b3)d(p \u03c1 * xy ||p xy ) where r (\u03b3) = \u03b3h(p \u03c1 * x|y ) + (1 \u2212 \u03b3)h(p \u03c1 * xy ) (102) so for \u03b3h(p x|y ) + (1 \u2212 \u03b3)h(p xy ) \u2264 r (\u03b3) \u2264 \u03b3h(p 1 x|y ) + (1 \u2212 \u03b3)h(p 1 xy ), from (92) we have the desired property:e ml x (r x , r y , \u03b3) = e un x (r x , r y , \u03b3) b",
        "prob": 0.8185185185185185
    }, {
        "ID": 7858,
        "phrase": " in this case, for all 0 \u2264 \u03c1 \u2264 1 \u2202e ml x (r x , r y , \u03b3, \u03c1) \u2202\u03c1 = r (\u03b3) \u2212 \u03b3h(p \u03c1 x|y ) \u2212 (1 \u2212 \u03b3)h(p \u03c1 xy ) \u2265 r (\u03b3) \u2212 \u03b3h(p 1 x|y ) \u2212 (1 \u2212 \u03b3)h(p 1 xy ) \u2265 0 so \u03c1 takes value 1 to maximize the error exponent e ml x (r x , r y , \u03b3, \u03c1), thus e ml x (r x , r y , \u03b3) = r (\u03b3) \u2212 \u03b3 log( \u2212 2(1 \u2212 \u03b3) log( convexoptimization techniques as case a, we notice the fact that \u03c1 * \u2265 1 for r (\u03b3) = \u03b3h(p \u03c1 * x|y ) + (1 \u2212 \u03b3)h(p \u03c1 * xy )",
        "prob": 0.6696969696969698
    }, {
        "ID": 7964,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.18333333333333335
    }, {
        "ID": 8483,
        "phrase": "1: if the mimo channel is transmit separable, then c mimo\u2212s (\u03c1, \u03b2) is bounded from above by max 0\u2264a\u2264 1 \u03b2 n r \u22121 l=0 {log(1 + a\u03b1 max \u03c1r l (0)) \u2212 ai l (\u03b1 max \u03c1)} (8) where \u03b1 max = max{\u03b1 0 , ",
        "prob": 0.47333333333333333
    }, {
        "ID": 8489,
        "phrase": " passing though d ml = 20 without any visible anomaly",
        "prob": 0.41
    }, {
        "ID": 8555,
        "phrase": " hence, ai\u00b5 acts with \u1e8fk = arg max y k v * \u00b5 kk ( \u1e8f\u1e8b <k y k ) = arg max y k r k r k \u2022\u00b5 ai ( \u1e8f\u1e59 <k yr k ) = arg max z k \u00b5 sp ( \u017c1 ",
        "prob": 0.33999999999999997
    }, {
        "ID": 8555,
        "phrase": " \u00b5 ai satisfies a strong separability condition",
        "prob": 0.2625
    }, {
        "ID": 8707,
        "phrase": " passing though d ml = 20 without any visible anomaly",
        "prob": 0.21000000000000002
    }, {
        "ID": 8708,
        "phrase": " passing though d ml = 20 without any visible anomaly",
        "prob": 0.31
    }, {
        "ID": 8907,
        "phrase": " denote the resulting sequence as x \u2032 ; 3) if x \u2032 is in the code c and d h (x \u2032 , r) \u2264 wmin 2 declare x \u2032 as the ml sequence",
        "prob": 0.425
    }, {
        "ID": 8907,
        "phrase": " lemma 8: for a fixed 0 < p < 1/2, the rate set r(p) \u2286 r ml (p), where r(p) is the set of rates t such that t \u2264 r, p < 3\u03b4\u22122 2\u03b4\u22121 \u03b1, t < d( 3\u03b4\u22122 2\u03b4\u22121 \u03b1||p),where \u03b1 = (2e \u03b4c+1 (\u03b4c/ (1 \u2212 r)) (1\u2212\u03b4)c ) \u2212 1 (1\u2212\u03b4)c\u22121 , for some r, c, \u03b4 satisfying 0 < r < 1, c \u2208 n, (2/3 + 1/(3c)) < \u03b4 < 1, \u03b4c \u2208 n, (1 \u2212 \u03b4)c \u2265 2",
        "prob": 0.5399999999999999
    }, {
        "ID": 9445,
        "phrase": "p r o p r i et ar y coaxi a lc a b l e a n d s h i e l d edtw is t e dp ai r ( stp) p r o d u c t s , w h i c h s u p p or t fddi l i n k s o f u p t o 100 m,a r ea lr e a d y a v a i l a b l e ",
        "prob": 0.19090909090909092
    }, {
        "ID": 9445,
        "phrase": " w h i l e i t i s e a s i e r t o h andl e d at a-gr ade tw is t e dp ai r ( ei a c at egor y 5) , al l owi n g c at egor y 3 c a b l e w oul d i n t r o d u ce m or e compl e x i t y ",
        "prob": 0.5071428571428571
    }, {
        "ID": 9679,
        "phrase": " \u2022 for any tree t : f rontier(t ) denotes the sentence (ordered sequence of terminals) on the frontier of t , nolex(t ) denotes the tree resulting from t after removing all terminal nodes, syntax(t ) denotes the tree resulting from nolex(t ) after substituting instead of every node-label syntaxl, semanticl the pair syntaxl, seml , semantic(t ) denotes the tree resulting from nolex(t ) after substituting instead of every node-label syntaxl, semanticl the pair sy nl, semanticl where sy ml is a nil syntactic category",
        "prob": 0.9290909090909091
    }, {
        "ID": 9680,
        "phrase": " \u2022 for any tree t : f rontier(t ) denotes the sentence (ordered sequence of terminals) on the frontier of t , nolex(t ) denotes the tree resulting from t after removing all terminal nodes, syntax(t ) denotes the tree resulting from nolex(t ) after substituting instead of every node-label syntaxl, semanticl the pair syntaxl, seml , semantic(t ) denotes the tree resulting from nolex(t ) after substituting instead of every node-label syntaxl, semanticl the pair sy nl, semanticl where sy ml is a nil syntactic category",
        "prob": 0.9109090909090909
    }, {
        "ID": 9826,
        "phrase": "3 (annotated code call condition \u03c7 : [ai 1 , ai 2 ], \u2297 ) if \u03c7 is a probabilistic code call condition, \u2297 is a conjunction strategy, and [ai 1 , ai 2 ] is an annotation, then \u03c7 : [ai 1 , ai 2 ], \u2297 is an annotated code call condition",
        "prob": 0.4789473684210526
    }, {
        "ID": 9826,
        "phrase": " intuitively, the ground annotated code call condition \u03c7 : [ai 1 , ai 2 ], \u2297 says that the probability of \u03c7 being true (under conjunction strategy \u2297) lies in the interval [ai 1 , ai 2 ]",
        "prob": 0.24117647058823527
    }, {
        "ID": 9826,
        "phrase": " o is said to satisfy a non-ground annotated code call \u03c7 : [ai 1 , ai 2 ], \u2297 iff o satisfies all ground instances of \u03c7 : [ai 1 , ai 2 ], \u2297 ",
        "prob": 0.4066666666666666
    }, {
        "ID": 9826,
        "phrase": " red 2 (\u2022), which maps annotated code call conditions to code call conditions by simply removing the annotations and the conjunction strategy: red 2 (\u03c7 : [ai 1 , ai 2 ], \u2297 ) = \u03c7",
        "prob": 0.531578947368421
    }, {
        "ID": 9826,
        "phrase": " then: (\u03c7 : [ai 1 , ai 2 ], \u2297 is a ground annotated code call condition, o s an agent state) satisfaction: the satisfaction relations coincide, i",
        "prob": 0.2733333333333333
    }, {
        "ID": 9826,
        "phrase": " for every annotated code call condition \u03c7 : [ai 1 , ai 2 ], \u2297 in the body of r, it is the case that o s |=[ai1,ai2]  \u03c7 : [ai 1 , ai 2 ], \u2297 and 3",
        "prob": 0.5083333333333333
    }, {
        "ID": 9826,
        "phrase": " then p-app pp,o p (ps) = {op \u03b1 | op \u03b1 is the head of a ground instance of a rule for every annotated code call condition \u03c7 : [ai 1 , ai 2 ], \u2297 in the body of r, it is the case that o p |= [ai1,ai2] \u03c7 : [ai 1 , ai 2 ], \u2297 ; 3",
        "prob": 0.32105263157894737
    }]
}, {
    "topic_id": 33,
    "top_words": ["goal", "theory", "systems", "self", "research", "artificial", "agents", "problem", "intelligence", "general", "environment", "since", "often", "design", "computer"],
    "phrases": [{
        "ID": 6,
        "phrase": " our success in reproducing these results allows us to confidently state the effectiveness and accuracy of our theory in predicting the expected error of machine learning agents in mass",
        "prob": 0.3857142857142857
    }, {
        "ID": 7,
        "phrase": " our success in reproducing these results allows us to confidently state the effectiveness and accuracy of our theory in predicting the expected error of machine learning agents in mass",
        "prob": 0.4809523809523809
    }, {
        "ID": 8,
        "phrase": " our success in reproducing these results allows us to confidently state the effectiveness and accuracy of our theory in predicting the expected error of machine learning agents in mass",
        "prob": 0.4809523809523809
    }, {
        "ID": 30,
        "phrase": " this is, of course, an ancient problem, and one which has not been ignored in machine learning",
        "prob": 0.21000000000000002
    }, {
        "ID": 141,
        "phrase": " the goal of ai systems should be to be useful to humans",
        "prob": 0.3875
    }, {
        "ID": 141,
        "phrase": " contents: section 2: the general framework for ai might be viewed as the design and study of intelligent agents  [31] ",
        "prob": 0.43571428571428567
    }, {
        "ID": 141,
        "phrase": " if we interpret the ai system as one player and the environment models the other rational player and the environment provides the reinforcement feedback c k , we see that the system-environment configuration satisfies all criteria of a game",
        "prob": 0.45909090909090905
    }, {
        "ID": 141,
        "phrase": " on the other hand, we know that the ai system can handle more general situations, since it interacts optimally with an environment, even if the environment is not a rational player with conflicting goals",
        "prob": 0.755
    }, {
        "ID": 141,
        "phrase": " the ai system takes the position of player 1",
        "prob": 0.5125
    }, {
        "ID": 141,
        "phrase": " for a symmetric situation we could take a second ai system as player 2, but for simplicity we take the environment as the second player and assume that this environmental player behaves according to the minimax strategy (51)",
        "prob": 0.29047619047619044
    }, {
        "ID": 141,
        "phrase": " if we would analyze and interpret these programs for realistic environments, we might find some of the unmentioned or unused or new ai methods at work in these algorithms",
        "prob": 0.5055555555555555
    }, {
        "ID": 141,
        "phrase": " if ai is possible at all, we would have reached the final goal, the construction of the most intelligent algorithm with computation \u2264 t",
        "prob": 0.3153846153846154
    }, {
        "ID": 141,
        "phrase": " a formal theory of something, even if not computable, is often a great step toward solving a problem and has also merits of its own, and ai should not be different (see previous item)",
        "prob": 0.755
    }, {
        "ID": 477,
        "phrase": "introduction the most general framework for artificial intelligence is the picture of an agent interacting with an environment  [rn95] ",
        "prob": 0.36428571428571427
    }, {
        "ID": 757,
        "phrase": " in the author's opinion the component approach addresses the real-life problem of using knowledge-based systems in networking environments in a straight-forward manner (which is a further development of traditional clientserver paradigm), while agent theory is better developed in theoretical terms and is targeted towards future developments in theoretical and practical artificial intelligence",
        "prob": 0.20769230769230768
    }, {
        "ID": 1317,
        "phrase": " this allows extension of i to infinite sequences \u03b1, \u03b2 \u2208 \u03c9 as i(\u03b1 : \u03b2) = log i,j m(i/\u03b1)m(j/\u03b2)2 i(i:j) , which 4 satisfies the following independence conservation inequalities 5 [l 74, l 84]: for any computable transformation a and measure \u00b5, i(a(a) : b) \u2264 i(a : b) + o(1), i((a, w) : b) \u2264 i(a : b) + log t a,b (w) + o(1) \n 7 2-adic integers are formal sums p i\u22650 ai2 i , ai \u2208 {0, 1}, with the usual arithmetic and the norm |(2a+1)2 b | = 2 \u2212b ",
        "prob": 0.30333333333333334
    }, {
        "ID": 1318,
        "phrase": " 7 2-adics are formal sums p i\u22650 ai2 i , ai \u2208 {0, 1}, with the usual arithmetic and the norm 2 \u2212b of (2a+1)2 b ",
        "prob": 0.61
    }, {
        "ID": 1319,
        "phrase": " 7 2-adics are formal sums p i\u22650 ai2 i , ai \u2208 {0, 1}, with the usual arithmetic and the norm 2 \u2212b of (2a+1)2 b ",
        "prob": 0.61
    }, {
        "ID": 1320,
        "phrase": " 7 2-adics are formal sums p i\u22650 ai2 i , ai \u2208 b, with the usual arithmetic and the norm 2 \u2212b of (2a+1)2 b ",
        "prob": 0.61
    }, {
        "ID": 1550,
        "phrase": " intelligent agents have not only become one of the central topics of artificial intelligence (nowadays sometimes even defined as \"the study of agents\",  [27] ), but also mainstream computer science, especially software engineering, has taken up agent-oriented programming as a new and exciting paradigm to investigate, while industries experiment with the use of it on a large scale, witness the results reported in conferences like autonomous agents (e",
        "prob": 0.258139534883721
    }, {
        "ID": 1564,
        "phrase": " \u03b4 n where \u03b4 i is a decision of agent \u03b1 i such that \u03b4 0 i \u2286 \u03b4 i \u2286 l ai for i = 1 ",
        "prob": 0.18333333333333335
    }, {
        "ID": 1881,
        "phrase": " thirdly, the realisation that classical, symbolic methods of artificial intelligence (ai), that are sometimes called gofai, for good old fashioned ai, are brittle and intractably complex on large-scale real world problems  (boden, 1990) , and that more robust methods are necessary, that can work with noisy and occasionally incorrect data -criteria which statistical methods satisfy",
        "prob": 0.2394736842105263
    }, {
        "ID": 1981,
        "phrase": " finally, section 11 will summarize the recent g\u00f6del machine  [56] , a selfreferential, theoretically optimal self-improver which explicitly addresses the 'grand problem of artificial intelligence'  [58]  by optimally dealing with limited resources in general reinforcement learning settings",
        "prob": 0.6241379310344828
    }, {
        "ID": 1981,
        "phrase": " \n the g\u00f6del machine the g\u00f6del machine  [56]  explicitly addresses the 'grand problem of artificial intelligence'  [58]  by optimally dealing with limited resources in general reinforcement learning settings, and with the possibly huge (but constant) slowdowns buried by aixi(t, l)  [22]  in the somewhat misleading o()-notation",
        "prob": 0.7129032258064517
    }, {
        "ID": 2044,
        "phrase": " \u2022 artificial intelligence, which is the study of reproducing intelligence and consciousness with a computer program",
        "prob": 0.3416666666666666
    }, {
        "ID": 2265,
        "phrase": " for example, sanella and tarlecki  [st89]  discuss the formal development of ml programs from algebraic specifications",
        "prob": 0.20666666666666667
    }, {
        "ID": 2333,
        "phrase": " the science of artificial intelligence (ai) may be defined as the construction of intelligent systems and their analysis",
        "prob": 0.46923076923076923
    }, {
        "ID": 2333,
        "phrase": " the goal of ai systems should be to be useful to humans",
        "prob": 0.3875
    }, {
        "ID": 2333,
        "phrase": " the science of artificial intelligence (ai) might be defined as the construction of intelligent systems and their analysis",
        "prob": 0.5461538461538461
    }, {
        "ID": 2333,
        "phrase": " 416 the general framework for ai might be viewed as the design and study of intelligent agents  [rn95] ",
        "prob": 0.5461538461538461
    }, {
        "ID": 2333,
        "phrase": " on the other hand, the ai models can handle more general situations, since it interacts optimally with an environment, even if the environment is not a rational player with conflicting goals",
        "prob": 0.7421052631578947
    }, {
        "ID": 2333,
        "phrase": " if we would analyze and interpret these programs for realistic environments, we might find some of the unmentioned or unused or new ai methods at work in these programs",
        "prob": 0.5611111111111111
    }, {
        "ID": 2333,
        "phrase": " a formal theory of something, even if not computable, is often a great step toward solving a problem and also has merits of its own, and ai should not be different in this respect (see previous item)",
        "prob": 0.8142857142857144
    }, {
        "ID": 2333,
        "phrase": " the goal of ai systems should be to be useful to humans",
        "prob": 0.5125
    }, {
        "ID": 2597,
        "phrase": " its conceptual simplicity notwithstanding, the g\u00f6del machine explicitly addresses the 'grand problem of artificial intelligence'  [42]  by optimally dealing with limited resources in general environments, and with the possibly huge (but constant) slowdowns buried by previous approaches  [16, 15]  in the widely used but often misleading o()-notation of theoretical computer science",
        "prob": 0.8638888888888889
    }, {
        "ID": 2598,
        "phrase": " its conceptual simplicity notwithstanding, the g\u00f6del machine explicitly addresses the 'grand problem of artificial intelligence'  [43]  by optimally dealing with limited resources in general environments, and with the possibly huge (but constant) slowdowns buried by previous approaches  [16, 15]  in the widely used but often misleading o()-notation of theoretical computer science",
        "prob": 0.8638888888888889
    }, {
        "ID": 2599,
        "phrase": " its conceptual simplicity notwithstanding, the g\u00f6del machine explicitly addresses the 'grand problem of artificial intelligence'  [44]  by optimally dealing with limited computational resources in general environments, and with the possibly huge (but constant) slowdowns buried by pre-vious approaches  [16, 15]  in the widely used but often misleading o()-notation of theoretical computer science",
        "prob": 0.8184210526315789
    }, {
        "ID": 2601,
        "phrase": " to attack this \"grand problem of artificial intelligence\"  [46] , we introduce a novel class of optimal, fully self-referential  [11]  general problem solvers called g\u00f6del machines  [45, 47, 49, 51, 50 ]",
        "prob": 0.3227272727272727
    }, {
        "ID": 2941,
        "phrase": " we think that defeasible argumentation can be used to improve ml approaches as the one described above as it provides a sound formalization for both expressing and reasoning with uncertain and incomplete information",
        "prob": 0.355
    }, {
        "ID": 2942,
        "phrase": " we think that defeasible argumentation can be used to improve ml approaches as the one described above as it provides a sound formalization for both expressing and reasoning with uncertain and incomplete information",
        "prob": 0.355
    }, {
        "ID": 3352,
        "phrase": "f (x) where f (x) \u2261 q i=1 x < ai \u2227 p i=1 bi < x \u2227 r i=1 ci dvd x + ti where x does not occur in any of a i , b i , t i ",
        "prob": 0.35000000000000003
    }, {
        "ID": 3353,
        "phrase": "f (x) where f (x) \u2261 q i=1 x < ai \u2227 p i=1 bi < x \u2227 r i=1 ci dvd x + ti where x does not occur in any of a i , b i , t i ",
        "prob": 0.35000000000000003
    }, {
        "ID": 3892,
        "phrase": " since network environments of the future will likely consist of both human and ai agents, it is important to explore whether groups of humans exhibit the phenomenon of ci when working on the types of highly-structured tasks where ai problem solving agents excel",
        "prob": 0.28928571428571426
    }, {
        "ID": 3902,
        "phrase": " autonomic computing proposes adding artificial intelligence into computer systems -in essence, giving the programs \"a sense of self\" (forrest 1ff)",
        "prob": 0.5549999999999999
    }, {
        "ID": 5275,
        "phrase": " during that time he served as an artificial intelligence project management officer, as chief of the plasma theory and computation center, and on the faculty of the united states air force academy",
        "prob": 0.3227272727272727
    }, {
        "ID": 6722,
        "phrase": " contrary to the objectivism dominating ai research, human navigation in an environment builds on information conceived (not just perceived!) by the navigator  [34] ",
        "prob": 0.31875
    }, {
        "ID": 6784,
        "phrase": "imagination is the critical point in development of realistic artificial intelligence (ai) systems",
        "prob": 0.25833333333333336
    }, {
        "ID": 6785,
        "phrase": "imagination is the critical point in developing of realistic artificial intelligence (ai) systems",
        "prob": 0.25833333333333336
    }, {
        "ID": 7085,
        "phrase": " designing a computer program that, for each text, discovers the same \"basic\" anomaly as human readers do, is an ambitious ai objective that nonetheless seems realistic",
        "prob": 0.33888888888888885
    }, {
        "ID": 7408,
        "phrase": "3 that a 0 {x \u2192 a 1 } \u2704 ai b 0 {x \u2192 b 1 } (in one step)",
        "prob": 0.22000000000000003
    }, {
        "ID": 7409,
        "phrase": " since l\u03c3 \u2192 ai r\u03c3, there is v such that d\u03c3 \u2192 * ai\u22121 v \u2190 * ai\u22121 c\u03c3",
        "prob": 0.22000000000000003
    }, {
        "ID": 7409,
        "phrase": "3 that a 0 {x \u2192 a 1 } \u2704 ai b 0 {x \u2192 b 1 } (in one step)",
        "prob": 0.22000000000000003
    }, {
        "ID": 7960,
        "phrase": " (t : v ) in ml notation)",
        "prob": 0.18333333333333335
    }, {
        "ID": 8111,
        "phrase": " in summary, generative ml extracts faithful models of the phenomenon at hand, taking advantage of whatever prior knowledge is available; these models can be used for discriminative purposes, though discrimination is not among the primary goals of generative ml",
        "prob": 0.21034482758620687
    }, {
        "ID": 8147,
        "phrase": " in ai for design  14  , viewpoints are considered as particular combinations of constraints, corresponding implicitly to levels of abstraction",
        "prob": 0.2928571428571428
    }, {
        "ID": 8148,
        "phrase": " in ai for design 14 , viewpoints are considered as particular combinations of constraints, corresponding implicitly to levels of abstraction",
        "prob": 0.2928571428571428
    }, {
        "ID": 8232,
        "phrase": " such an approach finds great success in other domains such as physicsand artificial intelligence",
        "prob": 0.2583333333333333
    }, {
        "ID": 8248,
        "phrase": " on the more prosaic roads that real ai has been forced to follow, such grand questions have almost died down",
        "prob": 0.23846153846153847
    }, {
        "ID": 8555,
        "phrase": " the goal of ai systems should be to be useful to humans",
        "prob": 0.3875
    }, {
        "ID": 8555,
        "phrase": " other discussed topics are a formal definition of an intelligence order relation, the horizon problem and relations of the aixi theory to other ai approaches",
        "prob": 0.24117647058823527
    }, {
        "ID": 8555,
        "phrase": " \n agents in known probabilistic environments the general framework for ai might be viewed as the design and study of intelligent agents  [rn03] ",
        "prob": 0.5352941176470588
    }, {
        "ID": 8555,
        "phrase": " if we interpret the ai system as one player and the environment models the other rational player and the environment provides the reinforcement feedback r k , we see that the agent-environment configuration satisfies all criteria of a game",
        "prob": 0.5045454545454545
    }, {
        "ID": 8555,
        "phrase": " on the other hand, the ai models can handle more general situations, since they interact optimally with an environment, even if the environment is not a rational player with conflicting goals",
        "prob": 0.7421052631578947
    }, {
        "ID": 8555,
        "phrase": " if we would analyze and interpret these programs for realistic environments, we might find some of the unmentioned or unused or new ai methods at work in these programs",
        "prob": 0.5055555555555555
    }, {
        "ID": 8555,
        "phrase": " a formal theory of something, even if not computable, is often a great step toward solving a problem and also has merits of its own, and ai should not be different in this respect (see previous item)",
        "prob": 0.8142857142857144
    }, {
        "ID": 8555,
        "phrase": " the discussion includes formal definitions of intelligence order relations, the horizon problem and relations of the aixi theory to other ai approaches",
        "prob": 0.3
    }, {
        "ID": 8817,
        "phrase": " then the trap function is defined as: ( )  \uf8f4 \uf8fe \uf8f4 \uf8fd \uf8fc \uf8f4 \uf8f3 \uf8f4 \uf8f2 \uf8f1 \u2212 \u2212 \u2212 \u00d7 = = otherwise k u k f k u if f u trap low high k , 1 \n hill-climbing in the building block space hill-climbing is used widely in artificial intelligence fields, for quickly reaching a goal state from a starting position",
        "prob": 0.3482758620689655
    }, {
        "ID": 8941,
        "phrase": " the goal of this research involving the whole scale of contemporary computer science from automata theory to artificial intelligence is to improve and enhance the complex design of modern computing and communications architectures with capabilities that occur in living systems such as self-configuration, self-optimization, self-repair and self-protection",
        "prob": 0.8916666666666667
    }, {
        "ID": 8942,
        "phrase": " the goal of this research involving the whole scale of contemporary computer science from automata theory to artificial intelligence is to improve and enhance the complex design of modern computing and communications architectures with capabilities that occur in living systems such as self-configuration, self-optimization, self-repair and self-protection",
        "prob": 0.8361111111111111
    }, {
        "ID": 8943,
        "phrase": " the goal of this research, involving the whole scale of contemporary computer science from automata theory to artificial intelligence, is to improve and enhance the complex design of modern computing and communications architectures with capabilities that occur in living systems such as self-configuration, self-optimization, self-repair and self-protection",
        "prob": 0.8638888888888889
    }, {
        "ID": 8944,
        "phrase": " the goal of this research, involving the whole scale of contemporary computer science from automata theory to artificial intelligence, is to improve and enhance the complex design of modern computing and communications architectures with capabilities that occur in living systems such as self-configuration, self-optimization, self-repair and self-protection",
        "prob": 0.8638888888888889
    }, {
        "ID": 8945,
        "phrase": " the goal of this research, involving the whole scale of contemporary computer science from automata theory to artificial intelligence, is to improve and enhance the complex design of modern computing and communications architectures with capabilities that occur in living systems such as self-configuration, self-optimization, self-repair and self-protection",
        "prob": 0.8916666666666667
    }, {
        "ID": 8946,
        "phrase": " the goal of this research, involving the whole scale of contemporary computer science from automata theory to artificial intelligence, is to improve and enhance the complex design of modern computing and communication architectures with capabilities that occur in living systems such as selfconfiguration, self-optimization, self-repair and self-protection",
        "prob": 0.86
    }, {
        "ID": 8947,
        "phrase": " the goal of this research, involving the whole scale of contemporary computer science from automata theory to artificial intelligence, is to improve and enhance the complex design of modern computing and communication architectures with capabilities that occur in living systems such as selfconfiguration, self-optimization, self-repair and self-protection",
        "prob": 0.8885714285714286
    }, {
        "ID": 8948,
        "phrase": " the goal of this research, involving the whole scale of contemporary computer science from automata theory to artificial intelligence, is to improve and enhance the complex design of modern computing and communication architectures with capabilities that occur in living systems such as selfconfiguration, self-optimization, self-repair and self-protection",
        "prob": 0.8885714285714286
    }, {
        "ID": 8949,
        "phrase": " the goal of this research, involving the whole scale of contemporary computer science from automata theory to artificial intelligence, is to improve and enhance the complex design of modern computing and communication architectures with organization and maintenance capabilities that occur in living systems  (foerster, 1962; eigen, 1971; miller, 1978; eigen & schuster, 1979; kauffman, 1993; camazine et al",
        "prob": 0.7594594594594595
    }, {
        "ID": 9244,
        "phrase": " although we intend that t-r programs for agent control be written by human programmers, we are also interested in methods for modifying them by automatic planning and machine learning",
        "prob": 0.2157894736842105
    }, {
        "ID": 9255,
        "phrase": " the local (or mental) state of an agent, which is the general agent's state discussed in the ai literature  (shoham, 1990) , will not be represented explicitly in our representation and will be built implicitly based on the agent's actions and observations",
        "prob": 0.3521739130434782
    }, {
        "ID": 9267,
        "phrase": " as a result, ai systembuilders often ignore theoretical developments, being forced to rely on trial-and-error engineering to achieve their goals",
        "prob": 0.2833333333333333
    }, {
        "ID": 9305,
        "phrase": " unlike typical des models which are concerned with physical processes or devices, ai is particularly interested in self-motivated agents, two concrete examples of which are rational agents, i",
        "prob": 0.24285714285714283
    }, {
        "ID": 9305,
        "phrase": " despite its somewhat futuristic avor (although instances of such shared environments are beginning to appear in cyberspace), this scenario is useful in illustrating the vulnerability of some of the most popular coordination mechanism appearing in the multi-agent literature within ai (e",
        "prob": 0.3
    }, {
        "ID": 9305,
        "phrase": " this work contributes to ai research by introducing and exploring a promising perspective on system design and it contributes to des research by considering two types of structural assumptions on agents, corresponding to rational and learning agents",
        "prob": 0.28400000000000003
    }, {
        "ID": 9315,
        "phrase": " applying artificial intelligence ideas, we could even imagine an organizer that predicts what you need to write and does it for you",
        "prob": 0.20666666666666667
    }, {
        "ID": 9321,
        "phrase": " in comparison to simon's early theory in administrative behavior, ai has downplayed the distinction between agent and environment",
        "prob": 0.2928571428571428
    }, {
        "ID": 9646,
        "phrase": " speech act based ai approaches normally make reference to mental attitudes and often provide links between the surface form of the utterance and the mental attitudes of both the speaker and hearer",
        "prob": 0.3521739130434782
    }, {
        "ID": 9663,
        "phrase": " as opposed to hand-tailored mas design, these alternative approaches potentially have the following benefits: one does not have to laboriously model the entire system; global performance is \"robust\"; one can scale up to very large systems; and one can maximally exploit the power of machine learning",
        "prob": 0.25357142857142856
    }, {
        "ID": 9779,
        "phrase": " moreover, designing that controller in a traditional ai fashion often results in brittle solutions",
        "prob": 0.23846153846153847
    }, {
        "ID": 9826,
        "phrase": " , ai n ) is an annotation item",
        "prob": 0.18333333333333335
    }]
}, {
    "topic_id": 34,
    "top_words": ["search", "ml", "complexity", "lattice", "would", "algorithm", "two", "possible", "points", "much", "simple", "reduced", "new", "closer", "exhaustive"],
    "phrases": [{
        "ID": 424,
        "phrase": " intuitively, we feel that if both matches are needed for establishing a forest fire, then both ml 1 = 1 and ml 2 = 1 together would be required to fully explain the unfortunate fate of the forest; pointing to just one of these events would only beg another \"how come?\" question, and would not stop any serious investigating team from continuing its search for a more complete answer",
        "prob": 0.3638888888888889
    }, {
        "ID": 425,
        "phrase": " intuitively, we feel that if both matches are needed for establishing a forest fire, then both ml 1 = 1 and ml 2 = 1 together would be required to fully explain the unfortunate fate of the forest; pointing to just one of these events would only beg another \"how come?\" question, and would not stop any serious investigating team from continuing its search for a more complete answer",
        "prob": 0.3361111111111111
    }, {
        "ID": 1981,
        "phrase": " a new kind of ai is emerging",
        "prob": 0.3
    }, {
        "ID": 2053,
        "phrase": " instead, si and ai together come from a large enough range of possible values that precomputing all likely hashes hi by brute-force is intractable",
        "prob": 0.22777777777777775
    }, {
        "ID": 2333,
        "phrase": " if ai is possible at all, we would have reached the final goal, the construction of the most intelligent algorithm with computation time \u2264 t",
        "prob": 0.43571428571428567
    }, {
        "ID": 2333,
        "phrase": " with a reasonable computation time, the aixi model would be a solution of ai (see next point if you disagree)",
        "prob": 0.2733333333333333
    }, {
        "ID": 3630,
        "phrase": " (  1 ), when the components of \u03bd are independent complex gaussian random variables, the ml decoding problem can be reduced to the closest lattice point search problem for the set of lattice points {m a | a \u2208 s t } and a received signal point x",
        "prob": 0.244
    }, {
        "ID": 3630,
        "phrase": " in addition, dikstra's algorithm does not require the radius of the sphere to be initially set, and it always finds out ml estimate without retrying to search for a lattice point with increased radius",
        "prob": 0.4826086956521739
    }, {
        "ID": 4061,
        "phrase": " similarly to the ml estimates, \u03b8q,ls is the solution of a nonlinear programming problem, requiring brute-force multidimensional search",
        "prob": 0.24117647058823527
    }, {
        "ID": 4089,
        "phrase": " brute force computation of the jointly ml codeword sequences for k users is o(q k\u03ba ) for q-ary modulation and constraint length \u03ba codes",
        "prob": 0.33888888888888885
    }, {
        "ID": 4659,
        "phrase": " (agents) a ::= tell(c) -tell | stop -stop | n i=1 ask(ci ) \u2192 ai -choice | now c then a else a -conditional | a || a -parallel | \u2203x a -hiding | p(x ) -procedure finally, the conditional agent (now c then a else b ) is the new agent introduced in the model in order to capture negative information",
        "prob": 0.3137931034482758
    }, {
        "ID": 4659,
        "phrase": " r1 tell(c), d \u2212\u2192 stop, c \u2294 d r2 n i=1 ask(ci ) \u2192 ai , d \u2212\u2192 aj , d j \u2208 [1, n] and d \u22a2 cj fig",
        "prob": 0.31
    }, {
        "ID": 4659,
        "phrase": " s[1] = true; tell(c) : s[1] = c; n i=1 ask(di ) \u2192 ai : for j = 1 to n s[j] = {di }; s[n+1] = true; now d then b1 else b2 : s1 = flat(st, instant(st \u2294 d , lb 1 )); s2 = flat(st, instant(not * (d ) \u2294 st, lb 2 )); s = append(s1, s2); b1||b2 : s = combine(instant(st, lb 1 ), instant(st, lb 2 )) \u2203x b1 : s[1] = {st[y/x ]} \u2294 instant(st, lb 1 ) // \n lemma 2 the time complexity for the algorithm flat(c,ll ) presented in figure  10 is o (n)  where n is the number of elements in the list ll ",
        "prob": 0.5702702702702703
    }, {
        "ID": 4786,
        "phrase": " for example, naive implementations of the ml decoder have complexity that grows exponentially with the number of transmit antennas",
        "prob": 0.27333333333333326
    }, {
        "ID": 4786,
        "phrase": " if the sphere is non-empty, the ml solution is guaranteed to be found inside the sphere, otherwise, the search radius is increased and the search is restarted",
        "prob": 0.4263157894736842
    }, {
        "ID": 4786,
        "phrase": " the ml performance, obtained via exhaustive search in figure  8 , is not feasible for higher dimensions due to exponential complexity in the number of dimensions",
        "prob": 0.32105263157894737
    }, {
        "ID": 4910,
        "phrase": " (17) however, the ml estimate is usually very complex to calculate",
        "prob": 0.21000000000000002
    }, {
        "ID": 5118,
        "phrase": " ml detection involves an exhaustive search over all the possible sequences of digitally modulated symbols, which grows exponentially as the number of transmit antennas",
        "prob": 0.531578947368421
    }, {
        "ID": 5118,
        "phrase": " when the received signal can be represented as in  (1) , lattice decoding algorithms, like sphere decoder (sd), can be utilized to attain ml performances with significant reduced complexity",
        "prob": 0.5761904761904761
    }, {
        "ID": 5118,
        "phrase": " the sd algorithms converges at the ml solution while searching a much lower number of lattice points than the exhaustive search required by a \"brute-force\" ml detector",
        "prob": 0.7318181818181819
    }, {
        "ID": 5118,
        "phrase": " in this paper, we propose a novel layered orthogonal lattice detector (lord) for two transmit antenna mimo systems, which achieves ml performance in case of hardoutput demodulation and optimally computes bit llrs when soft output information is generated",
        "prob": 0.43666666666666665
    }, {
        "ID": 5118,
        "phrase": " the interesting characteristic is that the number of lattice points needed to be search is well below the exhaustive search ml algorithm",
        "prob": 0.63125
    }, {
        "ID": 5118,
        "phrase": " section 4 details the reduced complexity ml demodulation technique",
        "prob": 0.3727272727272727
    }, {
        "ID": 5118,
        "phrase": " this change in ordering greatly impacts the complexity and architecture of the ml demodulator",
        "prob": 0.5916666666666667
    }, {
        "ID": 5118,
        "phrase": " the optimum ml word demodulator (5) would have to compute the ml metric for m 2lt constellation points and has a complexity o(m 4 ) for l t = 2",
        "prob": 0.56875
    }, {
        "ID": 5118,
        "phrase": " this search can be greatly simplified by noting for given values of x 3 and x 4 the maximum likelihood metric reduces to t = \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x 2 \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 c 3 (x 3 , x 4 ) (33) where c 1 (x 3 , x 4 ) = s 1 x 3 + s 2 x 4 c 2 (x 3 , x 4 ) = \u2212s 2 x 3 + s 1 x 4 c 3 (x 3 , x 4 ) \u2265 0 (34) it is clear from examining (33) that due to the orthogonality of the problem formulation the conditional ml decision on x 1 and x 2 can immediately be made by a simple threshold test, i",
        "prob": 0.3607142857142857
    }, {
        "ID": 5118,
        "phrase": " by definition, one of the two sequences is the (optimum) hard-decision ml solution of (5)",
        "prob": 0.3416666666666666
    }, {
        "ID": 5118,
        "phrase": " however, using sd, there is no guarantee that the other sequence is one of the valid lattice points found by sd during the process of the lattice search; that sequence is characterized by a bit value reversed compared to the value it has in the ml sequence",
        "prob": 0.4653846153846154
    }, {
        "ID": 5118,
        "phrase": " using arguments similar to those that led to the simplified ml demodulation (33)-(36), one can easily prove that the two sequences needed for every bit in x 2 are certainly found minimizing (32) over the possible m 2 values of (x 3 , x 4 )",
        "prob": 0.6565217391304348
    }, {
        "ID": 5118,
        "phrase": " l(b 1,k | \u1ef9s ) = min x 1 ,x 2 \u2208s(k) \u2212 1 t \u2032 \u2212 min x 1 ,x 2 \u2208s(k) + 1 t \u2032 ( thus, we have derived an exact max-log bit llr computation using two layer orderings and an overall lattice search over 2m 2 sequences instead of m 4 as would be required by the exhaustive search-based ml algorithm",
        "prob": 0.7129032258064517
    }, {
        "ID": 5118,
        "phrase": " \n conclusion we have presented a novel lattice search-based mimo detection algorithm for two transmit antennas, characterized by a low preprocessing complexity, that achieves optimal ml demodulation with a complexity of the order of s, if s is the constellation size",
        "prob": 0.48518518518518516
    }, {
        "ID": 5118,
        "phrase": " the algorithm achieves optimal maximum-likelihood (ml) performance in case of two transmit antennas, at the same time keeping a complexity much lower than the exhaustive search-based ml detection technique",
        "prob": 0.5038461538461538
    }, {
        "ID": 5119,
        "phrase": " ml detection involves an exhaustive search over all the possible sequences of digitally modulated symbols, which grows exponentially as the number of transmit antennas",
        "prob": 0.531578947368421
    }, {
        "ID": 5119,
        "phrase": " when the received signal can be represented as in  (1) , lattice decoding algorithms, like sphere decoder (sd), can be utilized to attain ml performances with significant reduced complexity",
        "prob": 0.4333333333333333
    }, {
        "ID": 5119,
        "phrase": " the sd algorithms converges at the ml solution while searching a much lower number of lattice points than the exhaustive search required by a \"brute-force\" ml detector",
        "prob": 0.7772727272727273
    }, {
        "ID": 5119,
        "phrase": " in this paper, we propose a novel layered orthogonal lattice detector (lord) for two transmit antenna mimo systems, which achieves ml performance in case of hardoutput demodulation and optimally computes bit llrs when soft output information is generated",
        "prob": 0.4033333333333333
    }, {
        "ID": 5119,
        "phrase": " the interesting characteristic is that the number of lattice points needed to be search is well below the exhaustive search ml algorithm",
        "prob": 0.56875
    }, {
        "ID": 5119,
        "phrase": " section 4 details the reduced complexity ml demodulation technique",
        "prob": 0.4636363636363636
    }, {
        "ID": 5119,
        "phrase": " this change in ordering greatly impacts the complexity and architecture of the ml demodulator",
        "prob": 0.6749999999999999
    }, {
        "ID": 5119,
        "phrase": " the optimum ml word demodulator (5) would have to compute the ml metric for m 2lt constellation points and has a complexity o(m 4 ) for l t = 2",
        "prob": 0.63125
    }, {
        "ID": 5119,
        "phrase": " this search can be greatly simplified by noting for given values of x 3 and x 4 the maximum likelihood metric reduces to t = \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x 2 \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 c 3 (x 3 , x 4 ) (33) where c 1 (x 3 , x 4 ) = s 1 x 3 + s 2 x 4 c 2 (x 3 , x 4 ) = \u2212s 2 x 3 + s 1 x 4 c 3 (x 3 , x 4 ) \u2265 0 (34) it is clear from examining (33) that due to the orthogonality of the problem formulation the conditional ml decision on x 1 and x 2 can immediately be made by a simple threshold test, i",
        "prob": 0.3607142857142857
    }, {
        "ID": 5119,
        "phrase": " by definition, one of the two sequences is the (optimum) hard-decision ml solution of (5)",
        "prob": 0.3416666666666666
    }, {
        "ID": 5119,
        "phrase": " however, using sd, there is no guarantee that the other sequence is one of the valid lattice points found by sd during the process of the lattice search; that sequence is characterized by a bit value reversed compared to the value it has in the ml sequence",
        "prob": 0.38846153846153847
    }, {
        "ID": 5119,
        "phrase": " using arguments similar to those that led to the simplified ml demodulation (33)-(36), one can easily prove that the two sequences needed for every bit in x 2 are certainly found minimizing (32) over the possible m 2 values of (x 3 , x 4 )",
        "prob": 0.7000000000000001
    }, {
        "ID": 5119,
        "phrase": " l(b 1,k | \u1ef9s ) = min x 1 ,x 2 \u2208s(k) \u2212 1 t \u2032 \u2212 min x 1 ,x 2 \u2208s(k) + 1 t \u2032 ( thus, we have derived an exact max-log bit llr computation using two layer orderings and an overall lattice search over 2m 2 sequences instead of m 4 as would be required by the exhaustive search-based ml algorithm",
        "prob": 0.7774193548387097
    }, {
        "ID": 5119,
        "phrase": " \n conclusion we have presented a novel lattice search-based mimo detection algorithm for two transmit antennas, characterized by a low preprocessing complexity, that achieves optimal ml demodulation with a complexity of the order of s, if s is the constellation size",
        "prob": 0.5222222222222223
    }, {
        "ID": 5119,
        "phrase": " the algorithm achieves optimal maximum-likelihood (ml) performance in case of two transmit antennas, at the same time keeping a complexity much lower than the exhaustive search-based ml detection technique",
        "prob": 0.4653846153846154
    }, {
        "ID": 5120,
        "phrase": " ml detection involves an exhaustive search over all the possible sequences of digitally modulated symbols, which grows exponentially as the number of transmit antennas",
        "prob": 0.531578947368421
    }, {
        "ID": 5120,
        "phrase": " sd can attain ml performances with significant reduced complexity",
        "prob": 0.6454545454545454
    }, {
        "ID": 5120,
        "phrase": " the sd algorithm converges at the ml solution while searching a much lower number of lattice points than the exhaustive search required by a \"brute-force\" ml detector",
        "prob": 0.8227272727272728
    }, {
        "ID": 5120,
        "phrase": " in this paper, we propose a novel layered orthogonal lattice detector (lord) for two transmit antenna mimo systems, which achieves ml performance in case of hardoutput demodulation and optimally computes bit llrs when soft output information is generated",
        "prob": 0.5366666666666667
    }, {
        "ID": 5120,
        "phrase": " the number of lattice points to be searched is well below the exhaustive search ml algorithm, and for soft output generation is linear in the number of transmit antennas",
        "prob": 0.40499999999999997
    }, {
        "ID": 5120,
        "phrase": " section 4 details the reduced complexity ml demodulation technique",
        "prob": 0.2818181818181818
    }, {
        "ID": 5120,
        "phrase": " this change in ordering greatly impacts the complexity and architecture of the ml demodulator",
        "prob": 0.6749999999999999
    }, {
        "ID": 5120,
        "phrase": " the optimum ml word demodulator (4) would have to compute the ml metric for m 2lt constellation points and has a complexity o(m 4 ) for l t = 2",
        "prob": 0.69375
    }, {
        "ID": 5120,
        "phrase": " this search can be greatly simplified by noting for given values of x 3 and x 4 the maximum likelihood metric reduces to t (x r ) = \u2212 (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 (\u1ef9 2 \u2212 \u03c3 2 1 x 2 \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 \u2212 c 3 (x 3 , x 4 ) (28) where c 1 (x 3 , x 4 ) = s 1 x 3 + s 2 x 4 c 2 (x 3 , x 4 ) = \u2212s 2 x 3 + s 1 x 4 c 3 (x 3 , x 4 ) \u2265 0 (29) it is clear from examining (28) that due to the orthogonality of the problem formulation the conditional ml decision on x 1 and x 2 can immediately be made by a simple threshold test, i",
        "prob": 0.3964285714285714
    }, {
        "ID": 5120,
        "phrase": " examining (30) and (31) shows this reduced complexity ml demodulation is a direct consequence of the reordered lattice formulation",
        "prob": 0.6066666666666667
    }, {
        "ID": 5120,
        "phrase": " by definition, one of the two sequences is the (optimum) hard-decision ml solution of (4)",
        "prob": 0.25833333333333336
    }, {
        "ID": 5120,
        "phrase": " using arguments similar to those that led to the simplified ml demodulation (28)-(30), one can easily prove that the two sequences needed for every bit in x 2 are certainly found minimizing (27) over the possible m 2 values of (x 3 , x 4 ) and performing a simple slicing operation to the constellation elements of \u03c9 x ; thus the desired couples (x 1 , x 2 ) are uniquely determined for every (x 3 , x 4 )",
        "prob": 0.5457142857142857
    }, {
        "ID": 5120,
        "phrase": " the reordered ml decision metric becomes t \u2032 (x s ) = \u2212 (\u1ef9 s1 \u2212 \u03c3 2 2 x 3 \u2212 s 1 x 1 + s 2 x 2 ) 2 \u03c3 2 2 \u2212 (\u1ef9 s2 \u2212 \u03c3 2 2 x 4 \u2212 s 2 x 1 \u2212 s 1 x 2 ) 2 \u03c3 2 2 \u2212 (\u1ef9 s3 \u2212 r 3 x 1 ) 2 \u03c3 2 2 r 3 \u2212 (\u1ef9 s4 \u2212 r 3 x 2 ) 2 \u03c3 2 2 r 3 (40) in a direct analogy to (26)",
        "prob": 0.2818181818181818
    }, {
        "ID": 5120,
        "phrase": " thus, we have derived an exact maxlog bit llr computation using two layer orderings and an overall lattice search over 2m 2 sequences instead of m 4 as would be required by the exhaustive search-based ml algorithm",
        "prob": 0.7814814814814816
    }, {
        "ID": 5120,
        "phrase": " \n conclusion we have presented a novel lattice search-based mimo detection algorithm for two transmit antennas, characterized by a low preprocessing complexity, that achieves optimal ml demodulation with a complexity of the order of s, if s is the constellation size",
        "prob": 0.48518518518518516
    }, {
        "ID": 5120,
        "phrase": " the algorithm achieves optimal maximum-likelihood (ml) performance in case of two transmit antennas, at the same time keeping a complexity much lower than the exhaustive search-based ml detection technique",
        "prob": 0.5038461538461538
    }, {
        "ID": 5210,
        "phrase": " furthermore, we provide a more direct, alternative derivation of the nda ml estimator and we propose a new, low complexity nda snr estimator",
        "prob": 0.3736842105263158
    }, {
        "ID": 5210,
        "phrase": " the performance of the new estimator is compared to previously suggested nda estimators and found to be similar to that of the nda ml estimator",
        "prob": 0.3
    }, {
        "ID": 5213,
        "phrase": " the absence of (computationally tractable) exact map or ml algorithms for two dimensions necessitates the search for low-complexity approximate schemes",
        "prob": 0.3736842105263158
    }, {
        "ID": 5435,
        "phrase": " in this paper, we show that we can implement, in standard ml  [15] , much of what one would expect from a language with a type system that directly supports the kind of specializations described above",
        "prob": 0.255
    }, {
        "ID": 5485,
        "phrase": " designing such programs would stimulate (in fact force) research in machine learning because it would be manifestly unintelligent for a computer individual existing over time not to benefit from its experiences",
        "prob": 0.2318181818181818
    }, {
        "ID": 5859,
        "phrase": " however, the use of ai in practical application is usually not simple and often computationally intensive",
        "prob": 0.3153846153846154
    }, {
        "ID": 6175,
        "phrase": " ( 48 ) the ml receiver is usually computationally complicated since it needs to examine all valid lattice points (complexity grows exponentially)",
        "prob": 0.6166666666666667
    }, {
        "ID": 6176,
        "phrase": " ( 41 ) the ml receiver is usually computationally complicated since it needs to examine all valid lattice points (complexity grows exponentially)",
        "prob": 0.7277777777777777
    }, {
        "ID": 6177,
        "phrase": " ( 41 ) the ml receiver is usually computationally complicated since it needs to examine all valid lattice points (complexity grows exponentially)",
        "prob": 0.7277777777777777
    }, {
        "ID": 6177,
        "phrase": " as snr increases, the loss is gradually reduced and the algorithm using simplified initialization matches the ml performance asymptotically",
        "prob": 0.24117647058823527
    }, {
        "ID": 6340,
        "phrase": " a straightforward implementation of the ml detector would require, for an uncoded complex constellation of size s and l t transmit antennas, an exhaustive search over all possible s lt transmit sequences, thus being prohibitively complex for high spectral efficiencies",
        "prob": 0.5035714285714286
    }, {
        "ID": 6340,
        "phrase": " two important families are the list-based detectors  [9] ,  [10] ,  [11] ,  [12] ,  [13] , based on the combination of ml and dfe principles, and the lattice decoders, among those the sphere decoder (sd)  [14]  is most well known",
        "prob": 0.43913043478260866
    }, {
        "ID": 6340,
        "phrase": " lattice detectors use the linear nature of the mimo channel to form a reduced complexity ml search",
        "prob": 0.47333333333333333
    }, {
        "ID": 6340,
        "phrase": " sd can attain ml performance with significantly reduced complexity",
        "prob": 0.3727272727272727
    }, {
        "ID": 6340,
        "phrase": " lord achieves a huge complexity reduction over the exhaustive-search ml algorithm and, as proven via numerical results, also obtains a better complexity-performance tradeoff than sd",
        "prob": 0.3521739130434782
    }, {
        "ID": 6340,
        "phrase": " lattice search and demodulation the system equations defined in section iii-a lead naturally to a simplified yet optimal ml demodulation",
        "prob": 0.3736842105263158
    }, {
        "ID": 6340,
        "phrase": " the optimum ml word demodulator (2) would have to compute the ml metric for m 2lt constellation points and has a complexity o(m 4 ) for l t = 2",
        "prob": 0.63125
    }, {
        "ID": 6340,
        "phrase": " this search can be greatly simplified by noting for given values of x 3 and x 4 the maximum likelihood metric reduces to t (x r ) = (\u1ef9 1 \u2212 \u03c3 2 1 x 1 \u2212 c 1 (x 3 , x 4 )) 2 \u03c3 2 1 + (\u1ef9 2 \u2212 \u03c3 2 1 x 2 \u2212 c 2 (x 3 , x 4 )) 2 \u03c3 2 1 + c 3 (x 3 , x 4 ) (36) where c 1 (x 3 , x 4 ) = s 1 x 3 + s 2 x 4 c 2 (x 3 , x 4 ) = \u2212s 2 x 3 + s 1 x 4 c 3 (x 3 , x 4 ) \u2265 0 (37) the originality of lord stems from the fact that -as clear from (36) -the conditional ml decision on x 1 and x 2 can immediately be made by a simple threshold test, i",
        "prob": 0.4517241379310345
    }, {
        "ID": 6340,
        "phrase": " it should be noticed that, in a direct analogy to (  29 )-(  30 ), the ml estimate could as well be found minimizing the reordered ml decision metric t \u2032 (x s ) = \u1ef9s \u2212 rs x s 2 = (\u1ef9 s1 \u2212 \u03c3 2 2 x 3 \u2212 s 1 x 1 + s 2 x 2 ) 2 \u03c3 2 2 + (\u1ef9 s2 \u2212 \u03c3 2 2 x 4 \u2212 s 2 x 1 \u2212 s 1 x 2 ) 2 \u03c3 2 2 + (\u1ef9 s3 \u2212 r 3 x 1 ) 2 \u03c3 2 2 r 3 + (\u1ef9 s4 \u2212 r 3 x 2 ) 2 \u03c3 2 2 r 3 ",
        "prob": 0.2833333333333333
    }, {
        "ID": 6340,
        "phrase": " we observe that this reduced complexity ml demodulation is a direct consequence of the reordered lattice formulation",
        "prob": 0.65
    }, {
        "ID": 6340,
        "phrase": " by employing arguments similar to those that led to the simplified ml estimator (39), it can be easily proven that the two ed terms needed for every bit in x c2 are certainly found computing  (35)  over the possible m 2 values of x c2 = (x 3 , x 4 ) and minimizing the expression over x c1 = (x 1 , x 2 ), for every value of x c2 ",
        "prob": 0.37407407407407406
    }, {
        "ID": 6340,
        "phrase": " a lower complexity optimal ml demodulation would still be possible through slicing (x 1 , x 2 ) over all the possible m 2(lt\u22121) values of the other elements, but this would still be too complex for l t > 2",
        "prob": 0.45499999999999996
    }, {
        "ID": 6340,
        "phrase": " it should be noted that by ml \"exhaustive search over the constellation symbols\" is meant throughout this section",
        "prob": 0.23846153846153847
    }, {
        "ID": 6340,
        "phrase": "february 1, 2008 draft \n\t\t\t this statement applies to the \"exhaustive-search\" ml demodulator; a triangular decomposition of the channel matrix in itself, as in a standard qrd, would be enough to lower the complexity of the search to o(m 2lt \u22121 )",
        "prob": 0.5458333333333333
    }, {
        "ID": 6435,
        "phrase": " this follows from the facts that asymptotically, the number l of resolvable paths can be expected to grow linearly with the bandwidth, and the number of required signal dimensions (hence also the spreading gain and symbol duration) is k e ml = 2 ",
        "prob": 0.29583333333333334
    }, {
        "ID": 6876,
        "phrase": " thus, the use of suboptimal (but computationally advantageous) alternatives to ml detection is motivated",
        "prob": 0.23846153846153847
    }, {
        "ID": 7000,
        "phrase": " ai has demonstrated that this trivialization can be reduced, but not radically reduced",
        "prob": 0.34444444444444444
    }, {
        "ID": 7477,
        "phrase": " , k} such that hj ai = 1",
        "prob": 0.22000000000000003
    }, {
        "ID": 7870,
        "phrase": " for error analysis analogous to  (7) , the ml performance can be bounded by the suboptimal, yet simple, hypothesis-testing based decoder in  [14] ",
        "prob": 0.24117647058823527
    }, {
        "ID": 7892,
        "phrase": " the matching algorithm then stores the list of unique subids, that are found at a node n in the list l ai designated for a i ",
        "prob": 0.36428571428571427
    }, {
        "ID": 8464,
        "phrase": " in other words, the ml decoding can be performed by minimizing the metric y \u2212 \u03c0 2 \u03c0 1 p 2 \u03c0 1 p + 1 s k (x k )h 2 (5) for each 1 \u2264 k \u2264 g individually instead of minimizing the computationally more intensive metric y \u2212 \u03c0 2 \u03c0 1 p 2 \u03c0 1 p + 1 s(x)h 2 (6) hence the ml decoding complexity is reduced to a large extent depending on the value of g",
        "prob": 0.4269230769230769
    }, {
        "ID": 8555,
        "phrase": " if ai is possible at all, we would have reached the final goal: the construction of the most intelligent algorithm with computation time \u2264 t",
        "prob": 0.36428571428571427
    }, {
        "ID": 8555,
        "phrase": " with a reasonable computation time, the aixi model would be a solution of ai (see the next point if you disagree)",
        "prob": 0.20666666666666667
    }, {
        "ID": 8907,
        "phrase": " if we perform exhaustive search whenever the algorithm fails, we have an ml algorithm",
        "prob": 0.425
    }, {
        "ID": 8941,
        "phrase": " furthermore, we need a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8447368421052632
    }, {
        "ID": 8942,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8487179487179487
    }, {
        "ID": 8943,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8230769230769232
    }, {
        "ID": 8944,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8487179487179487
    }, {
        "ID": 8945,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8487179487179487
    }, {
        "ID": 8946,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8487179487179487
    }, {
        "ID": 8947,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8487179487179487
    }, {
        "ID": 8948,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8230769230769232
    }, {
        "ID": 8949,
        "phrase": " furthermore, the author demands a new kind of unifying and real artificial intelligence, the expected 'quantum leap for ai'  (hirsch, 1999) , that goes beyond the pioneer days heuristics and hypothesis-driven modelling by placing itself much closer to the essence of living systems, and closer to the nature of the underlying processes in both organic and inorganic system complexes",
        "prob": 0.8487179487179487
    }, {
        "ID": 9267,
        "phrase": " it is not clear that ai would have embarked on the quest for calculative rationality had it not been operating in the halcyon days before formal intractability results were discovered",
        "prob": 0.24117647058823527
    }, {
        "ID": 9309,
        "phrase": " based on experience with search processes in ai in general, such a strategy has much to recommend it, as a simple default",
        "prob": 0.3642857142857143
    }, {
        "ID": 9445,
        "phrase": " t h i s i s s u cien t f or a 500 ml i nk",
        "prob": 0.3
    }, {
        "ID": 9483,
        "phrase": " 11 in a traditional frame-based ai systems, this is called 'spreading activation', but it should be apparent that, although the effect of the two processes is analogous, the mechanisms are quite different",
        "prob": 0.205
    }, {
        "ID": 9716,
        "phrase": " firstly, although it looks conspicuously similar to one that computes a maximum likelihood hypothesis for the lexicon by assuming a uniforum prior over all possible lexicons, we carefully distinguish it from a ml hypothesis because the question of multiple prior lexicons does not arise",
        "prob": 0.325
    }]
}, {
    "topic_id": 35,
    "top_words": ["intelligence", "artificial", "human", "would", "like", "strong", "important", "computational", "interesting", "non", "researchers", "least", "system", "could", "possible"],
    "phrases": [{
        "ID": 141,
        "phrase": " more important: when trying to make ai\u03be practically usable, some other ai methods, like genetic algorithms or neural nets, may be useful",
        "prob": 0.41764705882352937
    }, {
        "ID": 141,
        "phrase": " the main thing we wanted to point out is that the ai\u03be model does not lack any important known property of intelligence or known ai methodology",
        "prob": 0.63125
    }, {
        "ID": 141,
        "phrase": " \u2022 many researchers in ai believe that intelligence is something complicated and cannot be condensed into a few formulas",
        "prob": 0.6749999999999999
    }, {
        "ID": 141,
        "phrase": " non-computable physics (which is not too weird) could make turing computable ai impossible",
        "prob": 0.7
    }, {
        "ID": 141,
        "phrase": " as at least the world that is relevant for humans seems mainly to be computable we do not believe that it is necessary to integrate non-computable devices into an ai system",
        "prob": 0.6722222222222222
    }, {
        "ID": 141,
        "phrase": " we believe the same to be true for consciousness in the field of artificial intelligence",
        "prob": 0.51
    }, {
        "ID": 141,
        "phrase": " indeed, there is probably no practically interesting, non-incremental ai system at all",
        "prob": 0.5545454545454546
    }, {
        "ID": 424,
        "phrase": " actual causation is also important in artificial intelligence applications",
        "prob": 0.41
    }, {
        "ID": 425,
        "phrase": " actual causation is also important in artificial intelligence applications",
        "prob": 0.51
    }, {
        "ID": 477,
        "phrase": " elegance: many researchers in ai believe that intelligence is something complicated and cannot be condensed into a few formulas",
        "prob": 0.7
    }, {
        "ID": 575,
        "phrase": " stefik  [9]  gave the first algorithm using artificial intelligence",
        "prob": 0.2818181818181818
    }, {
        "ID": 713,
        "phrase": " 1974 artificial intelligence",
        "prob": 0.35000000000000003
    }, {
        "ID": 999,
        "phrase": " ai and automated deduction: set abstraction and operations have been shown to be fundamental in various subfields of artificial intelligence",
        "prob": 0.4066666666666666
    }, {
        "ID": 1254,
        "phrase": " since we, like most researchers in artificial intelligence, are mostly interested in iterated revisions, proper understanding, and semantics, for this dependence is crucial",
        "prob": 0.2833333333333333
    }, {
        "ID": 1282,
        "phrase": " the discipline of artificial intelligence (ai) was born in the 1950's",
        "prob": 0.2625
    }, {
        "ID": 1316,
        "phrase": " , we can modify t by blocking the intervals (ai, bi) if ai \u2265 x +y or shifting them by yi < y to (ai\u2212yi, bi\u2212yi) with ai\u2212yi < x",
        "prob": 0.5916666666666667
    }, {
        "ID": 1317,
        "phrase": " , we can modify t by blocking the intervals (ai, bi) if ai \u2265 x + y or shifting them by yi < y to (ai\u2212yi, bi\u2212yi) with ai \u2212yi < x",
        "prob": 0.5083333333333333
    }, {
        "ID": 1318,
        "phrase": " , we can modify t by blocking the intervals (ai, bi) if ai \u2265 x + y or shifting them by yi < y to (ai\u2212yi, bi\u2212yi) with ai \u2212yi < x",
        "prob": 0.425
    }, {
        "ID": 1319,
        "phrase": " , we can modify t by blocking the intervals (ai, bi) if ai \u2265 x + y or shifting them by yi < y to (ai\u2212yi, bi\u2212yi) with ai \u2212yi < x",
        "prob": 0.5083333333333333
    }, {
        "ID": 1320,
        "phrase": " , we can modify t by blocking the intervals (ai, bi) if ai \u2265 x + y or shifting them by yi < y to (ai\u2212yi, bi\u2212yi) with ai \u2212yi < x",
        "prob": 0.5083333333333333
    }, {
        "ID": 1398,
        "phrase": " there is some debate about whether logic is really a possible foundation for artificial intelligence",
        "prob": 0.5916666666666667
    }, {
        "ID": 1398,
        "phrase": " i make some specific predictions about the prospects for artificial intelligence in a later section",
        "prob": 0.425
    }, {
        "ID": 1398,
        "phrase": "\" i do not expect that artificial intelligence will be an all-or-nothing event of the kind frequently envisioned in popular literature where we one day suddenly discover that machines have become intelligent",
        "prob": 0.2318181818181818
    }, {
        "ID": 1525,
        "phrase": " in the beginnings of artificial intelligence, some people assumed that all the knowledge of a human adult might be programmed",
        "prob": 0.43571428571428567
    }, {
        "ID": 1613,
        "phrase": " then programmed creativity times super-recursive computing power will give birth to artificial intelligence that will really be on the same or even on the higher level than human intellect",
        "prob": 0.3857142857142857
    }, {
        "ID": 1613,
        "phrase": " as it is outlined above super-recursive algorithms have important implications for artificial intelligence",
        "prob": 0.25833333333333336
    }, {
        "ID": 1871,
        "phrase": " personally, as a researcher in artificial intelligence, i believe that it would be much more exciting to create a machine with non-human-like intelligence, than to create a machine with human-like intelligence",
        "prob": 0.4826086956521739
    }, {
        "ID": 1871,
        "phrase": " in the following, i will describe a simple unsupervised machine learning algorithm, called pmi-ir, that can generate human-like answers to subcognitive questions",
        "prob": 0.205
    }, {
        "ID": 1891,
        "phrase": " in decision theory  (pearl, 1988)  and in the uncertainty in artificial intelligence literature  (pipitone et al",
        "prob": 0.25833333333333336
    }, {
        "ID": 1969,
        "phrase": " at the same time, currently known techniques in artificial intelligence (ai) are not intelligent enough to cope with recognizing and trading qualitatively different assets quickly and accurately while reasoning on different levels of abstraction",
        "prob": 0.29583333333333334
    }, {
        "ID": 1980,
        "phrase": " so researchers in machine learning and artificial intelligence have often resorted to alternative methods that lack a strong theoretical foundation but at least seem feasible in certain limited contexts",
        "prob": 0.3086956521739131
    }, {
        "ID": 1981,
        "phrase": " so researchers in machine learning and artificial intelligence have often resorted to alternative methods that lack a strong theoretical foundation but at least seem feasible in certain limited contexts",
        "prob": 0.2652173913043478
    }, {
        "ID": 2333,
        "phrase": " what makes this challenge so interesting? a solution would have enormous implications on our society, and there are reasons to believe that the ai problem can be solved in my expected lifetime",
        "prob": 0.2833333333333333
    }, {
        "ID": 2333,
        "phrase": " making good predictions plays a central role in natural and artificial intelligence in general, and in machine learning in particular",
        "prob": 0.3
    }, {
        "ID": 2333,
        "phrase": " many researchers in ai believe that intelligence is something complicated and cannot be condensed into a few formulas",
        "prob": 0.6749999999999999
    }, {
        "ID": 2333,
        "phrase": " making good predictions plays a central role in natural and artificial intelligence in general, and in machine learning in particular",
        "prob": 0.4764705882352941
    }, {
        "ID": 2333,
        "phrase": " so the number of wrong predictions e ai n\u03be of agent (6",
        "prob": 0.2625
    }, {
        "ID": 2333,
        "phrase": " the main thing we wanted to point out is that the ai\u03be model does not lack any important known property of intelligence or known ai methodology",
        "prob": 0.56875
    }, {
        "ID": 2333,
        "phrase": " indeed, there is probably no practically interesting, non-incremental ai system at all",
        "prob": 0.5545454545454546
    }, {
        "ID": 2333,
        "phrase": " many researchers in ai believe that intelligence is something complicated and cannot be condensed into a few formulas",
        "prob": 0.6749999999999999
    }, {
        "ID": 2333,
        "phrase": " \n philosophical issues many arguments against (strong and weak) ai have been proposed: lucas' and penrose's arguments based on g\u00f6del's incompleteness theorem [luc61, pen89, pen94], searle's chinese room argument  [sea80] , the lookup-table argument [chu86], moravec's brain prosthesis experiment  [mor88] , the free will argument, and, of course, various religious reasons",
        "prob": 0.3275
    }, {
        "ID": 2333,
        "phrase": " non-computable physics (which is not too odd) could make turing computable ai impossible",
        "prob": 0.6230769230769231
    }, {
        "ID": 2333,
        "phrase": " as at least the world that is relevant for humans seems mainly to be computable we do not believe that it is necessary to integrate non-computable devices into an ai system",
        "prob": 0.7277777777777777
    }, {
        "ID": 2333,
        "phrase": "  4  we believe the same to be valid for consciousness in the field of artificial intelligence: philosophically highly interesting but practically unimportant",
        "prob": 0.6733333333333333
    }, {
        "ID": 2333,
        "phrase": "17) to e ai n\u03be \u00d7 \u00d7 \u2264 is wrong",
        "prob": 0.22000000000000003
    }, {
        "ID": 2521,
        "phrase": " when a learning agent is placed in a multiagent scenario these fundamental assumptions of machine learning are violated",
        "prob": 0.2928571428571428
    }, {
        "ID": 2629,
        "phrase": "introduction since joseph weizenbaum nearly forty years ago programmed his eliza, the early natural language dialog system between human and machine, to work as a psychiatrist (weizenbaum 1965), many similar programs have been made in this field of artificial intelligence",
        "prob": 0.22903225806451613
    }, {
        "ID": 2749,
        "phrase": " \n computational complexity many problems in artificial intelligence are known to be intractable if one wishes to obtain the best possible answer",
        "prob": 0.24117647058823527
    }, {
        "ID": 2749,
        "phrase": " \n relationship with other artificial intelligence systems it would take us too far afield to attempt a detailed comparison with artificial intelligence systems in the kinds of areas mentioned above",
        "prob": 0.24285714285714283
    }, {
        "ID": 2806,
        "phrase": " it would be pedagogically attractive for the learners to chat with such a system of artificial intelligence which could \"really\" understand the natural language and reasonably generate the natural language to form a human-like dialog",
        "prob": 0.564
    }, {
        "ID": 2850,
        "phrase": " the mechanism would be designed so that it could operate in 'rolls royce' mode for artificial intelligence applications but it should also be possible to apply constraints so that it would operate more like a conventional system, trading flexibility for speed",
        "prob": 0.35
    }, {
        "ID": 2850,
        "phrase": " it is in the nature of the sp system that it blurs many distinctions that are prevalent in computing and artificial intelligence",
        "prob": 0.43571428571428567
    }, {
        "ID": 2850,
        "phrase": " as we see in chapters that follow, much the same can be said about the boundary between this recognition-retrievaland-reasoning amalgam and other areas of artificial intelligence",
        "prob": 0.41764705882352937
    }, {
        "ID": 2987,
        "phrase": " (in the ai jargon this physicist would be called \"scruffy",
        "prob": 0.5666666666666667
    }, {
        "ID": 2987,
        "phrase": " (in the ai jargon this physicist would be called \"scruffy",
        "prob": 0.5666666666666667
    }, {
        "ID": 2988,
        "phrase": " (in the ai jargon this physicist would be called \"scruffy",
        "prob": 0.5666666666666667
    }, {
        "ID": 3443,
        "phrase": " the open source nature of the code behind the jndm is therefore an important component (along with the machine learning) in making it more democratic",
        "prob": 0.22777777777777775
    }, {
        "ID": 3443,
        "phrase": " the paper also mentions the wider implications that machine learning and the techniques used in the jndm may have for representative democracy in general",
        "prob": 0.24117647058823527
    }, {
        "ID": 3502,
        "phrase": " one can foresee a time when artificial intelligence has so advanced that it becomes impossible to distinguish between a software chat room partner and a human chat room partner",
        "prob": 0.5549999999999999
    }, {
        "ID": 3837,
        "phrase": " the origins of this technique in the artificial intelligence field concentrated on consistency notions for constraints with two or fewer variables",
        "prob": 0.25625
    }, {
        "ID": 3842,
        "phrase": " we believe that relational similarity plays a fundamental role in the mind and therefore relational similarity measures could be crucial for artificial intelligence",
        "prob": 0.7947368421052632
    }, {
        "ID": 3873,
        "phrase": " at the current state, the ai planning algorithm is a standalone program which the robot's planner calls by system call",
        "prob": 0.2733333333333333
    }, {
        "ID": 4294,
        "phrase": " key aspects like selforganization and artificial intelligence become increasingly important",
        "prob": 0.3153846153846154
    }, {
        "ID": 4552,
        "phrase": " the model integrates notions from education of critical thinking  [1]  and machine learning  [2] , and has been embedded in a problembased learning system",
        "prob": 0.31875000000000003
    }, {
        "ID": 5087,
        "phrase": " relational similarity plays a fundamental role in the mind and therefore relational similarity measures could be crucial for artificial intelligence  [medin et al",
        "prob": 0.7421052631578947
    }, {
        "ID": 5130,
        "phrase": " nevertheless, understanding universal learning is important: on the one hand, its practical success would lead a way to artificial intelligence",
        "prob": 0.3
    }, {
        "ID": 5485,
        "phrase": "  m armstrong, 1980)  the arrival of artificial intelligence (or ai as it is popularly known) has marked a veritable new high even from the goals of the empirical methodology for ai seeks to not merely present a theoretical explanation of our cognitive essence, but to create it in machines as well",
        "prob": 0.21785714285714283
    }, {
        "ID": 5485,
        "phrase": " viewed in this manner, the central difficulty in resolving the ai debate becomes apparent: that, as long as our own notions of human cognition are based on mechanistic neuro-biological conceptions, there can be really no basis for rejecting, in principle, the notion of thinking machines",
        "prob": 0.46785714285714286
    }, {
        "ID": 5485,
        "phrase": " consequently, although many distinguished critics of ai have contributed significantly to examining the ai-metaphor, the ultimate issue-namely, whether or not a fundamental difference between machine-stimulated behavior and human cognition exists-remains unresolved",
        "prob": 0.3607142857142857
    }, {
        "ID": 5485,
        "phrase": " notwithstanding the tenuous justification that ai researchers have drawn for their own position from the absence of proper theories for human cognition, they are being increasingly forced into recognizing the possible conceptual inadequacy of the \"computational metaphor\"",
        "prob": 0.4826086956521739
    }, {
        "ID": 5485,
        "phrase": "a growing number of ai researchers ask, why is it so difficult to elicit intelligent behavior from machines? is it poor engineering? overly ambitious goals? or is there something fundamental that puts the goals beyond our reach? these contradictions bring to the surface a fundamental gap in our notions of cognition-namely the gap between causality and behavior",
        "prob": 0.3742857142857143
    }, {
        "ID": 5485,
        "phrase": "artificial intelligence (or ai) is a field of computer science wherein attempts are being made to produce behavior in programmed machines that we associate with human beings",
        "prob": 0.32105263157894737
    }, {
        "ID": 5521,
        "phrase": " nodes are also called neurons, to remind us of the artificial intelligence nature of the algorithm",
        "prob": 0.6230769230769231
    }, {
        "ID": 5522,
        "phrase": " nodes are also called neurons, to remind us of the artificial intelligence nature of the algorithm",
        "prob": 0.6230769230769231
    }, {
        "ID": 5523,
        "phrase": " nodes are also called neurons, to remind us of the artificial intelligence nature of the algorithm",
        "prob": 0.6230769230769231
    }, {
        "ID": 5524,
        "phrase": " nodes are also called neurons, to remind us of the artificial intelligence nature of the algorithm",
        "prob": 0.5461538461538461
    }, {
        "ID": 5957,
        "phrase": " scholarly opinion is divided on whether ai machines can have real intelligence",
        "prob": 0.2818181818181818
    }, {
        "ID": 6130,
        "phrase": " it would be an extraordinary achievement in artificial intelligence to build a modeling system that could notice emergent phenomena and see how they could be exploited",
        "prob": 0.4789473684210526
    }, {
        "ID": 6573,
        "phrase": ", a m }, each of length n, is called a complementary set if m i=1 a ai (l) = 0, 1 \u2264 l \u2264 n \u2212 1 ",
        "prob": 0.2625
    }, {
        "ID": 6590,
        "phrase": "a fundamental problem in artificial intelligence is that nobody really knows what intelligence is",
        "prob": 0.425
    }, {
        "ID": 6784,
        "phrase": " to build really powerful ai system we should address this issue",
        "prob": 0.31
    }, {
        "ID": 6784,
        "phrase": " we believe that simulation of imagination is a first step for building powerful ai system",
        "prob": 0.17500000000000002
    }, {
        "ID": 6785,
        "phrase": " we think that the first step in making an artificial intelligence system conscious would be a mutual simulation of high-level human cognitive functions, such as memory and imagination with large-scale neural networks",
        "prob": 0.23461538461538461
    }, {
        "ID": 7000,
        "phrase": " hard ai is about using computers to simulate something resembling general human intelligence",
        "prob": 0.23846153846153847
    }, {
        "ID": 7023,
        "phrase": " one might think that there would be general binary classifiers similar to rbfs in the domain of machine learning",
        "prob": 0.2733333333333333
    }, {
        "ID": 7408,
        "phrase": " therefore, because l\u03c3 \u2704 ai r\u03b8, we have b = \u2205 and t = \u03bbx",
        "prob": 0.22000000000000003
    }, {
        "ID": 7940,
        "phrase": " however, they do illustrate the important point that polynomial-time ml decoding is possible",
        "prob": 0.3153846153846154
    }, {
        "ID": 8166,
        "phrase": " as it seems, being able to provide a tool that captures the lifecycle of the development of an ai application is a strong contributor to the success of the take-up of that application",
        "prob": 0.33888888888888885
    }, {
        "ID": 8247,
        "phrase": " developing an ai system like this would be a difficult affair, but then who said that it is easy to be human? we will expand the discussion on this in a later paper",
        "prob": 0.4764705882352941
    }, {
        "ID": 8248,
        "phrase": " does this mean that we can build artificial intelligence systems that are equivalent to natural systems? the answer to this question, like the truth, lies somewhere in between",
        "prob": 0.22777777777777775
    }, {
        "ID": 8248,
        "phrase": " the other side of the story, which is more important to us from the ai point of view, is that natural systems are not mere environment responsive entities",
        "prob": 0.50625
    }, {
        "ID": 8248,
        "phrase": " overcoming searle's chinese room forms a major stumbling block to the ai fantasy that one day we may be able to make human like systems",
        "prob": 0.45499999999999996
    }, {
        "ID": 8248,
        "phrase": " searle's argument therefore should not have come as a surprise to ai enthusiasts",
        "prob": 0.23333333333333334
    }, {
        "ID": 8248,
        "phrase": " this hiding and encapsulation, to use a c++ metaphor, works out to our disadvantage when programming for ai cognition, we really do not know how we recognize objects and therefore we find it difficult to map cognitive processes to our ai entities",
        "prob": 0.2652173913043478
    }, {
        "ID": 8248,
        "phrase": " we tend to take thought and speech for granted; even theorists in the field of ai cannot be absolved of making such anthropocentric assumptions",
        "prob": 0.2733333333333333
    }, {
        "ID": 8248,
        "phrase": " most of us tend to equate thinking with learning and that partly accounts for the incredulity of ai practitioners who are baffled by people who claim that machines cannot think",
        "prob": 0.22777777777777775
    }, {
        "ID": 8248,
        "phrase": " now that we see that the presence of mind give rise to thoughts and language, we should know that our learning ai entities, however good learners they be, are not really thinking",
        "prob": 0.26842105263157895
    }, {
        "ID": 8248,
        "phrase": " and in the absence of thought they could not be speaking either! not in human fashion anyway! to have thoughts and language they need minds and we see that minds arise out of an entirely different set of constraints and enablers than what we see for our usual ai machines",
        "prob": 0.3
    }, {
        "ID": 8248,
        "phrase": " searle did point this out; the very fact that most ai theorists do not see it as obvious makes searle's question look almost like a revelation",
        "prob": 0.3
    }, {
        "ID": 8248,
        "phrase": " we can however see that his point is valid and very important to highlevel ai design! that is if we plan to make humanoids! of the many implicit assumptions that turing makes on his \"can machines think\" question, the lack of thought of the very process of thought and its origins is glaring",
        "prob": 0.46785714285714286
    }, {
        "ID": 8248,
        "phrase": " present day ai entities do not have minds and cannot speak, nor is there really reason to",
        "prob": 0.2818181818181818
    }, {
        "ID": 8248,
        "phrase": " ai entities will need to follow a similar acquisition pathway if we need them to speak and think like we do",
        "prob": 0.36428571428571427
    }, {
        "ID": 8248,
        "phrase": " self-sentience in smaller ai entities may be beneficial to humans in the short term, but considering human history, the long-term effects may not be something that we would like to bet our species on",
        "prob": 0.484
    }, {
        "ID": 8555,
        "phrase": " making good predictions plays a central role in natural and artificial intelligence in general, and in machine learning in particular",
        "prob": 0.4764705882352941
    }, {
        "ID": 8555,
        "phrase": " more important: when trying to make ai\u03be practically usable, some other ai methods, like genetic algorithms or neural nets, especially for i/o pre/postprocessing, may be useful",
        "prob": 0.4263157894736842
    }, {
        "ID": 8555,
        "phrase": " the main thing we wanted to point out is that the ai\u03be model does not lack any important known property of intelligence or known ai methodology",
        "prob": 0.63125
    }, {
        "ID": 8555,
        "phrase": " indeed, there is probably no practically interesting, non-incremental ai system at all",
        "prob": 0.4636363636363636
    }, {
        "ID": 8555,
        "phrase": " many researchers in ai believe that intelligence is something complicated and cannot be condensed into a few formulas",
        "prob": 0.6749999999999999
    }, {
        "ID": 8555,
        "phrase": " non-computable physics (which is not too weird) could make turing computable ai impossible",
        "prob": 0.7
    }, {
        "ID": 8555,
        "phrase": " as at least the world that is relevant for humans seems mainly to be computable we do not believe that it is necessary to integrate non-computable devices into an ai system",
        "prob": 0.7833333333333333
    }, {
        "ID": 8555,
        "phrase": "  18  we believe the same to be valid for consciousness in the field of artificial intelligence: philosophically highly interesting but practically unimportant",
        "prob": 0.6733333333333333
    }, {
        "ID": 8555,
        "phrase": " \n conclusions the major theme of the article was to develop a mathematical foundation of artificial intelligence",
        "prob": 0.23846153846153847
    }, {
        "ID": 8941,
        "phrase": " while discussing the non-computational physics of mind, he placed indirectly what we call the fundamental question of strong artificial intelligence 7 ",
        "prob": 0.7705882352941176
    }, {
        "ID": 8941,
        "phrase": " if penrose and lucas are right, their conclusions might leads to the interesting result that strong artificial intelligence cannot be realized at all or at least in computational spaces as we know them now",
        "prob": 0.705
    }, {
        "ID": 8941,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.5545454545454546
    }, {
        "ID": 8942,
        "phrase": " while discussing the non-computational physics of mind, he placed indirectly what the author calls the fundamental question of strong artificial intelligence 7 ",
        "prob": 0.7833333333333333
    }, {
        "ID": 8942,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8942,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.5545454545454546
    }, {
        "ID": 8943,
        "phrase": " while discussing the non-computational physics of mind, he posed indirectly what the author calls the fundamental question of strong artificial intelligence 9 ",
        "prob": 0.7833333333333333
    }, {
        "ID": 8943,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8943,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.6454545454545454
    }, {
        "ID": 8944,
        "phrase": " while discussing the non-computational physics of mind, he posed indirectly what the author calls the fundamental question of strong artificial intelligence 9 ",
        "prob": 0.7277777777777777
    }, {
        "ID": 8944,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8944,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.6454545454545454
    }, {
        "ID": 8945,
        "phrase": " while discussing the non-computational physics of mind, he posed indirectly what the author calls the fundamental question of strong artificial intelligence 9 ",
        "prob": 0.7277777777777777
    }, {
        "ID": 8945,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least not in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8945,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.6454545454545454
    }, {
        "ID": 8946,
        "phrase": " while discussing the non-computational physics of mind, he posed indirectly what the author calls the fundamental question of strong artificial intelligence 9 ",
        "prob": 0.7833333333333333
    }, {
        "ID": 8946,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least not in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8946,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.6454545454545454
    }, {
        "ID": 8947,
        "phrase": " while discussing the non-computational physics of mind, he posed indirectly what the author calls the fundamental question of strong artificial intelligence 9 ",
        "prob": 0.7277777777777777
    }, {
        "ID": 8947,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least not in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8947,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.6454545454545454
    }, {
        "ID": 8948,
        "phrase": " while discussing the non-computational physics of mind, he posed indirectly what the author calls the fundamental question of strong artificial intelligence 9 ",
        "prob": 0.7833333333333333
    }, {
        "ID": 8948,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least not in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8948,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.5545454545454546
    }, {
        "ID": 8949,
        "phrase": " while discussing the non-computational physics of mind, he posed indirectly what the author calls the fundamental question of strong artificial intelligence [\"",
        "prob": 0.7833333333333333
    }, {
        "ID": 8949,
        "phrase": " if penrose and lucas are right, their conclusions might lead to the interesting result that strong artificial intelligence cannot be realized at all or at least not in computational spaces as they are currently known",
        "prob": 0.8142857142857144
    }, {
        "ID": 8949,
        "phrase": " the final word about strong artificial intelligence has not been said yet",
        "prob": 0.6454545454545454
    }, {
        "ID": 9228,
        "phrase": " a more convincing justification is the following derived inference rule, implemented in ml using the primitive rules: \n conclusions you may be thinking, \"conversions seem interesting, but must be hopelessly inefficient",
        "prob": 0.2125
    }, {
        "ID": 9245,
        "phrase": " indeed, a high degree of artificial intelligence would be required before ctwill could deduce that",
        "prob": 0.2928571428571428
    }, {
        "ID": 9252,
        "phrase": ") thus, at least in this example, the random-worlds method gives answers that follow from the heuristic assumptions made in many standard ai systems  (pearl, 1989; pollock, 1984; spiegelhalter, 1986) ",
        "prob": 0.3227272727272727
    }, {
        "ID": 9277,
        "phrase": " a question of great practical importance to vision researchers is whether a machine learning technique can derive a set of system parameters equivalent to the hand-crafted results of the system designer",
        "prob": 0.25416666666666665
    }, {
        "ID": 9353,
        "phrase": " it also has an important role to play in the analysis of causality  [lewis 1973 ], which is becoming an increasingly important issue in ai as well  [pearl 1995 ]",
        "prob": 0.63125
    }, {
        "ID": 9354,
        "phrase": " it also has an important role to play in the analysis of causality  [lewis 1973 ], which is becoming an increasingly important issue in ai as well  [pearl 1995 ]",
        "prob": 0.50625
    }, {
        "ID": 9591,
        "phrase": " artificial intelligence and expert systems aspire to fulfill computer mediated interactive assistance, but they have yet to provide long-term solutions to users' demands",
        "prob": 0.2904761904761905
    }, {
        "ID": 9615,
        "phrase": " in the third and final part i will make some points to do with the general nature of the irs position, within ai and computational natural language processing, and argue that the concession fl offer is unneeded: irs is a perfectly reasonable doctrine in its own right and needs no defence from those who really believe in the original fallacy",
        "prob": 0.3852941176470588
    }, {
        "ID": 9615,
        "phrase": " in earlier ai systems, such information about function might be stored as part of a lexical semantic formulas attached to a primitive goal (charniak and wilks, 1976  3  ), or (depending on its salience) within an associated knowledge structure  4  ",
        "prob": 0.284
    }, {
        "ID": 9616,
        "phrase": " that  (wilks, 1968 ) was what we would now call a classic ai toy system approach, one that used techniques later called preference semantics, but applied to real newspaper texts, as controls on the philosophical texts that were my real interest at the time",
        "prob": 0.37407407407407406
    }, {
        "ID": 9779,
        "phrase": " indeed, one of the most famous speculative works in the field can be viewed as an argument that ai should be approached as a coin design problem  [188] ",
        "prob": 0.20666666666666667
    }]
}, {
    "topic_id": 36,
    "top_words": ["machine", "learning", "data", "first", "number", "patterns", "table", "real", "repository", "available", "uci", "sets", "made", "large", "high"],
    "phrases": [{
        "ID": 260,
        "phrase": " this extremely high overhead for supervision and, additionally, the also serious learning overhead when common ml algorithms scale to real size wsd problems, explain why supervised methods have been seriously questioned",
        "prob": 0.444
    }, {
        "ID": 658,
        "phrase": " (52) ai requires six assignments",
        "prob": 0.4428571428571429
    }, {
        "ID": 682,
        "phrase": " the data for this research are available from a machine learning database located in the university of california at irvine with an ftp address at ftp",
        "prob": 0.5352941176470588
    }, {
        "ID": 785,
        "phrase": " the data set that has become standard for evaluation machine learning approaches is the one first used by ramshaw and marcus  (1995) ",
        "prob": 0.31875
    }, {
        "ID": 1160,
        "phrase": " the mushroom data set contains characteristics of various species of mushrooms, and was originally obtained from the uci repository of machine learning databases  [9] ",
        "prob": 0.6894736842105263
    }, {
        "ID": 1165,
        "phrase": " the mushroom data set contains characteristics of various species of mushrooms, and was originally obtained from the uci repository of machine learning databases  [4] ",
        "prob": 0.5842105263157894
    }, {
        "ID": 1280,
        "phrase": " simultaneous uses of evolutionary algorithms  (holland, 1975; koza, 1992)  and backpropagation  (rumelhart, hinton and williams 1986)  are relatively common in machine learning (ml) literature, although in most cases evolutionary algorithms are used to select the topology or learning parameters, and not to update weights",
        "prob": 0.35806451612903223
    }, {
        "ID": 1280,
        "phrase": " (1998)  obtained good results in several standard ml problems using simulated annealing and backpropagation, in a similar way to that which is applied in this work",
        "prob": 0.3736842105263158
    }, {
        "ID": 1422,
        "phrase": " this form of personalization has become very popular and many machine learning techniques have been used to induce the internal representation (e",
        "prob": 0.19375
    }, {
        "ID": 1499,
        "phrase": " all but the spam data sets are available from the uci repository of machine learning data sets [ma95] ",
        "prob": 0.5785714285714285
    }, {
        "ID": 1803,
        "phrase": " the algorithms have been tested on datasets from uci machine learning repository  [1] ",
        "prob": 0.6454545454545454
    }, {
        "ID": 1870,
        "phrase": " table  28  shows that our analysis is actually based on a relatively large sample size, by the current standards of the machine learning research community",
        "prob": 0.26842105263157895
    }, {
        "ID": 1888,
        "phrase": " contextual normalization is a strategy for using machine learning algorithms for supervised learning from examples",
        "prob": 0.5071428571428571
    }, {
        "ID": 1888,
        "phrase": " contextual normalization is a new strategy for employing machine learning",
        "prob": 0.4636363636363636
    }, {
        "ID": 1894,
        "phrase": " many standard machine learning datasets  (murphy & aha, 1996)  contain contextual features, although this is rarely (explicitly) exploited",
        "prob": 0.44999999999999996
    }, {
        "ID": 1896,
        "phrase": " turney weka 19 56% 50% weka ml project aqdt1 20 61% 47% ibrahim f",
        "prob": 0.2818181818181818
    }, {
        "ID": 2301,
        "phrase": " all the experiments were performed using the machine learning software of weka  (witten and frank, 1999) ",
        "prob": 0.46923076923076923
    }, {
        "ID": 2375,
        "phrase": " the data sets are available from the uci repository of machine learning data sets  [ma95] ",
        "prob": 0.7
    }, {
        "ID": 2454,
        "phrase": " standard machine learning tools (mbl, c5",
        "prob": 0.23333333333333334
    }, {
        "ID": 2482,
        "phrase": " in machine learning, an instance corresponds to another event, which is described as a set of attributes' events",
        "prob": 0.36428571428571427
    }, {
        "ID": 2749,
        "phrase": " parallel processing is now a recognised requirement to meet the high computational demands of large scale databases  (abdelguerfi and lavington, 1995; abdelguerfi and wong, 1998)  and large-scale applications in artificial intelligence",
        "prob": 0.30869565217391304
    }, {
        "ID": 2771,
        "phrase": " many ai and/or graph theory tricks should be employed in step 2) and 3): such as depth-first searching, width-first searching, weighted searching, domain-independent heuristic policies (such as selecting at first those seed sets that have the maximum number of seed fluents, or those that have the maximum number of atomic fluents, etc), and/or domain-dependent heuristic policies (such as selecting at first those fluents that encapsulate jumbo data storage or raw physical sensors, etc",
        "prob": 0.5980769230769231
    }, {
        "ID": 2850,
        "phrase": " sp mechanisms range from the relatively constrained kinds of searching and matching which is done in a typical compiler or database management system to the more ambitious kinds of searching and matching performed by artificial intelligence programs",
        "prob": 0.23461538461538461
    }, {
        "ID": 2898,
        "phrase": " the first collection includes all pairwise discrimination problems from 14 datasets in the uc-irvine machine learning depository  [2] ",
        "prob": 0.56875
    }, {
        "ID": 2980,
        "phrase": " these are huge samples, which are becoming more and more available in real applications, and which constitute a serious challenge for machine learning and statistical applications",
        "prob": 0.3
    }, {
        "ID": 3047,
        "phrase": " however, the framework is still rich enough to tackle problems of machine learning",
        "prob": 0.23846153846153847
    }, {
        "ID": 3443,
        "phrase": " in case you do not have a statistics or machine learning background, table  1  shows a simple pedagogical example containing some made-up historical data",
        "prob": 0.32105263157894737
    }, {
        "ID": 3443,
        "phrase": " presumably, provided suitable privacy precautions are taken, authors will not mind rejection information being made available to a machine learning algorithm",
        "prob": 0.3736842105263158
    }, {
        "ID": 3601,
        "phrase": " left: total number of guesses made by a decoder starting at \u01eb ml (divided by the blocklength)",
        "prob": 0.5071428571428571
    }, {
        "ID": 3602,
        "phrase": " left: total number of guesses made by a decoder starting at \u01eb ml (divided by the blocklength)",
        "prob": 0.43571428571428567
    }, {
        "ID": 3708,
        "phrase": " this paper surveys the several research problems addressed by the socrob project, building a systems theory standpoint on ai concepts",
        "prob": 0.3
    }, {
        "ID": 4102,
        "phrase": " the supernode has made ml total observations",
        "prob": 0.23333333333333334
    }, {
        "ID": 4121,
        "phrase": " here we considered the data set that can be downloaded from the uci machine learning repository (ftp to ics",
        "prob": 0.5785714285714285
    }, {
        "ID": 4121,
        "phrase": " these data can also be downloaded from the uci machine learning repository",
        "prob": 0.51
    }, {
        "ID": 4121,
        "phrase": " the set contains 167 instances and can be downloaded from the uci machine learning repository",
        "prob": 0.5083333333333333
    }, {
        "ID": 4383,
        "phrase": " let \u03c8 ml (w) denote the number of such erasure patterns as a function of their weight w",
        "prob": 0.3416666666666666
    }, {
        "ID": 4383,
        "phrase": " then the code c 2 \n table i two i parity-check matrices for the (24, 12, 8) golay code g 24 \n table iii two iii parity-check matrices for the \n table iv number iv of undecodable erasure patterns by weight w in three decoders for g 12 w total patterns \u03c8 ml (w) \u03c8 h 12 (w) \u03c8 h \u2032 12 (w) 0 1 0 0 0 1 12 0 0 0 2 66 0 0 0 3 220 0 20 0 4 495 0 150 0 5 792 0 456 0 6 924 132 758 377 7 ( 12 w ) ( 12 w ) ( 12 w ) ( 12 w ) \n )/(d\u22121) rows in h, all of weight w = d \u22a5 , and that each (d\u22121)-set is covered by exactly one row of h",
        "prob": 0.7131578947368421
    }, {
        "ID": 4384,
        "phrase": " let \u03c8 ml (w) denote the number of such erasure patterns as a function of their weight w",
        "prob": 0.3416666666666666
    }, {
        "ID": 4384,
        "phrase": " \n table i two i parity-check matrices for the (24, 12, 8)  golay code g 24 \n table ii number ii of undecodable erasure patterns by weight w in three decoders for g 24 w total patterns \u03c8 ml (w) \u03c8 h 24 (w) \u03c8 h \u2032 24 (w) 0 1 0 0 0 1 24 0 0 0 2 276 0 0 0 3 2024 0 0 0 4 10626 0 110 0 5 42504 0 2277 0 6 134596 0 19723 0 7 346104 0 100397 0 8 735471 759 343035 3598 9 1307504 12144 844459 82138 10 1961256 91080 1568875 585157 11 2496144 425040 2274130 1717082 12 2704156 1313116 2637506 2556402 13 ( 24 w ) ( 24 w ) ( 24 w ) ( 24 w ) \n 24\u2212w    where p is the erasure probability of the bec",
        "prob": 0.444
    }, {
        "ID": 4384,
        "phrase": " \n table iv number iv of undecodable erasure patterns by weight w in three decoders for g 12 w total patterns \u03c8 ml (w) \u03c8 h 12 (w) \u03c8 h \u2032 12 (w) 0 1 0 0 0 1 12 0 0 0 2 66 0 0 0 3 220 0 20 0 4 495 0 150 0 5 792 0 456 0 6 924 132 758 377 7 ( 12 w ) ( 12 w ) ( 12 w ) ( 12 w ) \n 1, it follows that h \u2032 contains at least one row whose support belongs to d",
        "prob": 0.6291666666666667
    }, {
        "ID": 4517,
        "phrase": " the evaluations are made on an artificial problem and some real datasets taken from the uci machine learning repository  [8]  as well as on real trauma dataset taken from the london emergency centre",
        "prob": 0.5695652173913043
    }, {
        "ID": 4517,
        "phrase": " three other problems are taken from the uci machine learning repository  [8] , and the last is a real problem for which it is required to predict survival probability of patient after injury",
        "prob": 0.505
    }, {
        "ID": 4517,
        "phrase": " we have compared the performances of the bayesian dt techniques with the standard and the sweeping strategies on a synthetic dataset as well as on some datasets from the machine learning repository and real injury data",
        "prob": 0.5045454545454545
    }, {
        "ID": 4518,
        "phrase": " in this paper we experimentally compare the classification uncertainty of the randomised dt ensemble technique and the bayesian dt technique with a restarting strategy on a synthetic dataset and some domain problems from uci machine learning repository  [5] ",
        "prob": 0.6192307692307693
    }, {
        "ID": 4518,
        "phrase": "in this paper we experimentally compare the classification uncertainty of the randomised decision tree (dt) ensemble technique and the bayesian dt technique with a restarting strategy on a synthetic dataset as well as on some datasets commonly used in the machine learning community",
        "prob": 0.5551724137931034
    }, {
        "ID": 4547,
        "phrase": " in this paper we compare the classification uncertainty of the bayesian dt technique with a restarting strategy, and the randomised dt ensemble technique, on a synthetic dataset and some domain problems commonly used in the machine learning community",
        "prob": 0.5807692307692307
    }, {
        "ID": 4547,
        "phrase": " the experiments were conducted on a synthetic dataset, and then on some domain problems from the uci machine learning repository  [9] ",
        "prob": 0.7214285714285714
    }, {
        "ID": 4547,
        "phrase": " \n experiments with the uci machine learning depository datasets in these experiments we used the 7 domain problems taken from the uci machine learning repository  [9] ",
        "prob": 0.5842105263157894
    }, {
        "ID": 4547,
        "phrase": " \n conclusion we have experimentally compared the classification uncertainty of the bayesian dt technique sampling posterior using mcmc with a restarting strategy and the randomised dt ensemble technique on an artificial data as well as on the machine learning repository problems",
        "prob": 0.5551724137931034
    }, {
        "ID": 4547,
        "phrase": " in this paper we experimentally compare the classification uncertainty of the bayesian model averaging with a restarting strategy and the randomised dt ensemble on a synthetic dataset and some domain problems commonly used in the machine learning community",
        "prob": 0.6192307692307693
    }, {
        "ID": 4962,
        "phrase": " algorithms similar to those presented in this paper may be useful to help circumvent the complexity induced by massive data sets in machine learning, possibly by parallelizing kernel methods",
        "prob": 0.2652173913043478
    }, {
        "ID": 5187,
        "phrase": "in many problems in data mining and machine learning, data items that need to be clustered or classified are not points in a high-dimensional space, but are distributions (points on a high dimensional simplex)",
        "prob": 0.5041666666666667
    }, {
        "ID": 5188,
        "phrase": "in many problems in data mining and machine learning, data items that need to be clustered or classified are not points in a high-dimensional space, but are distributions (points on a high dimensional simplex)",
        "prob": 0.42083333333333334
    }, {
        "ID": 5538,
        "phrase": " 1 r 1 2 + o(1) ln r r \n table ii parity ii check matrix with 34 rows for g 24 that achieves stopping distance 8 \n table iii number iii of undecodable erasure patterns by weight w for different iterative decoders for g 24 w \u03c8 h (w) \u03c8 h \u2032 24 (w) \u03c8 ml (w) \u2264 7 0 0 0 8 3284 3598 759 9 78218 82138 12144 10 580166 585157 91080 11 1734967 1717082 425040 12 2569618 2556402 1313116 \u2265 13 24 w 24 w 24 w \n\t\t\t in [1] , the observation was made with respect to covering numbers rather than tur\u00e1n numbers",
        "prob": 0.4575757575757576
    }, {
        "ID": 5845,
        "phrase": "introduction gp is particularly suited for problems that can be assimilated to learning tasks, with the minimization of the error between the obtained and desired outputs for a limited number of test cases -the training data, using a ml terminology",
        "prob": 0.26296296296296295
    }, {
        "ID": 5845,
        "phrase": " this approach is tested on six different data sets from the uci ml repository  [12] ",
        "prob": 0.46923076923076923
    }, {
        "ID": 5845,
        "phrase": " in order to test the effect of using a validation set and applying some parsimony pressure, gp will be tested on common binary classification data sets taken from the machine learning repository at uci  [12] ",
        "prob": 0.444
    }, {
        "ID": 5894,
        "phrase": " ongoing research in the machine learning community seeks to design statistically sound learning algorithms that scale to large data sets (e",
        "prob": 0.4789473684210526
    }, {
        "ID": 5914,
        "phrase": " taking the first one with a given class number, the precision n is rather large compared to h and |d|, since there are many forms with small a so that the sum h i=1 1 ai becomes comparatively large",
        "prob": 0.1952380952380952
    }, {
        "ID": 5974,
        "phrase": " , an : \u03c0a n \u2022 fn , just requires to push the fi down into the ai branches, for each 1 \u2264 i \u2264 n",
        "prob": 0.3875
    }, {
        "ID": 6208,
        "phrase": " this dataset was created based on the glass problem dataset from the uci repository of machine learning databases (http://www",
        "prob": 0.44375
    }, {
        "ID": 7000,
        "phrase": " can't ai do this? perhaps rarely in the research lab but not routinely in real life",
        "prob": 0.25833333333333336
    }, {
        "ID": 7692,
        "phrase": " \n experimental results we ran both bfph and nfph based k-modes algorithms on real-life datasets obtained from the uci machine learning repository  [11]  to test their clustering performance against original k-modes algorithm using random initialization",
        "prob": 0.38275862068965516
    }, {
        "ID": 7736,
        "phrase": " unfortunately, this is not true after decoding the inner code, since due to the characteristics of ml decoding, low-weight error patterns occur more frequently than high-weight patterns",
        "prob": 0.30869565217391304
    }, {
        "ID": 7737,
        "phrase": " unfortunately, this is not true after decoding the inner code, since due to the characteristics of ml decoding, low-weight error patterns occur more frequently than high-weight patterns",
        "prob": 0.2652173913043478
    }, {
        "ID": 7891,
        "phrase": " (2) it is clear that, in general, ml decoding requires |a | number of computations, one for each codeword",
        "prob": 0.25833333333333336
    }, {
        "ID": 7921,
        "phrase": "recent advances in machine learning make it possible to design efficient prediction algorithms for data sets with huge numbers of parameters",
        "prob": 0.26842105263157895
    }, {
        "ID": 8074,
        "phrase": "36] proposed stable random projections, now a popular tool for data streaming computations, data mining, and machine learning",
        "prob": 0.41764705882352937
    }, {
        "ID": 8075,
        "phrase": "the method of stable random projections  [39, 41]  is popular for data streaming computations, data mining, and machine learning",
        "prob": 0.44375
    }, {
        "ID": 8170,
        "phrase": " \n an indicative experimental evaluation we modified gatree to incorporate the above changes and we tested it on 12 data sets from the machine learning repository  (asuncion & newman, 2007) ",
        "prob": 0.26842105263157895
    }, {
        "ID": 8382,
        "phrase": " we ran attribute value weighting based k-modes algorithms on real-life datasets obtained from the uci machine learning repository  [20]  to test their clustering performance against original k-modes algorithm",
        "prob": 0.524
    }, {
        "ID": 8756,
        "phrase": " the number of undecodable erasure patterns of each weight for the described decoder and a ml decoder are shown in table  i ",
        "prob": 0.47333333333333333
    }, {
        "ID": 8756,
        "phrase": " \n in tableiwe list the number of undecodable erasure patterns of size up to \u03c3 = 12 encountered in several parity- number of undecodable erasure patterns \u03c3 h \u22c6 h agd a h w [4] ml 3 7 0 0 0 0 4 190 0 0 0 0 5 2231 0 0 0 0 6 15881 0 0 0 0 7 79381 0 0 0 0 8 293703 759 759 3284 759 9 805556 12144 12158 78218 12144 10 1613613 91080 93477 580166 91080 11 2378038 425040 481764 1734967 425040 12 2690112 1322178 \u2265 481764 \u2265 1734967 1313116 \u2265 13 `24 \u03c3 \u00b4`24 \u03c3 \u00b4`24 \u03c3 \u00b4`24 \u03c3 \u00b4`24 \u03c3 table i undecodable erasure patterns of the [24, 12, 8] golay code",
        "prob": 0.7346153846153847
    }, {
        "ID": 8757,
        "phrase": " the number of undecodable erasure patterns of each weight for the described decoder and a ml decoder are shown in table  i ",
        "prob": 0.47333333333333333
    }, {
        "ID": 8757,
        "phrase": " \n in tableiwe list the number of undecodable erasure patterns of size up to \u03c3 = 12 encountered in several parity- number of undecodable erasure patterns \u03c3 h \u22c6 h agd a h w [4] ml 3 7 0 0 0 0 4 190 0 0 0 0 5 2231 0 0 0 0 6 15881 0 0 0 0 7 79381 0 0 0 0 8 293703 759 759 3284 759 9 805556 12144 12158 78218 12144 10 1613613 91080 93477 580166 91080 11 2378038 425040 481764 1734967 425040 12 2690112 1322178 \u2265 481764 \u2265 1734967 1313116 \u2265 13 `24 \u03c3 \u00b4`24 \u03c3 \u00b4`24 \u03c3 \u00b4`24 \u03c3 \u00b4`24 \u03c3 table i undecodable erasure patterns of the [24, 12, 8] golay code",
        "prob": 0.7346153846153847
    }, {
        "ID": 8765,
        "phrase": " y + z = ai for some number a",
        "prob": 0.22000000000000003
    }, {
        "ID": 9249,
        "phrase": " our experiments were run on several articial concepts for which we know the correct answer and two naturally occurring databases from real world tasks available from the uci machine learning repository  (murphy & aha, 1994)  in which the correct answer is not known",
        "prob": 0.41724137931034483
    }, {
        "ID": 9254,
        "phrase": " and is available from the uc irvine machine learning repository  (murphy & aha, 1994) ",
        "prob": 0.6749999999999999
    }, {
        "ID": 9254,
        "phrase": " this data set, also available as a part of the uci ml repository, describes housing values in the suburbs of boston as a function of 12 continuous attributes and 1 binary attribute  (harrison & rubinfeld, 1978) ",
        "prob": 0.2217391304347826
    }, {
        "ID": 9259,
        "phrase": " the glass, vowel, soybean, audi-ologys, isolet, letter, and nettalk data sets are available from the irvine repository of machine learning databases  (murphy & aha, 1994) ",
        "prob": 0.6863636363636364
    }, {
        "ID": 9263,
        "phrase": " there are several machine learning algorithms that consider the costs of tests, such as eg2  (n\u00fa\u00f1ez, 1988 (n\u00fa\u00f1ez, , 1991 , cs-id3  (tan & schlimmer, 1989 tan, 1993) , and idx  (norton, 1989) ",
        "prob": 0.655
    }, {
        "ID": 9263,
        "phrase": " these two costs have been treated together in decision theory, but icet is the first machine learning system that handles both costs together",
        "prob": 0.39444444444444443
    }, {
        "ID": 9263,
        "phrase": " the experiments in this paper have compared icet to other machine learning systems that can handle test costs  (n\u00fa\u00f1ez, 1988 (n\u00fa\u00f1ez, , 1991 tan & schlimmer, 1989 tan, 1993; norton, 1989 ), but we have not compared icet to other machine learning systems that can handle classification error costs  (breiman et al",
        "prob": 0.7033333333333334
    }, {
        "ID": 9264,
        "phrase": " the promoter recognition problem comes with the initial domain theory shown in figure 4 (quoted almost verbatim from towell and shavlik's entry in the uci machine learning repository)",
        "prob": 0.2652173913043478
    }, {
        "ID": 9277,
        "phrase": ") \n test on a synthetic cup database the de nition and recognition of cups is a task that has been visited frequently in machine learning research  (mitchell, keller, & kedar-cabelli, 1986; winston, binford, katz, & lowry, 1983) ",
        "prob": 0.284
    }, {
        "ID": 9278,
        "phrase": " first, whereas most machine learning e orts concentrate on depth of a single type of learning from a single type of input, tutorial instruction requires a breadth of learning from a range of instructional interactions",
        "prob": 0.324
    }, {
        "ID": 9278,
        "phrase": " second, tutorial instruction has not been extensively studied in machine learning, so there is not a battery of standard systems and problems available",
        "prob": 0.31875
    }, {
        "ID": 9279,
        "phrase": " they can be extremely large -consider the definition of standard ml  [17] ",
        "prob": 0.31
    }, {
        "ID": 9281,
        "phrase": " the opus algorithms differ from most previous admissible search algorithms employed in machine learning  (clearwater & provost, 1990; murphy & pazzani, 1994; rymon, 1992; segal & etzioni, 1994; webb, 1990)  in that when such operators are identified, they are removed from consideration in all branches of the search tree that descend from the current node",
        "prob": 0.440625
    }, {
        "ID": 9281,
        "phrase": " \n fixed-order search a number of recent machine learning algorithms have performed restricted admissible search  (clearwater & provost, 1990; rymon, 1993; schlimmer, 1993; segal & etzioni, 1994; webb, 1990) ",
        "prob": 0.43913043478260866
    }, {
        "ID": 9281,
        "phrase": " this facility is crucial when searching large search spaces such as those encountered in machine learning",
        "prob": 0.23846153846153847
    }, {
        "ID": 9281,
        "phrase": " \n experimental method this search was performed on fourteen data sets from the uci repository of machine learning databases  (murphy & aha, 1993) ",
        "prob": 0.5055555555555555
    }, {
        "ID": 9286,
        "phrase": "  wedderburn, 1976)  that can be iteratively found using the newton{raphson method as follows: ^ (t+1) = (x 0 (t) x) 1 x 0 (t) z (t) with the (n n){matrix x built from the x i ,  starting with ^ (0) i = (y i +1=2)=(n i +1), the ml estimate ^ may usually be computed with high accuracy within a few steps since the method is quadratically convergent and relatively robust with respect to the choice of the starting vector",
        "prob": 0.21515151515151515
    }, {
        "ID": 9298,
        "phrase": " he found that, for a number of tasks from the uci repository of machine learning datasets  (murphy & aha, 1993) , the simple rules achieved accuracies of within a few percentage points of the complex trees",
        "prob": 0.30869565217391304
    }, {
        "ID": 9298,
        "phrase": " \n theoretical basis for the decision tree post-processor the similarity assumption is a common assumption in machine learning|that objects that are similar have high probability of belonging to the same class  (rendell & seshu, 1990) ",
        "prob": 0.37916666666666665
    }, {
        "ID": 9298,
        "phrase": " \n evaluation to evaluate the post-processor it was applied to all datasets containing continuous attributes from the uci machine learning repository  (murphy & aha, 1993 ) that were then held (due to previous machine learning experimentation) in the local repository at deakin university",
        "prob": 0.5551724137931034
    }, {
        "ID": 9318,
        "phrase": " many real-world applications have both nominal and linear attributes, including, for example, over half of the datasets in the uci machine learning database repository  (merz & murphy, 1996) ",
        "prob": 0.36818181818181817
    }, {
        "ID": 9318,
        "phrase": " \n normalization experiments in order to determine whether each normalization scheme n1, n2 and n3 gave unfair weight to either nominal or linear attributes, experiments were run on 15 databases from the machine learning database repository at the university of california, irvine  (merz & murphy, 1996) ",
        "prob": 0.5366666666666667
    }, {
        "ID": 9318,
        "phrase": " euclidean and hoem a nearest neighbor classifier (with k=1) using the three distance functions listed in table  3  was tested on 48 datasets from the uci machine learning database repository",
        "prob": 0.45909090909090905
    }, {
        "ID": 9318,
        "phrase": " as an example, consider the iris database from the uci machine learning databases",
        "prob": 0.425
    }, {
        "ID": 9318,
        "phrase": " the ivdm and dvdm algorithms were implemented and tested on 48 datasets from the uci machine learning databases",
        "prob": 0.5071428571428571
    }, {
        "ID": 9318,
        "phrase": " where range a = max a \u2212 min a , and vdm a (x, y) = p a,x,c \u2212 p a,y,c 2 c=1 c \u2211 vdm a (x a , y a ) vdm a (x a , y a ) vdm a (x a , y a ) each distance function was tested on 48 datasets from the uci machine learning databases, again using 10-fold cross-validation",
        "prob": 0.5875
    }, {
        "ID": 9318,
        "phrase": " he found that using discretization to preprocess data often degraded accuracy, and recommended that machine learning algorithms be designed to handle continuous attributes directly",
        "prob": 0.33809523809523806
    }, {
        "ID": 9323,
        "phrase": " discussion and future work  towell (1991)  showed kbann generalized better than many other machine learning algorithms on the promoter and splice-junction domains (the rbs dataset did not exist then)",
        "prob": 0.39565217391304347
    }, {
        "ID": 9323,
        "phrase": "  towell and shavlik (1994)  compared kbann with numerous machine learning algorithms where each learning algorithm was given a training set of 1000 examples; kbann's generalization ability compared favorably with these algorithms on the splice domain and regent, in turn, compared favorably with kbann in this article",
        "prob": 0.409375
    }, {
        "ID": 9343,
        "phrase": " \n using adtrees for machine learning as we will see in section 7, the adtree structure can substantially speed up the computation of contingency tables for large real datasets",
        "prob": 0.255
    }, {
        "ID": 9343,
        "phrase": " the tree is then shipped and re-used by anyone who wishes to do real-time counting queries, multivariate graphs and charts, or any machine learning algorithms on any subset of the attributes",
        "prob": 0.36818181818181817
    }, {
        "ID": 9343,
        "phrase": "this paper introduces new algorithms and data structures for quick counting for machine learning datasets",
        "prob": 0.47333333333333333
    }, {
        "ID": 9343,
        "phrase": " we also discuss the possible uses of adtrees in other machine learning methods, and discuss the merits of adtrees in comparison with alternative representations such as kd-trees, r-trees and frequent sets",
        "prob": 0.3227272727272727
    }, {
        "ID": 9345,
        "phrase": " \n implementation to test this hypothesis, we implemented several algorithms in common lisp, building on ray mooney's publicly available machine learning library",
        "prob": 0.305
    }, {
        "ID": 9345,
        "phrase": " \n domains we evaluated the algorithms on a variety of reasonably large and noise-free training sets from the uci collection of machine learning databases",
        "prob": 0.4263157894736842
    }, {
        "ID": 9478,
        "phrase": " if the least is verified experimentally for each concrete process then the proof has an experimentally mathematical character being based on the incomplete induction; note that the similar procedures are used in many self-educating systems of artificial intelligence, in which possible combinations of steps are realized (sometimes statistically) with subsequent verification of their correctness (a method of the random seeking for solutions)",
        "prob": 0.23333333333333334
    }, {
        "ID": 9480,
        "phrase": " however, due to the restriction that the data available is very large, many machine learning techniques do not always scale well and can not just simply be applied",
        "prob": 0.26842105263157895
    }, {
        "ID": 9571,
        "phrase": " this turned out to be the case especially for the gs data set, the only task presented here which has extensively been studied in the ml literature before (through the similar nettalk data set)",
        "prob": 0.355
    }, {
        "ID": 9599,
        "phrase": " we use standard experimental methodology from machine learning and present results for several evaluation metrics on independent test data including rank correlation coefficient and average rating of top-ranked books",
        "prob": 0.3
    }, {
        "ID": 9623,
        "phrase": " first, we have made a first step towards automating the adaptation process in toot, by using machine learning to develop a classifier for detecting dialogues with poor speech recognition  (litman et al",
        "prob": 0.29583333333333334
    }, {
        "ID": 9678,
        "phrase": " all other statistical and machine learning methods are eager (or greedy) learners: they abstract knowledge structures or probability distributions from the training data, forget the individual training instances, and extrapolate from the induced structures",
        "prob": 0.244
    }]
}, {
    "topic_id": 37,
    "top_words": ["model", "general", "even", "hard", "problem", "case", "particular", "problems", "np", "classes", "may", "system", "assumption", "class", "decision"],
    "phrases": [{
        "ID": 47,
        "phrase": " depth-first rules are the most widely used search rules in artificial intelligence and programming languages because they can be very efficiently implemented using a simple stack-based memory structure",
        "prob": 0.1782608695652174
    }, {
        "ID": 141,
        "phrase": " this, together with general convergence theorems motivates us to believe that the constructed universal ai system is the best one in a sense to be clarified in the sequel, i",
        "prob": 0.5055555555555555
    }, {
        "ID": 141,
        "phrase": " sections 5-9 show how a number of ai problem classes fit into the general ai\u03be model",
        "prob": 0.5083333333333333
    }, {
        "ID": 141,
        "phrase": " these sections should support the claim that every ai problem can be formulated (and hence solved) within the ai\u03be model",
        "prob": 0.2928571428571428
    }, {
        "ID": 141,
        "phrase": " universality of \u03be ai : in which sense the ai\u03be model is optimal will be clarified later",
        "prob": 0.61
    }, {
        "ID": 141,
        "phrase": " we want to call an ai model universal, if it is \u00b5 independent (unbiased, model-free) and is able to solve any solvable problem and learn any learnable task",
        "prob": 0.7833333333333333
    }, {
        "ID": 141,
        "phrase": " we even have difficulties in specifying what we can expect to hold for ai\u03be or any ai system which claims to be universally optimal",
        "prob": 0.6230769230769231
    }, {
        "ID": 141,
        "phrase": " again, this is not a drawback of ai\u03be since for no unbiased ai system the errors/credits could be bound in terms of k(\u00b5) and the errors/credits of ai\u00b5 only",
        "prob": 0.46923076923076923
    }, {
        "ID": 141,
        "phrase": " on the other hand, \u03be ai converges to \u00b5 ai in the limit  (37) , and (  43 ) should hold asymptotically for \u03be in some sense",
        "prob": 0.41
    }, {
        "ID": 141,
        "phrase": " this choice is in no way sufficient and satisfactory for the full ai\u03be model, as one single choice of m k should serve for all ai problem classes",
        "prob": 0.6066666666666667
    }, {
        "ID": 141,
        "phrase": " using the ai\u00b5 model for game playing: in the following, we demonstrate the applicability of the ai model to games",
        "prob": 0.46923076923076923
    }, {
        "ID": 141,
        "phrase": " we expect this to be true as \u00b5 ai factorizes in the case of games of fixed length, i",
        "prob": 0.3727272727272727
    }, {
        "ID": 141,
        "phrase": " the proof of equivalence was so simple because the fm model has already a rather general structure, which is similar to the full ai model",
        "prob": 0.56875
    }, {
        "ID": 141,
        "phrase": " so we expect \u00b5 r and hence r coded in the dominant contributions to \u03be ai in some way, where the plausible assumption was made that the y on the input tape do not matter",
        "prob": 0.63125
    }, {
        "ID": 141,
        "phrase": " as we claim universality of the ai\u03be model, we want to enlight which of, and how the other ai methods are incorporated in the ai\u03be model, by looking its structure",
        "prob": 0.7
    }, {
        "ID": 141,
        "phrase": " there are several ai problems that fall into this class",
        "prob": 0.5125
    }, {
        "ID": 141,
        "phrase": " \u2022 with a reasonable computation time, the ai\u03be model would be a solution of ai (see next point if you disagree)",
        "prob": 0.22142857142857145
    }, {
        "ID": 141,
        "phrase": " we gave a functional (2) and an iterative (  9 ) formulation of such a decision theoretic agent, which is general enough to cover all ai problem classes, as has been demonstrated by several examples",
        "prob": 0.6894736842105263
    }, {
        "ID": 374,
        "phrase": " data mining shares many traits with ai technologies in general, so we should be concerned that they do not share the same business fate",
        "prob": 0.20666666666666667
    }, {
        "ID": 477,
        "phrase": " universality of \u03be ai : it can be shown that \u03be ai defined in (9) is universal and converges to \u00b5 ai analogously to the sp case (5) and (6)",
        "prob": 0.425
    }, {
        "ID": 477,
        "phrase": " universally optimal ai systems: we want to call an ai model universal, if it is \u00b5-independent (unbiased, model-free) and is able to solve any solvable problem and learn any learnable task",
        "prob": 0.7666666666666667
    }, {
        "ID": 477,
        "phrase": " unfortunately, simple value bounds for ai\u03be or any other ai system in terms of v * analogously to the error bound (8) can not hold  [hut00b] ",
        "prob": 0.33999999999999997
    }, {
        "ID": 477,
        "phrase": " we even have difficulties in specifying what we can expect to hold for ai\u03be or any ai system which claims to be universally optimal",
        "prob": 0.7
    }, {
        "ID": 477,
        "phrase": " this sort of computability assumption, namely, that a general purpose computer of sufficient power and appropriate program is able to behave in an intelligent way, is the very basis of ai research",
        "prob": 0.5285714285714286
    }, {
        "ID": 477,
        "phrase": " applications:  [hut00b]  shows how a number of ai problem classes, including sequence prediction, strategic games, function minimization and supervised learning fit into the general ai\u03be model",
        "prob": 0.41363636363636364
    }, {
        "ID": 587,
        "phrase": " on the other hand, levin search has been successfully applied to solve rather difficult machine learning problems [sch97, szw97], even though it suffers from a large multiplicative factor of similar origin",
        "prob": 0.7240000000000001
    }, {
        "ID": 1483,
        "phrase": " in contrast, we utilize several completely prior-knowledge-free supervised machine learning methods, with the goal of understanding the inherent difficulty of the task",
        "prob": 0.355
    }, {
        "ID": 1520,
        "phrase": " on the other hand, levin search has been successfully applied to solve rather difficult machine learning problems  [14, 16] , even though it suffers from a large multiplicative factor of similar origin",
        "prob": 0.6565217391304348
    }, {
        "ID": 1666,
        "phrase": " nonbinary, nonuniversal variants of osearch were used to solve machine learning toy problems unsolvable by traditional methods  [58, 47] ",
        "prob": 0.41764705882352937
    }, {
        "ID": 1667,
        "phrase": " (1997b)  used rather general but nonuniversal variants of lsearch to solve machine learning toy problems unsolvable by traditional methods",
        "prob": 0.44999999999999996
    }, {
        "ID": 1881,
        "phrase": " there are a number of questions this argument raises: first, is the size of the atis corpus large enough to guarantee that the ml model is in some sense right? secondly, though the set of grammatical sentences of english, however this is defined, is probably weakly context-free, is the distribution over actual english sentences stochastically context free? that is to say, are there statistical dependencies in english that cannot be captured, even in principle by a pcfg? thirdly, even if english is not stochastically context-free, does that mean that the ml model is wrong? fourthly, does the structure of this hypothetical optimal pcfg correspond to a linguistic grammar? i have few answers to these questions, except to say that grammars written by linguists disagree frequently",
        "prob": 0.2753424657534247
    }, {
        "ID": 1881,
        "phrase": " since i accept the general thrust of this argument, i have taken pains to use general-purpose machine learning techniques, or variants thereof",
        "prob": 0.4263157894736842
    }, {
        "ID": 2333,
        "phrase": " chapter 6: we show how a number of ai problem classes fit into the general aixi model",
        "prob": 0.7
    }, {
        "ID": 2333,
        "phrase": " we want to call an ai model universal, if it is independent of the true environment \u00b5 (unbiased, model-free) and is able to solve any solvable problem and learn any learnable task",
        "prob": 0.705
    }, {
        "ID": 2333,
        "phrase": " unfortunately, simple value bounds for aixi or any other ai system in terms of v * \u03bd analogous to the loss bound (1",
        "prob": 0.36428571428571427
    }, {
        "ID": 2333,
        "phrase": " we even have difficulties in specifying what we can expect to hold for aixi or any ai system which claims to be universally optimal",
        "prob": 0.7214285714285714
    }, {
        "ID": 2333,
        "phrase": " this sort of computability assumption, namely, that a general purpose computer of sufficient power and appropriate program is able to behave in an intelligent way, is the very basis of ai research",
        "prob": 0.5285714285714286
    }, {
        "ID": 2333,
        "phrase": " we have shown how a number of ai problem classes, including sequence prediction, strategic games, function minimization and supervised learning fit into the general ai\u03be model",
        "prob": 0.355
    }, {
        "ID": 2333,
        "phrase": " \n universality of \u03be ai in which sense the aixi model is optimal will be clarified later",
        "prob": 0.6454545454545454
    }, {
        "ID": 2333,
        "phrase": "2) is universal and converges to \u00b5 ai analogous to the sp case (2",
        "prob": 0.4555555555555555
    }, {
        "ID": 2333,
        "phrase": " we want to call an ai model universal, if it is \u00b5 independent (unbiased, modelfree) and is able to solve any solvable problem and learn any learnable task",
        "prob": 0.7705882352941176
    }, {
        "ID": 2333,
        "phrase": " we even have difficulties in specifying what we can expect to hold for aixi or any ai system which claims to be universally optimal",
        "prob": 0.7214285714285714
    }, {
        "ID": 2333,
        "phrase": " again, this is not a drawback of aixi since for no unbiased ai system the errors/rewards could be bound in terms of k(\u00b5) and the errors/rewards of ai\u00b5 only",
        "prob": 0.65
    }, {
        "ID": 2333,
        "phrase": " this does not necessarily imply nonenumerability of \u03be ai alt ",
        "prob": 0.3
    }, {
        "ID": 2333,
        "phrase": " on the other hand, \u03be ai converges to \u00b5 ai in the limit (6",
        "prob": 0.4428571428571429
    }, {
        "ID": 2333,
        "phrase": " this choice is in no way sufficient and satisfactory for the full ai\u03be model, as one single choice of m k should serve for all ai problem classes",
        "prob": 0.6733333333333333
    }, {
        "ID": 2333,
        "phrase": " we expect this to be true as \u00b5 ai factorizes in the case of games of fixed length, i",
        "prob": 0.3727272727272727
    }, {
        "ID": 2333,
        "phrase": " so we expect \u00b5 r and hence r to be coded in the dominant contributions to \u03be ai in some way, where the plausible assumption was made that the y on the input tape do not matter",
        "prob": 0.56875
    }, {
        "ID": 2333,
        "phrase": " as we claim universality of the ai\u03be model, we want to enlight which of, and how the other ai methods are incorporated in the ai\u03be model, by looking at its structure",
        "prob": 0.6230769230769231
    }, {
        "ID": 2333,
        "phrase": " on the other hand, levin search has been successfully adapted/generalized and applied to solve rather difficult machine learning problems [sch97, szw97, sch02b], even though it suffers from a large multiplicative factor of similar origin",
        "prob": 0.6333333333333334
    }, {
        "ID": 2333,
        "phrase": " there are several ai problems that fall into this class",
        "prob": 0.5125
    }, {
        "ID": 2333,
        "phrase": " this is a general sociological problem which successful ai will cause, which has nothing specifically to do with aixi",
        "prob": 0.425
    }, {
        "ID": 2333,
        "phrase": " whether aixi can be scaled down in a systematic way to yield practical ai algorithms or whether it will only serve as a guiding principle in attacking difficult ai problems remains to be seen",
        "prob": 0.29047619047619044
    }, {
        "ID": 2333,
        "phrase": " finally, we speculate on the big questions of ai in general and the aixi model in particular, related to non-computable physics, the number of wisdom \u03c9, and consciousness",
        "prob": 0.32105263157894737
    }, {
        "ID": 2333,
        "phrase": " there are two possible objections to ai in general and, therefore, to aixi in particular",
        "prob": 0.3727272727272727
    }, {
        "ID": 2333,
        "phrase": "17) formulation of such a decision theoretic agent in chapter 4, which is general enough to cover all ai problem classes, as has been demonstrated by several examples",
        "prob": 0.5941176470588235
    }, {
        "ID": 2333,
        "phrase": "2 universality of \u03be ai ",
        "prob": 0.22000000000000003
    }, {
        "ID": 2333,
        "phrase": " this, together with general convergence theorems motivates us to believe that the constructed universal ai system is the best one in a sense to be clarified in the sequel, i",
        "prob": 0.5611111111111111
    }, {
        "ID": 2334,
        "phrase": " universally optimal ai systems: we want to call an ai model universal, if it is \u00b5-independent (unbiased, model-free) and is able to solve any solvable problem and learn any learnable task",
        "prob": 0.719047619047619
    }, {
        "ID": 2396,
        "phrase": " this analysis is consistent with numerous learning results in the game theory and machine learning literatures which guarantee convergence to a strategy or that the payoffs approach those of the equilibrium (e",
        "prob": 0.255
    }, {
        "ID": 2475,
        "phrase": " in particular, it shows that katsuno and mendelzon's notion of belief update (katsuno & mendelzon, 1991a) depends on several strong assumptions that may limit its applicability in artificial intelligence",
        "prob": 0.5045454545454545
    }, {
        "ID": 2850,
        "phrase": " this construct has been introduced in some ai systems so that classes can be derived from metaclasses in the same way that objects are derived from classes",
        "prob": 0.36428571428571427
    }, {
        "ID": 3569,
        "phrase": " a consequence is this: minimizing the data-to-model code length (finding the ml estimator or mdl estimator), in a class of contemplated models of prescribed maximal (kolmogorov) complexity, always results in a model of best fit, irrespective of whether the source producing the data is in the model class considered",
        "prob": 0.22499999999999998
    }, {
        "ID": 3878,
        "phrase": " according to the maker, \"the vpma structure may hold advances in neural net processing simulation, and ai applications",
        "prob": 0.25625
    }, {
        "ID": 5472,
        "phrase": " \n on morphisms s 1 i \u2212\u2192s 2 , t t t ai maps [s \u2032 , a] to the equivalence class of [s \u2032 , a(i + id s \u2032 )a]",
        "prob": 0.34444444444444444
    }, {
        "ID": 5473,
        "phrase": " \n on morphisms s 1 i \u2212\u2192s 2 , t t t ai maps [s \u2032 , a] to the equivalence class of [s \u2032 , a(i + id s \u2032 )a]",
        "prob": 0.34444444444444444
    }, {
        "ID": 5485,
        "phrase": " the \"bird and plane\" counter-argument from ai proponents illustrates the conceptual crisis rather well",
        "prob": 0.2928571428571428
    }, {
        "ID": 5540,
        "phrase": " an important advantage of the sobolev class h 1 ([0, 1]) over some other classes used in machine learning is that it is universal, in the sense that it is dense in the set of all continuous functions on [0, 1] (cf",
        "prob": 0.2157894736842105
    }, {
        "ID": 5908,
        "phrase": " on the other hand, experiments demonstrate that the number of cuts required to converge to the ml codeword (if the convergence is possible) does not grow very rapidly with length",
        "prob": 0.22777777777777775
    }, {
        "ID": 5908,
        "phrase": " we showed that redundant parity checks provide strong cuts, even though they may not guarantee ml performance",
        "prob": 0.41764705882352937
    }, {
        "ID": 6340,
        "phrase": " however, lattice reduction (lr) techniques such as the lenstra-lenstra-lov\u00e1sz  [20] ,  [21] ,  [15]  did not prove very useful to solve the constrained ml problem (2), as reported in  [17] , because they distort the original lattice and boundary control becomes difficult",
        "prob": 0.19615384615384615
    }, {
        "ID": 6387,
        "phrase": " \n consistency \n introduction while universal approximation is an important property, it is not sufficient to ensure that the considered model can be used with success for some machine learning task",
        "prob": 0.32105263157894737
    }, {
        "ID": 6519,
        "phrase": " for any r \u2208 r, rvi \u2208 ni, and, hence, rvi = aivi for some ai \u2208 f , because ni is one-dimensional",
        "prob": 0.31
    }, {
        "ID": 7000,
        "phrase": " hard ai can be considered a brilliantly successful failure today",
        "prob": 0.31
    }, {
        "ID": 7175,
        "phrase": " the main purpose of artificial intelligence is find a way of organizing knowledge in such a way that helps decision making to take place rapidly and efficiently; which means that learning should happen at optimal speed and in compact storage",
        "prob": 0.27307692307692305
    }, {
        "ID": 7233,
        "phrase": " even though there is a linear number of facets that contain the ml codeword, we show that it will require a constant number of fractional pseudocodewords to cover them",
        "prob": 0.3736842105263158
    }, {
        "ID": 7337,
        "phrase": " analysis of finite length practical encoders and hard decision ml component decoders we choose the weight factor to be w = 3 4 ",
        "prob": 0.3588235294117647
    }, {
        "ID": 7337,
        "phrase": " shown, along with the upper-bound on distortion when this particular choice of component code is used along with hard decision ml decoding for the component codes at the analog decoder",
        "prob": 0.43913043478260866
    }, {
        "ID": 7409,
        "phrase": " hence it remains to show that l\u03c3 \u2032 \u2704 ai r\u03b8 \u2032 ",
        "prob": 0.4428571428571429
    }, {
        "ID": 7476,
        "phrase": " this is a task for experimental machine learning; what learning theory can do is to study the relation of domination between various a priori plausible benchmark classes: e",
        "prob": 0.22777777777777775
    }, {
        "ID": 7921,
        "phrase": " the claim of validity of conformal predictors depends on an assumption that is shared by many other algorithms in machine learning, which we call the assumption of randomness: the objects and their labels are assumed to be generated independently from the same probability distribution",
        "prob": 0.244
    }, {
        "ID": 8170,
        "phrase": " complete binary decision trees are quite unlikely to occur in a practical machine learning context (linear ones are considerably more likely, also due to their intuitive layout)",
        "prob": 0.18636363636363634
    }, {
        "ID": 8555,
        "phrase": " chapter 5: we show how a number of ai problem classes fit into the general aixi model",
        "prob": 0.7
    }, {
        "ID": 8555,
        "phrase": " we want to call an ai model universal, if it is \u00b5-independent (unbiased, modelfree) and is able to solve any solvable problem and learn any learnable task",
        "prob": 0.7705882352941176
    }, {
        "ID": 8555,
        "phrase": " we even have difficulties in specifying what we can expect to hold for ai\u03be or any ai system that claims to be universally optimal",
        "prob": 0.7
    }, {
        "ID": 8555,
        "phrase": " again, this is not a drawback of ai\u03be since for no unbiased ai system could the errors/rewards be bound in terms of k(\u00b5) and the errors/rewards of ai\u00b5 only",
        "prob": 0.5461538461538461
    }, {
        "ID": 8555,
        "phrase": " on the other hand, \u03be ai converges to \u00b5 ai in the limit (23), and (28) should hold asymptotically for \u03be in some sense",
        "prob": 0.41
    }, {
        "ID": 8555,
        "phrase": " this choice is in no way sufficient and satisfactory for the full ai\u03be model, as one single choice of m k should serve for all ai problem classes",
        "prob": 0.74
    }, {
        "ID": 8555,
        "phrase": " in the following, we demonstrate the applicability of the ai model to games",
        "prob": 0.4555555555555555
    }, {
        "ID": 8555,
        "phrase": " we expect that no other learning scheme (with no extra information) can learn the game more quickly than ai\u03be, since \u00b5 ai factorizes in the case of games of fixed length, i",
        "prob": 0.5055555555555555
    }, {
        "ID": 8555,
        "phrase": " the proof is very simple since the fm model has already a rather general structure, which is similar to the full ai model",
        "prob": 0.63125
    }, {
        "ID": 8555,
        "phrase": " so we expect \u00b5 r and hence r to be coded in the dominant contributions to \u03be ai in some way, where the plausible assumption was made that the y on the input tape do not matter",
        "prob": 0.69375
    }, {
        "ID": 8555,
        "phrase": " as we claim universality of the ai\u03be model, we want to illuminate which of and how the other ai methods are incorporated in the ai\u03be model by looking at its structure",
        "prob": 0.6230769230769231
    }, {
        "ID": 8555,
        "phrase": " there are several ai problems that fall into this class",
        "prob": 0.3875
    }, {
        "ID": 8555,
        "phrase": " there are two possible objections to ai in general and, therefore, to aixi in particular",
        "prob": 0.2818181818181818
    }, {
        "ID": 8555,
        "phrase": " we presented a functional (3) and an iterative (11) formulation of such a decision-theoretic agent in section 2, which is general enough to cover all ai problem classes, as was demonstrated by several examples",
        "prob": 0.5549999999999999
    }, {
        "ID": 8907,
        "phrase": "we show that even in this more restricted case, the ml decoding problem is np-hard",
        "prob": 0.46923076923076923
    }, {
        "ID": 8907,
        "phrase": " finally, we observe that the argument of berlekamp, mceliece and van tilborg can be used to show that ml decoding of the considered class of codes constructed from ldpc codes with regular left degree, of which the considered expander codes are a special case, remains np-hard; thus giving an interesting contrast between the worst-case and expected complexities",
        "prob": 0.41282051282051285
    }, {
        "ID": 9163,
        "phrase": " along the way, we prove several general properties of lp relaxations of ml decoding that shed light upon the performance of lp and iterative decoding algorithms",
        "prob": 0.2318181818181818
    }, {
        "ID": 9163,
        "phrase": " in particular, we observe empirically that a number of cuts less than the length of the code is often enough to ensure convergence to the ml codeword",
        "prob": 0.22777777777777775
    }, {
        "ID": 9163,
        "phrase": " we showed that redundant parity checks provide strong cuts, even though they may not guarantee ml performance",
        "prob": 0.41764705882352937
    }, {
        "ID": 9239,
        "phrase": " propositional satis ability is the problem of deciding if there is an assignment for c 1993 ai access foundation and morgan kaufmann publishers",
        "prob": 0.47333333333333333
    }, {
        "ID": 9259,
        "phrase": ", c 1995 ai access foundation and morgan kaufmann publishers",
        "prob": 0.5666666666666667
    }, {
        "ID": 9268,
        "phrase": " the rst class of problems, which we will call here logic based relational learning problems, are rst-order variants of the sorts of classi cation problems typically considered within ai machine learning community: prototypical examples include  formulation of -helix prediction,  king et al",
        "prob": 0.30606060606060603
    }, {
        "ID": 9277,
        "phrase": " \n the training approach in order to learn all the various subcategories de ned in a category de nition tree, we utilize a machine learning approach which is based on an assumption about human learning known as one disjunct per lesson  (lehn, 1990) ",
        "prob": 0.284
    }, {
        "ID": 9277,
        "phrase": " we have chosen to utilize a machine learning algorithm which has underpinnings similar to van lehn's one-disjunct-per-lesson assumption",
        "prob": 0.3
    }, {
        "ID": 9338,
        "phrase": " in case of one-way streets, bidirectional search implements c 1997 ai access foundation and morgan kaufmann publishers",
        "prob": 0.75625
    }, {
        "ID": 9504,
        "phrase": "motivation artificial intelligence planning is a notoriously hard problem",
        "prob": 0.2818181818181818
    }, {
        "ID": 9631,
        "phrase": " while this may be a plausible assumption in database applications, it seems somewhat less reasonable in ai examples, particularly in cases involving reasoning about action",
        "prob": 0.26842105263157895
    }, {
        "ID": 9631,
        "phrase": " in particular, it shows that katsuno and mendelzon's notion of belief update (katsuno & mendelzon, 1991a) depends on several strong assumptions that may limit its applicability in artificial intelligence",
        "prob": 0.5954545454545455
    }, {
        "ID": 9678,
        "phrase": " pierrei np vinkeni np ,o 61i np yearsi np oldo ,o willi v p joini v p thei np boardi np aso ai np nonexecutivei np directori np nov",
        "prob": 0.444
    }, {
        "ID": 9845,
        "phrase": "\" ai complete is short for even harder than np complete",
        "prob": 0.41
    }]
}, {
    "topic_id": 38,
    "top_words": ["induction", "domain", "space", "relations", "use", "specific", "second", "follows", "multi", "point", "result", "hypothesis", "finally", "document", "properties"],
    "phrases": [{
        "ID": 141,
        "phrase": " finally, we want to comment on the input/output space x/y of the ai system",
        "prob": 0.41
    }, {
        "ID": 141,
        "phrase": " other discussed topics are formal definitions of intelligence order relations, the horizon problem and relations of the ai\u03be theory to other ai approaches",
        "prob": 0.19375
    }, {
        "ID": 682,
        "phrase": " in this paper, we introduce a new machine learning theory based on multi-channel parallel adaptation that shows great promise in learning the target rules from data by parallel global convergence",
        "prob": 0.284
    }, {
        "ID": 682,
        "phrase": " in this paper, we introduce a new machine learning theory based on multi-channel parallel adaptation that shows great promise in learning the target rules from data by parallel global convergence",
        "prob": 0.244
    }, {
        "ID": 1276,
        "phrase": " by definition h \u2294d (t) = a\u2208d h a (t) and from this and the induction hypothesis we can deduce t \u2208 h a0 (t) with t i \u2208 [ [ e i ] ] ai \u03b8 , for some a 0 , a 1 , ",
        "prob": 0.2625
    }, {
        "ID": 2333,
        "phrase": " finally, we want to comment on the input/output space x /y of the ai models",
        "prob": 0.4555555555555555
    }, {
        "ID": 2895,
        "phrase": "j p ai st, japan 4 * i nt el xeon 2 globus 18 [ linux clust er] brecca-2",
        "prob": 0.3416666666666666
    }, {
        "ID": 2941,
        "phrase": " a combined analytical and inductive ml method that overcomes the pitfalls associated with each separate approach (yet conserving their individual advantages) should be as follows: given a set of training examples d of some target function f (possibly containing errors), a domain theory b (possibly containing errors), and a space of candidate hypothesis h, determines which hypothesis h fits best the training examples and domain theory",
        "prob": 0.5931818181818183
    }, {
        "ID": 2942,
        "phrase": " a combined analytical and inductive ml method that overcomes the pitfalls associated with each separate approach (yet conserving their individual advantages) should be as follows: given a set of training examples d of some target function f (possibly containing errors), a domain theory b (possibly containing errors), and a space of candidate hypothesis h, determines which hypothesis h fits best the training examples and domain theory",
        "prob": 0.5931818181818183
    }, {
        "ID": 3406,
        "phrase": " b[[f \u2032 \u229b f \u2032\u2032 ]] b[[f \u2032 \u229b f \u2032\u2032 ]] = n i=1 (split 1 ai a \u2032 i a \u2032\u2032 i ) \u2227 m i=1 (split 2 fi f \u2032 i f \u2032\u2032 i ) \u2227 [[f \u2032 ]][ai := a \u2032 i ] n i=1 [fi := f \u2032 i ] m i=1 \u2227 [[f \u2032\u2032 ]][ai := a \u2032\u2032 i ] n i=1 [fi := f \u2032\u2032 i ] m i=1 split 1 a a \u2032 a \u2032\u2032 \u2261 \u2200x",
        "prob": 0.34444444444444444
    }, {
        "ID": 4472,
        "phrase": " partially motivated by some machine learning problems concerning document classification, bansal, blum, and chawla  [3]  also independently formulated and considered this problem",
        "prob": 0.4263157894736842
    }, {
        "ID": 4542,
        "phrase": " table2fields are the same with the fields in table \n table 3 3 representative systems employing multi-document summarization techniques input purpose output method evaluation [29] multi-document, user-oriented, extracts statistical (multi-document intrinsic english, text general purpose maximal marginal rele- vance -md-mrd), revision [30] multi-document, generic, general extracts statistical (support vector intrinsic \n table 4 4 summarization systems from medical documents input purpose output method evaluation [45] single-document indicative, user- sentences (ex- language processing extrinsic (also multi- oriented, domain- tracts) (named entity recogni- document), mu- specific tion, machine transla- tilingual, multime- tion), machine learning dia (text, audio, video) [49] single-document, indicative, user- sentences (ex- statistics (sentences intrinsic, multilingual, text oriented, domain- tracts), abstracts extraction), language extrinsic specific processing (semantic representation for ab- straction) [50] single-document, indicative, ge- sentences (ex- statistics (vector space monolingual, text neric, domain- tracts) model) specific [53] single-document, indicative, ge- abstracts language processing monolingual, text neric, domain- (information extraction) specific [56] multi-document, indicative- extracts, abstracts statistics (clustering extrinsic monolingual, text informative, ge- using similarity meas- neric, domain- ures), language process- specific ing [57] multi-document, informative, user- abstracts language processing monolingual, text oriented, domain- (information extraction, specific nlg) [59] single-document, generic, domain- video sequences image and video process- video (echocar- specific (extracts) ing diograms) [60] single-document, generic, domain- video sequences image and video process- video (clinical specific (extracts) ing operations, dia- logues, presenta- tions) [62, 63] multi-document, informative, user- abstracts agents simulating sum- monolingual, text oriented, domain- marization tasks, lan- specific guage processing \n\t\t\t muc (message understanding conferences) were evaluation conferences for information extraction systems; see http://www",
        "prob": 0.5847736625514403
    }, {
        "ID": 4659,
        "phrase": " stop : \u2113[1] = {}; tell(c) : \u2113[1] = {}; n i=1 ask(ci ) \u2192 ai : for j = 1 to n \u2113[j ] = la j ; \u2113[n + 1] = {ll }; now c then b1 else b2 : \u21131 = follows(lb 1 ); \u21132 = follows(lb 2 ); \u2113 = append(\u21131, \n proof first of all, we know that the agent a has a finite number of nested agents",
        "prob": 0.32105263157894737
    }, {
        "ID": 4680,
        "phrase": " second, extensive use of ml or scala-style pattern matching  [27]  is made to bind parts of complex, nested data structures to variables in a concise manner avoiding combinations of nested if-statements",
        "prob": 0.26296296296296295
    }, {
        "ID": 4731,
        "phrase": " more particularly in terms of the domain of knowledge which directly involves ontokads, dolce's commit-ment (corresponding to a consensus viewpoint within the ai and ke communities) can be summarized as follows  4  : \u2022 knowledge is the ability of an entity to perform an action, i",
        "prob": 0.27307692307692305
    }, {
        "ID": 5077,
        "phrase": "4 as well as the intermediate versions eval 1 and eval 3 in ml  [32] ",
        "prob": 0.51
    }, {
        "ID": 5078,
        "phrase": "4 as well as the intermediate versions eval 1 and eval 3 in ml  [32] ",
        "prob": 0.41
    }, {
        "ID": 5079,
        "phrase": "4 as well as the intermediate versions eval 1 and eval 3 in ml  [32] ",
        "prob": 0.51
    }, {
        "ID": 5080,
        "phrase": "4 as well as the intermediate versions eval 1 and eval 3 in ml  [32] ",
        "prob": 0.41
    }, {
        "ID": 6296,
        "phrase": " as a result of such grouping, the received symbols can be separated into k independent groups by simple linear processing or matched filtering, ml decoding of different groups can then be performed separately, and in parallel",
        "prob": 0.1782608695652174
    }, {
        "ID": 6421,
        "phrase": " associate with each time ti a point ai of a's interior and a point bi of b's interior that are collocated at time ti",
        "prob": 0.5461538461538461
    }, {
        "ID": 6421,
        "phrase": " we conclude that a and b have disjoint interiors at time ti, contradicting that ai and bi were defined to be interior points of a and b, respectively, that are collocated at time ti",
        "prob": 0.6066666666666667
    }, {
        "ID": 6422,
        "phrase": " associate with each time ti a point ai of a's interior and a point bi of b's interior that are collocated at time ti",
        "prob": 0.3923076923076923
    }, {
        "ID": 6422,
        "phrase": " we conclude that a and b have disjoint interiors at time ti, contradicting that ai and bi were defined to be interior points of a and b, respectively, that are collocated at time ti",
        "prob": 0.6066666666666667
    }, {
        "ID": 6640,
        "phrase": " research in this area can be classified according to the logical apparatus employed: -first-order theories of topological relations between regions, as studied in ai and philosophy [cla85, rcc92, ps98, ch01], spatial databases  [psv99, ss01]  and from an algebraic viewpoint in  [dwm01, ste00, dw05] ; -purely existential theories formulated as constraint satisfaction systems over jointly exhaustive and mutually disjoint sets of topological relations between regions [ege94, rn99, gpp95, ss01, rcc92, ben94, ch01] -modal logics of space with operators interpreted by the closure and interior operator of the underlying topological space and propositions interpreted as subsets of the topological space, see e",
        "prob": 0.755072463768116
    }, {
        "ID": 6641,
        "phrase": " research in this area can be classified according to the logical apparatus employed: -first-order theories of topological relations between regions, as studied in ai and philosophy [cla85, rcc92, ps98, ch01], spatial databases  [psv99, ss01]  and from an algebraic viewpoint in [dwm01, ste00, dw05]; -purely existential theories formulated as constraint satisfaction systems over jointly exhaustive and mutually disjoint sets of topological relations between regions [ege94, rn99, gpp95, ss01, rcc92, ben94, ch01] -modal logics of space with operators interpreted by the closure and interior operator of the underlying topological space and propositions interpreted as subsets of the topological space, see e",
        "prob": 0.7260869565217392
    }, {
        "ID": 7093,
        "phrase": "a unit cube in k dimensional space (or k-cube in short) is defined as the cartesian product r1 \u00d7 r2 \u00d7 \u2022 \u2022 \u2022 \u00d7 r k where ri(for 1 \u2264 i \u2264 k) is a closed interval of the form [ai, ai + 1] on the real line",
        "prob": 0.4263157894736842
    }, {
        "ID": 7094,
        "phrase": "a unit cube in k dimensional space (or k-cube in short) is defined as the cartesian product r1 \u00d7r2 \u00d7\u2022 \u2022 \u2022\u00d7r k where ri(for 1 \u2264 i \u2264 k) is a closed interval of the form [ai, ai + 1] on the real line",
        "prob": 0.3736842105263158
    }, {
        "ID": 7144,
        "phrase": " , h r,n are the values returned by r invocations (observations) of h (x n ), then the ml estimate isq (y, x n ) = |{n | h r,n = y}| /r, where |",
        "prob": 0.23846153846153847
    }, {
        "ID": 7408,
        "phrase": " the result follows from the commutation of \u2192 * ai and \u2704 * \u03b2 for all i \u2265 0",
        "prob": 0.4428571428571429
    }, {
        "ID": 7408,
        "phrase": " if s is an abstraction, the result follows from induction hypothesis (ih) and the context closure of \u2192 ai (cc)",
        "prob": 0.46923076923076923
    }, {
        "ID": 7408,
        "phrase": " \n second, use induction on the number of a i -steps to show that \u2701 \u03b2 \u2192 * ai \u2286 \u2192 * ai \u2704 \u03b2 ",
        "prob": 0.51
    }, {
        "ID": 7408,
        "phrase": " finally, to conclude that \u2701 * \u03b2 \u2192 * ai \u2286 \u2192 * ai \u2701 * \u03b2 , use an induction on the number of \u2704 \u03b2 -steps",
        "prob": 0.61
    }, {
        "ID": 7408,
        "phrase": " for all i \u2265 0, we use a nested parallelization of \u2192 ai ",
        "prob": 0.4428571428571429
    }, {
        "ID": 7408,
        "phrase": " these relations enjoy some nice properties: (1) \u2192 ai \u2286 \u2704 ai \u2286 \u2192 * ai , (2) s \u2704 ai t \u21d2 u{x \u2192 s} \u2704 ai u{x \u2192 t} and (3) [s \u2704 ai t & u \u2704 ai v] \u21d2 u{x \u2192 s} \u2704 ai v{x \u2192 t}",
        "prob": 0.6749999999999999
    }, {
        "ID": 7408,
        "phrase": " an induction on the number of \u2192 \u03b2\u222aai -steps leads us to prove that \u03b2nf (s) \u2704 ai \u03b2nf (t) whenever s \u2704 ai t and s has an arity-compliant \u03b2-normal form",
        "prob": 0.4764705882352941
    }, {
        "ID": 7408,
        "phrase": "l\u03c3 \u2032 \u2704 ai \u03b2nf (t)",
        "prob": 0.22000000000000003
    }, {
        "ID": 7408,
        "phrase": " we can then apply induction hypothesis on \u03c3 \u2704 ai \u03b8",
        "prob": 0.3
    }, {
        "ID": 7408,
        "phrase": " it follows that \u03b8 has an arity-compliant normal form \u03b8 \u2032 with \u03c3 \u2032 \u2704 ai \u03b8 \u2032 ",
        "prob": 0.34444444444444444
    }, {
        "ID": 7408,
        "phrase": " the relations \u2704 bi enjoy the same nice properties as the \u2704 ai 's",
        "prob": 0.5125
    }, {
        "ID": 7408,
        "phrase": " then, we consider the properties (1)-(3) of the walk relations \u2704 ai ",
        "prob": 0.3875
    }, {
        "ID": 7408,
        "phrase": " s \u2704 ai t \u21d2 u{x \u2192 s} \u2704 ai u{x \u2192 t}",
        "prob": 0.35000000000000003
    }, {
        "ID": 7408,
        "phrase": " [s \u2704 ai t & u \u2704 ai v] \u21d2 u{x \u2192 s} \u2704 ai v{x \u2192 t}",
        "prob": 0.35000000000000003
    }, {
        "ID": 7408,
        "phrase": " the first point is shown by induction on the definition of \u2704 ai ; the second by induction on u",
        "prob": 0.5545454545454546
    }, {
        "ID": 7408,
        "phrase": " for the last one, we also use an induction on \u2704 ai in u \u2704 ai v",
        "prob": 0.3
    }, {
        "ID": 7408,
        "phrase": " if u \u2704 ai v was obtained by parallel application or if u is an abstraction, the result follows from induction hypothesis",
        "prob": 0.5916666666666667
    }, {
        "ID": 7408,
        "phrase": " by induction hypothesis, we have \u03c3{x \u2192 s} \u2704 ai \u03b8{x \u2192 t}",
        "prob": 0.35000000000000003
    }, {
        "ID": 7409,
        "phrase": " the result follows from the commutation of \u2192 * ai and \u2704 * \u03b2 for all i \u2265 0",
        "prob": 0.4428571428571429
    }, {
        "ID": 7409,
        "phrase": " if s is an abstraction, the result follows from induction hypothesis (ih) and the context closure of \u2192 ai (cc)",
        "prob": 0.3923076923076923
    }, {
        "ID": 7409,
        "phrase": " \n second, use induction on the number of a i -steps to show that \u2701 \u03b2 \u2192 * ai \u2286 \u2192 * ai \u2704 \u03b2 ",
        "prob": 0.61
    }, {
        "ID": 7409,
        "phrase": " finally, to conclude that \u2701 * \u03b2 \u2192 * ai \u2286 \u2192 * ai \u2701 * \u03b2 , use an induction on the number of \u2704 \u03b2 -steps",
        "prob": 0.51
    }, {
        "ID": 7409,
        "phrase": " for all i \u2265 0, we use a nested parallelization of \u2192 ai ",
        "prob": 0.4428571428571429
    }, {
        "ID": 7409,
        "phrase": " these relations enjoy some nice properties: (1) \u2192 ai \u2286 \u2704 ai \u2286 \u2192 * ai , (2) s \u2704 ai t \u21d2 u{x \u2192 s} \u2704 ai u{x \u2192 t} and (3) [s \u2704 ai t & u \u2704 ai v] \u21d2 u{x \u2192 s} \u2704 ai v{x \u2192 t}",
        "prob": 0.6749999999999999
    }, {
        "ID": 7409,
        "phrase": " an induction on the number of \u2192 \u03b2\u222aai -steps leads us to prove that \u03b2nf (s) \u2704 ai \u03b2nf (t) whenever s \u2704 ai t and s has an arity-compliant \u03b2-normal form",
        "prob": 0.4764705882352941
    }, {
        "ID": 7409,
        "phrase": "l\u03c3 \u2032 \u2704 ai \u03b2nf (t)",
        "prob": 0.22000000000000003
    }, {
        "ID": 7409,
        "phrase": " we can then apply induction hypothesis on \u03c3 \u2704 ai \u03b8",
        "prob": 0.3
    }, {
        "ID": 7409,
        "phrase": " it follows that \u03b8 has an arity-compliant normal form \u03b8 \u2032 with \u03c3 \u2032 \u2704 ai \u03b8 \u2032 ",
        "prob": 0.4555555555555555
    }, {
        "ID": 7409,
        "phrase": " the relations \u2704 bi enjoy the same nice properties as the \u2704 ai 's",
        "prob": 0.5125
    }, {
        "ID": 7409,
        "phrase": " then, we consider the properties (1)-(3) of the walk relations \u2704 ai ",
        "prob": 0.3875
    }, {
        "ID": 7409,
        "phrase": " s \u2704 ai t \u21d2 u{x \u2192 s} \u2704 ai u{x \u2192 t}",
        "prob": 0.35000000000000003
    }, {
        "ID": 7409,
        "phrase": " [s \u2704 ai t & u \u2704 ai v] \u21d2 u{x \u2192 s} \u2704 ai v{x \u2192 t}",
        "prob": 0.35000000000000003
    }, {
        "ID": 7409,
        "phrase": " the first point is shown by induction on the definition of \u2704 ai ; the second by induction on u",
        "prob": 0.4636363636363636
    }, {
        "ID": 7409,
        "phrase": " for the last one, we also use an induction on \u2704 ai in u \u2704 ai v",
        "prob": 0.3
    }, {
        "ID": 7409,
        "phrase": " if u \u2704 ai v was obtained by parallel application or if u is an abstraction, the result follows from induction hypothesis",
        "prob": 0.5083333333333333
    }, {
        "ID": 7409,
        "phrase": " by induction hypothesis, we have \u03c3{x \u2192 s} \u2704 ai \u03b8{x \u2192 t}",
        "prob": 0.35000000000000003
    }, {
        "ID": 8555,
        "phrase": " finally, we want to comment on the input/output space x /y of the ai models",
        "prob": 0.4555555555555555
    }, {
        "ID": 8784,
        "phrase": " , m \u2212 1 ( 15 ) in our scheme, we use a non-sequential ml estimator for the above probabilities, that is easily obtained by computing the empirical frequency of zeros for each context \u03ba, where separate bit-counts are maintained for each data block with homogeneous local statistics as explained in the following",
        "prob": 0.24482758620689654
    }, {
        "ID": 8797,
        "phrase": " an are pairwise disjoint, but with each ai touching a0 for 1 i n",
        "prob": 0.3
    }, {
        "ID": 9005,
        "phrase": "\" using ac to quantify \"simple\" allowed solomonoff and others to develop their universal theories of induction and action, in the field of artificial intelligence",
        "prob": 0.1631578947368421
    }, {
        "ID": 9445,
        "phrase": " u n d er h eavy l oad, o ccasion a l l y i t m a y h a v e t o w ai t f or 330 ms ",
        "prob": 0.2625
    }, {
        "ID": 9445,
        "phrase": "t h e m ai n pr o b l e m f a c i n g f d d i u s e r sist h at ev enif on l y o n e o r t w os t a t io n s r e q u i r e i s o c h r o n ous s e rv ice, h ar dwa r eo na lls t a t io n s o n t h e r i n g w oul d h a v e t o b e u p gr adedtof d d i -i i ",
        "prob": 0.3
    }, {
        "ID": 9445,
        "phrase": " fddi t w is t e d -p ai r pm d i ss t i l lu n d er d ev elop m en t ",
        "prob": 0.41
    }, {
        "ID": 9447,
        "phrase": " the r e m ai nder of t h e p aper di s c u sse sth e v a l i d i t y o f t h e sea ssu m p t io n s",
        "prob": 0.34444444444444444
    }, {
        "ID": 9447,
        "phrase": " t herefore, rout e r -b asedcont r o lsa r e good f or enf o r c i n g f a i r n ess underoverl oad, w h i l e s o u rce-basedcontro lsa rere q u i r e d f o r su st ai nedoverl oad",
        "prob": 0.505
    }, {
        "ID": 9447,
        "phrase": " e x ampl e s o f r o u t e r -b asedcontro lsa rera n d om-d ro pp ol i cy [ 15] , f ai r queueing [ 16] , and b ackpre ssu re",
        "prob": 0.38125
    }, {
        "ID": 9447,
        "phrase": "the w al k-i ns c h em es do n ot requi r e m ai nt a in ance of anys t a t ea n d , t h erefore, are i de a l l y s u i t e d f o r h i g h l y d y n ami c e n v i r o n m ent s ",
        "prob": 0.6749999999999999
    }, {
        "ID": 9447,
        "phrase": " j ai n, \\ c ongest i on cont rol i n comput e rn etw orks: issu es and t re n d s,\"ie e e n etw ork m agazi ne, m ay 1990, pp",
        "prob": 0.75625
    }, {
        "ID": 9447,
        "phrase": " j ai n, \\ a d elay-b ased approach f or congest i on avoi dance inint e r c o n n ected h eterogeneous c omput e rn etw orks,\"c omput e rc omm uni c a t i o n s r evi e w , v ol ",
        "prob": 0.6565217391304348
    }, {
        "ID": 9448,
        "phrase": " vi ol at i ng t hi s r ul e , f o r e x a m pl e , by ove r al l oc at i ng t he s ynchr onous bandwi dt h, r e s ul t s i n unf ai r ne s s and s t ar vation",
        "prob": 0.5352941176470588
    }, {
        "ID": 9448,
        "phrase": " h i ghe r l oad l e ve l s c an be obt ai ne d e i t he r by r e duc i ng t he i nt e r b u r s tt i m e o r b y i nc r e as i ng t he numb e ro fs t a t i o n s ",
        "prob": 0.63125
    }, {
        "ID": 9448,
        "phrase": " si nc e t he s i z e of protocol he ade r s and t r ai l e r s i s xe d, l a r g e r f r a m e s c a u sele ssp ro to c o lo v e rh e a d ",
        "prob": 0.2583333333333333
    }, {
        "ID": 9449,
        "phrase": " thereceivi n g l ogi c of t he p h y sic a lla y er  the h al t sym bol i ndi cat es a f orced l ogi cal break i n act i vi t y o n t h e m edi u m , w h i l e m ai nt a in i n g a cb al ance onthe t r a n sm issio n m edi u m ",
        "prob": 0.7541666666666668
    }, {
        "ID": 9449,
        "phrase": " i nt h e r e m ai nder of thi s p aper, w e u seth e t e r m l a r ge fddi r i n g s t od enot e t hi s d efaul t m axi m u m congurat i on wi t h l a r g e s i z e f r a m es being c o n t in u ouslytran sm it t e do nt h e r i n g, unle sssp ecied ot herw i s e ",
        "prob": 0.6130434782608696
    }, {
        "ID": 9449,
        "phrase": "t h e f r a m e c a n t h enbe r e p re se n t e db y t h e p ol ynomi a l : f ( x ) = x i b i x i i ft h e r e m ai nder m od(f (x); g ( x ) )isz e r o ,t h e f r a m e i s s a i d t o h a v e t h e correct f c s 2 ",
        "prob": 0.46923076923076923
    }, {
        "ID": 9449,
        "phrase": " ai ndi cat or checki n g a t t h e d estinat i on shoul d , t h erefore, be o p t io n al rat her than a requi r e m ent ",
        "prob": 0.5083333333333333
    }, {
        "ID": 9449,
        "phrase": " j ai n, \\ m ore on erro rc h aract eri st i cs of fi b erd i s t r i b u t e dd at a i nt erf ace ( fddi ) , \" u n d er pre p arat i on",
        "prob": 0.33888888888888885
    }, {
        "ID": 9449,
        "phrase": " a s s h o w n i n t abl e 1 ,t h re eo f t h ese sym bo lsa rere se rv e d a s l i n es t a t es y m b ol s f or useo nth e m edi u mbetw eenfram e t r a n sm issio n s; v e s y m b ol s are use da sc o n t r o lc h aract ers f or f rame d e l i m i t i n g a n ds t a t u s i n d i c a t i o n ; 1 6 s y m b ol s are used f or dat a t ransm issio nw i t h i n f r a m e b oundari es; and t h e re m ai ni n g e i g h t s y m b ol s are not use d ",
        "prob": 0.6794117647058824
    }, {
        "ID": 9449,
        "phrase": " \n 5 ta x o n o m y , n o t a t i o n ,a n d a s s u m pt i o n s i nt h i s s e c t i o n w e d ene s o m e o f t h e t e r m s u s e d i n t h e r e m ai nder of thi s p aper",
        "prob": 0.3875
    }, {
        "ID": 9449,
        "phrase": "t h e r e m ai ni n g s y m b ol s are dat a sym bol s",
        "prob": 0.4428571428571429
    }, {
        "ID": 9449,
        "phrase": "f or unr e l i a b l e m edi a ,su ch as radi o l i n k s, one m a y e i t h er al l ocat e a l arger sha retoe rro rlo ss, o rd esignhi g h er level pr o t o c o lst ob e a b l e t o s u st ai n a h i g h e rlo ssra te ",
        "prob": 0.5499999999999999
    }, {
        "ID": 9449,
        "phrase": " 91%of t he d a tae rro rsre su l t i n i , v , o r h s y m b ol s, whi c h w i l l c a u seth e m a clayer t op re m at ure lyte rm i n at e t he f r a m e a n d r e p l a c e t h e r e m ai ni n g p art of t he f r a m e b y i d l e s y m b ol s",
        "prob": 0.63125
    }, {
        "ID": 9449,
        "phrase": " addi n g a m u l t i p l e o ft h e d i v i s o r ( f c s p ol ynomi a l ) t o t h e d i v i d end ( f r a m e p ol ynomi a l ) d oes not aect the r e m ai nder",
        "prob": 0.6230769230769231
    }, {
        "ID": 9449,
        "phrase": " 17e+12 w i t h o p t io n al ai ndi cat or handl i n g r u l e s : p ( u e d u e t o f al se ed) 2",
        "prob": 0.35000000000000003
    }, {
        "ID": 9449,
        "phrase": " [ 2 ]f i b er-di s t r i b u t e d d a t ai n t e r fa c e ( f d d i) t o ken ri n g m e d i aa c c ess cont r o l ( m a c ) , a m eri can nat i onal st a n d ard, a n s i x 3",
        "prob": 0.38125
    }, {
        "ID": 9449,
        "phrase": " j ai n, perf orm ance a n a l y sis of f d d i t o ken ri n g n etworks: e ect of p a rameters and g u i d el i nes f or s e t t in g t t r t , d e c t echni cal report , dec-t r -655, sept e m b er 1989, 14pp",
        "prob": 0.505
    }, {
        "ID": 9449,
        "phrase": " \n table 1 1 : 4 b /5b code code symbol assignm ent bi ts dat a sym bol s: 0 0000 1 0001 2 0010 3 0011 4 0100 5 0101 6 0110 7 0111 8 1000 9 1001 a 1010 b 1011 c 1100 d 1101 e 1110 f 1111 li n e s t a t es y m b ol s: q qui e t i i d l e h hal t cont rol sym bol s: j 1st of sequent i al sdp ai r k 2nd o f s e q u ent i al sdpai r t use dtote rm i n at e t he d at a st ream r denot i nglogical zero(reset) s denot i ng l ogi cal one ( s e t ) i n v a l i d c ode a ssig n m ent s : vh the c o d e p a t t e r n s m arkedvor v h vh sh al l not be t r a n sm it t e db ecause v t h eyvi o l a t e c o n secut iv e c o d e-bi t v zeros or dutyc y cle requi r e m ent s ",
        "prob": 0.6381818181818182
    }, {
        "ID": 9450,
        "phrase": " o t h e r w i s e ,t h et r a c t hat i s not even us - i ng t he conges t ed r es our ces i s unf ai r l y aectedb y the backpressure propagatingthroughout the network",
        "prob": 0.46923076923076923
    }, {
        "ID": 9450,
        "phrase": " t he f ai r queuei ng s cheme [ 7 ] , v a r i ous buercla sssch em es , and t he l eaky bucket algorithm  [ 31]  are exampl es of t hi s appr oach",
        "prob": 0.3
    }, {
        "ID": 9450,
        "phrase": " i ns o m e n e t w orks, there is a separate queue for eachsource and, thus , f ai r nes s amo n ga llso u rcesca be guaranteed ",
        "prob": 0.4066666666666666
    }, {
        "ID": 9826,
        "phrase": " \u2022 if f is an annotation function of arity n and ai 1 , ",
        "prob": 0.3
    }, {
        "ID": 9826,
        "phrase": " , ai n are annotation items, then f (ai 1 , ",
        "prob": 0.35000000000000003
    }, {
        "ID": 9826,
        "phrase": "2 (annotation [ai 1 , ai 2 ]) if ai 1 , ai 2 are annotation items, then [ai 1 , ai 2 ] is an annotation",
        "prob": 0.5125
    }]
}, {
    "topic_id": 39,
    "top_words": ["ml", "performance", "decoding", "decoder", "optimal", "iterative", "figure", "algorithm", "sub", "sum", "code", "db", "gap", "compared", "ms"],
    "phrases": [{
        "ID": 287,
        "phrase": " figure  3  shows a graphical representation of all ai constraints",
        "prob": 0.34444444444444444
    }, {
        "ID": 287,
        "phrase": " \n figure 3 : 3 figure 3: ai constraints",
        "prob": 0.3
    }, {
        "ID": 1553,
        "phrase": "   \n experiments and practical benefits in the first series of experiments with algorithms inf o greedy and inf o iter for decision making, machine learning benchmarks were used (table  3 )",
        "prob": 0.2318181818181818
    }, {
        "ID": 2333,
        "phrase": "y n , is therefore \u00b5 ai (y 1 x 1 ",
        "prob": 0.22000000000000003
    }, {
        "ID": 2333,
        "phrase": " posterialize this to a bound e ai kn\u03be \u00d7 \u2264 \u03be ai ( \u1e8f\u1e8b <k )/\u03be sp ( \u017c1:n ) on the number of errors in cycles k to n",
        "prob": 0.2818181818181818
    }, {
        "ID": 3512,
        "phrase": " it is important to mention that this bound is valid under ml decoding, and hence, it also holds for every sub-optimal decoding algorithm",
        "prob": 0.4764705882352941
    }, {
        "ID": 3512,
        "phrase": " the lower bound on the asymptotic degree of the parity-check nodes in (50) is valid under ml decoding (and hence, it is also valid under any sub-optimal decoding algorithm, such as mpi decoding)",
        "prob": 0.45909090909090905
    }, {
        "ID": 3513,
        "phrase": " it is important to mention that this bound is valid under ml decoding, and hence, it also holds for every sub-optimal decoding algorithm",
        "prob": 0.41764705882352937
    }, {
        "ID": 3630,
        "phrase": " we remark that all methods in this subsection are ml decoding and hence the error rates of these ml decoding methods are the same",
        "prob": 0.2733333333333333
    }, {
        "ID": 4208,
        "phrase": " it is also shown that, for certain cyclic codes, the modified iterative decoder can achieve ml performance",
        "prob": 0.2928571428571428
    }, {
        "ID": 4208,
        "phrase": " more likely codewords in relation to ml and iterative decoders realising an optimum decoder for any coded system is npcomplete  [10] ",
        "prob": 0.38125
    }, {
        "ID": 4208,
        "phrase": " the iterative decoder is a suboptimal decoder approximating ml performance",
        "prob": 0.6454545454545454
    }, {
        "ID": 4208,
        "phrase": " this is illustrated by the twodimensional representation of the ml decision criterion shown in fig",
        "prob": 0.3416666666666666
    }, {
        "ID": 4208,
        "phrase": " the percentage of mrl codewords output from the iterative decoder gives us a performance indication of how close the iterative decoder is from the ml decoder for the same code",
        "prob": 0.40499999999999997
    }, {
        "ID": 4208,
        "phrase": " the mrl-fer provides the lower-bound on the ml performance of a code in comparison to the maximum-likelihood-asymptote (mla) which provides the upper-bound",
        "prob": 0.45499999999999996
    }, {
        "ID": 4208,
        "phrase": " it is shown that the modified bp decoder, provided enough substitutions and trials are used, can achieve the ml performance as indicated by the mrl-fer and the fer of the modified bp decoder that produce the same curve",
        "prob": 0.40399999999999997
    }, {
        "ID": 4208,
        "phrase": " table  ii  shows how close the performance of the modified bp decoder is to the ml decoder",
        "prob": 0.3923076923076923
    }, {
        "ID": 4208,
        "phrase": " ml performance is achieved with 8 substitutions and 300 trials",
        "prob": 0.4555555555555555
    }, {
        "ID": 4208,
        "phrase": " for the (63, 37), (93, 47) and (105, 53) cyclic codes, the modified bp decoder has been shown to achieve ml performance",
        "prob": 0.3153846153846154
    }, {
        "ID": 4456,
        "phrase": " then the optimal min-sum decoder (or, ml decoder) estimates the codeword c * = arg min c\u2208c (c 1 w 1 + c 2 w 2 + ",
        "prob": 0.43571428571428567
    }, {
        "ID": 4456,
        "phrase": " with a maximum of 10 4 decoding iterations, the performance obtained by the iterative decoder on the single cycle constraint graph of figure  7  is the same as the optimal ml performance (the two curves are one on top of the other), thereby, confirming that the graph has no nc-pseudocodewords",
        "prob": 0.7814814814814816
    }, {
        "ID": 4456,
        "phrase": ") to de-emphasize the effect of non-codeword pseudocodewords, arising out of the computation tree of figure  8 , on the iterative decoder, the messages were suitably scaled and this pushed the performance to the optimal ml performance! this example illustrates that the fundamental polytope of  [5]  does not capture the entire set of min-sum-iterativedecoding-pseudocodewords of a tanner graph",
        "prob": 0.6513513513513514
    }, {
        "ID": 4456,
        "phrase": " (we note that an optimal ml decoder would yield a performance closest to that of the iterative decoder on representation b",
        "prob": 0.6066666666666667
    }, {
        "ID": 4456,
        "phrase": " it is evident that the min-sum and the sum-product decoders are inferior in performance in comparison to the optimal ml decoder",
        "prob": 0.75625
    }, {
        "ID": 4456,
        "phrase": "  min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.6454545454545454
    }, {
        "ID": 4456,
        "phrase": " the performance difference between the min-sum (respectively, the sum-product) decoder and the optimal ml decoder is more pronounced for odd m",
        "prob": 0.711764705882353
    }, {
        "ID": 4456,
        "phrase": ") since the graph has low weight bad pseudocodewords, in comparison to the minimum distance, the performance of the min-sum decoder in the high snr regime is clearly inferior to that of the ml decoder",
        "prob": 0.6708333333333334
    }, {
        "ID": 4456,
        "phrase": " performance of example 1 -ldpc code: min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.74
    }, {
        "ID": 4456,
        "phrase": " performance of example 2 -ldpc code: min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.74
    }, {
        "ID": 4456,
        "phrase": " performance of example 3 -ldpc code for m = 10: min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.74
    }, {
        "ID": 4457,
        "phrase": " then the optimal min-sum decoder (or, ml decoder) estimates the codeword c * = arg min c\u2208c (c 1 w 1 + c 2 w 2 + ",
        "prob": 0.36428571428571427
    }, {
        "ID": 4457,
        "phrase": " with a maximum of 10 4 decoding iterations, the performance obtained by the iterative decoder on the single cycle constraint graph of figure  9  is the same as the optimal ml performance (the two curves are one on top of the other), thereby, confirming that the graph has no nc-pseudocodewords",
        "prob": 0.7444444444444445
    }, {
        "ID": 4457,
        "phrase": ") to de-emphasize the effect of non-codeword pseudocodewords, arising out of the computation tree of figure  10 , on the iterative decoder, the message log-likelihood ratios were suitably scaled, as suggested in  [6] , and this pushed the performance to the optimal ml performance",
        "prob": 0.5392857142857143
    }, {
        "ID": 4457,
        "phrase": " if this graph does not have any bad nc-pseudocodewords (both, lift-realizable ones and those arising on the computation tree) then the performance obtained with iterative decoding is the same as the optimal ml performance",
        "prob": 0.8142857142857144
    }, {
        "ID": 4457,
        "phrase": " (we note that an optimal ml decoder would yield a performance closest to that of the iterative decoder on representation b",
        "prob": 0.6066666666666667
    }, {
        "ID": 4457,
        "phrase": " here again, representation b, having the best pseudocodeword-weight distribution among the three representations, yields the best performance with min-sum iterative decoding and is closest in performance to that of the ml decoder",
        "prob": 0.43913043478260866
    }, {
        "ID": 4457,
        "phrase": " it is evident that the min-sum and the sum-product decoders are inferior in performance in comparison to the optimal ml decoder",
        "prob": 0.69375
    }, {
        "ID": 4457,
        "phrase": " when  min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.6454545454545454
    }, {
        "ID": 4457,
        "phrase": " the performance difference between the min-sum (respectively, the sum-product) decoder and the optimal ml decoder is more pronounced for odd m",
        "prob": 0.7705882352941176
    }, {
        "ID": 4457,
        "phrase": ") since the graph has low weight bad pseudocodewords, in comparison to the minimum distance, the performance of the min-sum decoder in the high snr regime is clearly inferior to that of the ml decoder",
        "prob": 0.5875
    }, {
        "ID": 4457,
        "phrase": " performance of example 1 -ldpc code: min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.6733333333333333
    }, {
        "ID": 4457,
        "phrase": " performance of example 2 -ldpc code: min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.74
    }, {
        "ID": 4457,
        "phrase": " performance of example 3 -ldpc code for m = 10: min-sum, sum-product, ml decoding over the biawgnc",
        "prob": 0.6733333333333333
    }, {
        "ID": 4458,
        "phrase": " however, it is still sub-optimal compared to the ml decoder",
        "prob": 0.4636363636363636
    }, {
        "ID": 4458,
        "phrase": " thus, its estimate may not not always correspond to a single codeword (as the ml decoder), or a single pseudocodeword (as the ms decoder)",
        "prob": 0.24117647058823527
    }, {
        "ID": 4458,
        "phrase": " the ml performance of the code is also shown as reference",
        "prob": 0.5666666666666667
    }, {
        "ID": 4458,
        "phrase": " with a maximum of 10 4 decoding iterations, the performance obtained by the iterative decoder on the single cycle constraint graph of figure  4  is the same as the optimal ml performance (the two curves are one on top of the other), thereby confirming that the graph has no nc-pseudocodewords",
        "prob": 0.7074074074074075
    }, {
        "ID": 4458,
        "phrase": "  figure  9  shows the performance of this code on a biawgnc with ms, sp, and ml decoding",
        "prob": 0.6230769230769231
    }, {
        "ID": 4458,
        "phrase": " figures 13 and 14 show the performance of the code for odd and even m, respectively, on a biawgnc with ms, sp, and ml decoding",
        "prob": 0.50625
    }, {
        "ID": 4458,
        "phrase": " the performance difference between the ms (respectively, the sp) decoder and the optimal ml decoder is more pronounced for odd m",
        "prob": 0.6733333333333333
    }, {
        "ID": 4458,
        "phrase": ") since the graph has low weight bad pseudocodewords, in comparison to the minimum distance, the performance of the ms decoder in the high snr regime is clearly inferior to that of the ml decoder",
        "prob": 0.6130434782608696
    }, {
        "ID": 4458,
        "phrase": " if this graph does not have any bad nc-pseudocodewords (both lift-realizable ones and those arising on the computation tree) then the performance obtained with iterative decoding is the same as the optimal ml performance",
        "prob": 0.8142857142857144
    }, {
        "ID": 4458,
        "phrase": " (we note that an optimal ml decoder would yield a performance closest to that of the iterative decoder on representation b",
        "prob": 0.6733333333333333
    }, {
        "ID": 4458,
        "phrase": "   the performance of ms decoding using representation b was identical to the performance of the ml decoder and the ms decoder always converged to the ml codeword with representation b",
        "prob": 0.505
    }, {
        "ID": 4458,
        "phrase": "1 -ldpc code: ms, sp, ml decoding over the biawgnc",
        "prob": 0.6454545454545454
    }, {
        "ID": 4458,
        "phrase": " 3 : 1143 figure 11  shows the performance of this code on a biawgnc with ms, sp, and ml decoding",
        "prob": 0.7
    }, {
        "ID": 4458,
        "phrase": " it is evident in the figure that the ms and the sp decoders are inferior in performance in comparison to the optimal ml decoder",
        "prob": 0.74
    }, {
        "ID": 4458,
        "phrase": "2 -ldpc code: ms, sp, ml decoding over the biawgnc",
        "prob": 0.5545454545454546
    }, {
        "ID": 4458,
        "phrase": " the figure shows that all four-bit or less error patterns were corrected by the ms and the ml \n fig",
        "prob": 0.33999999999999997
    }, {
        "ID": 4458,
        "phrase": "3 -ldpc code for m = 11: ms, sp, ml decoding over the biawgnc",
        "prob": 0.6454545454545454
    }, {
        "ID": 4458,
        "phrase": "3 -ldpc code for m = 10: ms, sp, ml decoding over the biawgnc",
        "prob": 0.6454545454545454
    }, {
        "ID": 4458,
        "phrase": " of output errors performance of example 3 with min\u2212sum decoding and ml decoding ex 3, n=12,m=11, ms dec",
        "prob": 0.38125
    }, {
        "ID": 4458,
        "phrase": "3-ldpc code for m = 11, m = 12 with ms and ml decoding over the bsc",
        "prob": 0.41
    }, {
        "ID": 4459,
        "phrase": " however, it is still sub-optimal compared to the ml decoder",
        "prob": 0.3727272727272727
    }, {
        "ID": 4459,
        "phrase": " thus, its estimate may not not always correspond to a single codeword (as the ml decoder), or a single pseudocodeword (as the ms decoder)",
        "prob": 0.3
    }, {
        "ID": 4459,
        "phrase": " the ml performance of the code is also shown as reference",
        "prob": 0.34444444444444444
    }, {
        "ID": 4459,
        "phrase": " with a maximum of 10 4 decoding iterations, the performance obtained by the iterative decoder on the single cycle constraint graph of figure  4  is the same as the optimal ml performance (the two curves are one on top of the other), thereby confirming that the graph has no nc-pseudocodewords",
        "prob": 0.7444444444444445
    }, {
        "ID": 4459,
        "phrase": "9) separately, as shown below: figure  9  shows the performance of this code on a biawgnc with ms, sp, and ml decoding",
        "prob": 0.6066666666666667
    }, {
        "ID": 4459,
        "phrase": " the performance difference between the ms (respectively, the sp) decoder and the optimal ml decoder is more pronounced for odd m",
        "prob": 0.74
    }, {
        "ID": 4459,
        "phrase": ") since the graph has low weight bad pseudocodewords, in comparison to the minimum distance, the performance of the ms decoder in the high snr regime is clearly inferior to that of the ml decoder",
        "prob": 0.5695652173913043
    }, {
        "ID": 4459,
        "phrase": " if this graph does not have any bad nc-pseudocodewords (both lift-realizable ones and those arising on the computation tree) then the performance obtained with iterative decoding is the same as the optimal ml performance",
        "prob": 0.7666666666666667
    }, {
        "ID": 4459,
        "phrase": " (we note that an optimal ml decoder would yield a performance closest to that of the iterative decoder on representation b",
        "prob": 0.6066666666666667
    }, {
        "ID": 4459,
        "phrase": "  the performance of ms decoding using representation b was identical to the performance of the ml decoder and the ms decoder always converged to the ml codeword with representation b",
        "prob": 0.40499999999999997
    }, {
        "ID": 4459,
        "phrase": "1 -ldpc code: ms, sp, ml decoding over the biawgnc",
        "prob": 0.6454545454545454
    }, {
        "ID": 4459,
        "phrase": " \n figure 11 11 figure 11  shows the performance of this code on a biawgnc with ms, sp, and ml decoding",
        "prob": 0.7214285714285714
    }, {
        "ID": 4459,
        "phrase": " it is evident in the figure that the ms and the sp decoders are inferior in performance in comparison to the optimal ml decoder",
        "prob": 0.74
    }, {
        "ID": 4459,
        "phrase": "2 -ldpc code: ms, sp, ml decoding over the biawgnc",
        "prob": 0.5545454545454546
    }, {
        "ID": 4459,
        "phrase": " the figure shows that all four-bit or less error patterns were corrected by the ms and the ml decoders",
        "prob": 0.2733333333333333
    }, {
        "ID": 4459,
        "phrase": " the figure also shows that ms decoding is closer to ml decoding for the m = 10 code than for the m = 11 code",
        "prob": 0.6230769230769231
    }, {
        "ID": 4459,
        "phrase": "3 -ldpc code for m = 11: ms, sp, ml decoding over the biawgnc",
        "prob": 0.6454545454545454
    }, {
        "ID": 4459,
        "phrase": "3 -ldpc code for m = 10: ms, sp, ml decoding over the biawgnc",
        "prob": 0.5545454545454546
    }, {
        "ID": 4459,
        "phrase": " of output errors performance of example 3 with min\u2212sum decoding and ml decoding ex 3, n=12,m=11, ms dec",
        "prob": 0.38125
    }, {
        "ID": 4695,
        "phrase": "  2 , we consider the case when the decoder is the soft-decision ml decoder",
        "prob": 0.3727272727272727
    }, {
        "ID": 4698,
        "phrase": " further, it assumes a sub-optimal (iterative) decoding algorithm, where the statements in  [1, 13]  and this paper are valid even under optimal ml decoding",
        "prob": 0.711764705882353
    }, {
        "ID": 4698,
        "phrase": " comparing the new upper bounds on the achievable rates with thresholds provided by a density-evolution analysis gives rigorous bounds on the inherent loss in performance due to the sub-optimality of iterative message-passing decoding (as compared to soft-decision ml decoding)",
        "prob": 0.4575757575757576
    }, {
        "ID": 4698,
        "phrase": " the bound refers to soft-decision ml decoding, and it is therefore valid for any suboptimal decoding algorithm",
        "prob": 0.74
    }, {
        "ID": 4698,
        "phrase": " the bound refers of soft-decision ml decoding, and it is therefore valid for any sub-optimal decoding algorithm",
        "prob": 0.75625
    }, {
        "ID": 4698,
        "phrase": " the bound refers of optimal ml decoding, and is therefore valid for any sub-optimal decoding algorithm",
        "prob": 0.5399999999999999
    }, {
        "ID": 4698,
        "phrase": " it is well known that cyclefree codes are not good in terms of performance, even under optimal ml decoding  [15] ; hence, good error-correcting codes (e",
        "prob": 0.255
    }, {
        "ID": 4698,
        "phrase": " the rather small gap between the de thresholds and the un-quantized lower bounds on the thresholds under ml decoding also indicate that for the degree distributions which are provided by the ldpc optimizer  [16] , the asymptotic degradation in performance due to the sub-optimality of belief propagation is marginal (it is observed from tables  2 and 3  that for several ldpc ensembles, this degradation in the asymptotic performance is at most in the order of hundredthes of a decibel)",
        "prob": 0.36829268292682926
    }, {
        "ID": 4698,
        "phrase": " the bounds hold under optimal ml decoding, and hence, they hold in particular under any sub-optimal decoding algorithm",
        "prob": 0.50625
    }, {
        "ID": 4698,
        "phrase": " this degradation in the asymptotic performance is due to the sub-optimality of iterative message-passing decoding (as compared to optimal ml decoding)",
        "prob": 0.7833333333333333
    }, {
        "ID": 4698,
        "phrase": " the upper bounds on the achievable rates enable to assess the inherent loss in performance of various iterative decoding algorithms as compared to optimal ml decoding",
        "prob": 0.4809523809523809
    }, {
        "ID": 4727,
        "phrase": " further, it assumes a sub-optimal (iterative) decoding algorithm, where the statements in  [1, 11]  and this paper are valid even under optimal ml decoding",
        "prob": 0.6529411764705882
    }, {
        "ID": 4727,
        "phrase": " comparing the new upper bounds on the achievable rates with thresholds provided by a density-evolution analysis gives rigorous bounds on the inherent loss in performance due to the sub-optimality of iterative message-passing decoding (as compared to soft-decision ml decoding)",
        "prob": 0.5181818181818182
    }, {
        "ID": 4727,
        "phrase": " the bounds hold under optimal ml decoding, and hence, they hold in particular under any sub-optimal decoding algorithm",
        "prob": 0.56875
    }, {
        "ID": 4727,
        "phrase": " this degradation in the asymptotic performance is due to the sub-optimality of iterative message-passing decoding (as compared to optimal ml decoding)",
        "prob": 0.6722222222222222
    }, {
        "ID": 4727,
        "phrase": " further, it assumes a sub-optimal (iterative) decoding algorithm, where the statements in  [1, 11]  and this paper are valid even under optimal ml decoding",
        "prob": 0.6529411764705882
    }, {
        "ID": 4727,
        "phrase": " comparing the new upper bounds on the achievable rates with thresholds provided by a density-evolution analysis gives rigorous bounds on the inherent loss in performance due to the sub-optimality of iterative message-passing decoding (as compared to soft-decision ml decoding)",
        "prob": 0.4878787878787879
    }, {
        "ID": 4727,
        "phrase": " the bounds hold under optimal ml decoding, and hence, they hold in particular under any sub-optimal decoding algorithm",
        "prob": 0.50625
    }, {
        "ID": 4727,
        "phrase": " this degradation in the asymptotic performance is due to the sub-optimality of iterative message-passing decoding (as compared to optimal ml decoding)",
        "prob": 0.7833333333333333
    }, {
        "ID": 4727,
        "phrase": " the upper bounds on the achievable rates enable to assess the inherent loss in performance of various iterative decoding algorithms as compared to optimal ml decoding",
        "prob": 0.6238095238095238
    }, {
        "ID": 4728,
        "phrase": " further, it assumes a sub-optimal (iterative) decoding algorithm, where the statements in  [1, 12]  and this paper are valid even under optimal ml decoding",
        "prob": 0.711764705882353
    }, {
        "ID": 4728,
        "phrase": " the bounds hold under optimal ml decoding, and hence, they hold in particular under any sub-optimal decoding algorithm",
        "prob": 0.44375
    }, {
        "ID": 4728,
        "phrase": " this degradation in the asymptotic performance is due to the sub-optimality of mpi decoding (as compared to optimal ml decoding)",
        "prob": 0.56875
    }, {
        "ID": 4786,
        "phrase": " the complexity of such decoders were shown, via simulation and numerical analysis, to be significantly smaller than the naive ml decoder in many scenarios of practical interest (e",
        "prob": 0.355
    }, {
        "ID": 4786,
        "phrase": " it was shown in  [15]  that the performance of this decoder is within a fraction of a db from the ml decoder in systems with small dimensions",
        "prob": 0.5399999999999999
    }, {
        "ID": 4786,
        "phrase": " \n theorem 3 the stack algorithm and the fano decoder with any finite bias b, achieve the same diversity as the ml decoder when applied to a v-blast configuration",
        "prob": 0.2833333333333333
    }, {
        "ID": 4786,
        "phrase": " moreover, the performance of the the fano decoder is seen to be only a fraction of a db away from that of the se decoder, which achieves ml performance",
        "prob": 0.50625
    }, {
        "ID": 4786,
        "phrase": " it is shown that the performance of the proposed decoder is within a fraction of a db from that of ml decoder, whereas the algorithm in  [49, 46]  exhibits a loss of more than 3 db",
        "prob": 0.5611111111111111
    }, {
        "ID": 4786,
        "phrase": "1 db away from the ml decoder for both cases",
        "prob": 0.4555555555555555
    }, {
        "ID": 4786,
        "phrase": " in both case, the performance of the mmse-dfe lattice decoder is seen to be essentially same as the ml performance",
        "prob": 0.36428571428571427
    }, {
        "ID": 4786,
        "phrase": " the second term also has the dependence \u03c1 \u2212(n/2) , and hence the fano decoder achieves the same diversity as that of the ml decoder for this system",
        "prob": 0.2733333333333333
    }, {
        "ID": 4786,
        "phrase": " \n figure 2 : 2 figure 2: the effect of left preprocessing on the lattice and the right preprocessing on the information set \n figure 3 : 3 figure 3: complexity and performance of se enumeration and fano decoder for a 20\u00d720 16\u2212qam v-blast system \n figure 4 : 4 figure 4: complexity and performance of fano decoder with zf-dfe and mmse-dfe based preprocessing for a 30 \u00d7 30 4\u2212qam v-blast system \n figure 5 :figure 6 : 56 figure 5: complexity and performance of fano decoder with different bias, for a 20 \u00d7 20 4\u2212qam v-blast system with zf-dfe preprocessing \n figure 7 : 7 figure 7: performance of tast codes under mmse-dfe lattice decoding and ml detection with m = 3 and n = 1",
        "prob": 0.41692307692307695
    }, {
        "ID": 4855,
        "phrase": " consequently, analytical performance bounds on the performance of rs codes under ml decoding are of interest as benchmarks for suboptimal decoders",
        "prob": 0.5941176470588235
    }, {
        "ID": 4855,
        "phrase": " therefore, it is reasonable to evaluate the performance of the grse, which gives some idea about the performance of a specific rs code under ml decoding",
        "prob": 0.41764705882352937
    }, {
        "ID": 4855,
        "phrase": " here, we use standard bounding techniques to study the performance of the grse under ml decoding",
        "prob": 0.3153846153846154
    }, {
        "ID": 4855,
        "phrase": " it can be seen that the ml upper bound of the grse is tight in the high snr region, which is 0",
        "prob": 0.23846153846153847
    }, {
        "ID": 4855,
        "phrase": "5db away from the simulation-based ml lower bound of a specific rs code (expanded using a fixed basis) at an fer = 10 \u22124 ",
        "prob": 0.32105263157894737
    }, {
        "ID": 4855,
        "phrase": " besides, the hdd performance is 2-3db away from the optimal performance under ml decoding, which is consistent with the commonly believed potential performance gain via using soft decoding over hdd",
        "prob": 0.6708333333333334
    }, {
        "ID": 4855,
        "phrase": " hence, we will use the grse upper bound under ml decoding as a performance benchmark for long rs codes",
        "prob": 0.31875
    }, {
        "ID": 4855,
        "phrase": " note that for these lengths, all known decoders up to now are still away from the performance under ml decoding, making it difficult to obtain good simulation based lower bounds",
        "prob": 0.3857142857142857
    }, {
        "ID": 4855,
        "phrase": " we can see that, the hdd is asymptotically 3db worse than the performance under ml decoding (the largest gap is about 4db, which appears at around an f er = 10 \u221220 )",
        "prob": 0.5941176470588235
    }, {
        "ID": 4855,
        "phrase": " for practical snrs, it has approximately 2db loss compared with the performance under ml decoding",
        "prob": 0.7
    }, {
        "ID": 4855,
        "phrase": " for this code, the performance gap of symbol-level bounded distance decoding from the ml decoder is even larger, e",
        "prob": 0.38125
    }, {
        "ID": 4855,
        "phrase": " figure  3(b)  shows the performance in the more practical snr region, where we can see that the performance under ml decoding of the grse reaches an fer = 10 \u22124 at an e b /n 0 = 1",
        "prob": 0.711764705882353
    }, {
        "ID": 4855,
        "phrase": " however, the above example shows that even the \"genie decoder\", which decodes up to t = d min \u2212 1, performs far away from ml decoding",
        "prob": 0.38125
    }, {
        "ID": 4855,
        "phrase": " the erased bits), ml decoding performance can be achieved  [5] ",
        "prob": 0.51
    }, {
        "ID": 4855,
        "phrase": " it can be shown that the sum of the lower bound on the ml decoder performance and the actual simulation performance is always an upper bound on the achievable fer and, hence, from the results, it can be seen that the contribution from such errors is not very significant",
        "prob": 0.324
    }, {
        "ID": 4855,
        "phrase": " using the grouping method, the proposed adp  (20, 3)  & hdd can approach the ml lower bound within 0",
        "prob": 0.33999999999999997
    }, {
        "ID": 4855,
        "phrase": "75 db within ml lower bound at an fer = 10 \u22124 ",
        "prob": 0.61
    }, {
        "ID": 4855,
        "phrase": " though we are unable to get the ml lower bound via simulation (it is trivially zero), compared with the ml upper bound in figure  2 , adp is only several tenths of db away from ml   \n b",
        "prob": 0.484
    }, {
        "ID": 4855,
        "phrase": " we first investigate the performance of grse under ml decoding and show the huge potential performance gain over hdd",
        "prob": 0.38125
    }, {
        "ID": 4856,
        "phrase": " the erased bits), ml decoding performance can be achieved  [24]  in one iteration",
        "prob": 0.3727272727272727
    }, {
        "ID": 4856,
        "phrase": ", when the ml decoder would have made errors, the result of the actual decoder may be different from the genie aided decoder and, hence, the genie aided decoder may be optimistic",
        "prob": 0.39565217391304347
    }, {
        "ID": 4856,
        "phrase": " performance of reed solomon codes under maximum likelihood decoding we first study the performance of rs codes under ml decoding",
        "prob": 0.33888888888888885
    }, {
        "ID": 4856,
        "phrase": " we can see that, the hdd is asymptotically 3db worse than the performance under ml decoding (the largest gap is about 4db, which appears at around an fer = 10 \u221220 )",
        "prob": 0.6166666666666667
    }, {
        "ID": 4856,
        "phrase": " for practical snr's, there is a loss of approximately 2db compared to the performance of the ml decoder",
        "prob": 0.6230769230769231
    }, {
        "ID": 4856,
        "phrase": " we can see that the performance under ml decoding of the rs ensemble reaches an fer = 10 \u22124 at an e b /n 0 = 1",
        "prob": 0.5083333333333333
    }, {
        "ID": 4856,
        "phrase": " the ml performance of rs ensemble is only 0",
        "prob": 0.2625
    }, {
        "ID": 4856,
        "phrase": " note that for this code, all known decoders up to now are still away from the performance under ml decoding, making it difficult to obtain good simulation based lower bounds to estimate the ml performance of the rs code",
        "prob": 0.5038461538461538
    }, {
        "ID": 4856,
        "phrase": " the hypothetical decoder, which decodes up to t = d min \u2212 1, still performs far away from ml decoding, which suggests that an alternative design principle should be adopted for rs soft decision decoding",
        "prob": 0.41363636363636364
    }, {
        "ID": 4856,
        "phrase": " besides, the analytical performance bounds of rs codes under ml decoding are of interest as benchmarks for suboptimal decoders as will be discussed in the following subsections",
        "prob": 0.6368421052631579
    }, {
        "ID": 4856,
        "phrase": " using the grouping method, the proposed adp  (20, 3)  & hdd can approach the ml lower bound within 0",
        "prob": 0.2733333333333333
    }, {
        "ID": 4856,
        "phrase": "5db away from the ml lower bound at an fer = 10 \u22124 and these two bounds converge in the high snr region",
        "prob": 0.63125
    }, {
        "ID": 4856,
        "phrase": " compared with the ml lower bound obtained by using a near ml decoding algorithm recently proposed in  [35] , the adaptive algorithm is still 0",
        "prob": 0.2157894736842105
    }, {
        "ID": 4856,
        "phrase": "6db away from ml lower bound at an fer = 10 \u22123 ",
        "prob": 0.61
    }, {
        "ID": 4951,
        "phrase": " in the limit of very large snr, s \u2192 \u221e, ml and map become indistinguishable and the bp algorithm reduces to the min-sum algorithm: \u03b7 (n+1) i\u03b1 = h i + \u03b2\u220bi \u2211 \u03b2 =\u03b1 j\u2208\u03b2 \u220f j =i sign \u03b7 (n) j\u03b2 j\u2208\u03b2 min j =i \u03b7 (n) j\u03b2 , (1) where the message field \u03b7 (n) i\u03b1 is defined on the edge that connects bit i and check \u03b1 at the n-th step of the iterative procedure and \u03b7 (0) i\u03b1 \u2261 0",
        "prob": 0.3137931034482758
    }, {
        "ID": 4952,
        "phrase": " in the limit of very large snr, s \u2192 \u221e, ml and map become indistinguishable and the bp algorithm reduces to the min-sum algorithm: \u03b7 (n+1) i\u03b1 = h i + \u03b2\u220bi \u2211 \u03b2 =\u03b1 j\u2208\u03b2 \u220f j =i sign \u03b7 (n) j\u03b2 j\u2208\u03b2 min j =i \u03b7 (n) j\u03b2 , (1) where the message field \u03b7 (n) i\u03b1 is defined on the edge that connects bit i and check \u03b1 at the n-th step of the iterative procedure and \u03b7 (0) i\u03b1 \u2261 0",
        "prob": 0.41724137931034483
    }, {
        "ID": 5031,
        "phrase": " the root cause of the difference between these suboptimal decoders and ml decoding is the occurrence of so called pseudo-codewords; from the perspective of an lp or bp decoder, the pseudo-codewords act as attractive solutions to the decoding problem, even though they are not actual codewords in the ldpc code under consideration",
        "prob": 0.33636363636363636
    }, {
        "ID": 5037,
        "phrase": " minimal codewords although ml decoding is often impractical, knowing bounds on the block error rate of an ml decoder can help in assessing the performance of sub-optimal but practical decoding algorithms",
        "prob": 0.4269230769230769
    }, {
        "ID": 5037,
        "phrase": " we note that by applying simple performance bounding techniques it can be shown that the larger the gap is, the closer is the lp decoding performance (and potentially also the iterative decoding performance  [1] ) to the ml decoding performance as the snr goes to infinity",
        "prob": 0.44814814814814813
    }, {
        "ID": 5046,
        "phrase": " moreover, if a maximum-likelihood (ml) decoder is used to decode rm q (1, m), then the supercode decoder performs ml decoding too  [3] ,  [1] ",
        "prob": 0.3
    }, {
        "ID": 5046,
        "phrase": " in this reference it was shown that an ml decoder for rm 2 (r, m) can be obtained when the list length is equal to 2",
        "prob": 0.3153846153846153
    }, {
        "ID": 5129,
        "phrase": " this bound refers to ml decoding (and hence, to any sub-optimal decoding algorithm)",
        "prob": 0.7
    }, {
        "ID": 5129,
        "phrase": " the fractional gap to capacity (see the rightmost column) measures the ratio of the gap to capacity under optimal ml decoding and the achievable gap to capacity under (suboptimal) iterative message-passing decoding",
        "prob": 0.8440000000000001
    }, {
        "ID": 5129,
        "phrase": " on one hand, tables 1-3 provide a quantitative assessment of the loss in the asymptotic performance which is attributed to the sub-optimality of iterative decoding (as compared to optimal ml decoding), and on the other hand, they provide an assessment of the inherent loss in performance which is attributed to the structure of the ensembles, even if optimal ml decoding could be applied to decode these codes",
        "prob": 0.6342105263157896
    }, {
        "ID": 5129,
        "phrase": "6 db; however, under ml decoding, the gap to capacity is always greater than  1  3 of the corresponding gap to capacity under this iterative decoding algorithm; therefore, the results in table  1  regarding the thresholds under ml decoding further emphasize the efficiency of the sum-product decoding algorithm for these ensembles, especially in light of its moderate complexity",
        "prob": 0.6416666666666667
    }, {
        "ID": 5129,
        "phrase": " the fractional gap to capacity (see the rightmost column) measures the ratio of the gap to capacity under optimal ml decoding and the achievable gap to capacity under (sub-optimal) iterative message-passing decoding",
        "prob": 0.8500000000000001
    }, {
        "ID": 5129,
        "phrase": " the fractional gap to capacity (see the rightmost column) measures the ratio of the gap to capacity under optimal ml decoding and the achievable gap to capacity under (sub-optimal) iterative message-passing decoding",
        "prob": 0.8500000000000001
    }, {
        "ID": 5129,
        "phrase": " for ensembles of punctured ldpc codes, the calculation of bounds on their thresholds under ml decoding and their exact thresholds under iterative decoding (based on density evolution analysis) is of interest in the sense that it enables to assess the degradation in the asymptotic performance which is attributed to the sub-optimality of iterative decoding (as compared to ml decoding), and also to assess the inherent loss in the asymptotic performance which is attributed to the structure of these ensembles, even if ml decoding could be applied to decode ldpc codes",
        "prob": 0.5403846153846155
    }, {
        "ID": 5210,
        "phrase": " the ml estimator after k = 10 iterations has the lowest nmse at -6 db, but fig",
        "prob": 0.3727272727272727
    }, {
        "ID": 5288,
        "phrase": " thus, it is conceivable that the ml performance can be achieved with decoding algorithms having complexity close to that of iterative decoding",
        "prob": 0.6066666666666667
    }, {
        "ID": 5289,
        "phrase": " thus, it is conceivable that the ml performance can be achieved with decoding algorithms having complexity close to that of iterative decoding",
        "prob": 0.5399999999999999
    }, {
        "ID": 5290,
        "phrase": " note that, although the ml performance does not translate directly to the iterative decoding performance of the codes, the value of this result is twofold",
        "prob": 0.41764705882352937
    }, {
        "ID": 5290,
        "phrase": " first, there are improved iterative decoding algorithms that approach closely the ml performance  [11, 12] ",
        "prob": 0.3153846153846154
    }, {
        "ID": 5290,
        "phrase": " thus, it is conceivable that the ml performance can be achieved with decoding algorithms having complexity close to that of iterative decoding",
        "prob": 0.6066666666666667
    }, {
        "ID": 5334,
        "phrase": " bounds on the ml error probability as important as it is to compare our algorithms with other algorithms, it is even more important to compare it with the ultimate performance limits, which is that of the soft decision ml decoder",
        "prob": 0.41363636363636364
    }, {
        "ID": 5334,
        "phrase": " comparing its performance with soft decision ml decoding of the rs code, we see that abp-asd has a near ml performance with a performance gain of about 3 db over hd-bm at a cer of 10 \u22126 ",
        "prob": 0.7958333333333334
    }, {
        "ID": 5334,
        "phrase": ") moreover, the averaged tsb on the ml codeword error probability is shown to confirm that it is a tight upper bound and that the abp-asd algorithm is near optimal for this code",
        "prob": 0.5045454545454545
    }, {
        "ID": 5334,
        "phrase": " near ml decoding for the same code is also achieved by the abp-asd algorithm with a finite cost of 10 3 as shown in fig",
        "prob": 0.63125
    }, {
        "ID": 5334,
        "phrase": " the performance of abp-asd with 20 inner iterations (n1) and 10 outer iterations (n2) is better than the ml upper bound and has more than 3 db coding gain over the bm algorithm at an cer of 10 \u22124 ",
        "prob": 0.6238095238095238
    }, {
        "ID": 5334,
        "phrase": " moreover, the performance of the abp-asd decoder is within 1 db of the averaged ml tsb",
        "prob": 0.65
    }, {
        "ID": 5334,
        "phrase": "  7 , ml soft-decision decoding offers about 4 db coding gain over the hard decision gs algorithm and about 2",
        "prob": 0.25625
    }, {
        "ID": 5334,
        "phrase": " it remains an open problem to find polynomialtime decoding algorithms with near ml performance",
        "prob": 0.22142857142857145
    }, {
        "ID": 5379,
        "phrase": " the complexity of this method is much less than that in the soft ml decoder",
        "prob": 0.2818181818181818
    }, {
        "ID": 5379,
        "phrase": " the ml decoding performance is also denoted by a curved line with circles",
        "prob": 0.3727272727272727
    }, {
        "ID": 5380,
        "phrase": " the sdp soft decoder is derived as an efficient solution of the max-approximated soft ml decoder",
        "prob": 0.33999999999999997
    }, {
        "ID": 5380,
        "phrase": " the complexity of this method is much less than that in the soft ml decoder",
        "prob": 0.2818181818181818
    }, {
        "ID": 5380,
        "phrase": " the ml decoding performance is also denoted by a curved line with circles",
        "prob": 0.3727272727272727
    }, {
        "ID": 5380,
        "phrase": " this curve is close to ml performance",
        "prob": 0.3875
    }, {
        "ID": 5404,
        "phrase": " we are interested in these vectors, especially those with small pseudo-weight, because they are relevant in quantifying the spectrum gap, which in turn quantifies the performance difference between lp and ml decoding",
        "prob": 0.2904761904761905
    }, {
        "ID": 5728,
        "phrase": " this bound holds for optimal ml decoding and is therefore valid under any sub-optimal decoding algorithm",
        "prob": 0.6066666666666667
    }, {
        "ID": 5728,
        "phrase": " the bound also gives an indication of the loss of punctured codes even under ml decoding due to the structure of the codes (as compared to random coding)",
        "prob": 0.4263157894736842
    }, {
        "ID": 5728,
        "phrase": " the fractional gap to capacity (see the rightmost column) measures the ratio of the gap to capacity under optimal ml decoding and the achievable gap to capacity under (sub-optimal) iterative message-passing decoding",
        "prob": 0.8115384615384615
    }, {
        "ID": 5728,
        "phrase": " the study of this tradeoff is done via information-theoretic bounds which also enable to get an indication on the sub-optimality of message-passing iterative decoding algorithms (as compared to optimal ml decoding)",
        "prob": 0.524
    }, {
        "ID": 5729,
        "phrase": " this bound refers to ml decoding (and hence, to any sub-optimal decoding algorithm)",
        "prob": 0.7
    }, {
        "ID": 5729,
        "phrase": " if the asymptotic bit error probability of this sequence vanishes under ml decoding (or any sub-optimal decoding algorithm) as r \u2192 \u221e, then in probability 1 w",
        "prob": 0.41764705882352937
    }, {
        "ID": 5729,
        "phrase": " on one hand, table  1  provides a quantitative assessment of the loss in the asymptotic performance which is attributed to the suboptimality of iterative decoding (as compared to optimal ml decoding), and on the other hand, they provide an assessment of the inherent loss in performance which is attributed to the structure of the ensembles, even if optimal ml decoding could be applied to decode these codes",
        "prob": 0.4351351351351352
    }, {
        "ID": 5729,
        "phrase": "6 db; however, under ml decoding, the gap to capacity is always greater than  1  3 of the corresponding gap to capacity under this iterative decoding algorithm; therefore, the results in table  1  regarding the thresholds under ml decoding further emphasize the efficiency of the sumproduct decoding algorithm for these ensembles, especially in light of its moderate complexity",
        "prob": 0.5457142857142857
    }, {
        "ID": 5729,
        "phrase": "2 (which provides a lower bound on e b n 0 under ml decoding), and thresholds under iterative message-passing decoding",
        "prob": 0.43571428571428567
    }, {
        "ID": 5729,
        "phrase": " the fractional gap to capacity (see the rightmost column) measures the ratio of the gap to capacity under optimal ml decoding and the achievable gap to capacity under (sub-optimal) iterative message-passing decoding",
        "prob": 0.8500000000000001
    }, {
        "ID": 5729,
        "phrase": " it is exemplified numerically that for various good ensembles of ip-ldpc codes, the asymptotic loss in performance due to the code structure is still non-negligible as compared to the corresponding loss due to the sub-optimality of iterative decoding (as compared to optimal ml decoding)",
        "prob": 0.5484848484848486
    }, {
        "ID": 5903,
        "phrase": " \u2022 the ml analytical bounds provide very useful information also for iterative decoding performance",
        "prob": 0.3923076923076923
    }, {
        "ID": 5903,
        "phrase": " in fact, the penalty paid by iterative decoding with respect to ideal ml decoding is very limited, as shown in the figure (feedback coefficients for weighting the extrinsic information and improve iterative decoding has been employed, as explained in  [10] )",
        "prob": 0.31153846153846154
    }, {
        "ID": 5903,
        "phrase": " this enables us to study the ml performance of product codes at both low and high snrs by applying the poltyrev bound",
        "prob": 0.41764705882352937
    }, {
        "ID": 5908,
        "phrase": " we also prove some properties for the lp relaxation of ml decoding which can be useful for performance analysis of lp and/or iterative decoding algorithms",
        "prob": 0.33888888888888885
    }, {
        "ID": 5934,
        "phrase": " thus the lp decoding performance is strictly worser than the ml decoding performance for snr \u2192 \u221e",
        "prob": 0.5785714285714285
    }, {
        "ID": 5935,
        "phrase": " thus the lp decoding performance is strictly worse than the ml decoding performance for snr \u2192 \u221e",
        "prob": 0.5785714285714285
    }, {
        "ID": 5969,
        "phrase": " m ai (0 4 k ) will accept if and only if 0 4 k / \u2208 l ai ",
        "prob": 0.22000000000000003
    }, {
        "ID": 6175,
        "phrase": " the performance of the ml algorithm that exhaustively searches all possible valid codewords and picks the one with the ml is plotted as reference",
        "prob": 0.25625
    }, {
        "ID": 6175,
        "phrase": "5 db away from the ml performance in low snr region",
        "prob": 0.4636363636363636
    }, {
        "ID": 6176,
        "phrase": " the ml algorithm searches all possible valid codewords then selects the one that maximizes the likelihood; ml's optimal performance serves as benchmark",
        "prob": 0.22777777777777775
    }, {
        "ID": 6176,
        "phrase": "5db performance loss is observed relative to ml at low snr",
        "prob": 0.5083333333333333
    }, {
        "ID": 6176,
        "phrase": " as snr increases, the loss is gradually reduced and the algorithm using simplified initialization matches the ml performance asymptotically",
        "prob": 0.3
    }, {
        "ID": 6177,
        "phrase": "5db performance loss is observed relative to ml at low snr",
        "prob": 0.425
    }, {
        "ID": 6190,
        "phrase": " although ml decoding is often impractical, knowing bounds on the block error rate of an ml decoder can help in assessing the performance of sub-optimal but practical decoding algorithms",
        "prob": 0.42083333333333334
    }, {
        "ID": 6190,
        "phrase": " we note that by applying simple performance bounding techniques it can be shown that the larger the gap is, the closer is the lp decoding performance (and potentially also the iterative decoding performance  [3, 4] ) to the ml decoding performance as the snr goes to infinity",
        "prob": 0.48518518518518516
    }, {
        "ID": 6190,
        "phrase": " 5  in the light of the ml decoder as formulated in (2), these algorithms can be seen as variations of the simplex method (cf",
        "prob": 0.22142857142857142
    }, {
        "ID": 6340,
        "phrase": "4 db for 64qam cr 5/6 and channel b; also, comparisons with ml confirm the optimality of lord with l t = 2",
        "prob": 0.3923076923076923
    }, {
        "ID": 6340,
        "phrase": " the small performance degradation of lord has to be attributed to the log-map llr computation used for ml as opposed to the max-log used for lord",
        "prob": 0.355
    }, {
        "ID": 6340,
        "phrase": " results confirm that lord is suboptimal if more than two transmit antennas are used, but the gap over ml is contained within 2 db for cr 1/2, and is only 1",
        "prob": 0.2833333333333333
    }, {
        "ID": 6340,
        "phrase": " also, lord shows > 3 db of snr gain over mmse-sic with channel d, while this gain increases to > 9 db if channel b also show that for short block length codes like the gcs, a hard-output ml decoder like sd is not sufficient to make them attractive for next generation wireless systems; this would still be true even if optional front-end to accelerate the decoder convergence were used, as proposed in  [18] ",
        "prob": 0.21041666666666667
    }, {
        "ID": 6340,
        "phrase": " this paper proposes a new class of lattice detectors that combines some of the principles of both list and lattice decoding, thus resulting in an efficient parallelizable implementation and near optimal soft-ouput ml performance",
        "prob": 0.31153846153846154
    }, {
        "ID": 6658,
        "phrase": " now, to filter each sub-block, it plugs the ml estimator in \u03b8 \u03b4 k k obtained from the entire observation of noisy signal up to the previous sub-block",
        "prob": 0.22777777777777775
    }, {
        "ID": 6829,
        "phrase": " it is well known that the lp decoding is asymptotically optimal, in the sense that the ratio of the probabilities of decoding errors of lp decoding and ml decoding approaches to 1 as the snr leads to infinity, if and only if d p (h) = d and b p (h) = a d ",
        "prob": 0.3521739130434783
    }, {
        "ID": 6969,
        "phrase": " (b) performance bounds for the bit error probability under ml decoding versus computer simulation results of iterative log-map decoding (with 10 iterations)",
        "prob": 0.45499999999999996
    }, {
        "ID": 6969,
        "phrase": " \n log\u2212map decoder (10 iterations) (b) performance bounds under ml decoding versus simulation results of iterative log-map decoding",
        "prob": 0.5611111111111111
    }, {
        "ID": 6970,
        "phrase": " due to the hard-decision ml decoding of the (127, 99, 29) rs code, its decoder can correct up to t = \u230a d min \u22121 2 \u230b = 14 erroneous symbols",
        "prob": 0.47333333333333333
    }, {
        "ID": 7249,
        "phrase": " the particular case where l = 1 clearly provides a lower bound on the performance under optimal ml decoding",
        "prob": 0.2928571428571428
    }, {
        "ID": 7250,
        "phrase": " the particular case where l = 1 clearly provides a lower bound on the performance under optimal ml decoding",
        "prob": 0.43571428571428567
    }, {
        "ID": 7311,
        "phrase": " the achievable rate is obtained via a random generated coding scheme that utilizes feedback, along with a ml decoder",
        "prob": 0.24117647058823527
    }, {
        "ID": 7337,
        "phrase": " in the second case we have a low complexity near ml decoding algorithm readily available in the form of the message passing algorithm",
        "prob": 0.39444444444444443
    }, {
        "ID": 7408,
        "phrase": " hence we have s \u2704 ai \u03bbx",
        "prob": 0.22000000000000003
    }, {
        "ID": 7409,
        "phrase": " hence we have s \u2704 ai \u03bbx",
        "prob": 0.22000000000000003
    }, {
        "ID": 7663,
        "phrase": " this demonstrated the promise of ldpc codes independently of their decoding algorithms (since ml decoding is the optimal decoding algorithm in terms of minimizing error probability)",
        "prob": 0.24285714285714283
    }, {
        "ID": 7736,
        "phrase": " however, since an erroneous decision of the inner ml decoder may affect a complete column of the matrix r, it occurs to be more expedient to apply the collaborative decoding strategy described in section iii to decode all rows of the irs code simultaneously",
        "prob": 0.37
    }, {
        "ID": 7737,
        "phrase": " however, since an erroneous decision of the inner ml decoder may affect a complete column of the matrix r, it occurs to be more expedient to apply the collaborative decoding strategy described in section iii to decode all rows of the irs code simultaneously",
        "prob": 0.37
    }, {
        "ID": 8041,
        "phrase": " also note that the averaged performance of the ml decoder over the rs ensemble is very close to the capacity of the bec, which shows that rs codes are good codes",
        "prob": 0.4263157894736842
    }, {
        "ID": 8042,
        "phrase": " it is known in the literature (see  [12]  [15]  [16] ) that p list \u226b p ml for many practical high rate long rs codes",
        "prob": 0.19375
    }, {
        "ID": 8042,
        "phrase": " also note that the averaged performance of the ml decoder over the rs ensemble is very close to the capacity of the bec, which shows that rs codes are good codes",
        "prob": 0.4263157894736842
    }, {
        "ID": 8462,
        "phrase": " convergence considerations the upper bound on the bep for ml soft decoding provides an accurate estimate of the suboptimal iterative decoder performance at high e b /n 0 values, for an increasing number of iterations  [12] ",
        "prob": 0.37916666666666665
    }, {
        "ID": 8462,
        "phrase": "  4  we see that the performance of both parent rate-1/3 pcccs coincides with the corresponding upper bounds for ml decoding, at high e b /n 0 values",
        "prob": 0.3
    }, {
        "ID": 8464,
        "phrase": " moreover its performance is only slightly inferior compared to the 1-group ml decodable dstc from field extensions  [6] ,  [7] ,  [8] ",
        "prob": 0.33999999999999997
    }, {
        "ID": 8465,
        "phrase": " however the above code retains the same low ml decoding complexity because z i z t i = i 8 , i = 1, ",
        "prob": 0.2818181818181818
    }, {
        "ID": 8490,
        "phrase": " passing though d ml = 20 without any visible anomaly",
        "prob": 0.31
    }, {
        "ID": 8687,
        "phrase": " it is well known that ml decoding for general binary linear codes is np-hard  [2] , which motivates the study of sub-optimal but practical algorithms for decoding",
        "prob": 0.29047619047619044
    }, {
        "ID": 8707,
        "phrase": " even though bp and lp decodings are suboptimal with respect to ml at all snrs, the difference in fer is only order one in the water-fall regime of small snrs",
        "prob": 0.6714285714285714
    }, {
        "ID": 8708,
        "phrase": " even though bp and lp decodings are suboptimal with respect to ml at all snrs, the difference in fer is only order one in the water-fall regime of small snrs",
        "prob": 0.719047619047619
    }, {
        "ID": 8907,
        "phrase": " although the exact ml algorithms in this paper are not practical by themselves, they may provide new insight into improvements of suboptimal message passing algorithm in this regime",
        "prob": 0.355
    }, {
        "ID": 8907,
        "phrase": " we now give an achievable region of r ml (p), for 0 < p < 1/2",
        "prob": 0.2625
    }, {
        "ID": 9449,
        "phrase": " t h e r e m ai ni n g 5 0 code-bi t s a r e u se db y t h e p re a m b l e , s d , e d , a n d f s elds",
        "prob": 0.3875
    }]
}]